[
  {
    "type": "document",
    "slug": "backlog/_folder",
    "title": "backlog/_folder",
    "category": "General",
    "url": "/docs/backlog/_folder",
    "chunks": [
      {
        "id": "backlog/_folder-chunk-0",
        "text": "Development Backlog\nThis section contains documentation for features that have been approved for development but not yet scheduled for a specific release. These features are prioritized and will be assigned to future versions.\nGuidelines\nFeatures approved for development\nAwaiting scheduling to specific version\nPrioritized based on roadmap\nWill be moved to version folders when scheduled",
        "startIndex": 0,
        "preview": "Development Backlog\nThis section contains documentation for features that have been approved for development but not yet scheduled for a specific rele..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "declined/_folder",
    "title": "declined/_folder",
    "category": "General",
    "url": "/docs/declined/_folder",
    "chunks": [
      {
        "id": "declined/_folder-chunk-0",
        "text": "Declined Proposals\nThis section contains documentation for features and proposals that have been evaluated and declined. These are archived for historical reference and decision context.\nGuidelines\nFeatures evaluated and declined\nArchived for reference only\nHidden from main navigation\nAccessible via direct URL only",
        "startIndex": 0,
        "preview": "Declined Proposals\nThis section contains documentation for features and proposals that have been evaluated and declined. These are archived for histor..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "drafts/_folder",
    "title": "drafts/_folder",
    "category": "General",
    "url": "/docs/drafts/_folder",
    "chunks": [
      {
        "id": "drafts/_folder-chunk-0",
        "text": "Draft Documentation\nThis section contains documentation that is currently being written and developed. Content here may be incomplete, contain placeholder text, or be subject to significant changes.\nGuidelines\nContent is work-in-progress\nMay contain incomplete sections\nSubject to review and revision\nNot suitable for production reference",
        "startIndex": 0,
        "preview": "Draft Documentation\nThis section contains documentation that is currently being written and developed. Content here may be incomplete, contain placeho..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "drafts/test-error-display",
    "title": "Test Error Display",
    "category": "Test",
    "url": "/docs/drafts/test-error-display",
    "chunks": [
      {
        "id": "drafts/test-error-display-chunk-0",
        "text": "Test Error Display\nThis is a test page to verify that our front-matter error display is working.\nCode with Front-Matter (Should be fine)\n`csharp{\ntitle: \"Good Example\"\ndescription: \"This has proper front-matter\"\nframework: \"NET8\"\ncategory: \"Test\"\ndifficulty: \"BEGINNER\"\ntags: [\"Test\"]\n}\npublic class GoodExample {\n    public string Message { get; set; } = \"I have front-matter!\";\n}\n`\nCode WITHOUT Front-Matter (Should show error)\n`csharp\npublic class BadExample {\n    public string Message { get; set; } = \"I need front-matter!\";\n}\n`\nAnother Bad Example\n`javascript\nfunction badFunction() {\n    console.log(\"This JS code also needs front-matter!\");\n}\n`\nNon-Code Block (Should be fine)\n`text\nThis is just text, no error needed.\n`",
        "startIndex": 0,
        "preview": "Test Error Display\nThis is a test page to verify that our front-matter error display is working.\nCode with Front-Matter (Should be fine)\n`csharp{\ntitl..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "future/README",
    "title": "Future Versions Roadmap",
    "category": "Roadmap",
    "url": "/docs/future/README",
    "chunks": [
      {
        "id": "future/README-chunk-0",
        "text": "Future Versions Roadmap\nOverview\nThese versions represent the long-term vision for Whizbang, building on the solid foundation established in v0 1 0-v0 5 0 Each future version focuses on a specific theme while maintaining backward compatibility Version Timeline\nv0 6 0 - Production Hardening\nTheme: Enterprise-ready features  \nTarget: Q3 2025\nKey Features:\nOpenTelemetry Integration: Full observability\nSecurity: Encryption, authorization, audit logging\nCompliance: GDPR, data retention, PII handling\nAdvanced Policies: Caching, rate limiting, authorization\nMonitoring Dashboard: Real-time metrics and health\nv0 7 0 - Performance & Scale\nTheme: High-performance optimizations  \nTarget: Q4 2025\nKey Features:\nZero Allocation: Memory-efficient operations\nAOT Support: Full trimming compatibility\nSIMD Operations: Vectorized processing\nPartitioning: Event stream partitioning\nLoad Balancing: Smart work distribution\nv0 8 0 - Cloud Native\nTheme: Cloud-native capabilities  \nTarget: Q1 2026\nKey Features:\nKubernetes Operator: Auto-scaling, management\nServerless Adapters: Lambda, Azure Functions\nCloud Storage: S3, Azure Blob integration\nService Mesh: Istio/Linkerd integration\nMulti-Region: Cross-region replication\nv0 9 0 - Innovation\nTheme: Advanced and experimental features  \nTarget: Q2 2026\nKey Features:\nEffect System: Track and control side effects\nPure Function Verification: Compile-time purity\nAI Integration: Intelligent routing and optimization\nTime Travel Debugging: Production replay\nVisual Programming: Node-based workflow editor\nFeature Deep Dives\nProduction Hardening (v0 6 0)\nObservability\n`csharp\n[Trace]\n[Metric(\"order processing time\")]\n[Log(Level Debug)]\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    // Automatic instrumentation via attributes\n}\n`\nSecurity\n`csharp\n[Authorize(Policy = \"OrderAdmin\")]\n[Audit(Level = AuditLevel Full)]\n[EncryptPII]\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    // Security policies applied automatically\n}\n`\nPerformance & Scale (v0 7",
        "startIndex": 0,
        "preview": "Future Versions Roadmap\nOverview\nThese versions represent the long-term vision for Whizbang, building on the solid foundation established in v0 1 0-v0..."
      },
      {
        "id": "future/README-chunk-1",
        "text": "0) Observability `csharp [Trace] [Metric(\"order processing time\")] [Log(Level Debug)] public class OrderReceptor : IReceptor<CreateOrder> { // Automatic instrumentation via attributes } ` Security `csharp [Authorize(Policy = \"OrderAdmin\")] [Audit(Level = AuditLevel Full)] [EncryptPII] public class OrderReceptor : IReceptor<CreateOrder> { // Security policies applied automatically } ` Performance & Scale (v0 7 0)\nZero Allocation\n`csharp\n// All operations use object pooling and spans\npublic readonly struct OrderCommand {\n    public ReadOnlySpan<byte> CustomerId { get; }\n    public ReadOnlySpan<OrderItem> Items { get; }\n}\n`\nAOT Support\n`csharp\n// Full trimming and native AOT compilation\n[JsonSerializable(typeof(OrderCreated))]\n[WhizbangAot]\npublic partial class OrderContext : JsonSerializerContext { }\n`\nCloud Native (v0 8 0)\nKubernetes Operator\n`yaml\napiVersion: whizbang io/v1\nkind: WhizbangDeployment\nmetadata:\n  name: order-service\nspec:\n  replicas:\n    min: 2\n    max: 10\n  autoscaling:\n    metric: eventLag\n    target: 1000\n`\nServerless\n`csharp\n[Lambda]\npublic class OrderFunction : WhizbangFunction<CreateOrder, OrderCreated> {\n    // Automatically deployed as Lambda function\n}\n`\nInnovation (v0 9 0)\nEffect System\n`csharp\n[Pure]  // Verified at compile time\npublic Effect<OrderCreated> CreateOrder(CreateOrder cmd) {\n    return Effect Validate(cmd) Map(c => new OrderCreated(c Id))",
        "startIndex": 2009,
        "preview": "0) Observability `csharp [Trace] [Metric(\"order processing time\")] [Log(Level Debug)] public class OrderReceptor : IReceptor<CreateOrder> { // Automat..."
      },
      {
        "id": "future/README-chunk-2",
        "text": "autoscaling: metric: eventLag target: 1000 ` Serverless `csharp [Lambda] public class OrderFunction : WhizbangFunction<CreateOrder, OrderCreated> { // Automatically deployed as Lambda function } ` Innovation (v0 9 0) Effect System `csharp [Pure] // Verified at compile time public Effect<OrderCreated> CreateOrder(CreateOrder cmd) { return Effect Validate(cmd) Map(c => new OrderCreated(c Id)) Tap(e => Log(e));  // Effects tracked\n}\n`\nAI Integration\n`csharp\n[AIOptimized]\npublic class SmartDispatcher : IDispatcher {\n    // Uses ML to predict best routing path\n    // Learns from historical performance data\n    // Automatically optimizes over time\n}\n`\nResearch Areas\nPerformance Research\nHardware acceleration (GPU/FPGA)\nCustom memory allocators\nLock-free data structures\nio_uring integration\nDistributed Systems Research\nConsensus algorithms (Raft/Paxos)\nCRDTs for conflict resolution\nByzantine fault tolerance\nQuantum-resistant cryptography\nLanguage Research\nLinear types for resource management\nDependent types for correctness\nEffect handlers\nAlgebraic effects\nAI/ML Research\nPredictive scaling\nAnomaly detection\nAutomated optimization\nNatural language queries\nCommunity Involvement\nThese future versions will be shaped by community feedback:\nRFC Process\nEach major feature will have an RFC (Request for Comments):\nProposal published\nCommunity discussion (30 days)\nRevision based on feedback\nFinal decision\nImplementation\nExperimental Flags\nFeatures can be tried early via experimental flags:\n`csharp\nservices AddWhizbang(options => {\n    options EnableExperimental(Features EffectSystem);\n    options EnableExperimental(Features AIRouting);\n});\n`\nBeta Program\nEarly access to future versions:\nBeta releases 3 months before GA\nDedicated support channel\nInfluence final design\nRecognition in release notes\nSuccess Metrics\nAdoption Goals\nv0 6 0: 100+ production deployments\nv0 7 0: 1M+ messages/second achieved\nv0 8 0: 50+ Kubernetes deployments\nv0 9 0: Industry innovation award\nTechnical Goals\nZero security vulnerabilities\n99 999% uptime achieved\n< 1ms p99 latency maintained\n100% backward compatibility\nMigration Strategy\nEach version maintains compatibility:\n`csharp\n// v0 6 0 code still works in v0 9 0\nservices AddWhizbang() UsePostgreSQL()",
        "startIndex": 3021,
        "preview": "autoscaling: metric: eventLag target: 1000 ` Serverless `csharp [Lambda] public class OrderFunction : WhizbangFunction<CreateOrder, OrderCreated> { //..."
      },
      {
        "id": "future/README-chunk-3",
        "text": "v0 8 0: 50+ Kubernetes deployments v0 9 0: Industry innovation award Technical Goals Zero security vulnerabilities 99 999% uptime achieved < 1ms p99 latency maintained 100% backward compatibility Migration Strategy Each version maintains compatibility: `csharp // v0 6 0 code still works in v0 9 0 services AddWhizbang() UsePostgreSQL() UseKafka();\n`\nNew features are additive:\n`csharp\n// v0 9 0 with new features\nservices AddWhizbang() UsePostgreSQL() UseKafka() UseEffects()  // New in v0 9 0 UseAI();      // New in v0 9 0\n`\nGet Involved\nHelp shape the future of Whizbang:\nJoin discussions: https://github com/whizbang/whizbang/discussions\nPropose features: https://github com/whizbang/whizbang/rfcs\nContribute code: https://github com/whizbang/whizbang\nShare feedback: feedback@whizbang dev\nSummary\nThe future of Whizbang is:\nProduction Ready (v0 6 0)\nBlazing Fast (v0 7 0)\nCloud Native (v0 8 0)\nInnovative (v0 9 0)\nAll while maintaining our core principles:\nZero reflection\nProgressive enhancement\nExceptional developer experience\nComprehensive testing\nPerformance by default",
        "startIndex": 4888,
        "preview": "v0 8 0: 50+ Kubernetes deployments v0 9 0: Industry innovation award Technical Goals Zero security vulnerabilities 99 999% uptime achieved < 1ms p99 l..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/_folder",
    "title": "proposals/_folder",
    "category": "General",
    "url": "/docs/proposals/_folder",
    "chunks": [
      {
        "id": "proposals/_folder-chunk-0",
        "text": "Proposed Features\nThis section contains documentation for features that have been proposed but not yet approved for development. These represent ideas and concepts being evaluated for future releases.\nGuidelines\nFeatures under consideration\nNot yet approved for development\nSubject to approval process\nMay be modified or rejected",
        "startIndex": 0,
        "preview": "Proposed Features\nThis section contains documentation for features that have been proposed but not yet approved for development. These represent ideas..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/advanced-features",
    "title": "Advanced Features",
    "category": "Architecture & Design",
    "url": "/docs/proposals/advanced-features",
    "chunks": [
      {
        "id": "proposals/advanced-features-chunk-0",
        "text": "Advanced Features\nWhizbang includes advanced features for enterprise scenarios, including cross-aggregate transactions, performance monitoring, Kubernetes operators, and debugging tools Cross-Aggregate Transactions\nUnit of Work Pattern\nCoordinate transactions across multiple aggregates while maintaining consistency:\n`csharp{title=\"Unit of Work Configuration\" description=\"Unit of work pattern configuration for cross-aggregate transactions\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Unit-of-Work\", \"Cross-Aggregate-Transactions\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options UseUnitOfWork(uow => {\n        uow IsolationLevel = IsolationLevel ReadCommitted;\n        uow Timeout = TimeSpan FromSeconds(30);\n        uow EnableDistributedTransactions = true;\n    });\n});\n`csharp{title=\"Multi-Aggregate Command Handler\" description=\"Command handler using unit of work for coordinated multi-aggregate operations\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Unit-of-Work\", \"Command-Handlers\"] framework=\"NET8\"}\n// Usage in handlers\npublic class PlaceOrderHandler : ICommandHandler<PlaceOrder> {\n    private readonly IUnitOfWork _unitOfWork;\n    private readonly IRepository<Order> _orderRepository;\n    private readonly IRepository<Customer> _customerRepository;\n    private readonly IRepository<Product> _productRepository;\n    public async Task<OrderPlaced> Handle(PlaceOrder command) {\n        return await _unitOfWork ExecuteAsync(async () => {\n            // Load multiple aggregates\n            var customer = await _customerRepository Load(command CustomerId);\n            var products = await _productRepository LoadMany(command ProductIds);\n            // Validate business rules across aggregates\n            if ( customer CanPlaceOrder(command Total)) {\n                throw new DomainException(\"Customer credit limit exceeded\");\n            }\n            foreach (var product in products) {\n                if ( product IsAvailable(command GetQuantity(product Id))) {\n                    throw new DomainException($\"Product {product Id} not available\");\n                }\n            }\n            // Create new aggregate\n            var order = new Order(command CustomerId, command Items);\n            // Update existing aggregates\n            customer ReserveCreditLimit(command Total);\n            foreach (var product in products) {\n                product ReserveStock(command GetQuantity(product Id));\n            }\n            // Save all changes in single transaction\n            await _orderRepository Save(order);\n            await _customerRepository Save(customer);\n            await _productRepository SaveMany(products);\n            return new OrderPlaced(order Id, command CustomerId, DateTimeOffset UtcNow);\n        });\n    }\n}\n`\nDistributed Transactions with Saga Fallback\n`csharp{title=\"Distributed Transactions with Saga Fallback\" description=\"Distributed transactions with saga fallback for complex operations\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Cross-Aggregate-Transactions\", \"Saga-Fallback\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options CrossAggregateTransactions(transactions => {\n        transactions DefaultStrategy = TransactionStrategy UnitOfWork;\n        transactions FallbackToSaga = true;\n        transactions",
        "startIndex": 0,
        "preview": "Advanced Features\nWhizbang includes advanced features for enterprise scenarios, including cross-aggregate transactions, performance monitoring, Kubern..."
      },
      {
        "id": "proposals/advanced-features-chunk-1",
        "text": "CustomerId, DateTimeOffset UtcNow); }); } } ` Distributed Transactions with Saga Fallback `csharp{title=\"Distributed Transactions with Saga Fallback\" description=\"Distributed transactions with saga fallback for complex operations\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Cross-Aggregate-Transactions\", \"Saga-Fallback\"] framework=\"NET8\"} services AddWhizbang(options => { options CrossAggregateTransactions(transactions => { transactions DefaultStrategy = TransactionStrategy UnitOfWork; transactions FallbackToSaga = true; transactions SagaTimeoutMs = 30000;\n        // Configure per-operation\n        transactions ForOperation<PlaceOrder>(op => {\n            op Strategy = TransactionStrategy UnitOfWork;\n            op MaxAggregatesInTransaction = 5;\n        });\n        transactions ForOperation<ComplexOrderWorkflow>(op => {\n            op Strategy = TransactionStrategy Saga; // Force saga for complex operations\n        });\n    });\n});\n`\nTransaction Boundaries\n`csharp{title=\"Transaction Boundary Implementation\" description=\"Transaction boundary implementation with automatic rollback on failure\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Transaction-Boundaries\", \"Error-Handling\"] framework=\"NET8\"}\npublic class TransactionBoundary : ITransactionBoundary {\n    public async Task<T> ExecuteInTransaction<T>(Func<Task<T>> operation) {\n        using var scope = new TransactionScope(TransactionScopeAsyncFlowOption Enabled);\n        try {\n            var result = await operation();\n            scope Complete();\n            return result;\n        } catch (Exception ex) {\n            // Transaction automatically rolled back\n            _logger LogError(ex, \"Transaction failed and was rolled back\");\n            throw;\n        }\n    }\n}\n`\nPerformance Budgets & Monitoring\n> üìã Detailed Coverage: For comprehensive performance budgets, observability, and monitoring details, see Observability & Metrics\nPerformance Budget Overview\nPerformance budgets provide automatic tracking and alerting for handler performance:\n`csharp{title=\"Performance Budget Attributes\" description=\"Performance budget attributes for automatic tracking and alerting\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Performance-Budgets\", \"Monitoring\"] framework=\"NET8\"}\n[PerformanceBudget(MaxLatencyMs = 100)]\npublic class PlaceOrderHandler : ICommandHandler<PlaceOrder> {\n    // Automatic budget tracking and violation alerts\n}\n`\nOpenTelemetry Integration\n> üìã Detailed Coverage: For complete OpenTelemetry setup, metrics, and distributed tracing, see Observability & Metrics\n`csharp{title=\"OpenTelemetry Integration Configuration\" description=\"OpenTelemetry integration configuration for comprehensive observability\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"OpenTelemetry\", \"Observability\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Observability(observability => {\n        observability UseOpenTelemetry(otel => {\n            otel TraceAllCommands = true;\n            otel TraceAllEvents = true;\n            otel TraceProjections = true;\n            otel TraceSagas = true;\n            // Custom metrics\n            otel",
        "startIndex": 3401,
        "preview": "CustomerId, DateTimeOffset UtcNow); }); } } ` Distributed Transactions with Saga Fallback `csharp{title=\"Distributed Transactions with Saga Fallback\" ..."
      },
      {
        "id": "proposals/advanced-features-chunk-2",
        "text": "& Metrics `csharp{title=\"OpenTelemetry Integration Configuration\" description=\"OpenTelemetry integration configuration for comprehensive observability\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"OpenTelemetry\", \"Observability\"] framework=\"NET8\"} services AddWhizbang(options => { options Observability(observability => { observability UseOpenTelemetry(otel => { otel TraceAllCommands = true; otel TraceAllEvents = true; otel TraceProjections = true; otel TraceSagas = true; // Custom metrics otel EmitCustomMetrics = true;\n            otel MetricsPrefix = \"whizbang\";\n            // Performance budget violations\n            otel TracePerformanceBudgetViolations = true;\n            otel AlertOnBudgetViolation = true;\n        });\n    });\n});\n`csharp{title=\"Custom Performance Tracking Handler\" description=\"Custom performance tracking handler with detailed metrics collection\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Performance-Tracking\", \"Custom-Metrics\"] framework=\"NET8\"}\n// Custom performance tracking\npublic class PerformanceTrackingHandler<T> : ICommandHandler<T> where T : ICommand {\n    private readonly ICommandHandler<T> _innerHandler;\n    private readonly IMetrics _metrics;\n    public async Task Handle(T command) {\n        using var activity = Activity StartActivity($\"Command {typeof(T) Name}\");\n        using var timer = _metrics StartTimer($\"command {typeof(T) Name ToLower()} duration\");\n        var startMemory = GC GetTotalMemory(false);\n        var stopwatch = Stopwatch StartNew();\n        try {\n            await _innerHandler Handle(command);\n            // Record success metrics\n            _metrics IncrementCounter($\"command {typeof(T) Name ToLower()} success\");\n        } catch (Exception ex) {\n            // Record failure metrics\n            _metrics IncrementCounter($\"command {typeof(T) Name ToLower()} failure\", \n                new[] { (\"error_type\", ex GetType() Name) });\n            activity SetStatus(ActivityStatusCode Error, ex Message);\n            throw;\n        } finally {\n            stopwatch Stop();\n            var endMemory = GC GetTotalMemory(false);\n            // Record performance metrics\n            activity SetTag(\"duration_ms\", stopwatch ElapsedMilliseconds);\n            activity SetTag(\"memory_allocated_bytes\", endMemory - startMemory);\n            _metrics RecordValue($\"command {typeof(T) Name ToLower()} memory\", endMemory - startMemory);\n        }\n    }\n}\n`\nKubernetes Operator Features\n> üìã Detailed Coverage: For production deployment patterns, health checks, and operational best practices, see Deployment & Operations\nAuto-Scaling Projection Workers\n`yaml\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Advanced-Features, Kubernetes-Operator, Auto-Scaling]\ndescription: Kubernetes custom resource for auto-scaling projection workers\n---\napiVersion: whizbang",
        "startIndex": 6106,
        "preview": "& Metrics `csharp{title=\"OpenTelemetry Integration Configuration\" description=\"OpenTelemetry integration configuration for comprehensive observability..."
      },
      {
        "id": "proposals/advanced-features-chunk-3",
        "text": "} } } ` Kubernetes Operator Features > üìã Detailed Coverage: For production deployment patterns, health checks, and operational best practices, see Deployment & Operations Auto-Scaling Projection Workers `yaml --- category: Design difficulty: ADVANCED tags: [Design, Advanced-Features, Kubernetes-Operator, Auto-Scaling] description: Kubernetes custom resource for auto-scaling projection workers --- apiVersion: whizbang io/v1\nkind: ProjectionWorker\nmetadata:\n  name: order-summary-projection\nspec:\n  projectionName: order-summary\n  scaling:\n    strategy: lag-based\n    minReplicas: 2\n    maxReplicas: 10\n    lagThresholdSeconds: 30\n    scaleUpCooldownMs: 300000   5 minutes\n    scaleDownCooldownMs: 600000 10 minutes\n  partitioning:\n    enabled: true\n    partitionCount: 8\n    partitionBy: \"streamId\"\n  resources:\n    requests:\n      cpu: 100m\n      memory: 128Mi\n    limits:\n      cpu: 500m\n      memory: 512Mi\n`\nPartition-Aware Pod Placement\n`yaml\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Advanced-Features, Kubernetes-Operator, Partition-Aware-Placement]\ndescription: Partition-aware pod placement for distributed projection processing\n---\napiVersion: whizbang io/v1\nkind: PartitionedProjection\nmetadata:\n  name: analytics-projection\nspec:\n  projectionName: analytics\n  partitions:\nid: 0\n    nodeSelector:\n      whizbang io/partition-group: \"group-a\"\nid: 1\n    nodeSelector:\n      whizbang io/partition-group: \"group-a\"\nid: 2\n    nodeSelector:\n      whizbang io/partition-group: \"group-b\"\nid: 3\n    nodeSelector:\n      whizbang io/partition-group: \"group-b\"\n  antiAffinity:\n    enabled: true\n    topologyKey: kubernetes io/hostname\n`\nBlue/Green Projection Deployments\n`yaml\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Advanced-Features, Kubernetes-Operator, Blue-Green-Deployment]\ndescription: Blue/green projection deployments with validation and automatic switchover\n---\napiVersion: whizbang io/v1\nkind: ProjectionDeployment\nmetadata:\n  name: order-summary-deployment\nspec:\n  strategy: blue-green\n  validation:\n    samplingRate: 0 1          Validate 10% of data\n    accuracyThreshold: 0 99    99% accuracy required\n    validationTimeoutMinutes: 30\n  switchover:\n    automatic: false           Manual approval required\n    trafficSplitDurationMinutes: 10\n  cleanup:\n    retainBlueVersionHours: 24 Keep blue for 24 hours after switchover\n`\nAutomatic Backfilling\n`yaml\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Advanced-Features, Kubernetes-Operator, Automatic-Backfilling]\ndescription: Kubernetes job for automatic projection backfilling with resource management\n---\napiVersion: whizbang",
        "startIndex": 8490,
        "preview": "} } } ` Kubernetes Operator Features > üìã Detailed Coverage: For production deployment patterns, health checks, and operational best practices, see De..."
      },
      {
        "id": "proposals/advanced-features-chunk-4",
        "text": "99% accuracy required validationTimeoutMinutes: 30 switchover: automatic: false Manual approval required trafficSplitDurationMinutes: 10 cleanup: retainBlueVersionHours: 24 Keep blue for 24 hours after switchover ` Automatic Backfilling `yaml --- category: Design difficulty: ADVANCED tags: [Design, Advanced-Features, Kubernetes-Operator, Automatic-Backfilling] description: Kubernetes job for automatic projection backfilling with resource management --- apiVersion: whizbang io/v1\nkind: BackfillJob\nmetadata:\n  name: customer-analytics-backfill\nspec:\n  projectionName: customer-analytics\n  trigger: deployment-update  Trigger on projection deployment\n  source:\n    fromDate: \"2024-01-01T00:00:00Z\"\n    toDate: null              Current time\n  execution:\n    batchSize: 1000\n    parallelism: 4\n    maxRetries: 3\n  resources:\n    requests:\n      cpu: 200m\n      memory: 256Mi\n    limits:\n      cpu: 1000m\n      memory: 1Gi\n`\nKubernetes Operator Implementation\n`csharp{title=\"Kubernetes Operator Implementation\" description=\"Kubernetes operator implementation for Whizbang resource management\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Kubernetes-Operator\", \"Implementation\"] framework=\"NET8\"}\npublic class WhizbangOperator : IHostedService {\n    private readonly IKubernetesClient _kubernetesClient;\n    private readonly IProjectionManager _projectionManager;\n    public async Task StartAsync(CancellationToken cancellationToken) {\n        // Watch for ProjectionWorker resources\n        await _kubernetesClient WatchAsync<ProjectionWorker>(\n            onEvent: async (eventType, resource) => {\n                switch (eventType) {\n                    case WatchEventType Added:\n                        await CreateProjectionWorker(resource);\n                        break;\n                    case WatchEventType Modified:\n                        await UpdateProjectionWorker(resource);\n                        break;\n                    case WatchEventType Deleted:\n                        await DeleteProjectionWorker(resource);\n                        break;\n                }\n            },\n            cancellationToken: cancellationToken\n        );\n        // Monitor projection lag and auto-scale\n        _ = Task Run(() => MonitorAndScale(cancellationToken), cancellationToken);\n    }\n    private async Task MonitorAndScale(CancellationToken cancellationToken) {\n        while ( cancellationToken IsCancellationRequested) {\n            var projections = await _projectionManager GetAllProjections();\n            foreach (var projection in projections) {\n                var lag = await _projectionManager GetLag(projection Name);\n                var workerSpec = await GetProjectionWorkerSpec(projection Name);\n                if (ShouldScaleUp(lag, workerSpec)) {\n                    await ScaleUpProjectionWorker(projection Name, workerSpec);\n                } else if (ShouldScaleDown(lag, workerSpec)) {\n                    await ScaleDownProjectionWorker(projection Name, workerSpec);\n                }\n            }\n            await Task Delay(TimeSpan",
        "startIndex": 10706,
        "preview": "99% accuracy required validationTimeoutMinutes: 30 switchover: automatic: false Manual approval required trafficSplitDurationMinutes: 10 cleanup: reta..."
      },
      {
        "id": "proposals/advanced-features-chunk-5",
        "text": "IsCancellationRequested) { var projections = await _projectionManager GetAllProjections(); foreach (var projection in projections) { var lag = await _projectionManager GetLag(projection Name); var workerSpec = await GetProjectionWorkerSpec(projection Name); if (ShouldScaleUp(lag, workerSpec)) { await ScaleUpProjectionWorker(projection Name, workerSpec); } else if (ShouldScaleDown(lag, workerSpec)) { await ScaleDownProjectionWorker(projection Name, workerSpec); } } await Task Delay(TimeSpan FromSeconds(30), cancellationToken);\n        }\n    }\n}\n`\nDebugging and Development Tools\n> üìã Detailed Coverage: For comprehensive testing framework, development tools, CLI, and IDE integration, see Testing & Development Tools and Source Generation & IDE Integration\nOpenTelemetry Journey Visualization\nCapture and visualize message journeys for debugging:\n`csharp{title=\"Message Journey Debugging Configuration\" description=\"Debugging configuration for message journey capture and visualization\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Debugging\", \"Message-Journeys\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Debugging(debugging => {\n        debugging CaptureMessageJourneys = true;\n        debugging JourneyRetentionDays = 7;\n        debugging EnableBreakpoints = true;\n        debugging EnableStateInspection = true;\n    });\n});\n`csharp{title=\"Message Journey Tracking Interceptor\" description=\"Message journey tracking interceptor for debugging and visualization\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Debugging\", \"Journey-Tracking\"] framework=\"NET8\"}\n// Message journey tracking\npublic class MessageJourneyTracker : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message, \n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        var journeyId = context CorrelationId Guid NewGuid() ToString();\n        using var activity = Activity StartActivity(\"MessageJourney\");\n        activity SetTag(\"journey_id\", journeyId);\n        activity SetTag(\"message_type\", typeof(TRequest) Name);\n        activity SetTag(\"handler_type\", context HandlerType Name);\n        var stopwatch = Stopwatch StartNew();\n        try {\n            var response = await next(message, context);\n            await _journeyStore RecordStep(new JourneyStep {\n                JourneyId = journeyId,\n                MessageType = typeof(TRequest) Name,\n                HandlerType = context HandlerType Name,\n                Duration = stopwatch Elapsed,\n                Status = \"Success\",\n                Input = JsonSerializer Serialize(message),\n                Output = JsonSerializer Serialize(response)\n            });\n            return response;\n        } catch (Exception ex) {\n            await _journeyStore RecordStep(new JourneyStep {\n                JourneyId = journeyId,\n                MessageType = typeof(TRequest) Name,\n                HandlerType = context HandlerType Name,\n                Duration = stopwatch Elapsed,\n                Status = \"Failed\",\n                Error = ex ToString(),\n                Input = JsonSerializer",
        "startIndex": 13335,
        "preview": "IsCancellationRequested) { var projections = await _projectionManager GetAllProjections(); foreach (var projection in projections) { var lag = await _..."
      },
      {
        "id": "proposals/advanced-features-chunk-6",
        "text": "Status = \"Success\", Input = JsonSerializer Serialize(message), Output = JsonSerializer Serialize(response) }); return response; } catch (Exception ex) { await _journeyStore RecordStep(new JourneyStep { JourneyId = journeyId, MessageType = typeof(TRequest) Name, HandlerType = context HandlerType Name, Duration = stopwatch Elapsed, Status = \"Failed\", Error = ex ToString(), Input = JsonSerializer Serialize(message)\n            });\n            throw;\n        }\n    }\n}\n`\nReplay and Simulation\nReplay events for debugging and testing:\n`csharp{title=\"Event Replay Service Interface\" description=\"Event replay service interface for debugging and testing scenarios\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Event-Replay\", \"Simulation\"] framework=\"NET8\"}\npublic interface IEventReplayService {\n    Task<ReplayResult> ReplayEvents(ReplayOptions options);\n    Task<SimulationResult> SimulateEventStream(SimulationOptions options);\n    IAsyncEnumerable<ReplayProgress> GetReplayProgress(string replayId);\n}\npublic class EventReplayService : IEventReplayService {\n    public async Task<ReplayResult> ReplayEvents(ReplayOptions options) {\n        var replayId = Guid NewGuid() ToString();\n        // Create isolated replay environment\n        var replayContext = await CreateReplayContext(replayId, options);\n        try {\n            // Load events to replay\n            var events = await LoadEventsForReplay(options);\n            // Replay events in isolated context\n            foreach (var @event in events) {\n                if (options Breakpoints Contains(@event EventNumber) == true) {\n                    await PauseForBreakpoint(@event, replayContext);\n                }\n                await replayContext ProcessEvent(@event);\n                if (options StepByStep) {\n                    await WaitForContinueSignal(replayId);\n                }\n            }\n            return new ReplayResult {\n                ReplayId = replayId,\n                EventsProcessed = events Count(),\n                Status = ReplayStatus Completed\n            };\n        } catch (Exception ex) {\n            return new ReplayResult {\n                ReplayId = replayId,\n                Status = ReplayStatus Failed,\n                Error = ex Message\n            };\n        }\n    }\n}\n`csharp{title=\"Event Replay Usage Example\" description=\"Event replay configuration options and usage example\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Event-Replay\", \"Usage-Example\"] framework=\"NET8\"}\n// Usage\nvar replayOptions = new ReplayOptions {\n    FromEventNumber = 1000,\n    ToEventNumber = 2000,\n    StreamFilter = streamId => streamId StartsWith(\"Order-\"),\n    StepByStep = true,\n    Breakpoints = new[] { 1500, 1750 },\n    IsolatedEnvironment = true\n};\nvar result = await _replayService",
        "startIndex": 16074,
        "preview": "Status = \"Success\", Input = JsonSerializer Serialize(message), Output = JsonSerializer Serialize(response) }); return response; } catch (Exception ex)..."
      },
      {
        "id": "proposals/advanced-features-chunk-7",
        "text": "options and usage example\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Event-Replay\", \"Usage-Example\"] framework=\"NET8\"} // Usage var replayOptions = new ReplayOptions { FromEventNumber = 1000, ToEventNumber = 2000, StreamFilter = streamId => streamId StartsWith(\"Order-\"), StepByStep = true, Breakpoints = new[] { 1500, 1750 }, IsolatedEnvironment = true }; var result = await _replayService ReplayEvents(replayOptions);\n`\nState Inspection and Breakpoints\nInspect aggregate and projection state during debugging:\n`csharp{title=\"State Inspection Interface\" description=\"State inspection interface for debugging aggregate and projection state\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"State-Inspection\", \"Debugging\"] framework=\"NET8\"}\npublic interface IStateInspector {\n    Task<AggregateState> InspectAggregate(string streamId, long version = null);\n    Task<ProjectionState> InspectProjection(string projectionName, string documentId);\n    Task<IEnumerable<EventInfo>> GetEventHistory(string streamId);\n    Task SetBreakpoint(string streamId, long eventVersion);\n    Task<BreakpointContext> WaitForBreakpoint(string breakpointId);\n}\n`csharp{title=\"Breakpoint Handler Implementation\" description=\"Breakpoint handler implementation for debugging event processing\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Breakpoints\", \"Implementation\"] framework=\"NET8\"}\n// Breakpoint implementation\npublic class BreakpointHandler : IEventHandler<object> {\n    public async Task Handle(object @event, EventContext context) {\n        var breakpoints = await _breakpointStore GetActiveBreakpoints(context StreamId);\n        foreach (var breakpoint in breakpoints) {\n            if (ShouldTriggerBreakpoint(breakpoint, @event, context)) {\n                var breakpointContext = new BreakpointContext {\n                    BreakpointId = breakpoint Id,\n                    Event = @event,\n                    StreamId = context StreamId,\n                    EventVersion = context EventVersion,\n                    AggregateState = await LoadAggregateState(context StreamId, context EventVersion - 1),\n                    Timestamp = DateTimeOffset UtcNow\n                };\n                await _breakpointStore RecordBreakpointHit(breakpointContext);\n                await _notificationService NotifyBreakpointHit(breakpointContext);\n                // Pause execution until developer continues\n                await WaitForContinueSignal(breakpoint Id);\n            }\n        }\n    }\n}\n`\nW3C Trace Context Integration\nDistributed tracing with W3C standards:\n`csharp{title=\"W3C Trace Context Configuration\" description=\"W3C trace context integration configuration for distributed tracing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Distributed-Tracing\", \"W3C-Standards\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DistributedTracing(tracing => {\n        tracing UseW3CTraceContext = true;\n        tracing PropagateTraceHeaders = true;\n        tracing SampleRate = 0 1; // Sample 10% of traces\n        tracing CustomTags Add(\"service name\", \"whizbang-orders\");\n        tracing CustomTags Add(\"service version\", \"1 2",
        "startIndex": 18526,
        "preview": "options and usage example\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Event-Replay\", \"Usage-Example\"] framework..."
      },
      {
        "id": "proposals/advanced-features-chunk-8",
        "text": "context integration configuration for distributed tracing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Distributed-Tracing\", \"W3C-Standards\"] framework=\"NET8\"} services AddWhizbang(options => { options DistributedTracing(tracing => { tracing UseW3CTraceContext = true; tracing PropagateTraceHeaders = true; tracing SampleRate = 0 1; // Sample 10% of traces tracing CustomTags Add(\"service name\", \"whizbang-orders\"); tracing CustomTags Add(\"service version\", \"1 2 3\");\n    });\n});\n`csharp{title=\"W3C Trace Context Propagation\" description=\"Automatic W3C trace context propagation implementation\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Trace-Propagation\", \"W3C-Implementation\"] framework=\"NET8\"}\n// Automatic trace propagation\npublic class TraceContextPropagator : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        // Extract W3C trace context from headers\n        var traceParent = context Headers GetValueOrDefault(\"traceparent\");\n        var traceState = context Headers GetValueOrDefault(\"tracestate\");\n        if (traceParent = null) {\n            // Parse W3C trace context\n            var traceContext = W3CTraceContext Parse(traceParent, traceState);\n            // Create child span\n            using var activity = Activity StartActivity($\"Handle{typeof(TRequest) Name}\");\n            activity SetParentId(traceContext TraceId, traceContext SpanId);\n            activity SetTag(\"whizbang correlation_id\", context CorrelationId);\n            activity SetTag(\"whizbang message_type\", typeof(TRequest) Name);\n            // Add custom trace state\n            var newTraceState = $\"whizbang=correlation-id:{context CorrelationId}\";\n            if ( string IsNullOrEmpty(traceState)) {\n                newTraceState = $\"{traceState},{newTraceState}\";\n            }\n            activity SetTag(\"tracestate\", newTraceState);\n            return await next(message, context);\n        }\n        // No parent trace - start new one\n        using var rootActivity = Activity StartActivity($\"Handle{typeof(TRequest) Name}\");\n        return await next(message, context);\n    }\n}\n`\nConfiguration Examples\nComprehensive Advanced Features Setup\n`csharp{title=\"Comprehensive Advanced Features Setup\" description=\"Comprehensive advanced features configuration combining all options\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Advanced-Features\", \"Comprehensive-Setup\", \"Configuration\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    // Cross-aggregate transactions\n    options UseUnitOfWork(uow => {\n        uow IsolationLevel = IsolationLevel ReadCommitted;\n        uow EnableDistributedTransactions = true;\n        uow FallbackToSaga = true;\n    });\n    // Performance budgets\n    options PerformanceBudgets(budgets => {\n        budgets DefaultCommandLatency = TimeSpan FromMilliseconds(500);\n        budgets AlertOnViolation = true;\n        budgets UseOpenTelemetryMetrics = true;\n    });\n    // Observability\n    options Observability(observability => {\n        observability UseOpenTelemetry();\n        observability CaptureMessageJourneys = true;\n        observability EnableDistributedTracing = true;\n    });\n    // Debugging\n    options Debugging(debugging => {\n        debugging",
        "startIndex": 21366,
        "preview": "context integration configuration for distributed tracing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Advanced-Features\", \"Distribut..."
      },
      {
        "id": "proposals/advanced-features-chunk-9",
        "text": "uow FallbackToSaga = true; }); // Performance budgets options PerformanceBudgets(budgets => { budgets DefaultCommandLatency = TimeSpan FromMilliseconds(500); budgets AlertOnViolation = true; budgets UseOpenTelemetryMetrics = true; }); // Observability options Observability(observability => { observability UseOpenTelemetry(); observability CaptureMessageJourneys = true; observability EnableDistributedTracing = true; }); // Debugging options Debugging(debugging => { debugging EnableBreakpoints = true;\n        debugging EnableStateInspection = true;\n        debugging EnableEventReplay = true;\n        debugging RetainDebugDataDays = 7;\n    });\n    // Kubernetes integration\n    options Kubernetes(k8s => {\n        k8s EnableOperator = true;\n        k8s AutoScaleProjections = true;\n        k8s EnableBlueGreenDeployments = true;\n        k8s",
        "startIndex": 14146,
        "preview": "uow FallbackToSaga = true; }); // Performance budgets options PerformanceBudgets(budgets => { budgets DefaultCommandLatency = TimeSpan FromMillisecond..."
      },
      {
        "id": "proposals/advanced-features-chunk-10",
        "text": "= true; observability EnableDistributedTracing = true; }); // Debugging options Debugging(debugging => { debugging EnableBreakpoints = true; debugging EnableStateInspection = true; debugging EnableEventReplay = true; debugging RetainDebugDataDays = 7; }); // Kubernetes integration options Kubernetes(k8s => { k8s EnableOperator = true; k8s AutoScaleProjections = true; k8s EnableBlueGreenDeployments = true; k8s PartitionAwarePlacement = true;\n    });\n});\n`\nBest Practices\nTransaction Guidelines\nKeep transactions short - Minimize time holding locks\nLimit aggregate count - Avoid transactions with too many aggregates\nUse sagas for long processes - Don't use transactions for workflows\nTest rollback scenarios - Ensure proper cleanup on failure\nMonitor transaction metrics - Track duration and failure rates\nPerformance Monitoring\nSet realistic budgets - Base on actual performance requirements\nMonitor trends - Track performance over time\nAlert on violations - Set up proper alerting for budget violations\nUse sampling - Don't trace every request in production\nCorrelate with business metrics - Connect performance to business impact\nDebugging Best Practices\nUse structured logging - Include correlation IDs and context\nLimit debug data retention - Don't keep debug data indefinitely\nSecure sensitive data - Mask PII in debug traces\nTest replay scenarios - Ensure replay works correctly\nDocument debugging procedures - Help team members debug effectively\n---\nRelated Documentation\nCore Architecture\nEvent Store & Projections - Core storage architecture\nConcurrency Control - Managing concurrent updates\nPolicy Engine - Universal configuration scoping mechanism\nFlags & Tags System - Cross-service context propagation\nImplementation & Operations\nSource Generation & IDE Integration - Development tooling and navigation\nTesting & Development Tools - Testing framework and CLI tools  \nObservability & Metrics - Production monitoring and observability\nDeployment & Operations - Operational patterns and best practices",
        "startIndex": 24675,
        "preview": "= true; observability EnableDistributedTracing = true; }); // Debugging options Debugging(debugging => { debugging EnableBreakpoints = true; debugging..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/concurrency-control",
    "title": "Concurrency Control",
    "category": "Architecture & Design",
    "url": "/docs/proposals/concurrency-control",
    "chunks": [
      {
        "id": "proposals/concurrency-control-chunk-0",
        "text": "Concurrency Control\nWhizbang provides flexible concurrency control mechanisms to handle concurrent updates to aggregates, supporting multiple strategies that developers can choose globally or per-operation Concurrency Strategies\nA Expected Version (Default)\nStandard event sourcing pattern - explicitly specify the expected version:\n`csharp{title=\"Expected Version Concurrency Control\" description=\"Standard event sourcing pattern with explicit version checking\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"expected-version\", \"optimistic-locking\", \"event-sourcing\"] framework=\"NET8\"}\n// Load aggregate at version 5\nvar order = await repository Load<Order>(orderId);\n// Make changes\norder AddItem(new OrderItem(\"Product\", 10 00m));\n// Save with expected version - will fail if current version = 5\nawait repository Save(order, expectedVersion: 5);\n`\nBenefits:\n‚úÖ Detects all conflicts\n‚úÖ Standard event sourcing pattern\n‚úÖ Explicit and predictable\nDrawbacks:\n‚ùå Requires version tracking\n‚ùå Manual conflict resolution\nB Timestamp-Based (Last-Modified)\nHTTP-style semantics using timestamps:\n`csharp{title=\"Timestamp-Based Concurrency Control\" description=\"HTTP-style semantics using last-modified timestamps\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"timestamp-based\", \"http-semantics\", \"last-modified\"] framework=\"NET8\"}\nvar order = await repository Load<Order>(orderId);\nvar lastModified = order LastModified;\n// Make changes\norder AddItem(new OrderItem(\"Product\", 10 00m));\n// Save with timestamp check\nawait repository Save(order, ifNotModifiedSince: lastModified);\n`\nBenefits:\n‚úÖ Familiar HTTP semantics\n‚úÖ No version number tracking\nDrawbacks:\n‚ùå Clock skew potential\n‚ùå Less precise than versions\nC Automatic Retry with Conflict Resolution\nSmart retry with configurable resolution strategies:\n`csharp{title=\"Automatic Retry with Conflict Resolution\" description=\"Smart retry with configurable resolution strategies via policies\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"automatic-retry\", \"conflict-resolution\", \"policy-engine\"] framework=\"NET8\"}\n// Configure automatic retry via policies\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Default strategy for all operations\n        policies When(ctx => true) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config SetRetryAttempts(3)) And(config => config SetRetryDelay(TimeSpan FromMilliseconds(100)));\n        // Custom conflict resolution for Order aggregates\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver((current, attempted) => {\n                    // Custom merge logic\n                    var merged = current Copy();\n                    merged",
        "startIndex": 0,
        "preview": "Concurrency Control\nWhizbang provides flexible concurrency control mechanisms to handle concurrent updates to aggregates, supporting multiple strategi..."
      },
      {
        "id": "proposals/concurrency-control-chunk-1",
        "text": "for all operations policies When(ctx => true) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config SetRetryAttempts(3)) And(config => config SetRetryDelay(TimeSpan FromMilliseconds(100))); // Custom conflict resolution for Order aggregates policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver((current, attempted) => { // Custom merge logic var merged = current Copy(); merged MergeChanges(attempted);\n                    return merged;\n                }));\n    });\n});\n// Save with automatic retry\nawait repository Save(order); // Retries automatically on conflict\n`\nBenefits:\n‚úÖ Handles most conflicts automatically\n‚úÖ Better developer experience\n‚úÖ Configurable retry policies\nDrawbacks:\n‚ùå Complex to implement\n‚ùå Not all conflicts can be auto-resolved\nMarten-Inspired Extensions\nDrawing from Marten's concurrency features, Whizbang also supports:\nD Token-Based Concurrency\nUsing opaque tokens instead of version numbers:\n`csharp{title=\"Token-Based Concurrency Control\" description=\"Using opaque tokens instead of version numbers\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"token-based\", \"opaque-tokens\", \"marten-inspired\"] framework=\"NET8\"}\nvar (order, token) = await repository LoadWithToken<Order>(orderId);\n// Make changes\norder AddItem(new OrderItem(\"Product\", 10 00m));\n// Save with token\nawait repository Save(order, concurrencyToken: token);\n`\nE Revision-Based Tracking\nMarten-style revision tracking with metadata:\n`csharp{title=\"Revision-Based Tracking\" description=\"Marten-style revision tracking with automatic metadata\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"revision-based\", \"marten-style\", \"metadata\"] framework=\"NET8\"}\npublic class Order : Aggregate {\n    // Whizbang tracks revision automatically\n    public int Revision { get; internal set; }\n    public DateTime LastModified { get; internal set; }\n    public string LastModifiedBy { get; internal set; }\n}\nawait repository Save(order, expectedRevision: order Revision);\n`\nF Conditional Updates\nSQL-style conditional updates:\n`csharp{title=\"Conditional Updates\" description=\"SQL-style conditional updates with business logic conditions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"conditional-updates\", \"sql-style\", \"business-logic\"] framework=\"NET8\"}\nawait repository Save(order, condition: o => o Status == OrderStatus Pending);\n// Only saves if order is still pending\n`\nPolicy-Driven Configuration\n> üìã Universal Configuration: Whizbang uses the Policy Engine as the universal configuration scoping mechanism",
        "startIndex": 2873,
        "preview": "for all operations policies When(ctx => true) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config S..."
      },
      {
        "id": "proposals/concurrency-control-chunk-2",
        "text": "conditional updates with business logic conditions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"conditional-updates\", \"sql-style\", \"business-logic\"] framework=\"NET8\"} await repository Save(order, condition: o => o Status == OrderStatus Pending); // Only saves if order is still pending ` Policy-Driven Configuration > üìã Universal Configuration: Whizbang uses the Policy Engine as the universal configuration scoping mechanism All concurrency strategies, retry policies, and conflict resolution rules are configured through policies rather than direct configuration methods Basic Policy Configuration\nConfigure concurrency strategies using the Policy Engine - the universal configuration scoping mechanism:\n`csharp{title=\"Basic Policy Configuration\" description=\"Global concurrency strategy configuration using policy engine\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"policy-configuration\", \"global-strategy\", \"policy-engine\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Global default strategy\n        policies When(ctx => true) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetRetryAttempts(3)) And(config => config SetRetryDelay(TimeSpan FromMilliseconds(100)));\n    });\n});\n`\nAdvanced Policy Scenarios\nCombine multiple conditions for sophisticated concurrency control:\n`csharp{title=\"Advanced Policy Scenarios\" description=\"Sophisticated concurrency control with context-dependent strategies\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"advanced-policies\", \"context-dependent\", \"tenant-specific\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Orders get automatic retry with more attempts\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config SetRetryAttempts(5)); // Orders get more retries\n        // Shopping carts use timestamp-based for simplicity\n        policies When(ctx => ctx MatchesAggregate<ShoppingCart>()) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy TimestampBased));\n        // High-volume commands get automatic retry\n        policies When(ctx => ctx HasTag(\"high-volume\")) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config SetRetryAttempts(5));\n        // Load testing uses relaxed concurrency\n        policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy LastWriteWins));\n        // Environment-based strategies\n        policies When(ctx => ctx Environment == \"production\") Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetRetryAttempts(3));\n        policies When(ctx => ctx Environment == \"development\") Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy LastWriteWins)); // Relaxed for dev\n        // Tenant-specific strategies\n        policies When(ctx => ctx TenantId = null && ctx HasTag(\"enterprise-tenant\")) Then(config => config",
        "startIndex": 5051,
        "preview": "conditional updates with business logic conditions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"conditional-updates\", \"sql-style..."
      },
      {
        "id": "proposals/concurrency-control-chunk-3",
        "text": "Environment-based strategies policies When(ctx => ctx Environment == \"production\") Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetRetryAttempts(3)); policies When(ctx => ctx Environment == \"development\") Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy LastWriteWins)); // Relaxed for dev // Tenant-specific strategies policies When(ctx => ctx TenantId = null && ctx HasTag(\"enterprise-tenant\")) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetRetryAttempts(5)) And(config => config EnableStrictConflictResolution());\n    });\n});\n`\nRuntime Policy Evaluation\nPolicies are evaluated at runtime based on the current context:\n`csharp{title=\"Runtime Policy Evaluation\" description=\"Context-driven policy evaluation with automatic strategy selection\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"runtime-evaluation\", \"context-driven\", \"automatic-selection\"] framework=\"NET8\"}\n// Policy evaluation happens automatically during save operations\nawait repository Save(order, context => {\n    context WithTag(\"high-volume\");        // Triggers high-volume policy\n    context WithFlag(WhizbangFlags Production); // Triggers production policy\n});\n// Context determines which concurrency strategy is used\n// No need to manually specify strategy - policies handle it\n`\nManual Override (When Needed)\nOverride policies for exceptional cases:\n`csharp{title=\"Manual Override\" description=\"Explicit override of policy-driven concurrency for critical operations\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"manual-override\", \"policy-bypass\", \"critical-operations\"] framework=\"NET8\"}\n// Explicit override for critical operations\nawait repository Save(order, saveOptions => {\n    saveOptions OverrideConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion);\n    saveOptions SetExpectedVersion(5);\n    saveOptions BypassPolicies(); // Skip policy evaluation\n});\n`\nConflict Resolution Strategies\nBuilt-in Resolvers\n`csharp{title=\"Built-in Conflict Resolvers\" description=\"Common conflict resolution strategies for different scenarios\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"built-in-resolvers\", \"conflict-strategies\", \"merge-strategies\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Last-write-wins for Order aggregates\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver(ConflictResolvers LastWriteWins));\n        // First-write-wins for Customer aggregates (reject conflicting changes)\n        policies When(ctx => ctx MatchesAggregate<Customer>()) Then(config => config SetConflictResolver(ConflictResolvers FirstWriteWins));\n        // Additive merge for ShoppingCart (combine collections)\n        policies When(ctx => ctx MatchesAggregate<ShoppingCart>()) Then(config => config SetConflictResolver(ConflictResolvers",
        "startIndex": 2346,
        "preview": "Environment-based strategies policies When(ctx => ctx Environment == \"production\") Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy Ex..."
      },
      {
        "id": "proposals/concurrency-control-chunk-4",
        "text": "{ // Last-write-wins for Order aggregates policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver(ConflictResolvers LastWriteWins)); // First-write-wins for Customer aggregates (reject conflicting changes) policies When(ctx => ctx MatchesAggregate<Customer>()) Then(config => config SetConflictResolver(ConflictResolvers FirstWriteWins)); // Additive merge for ShoppingCart (combine collections) policies When(ctx => ctx MatchesAggregate<ShoppingCart>()) Then(config => config SetConflictResolver(ConflictResolvers AdditiveMerge));\n    });\n});\n`\nCustom Conflict Resolvers via Policies\nDefine custom conflict resolution logic through policies:\n`csharp{title=\"Custom Conflict Resolvers\" description=\"Domain-specific merge logic for different aggregate properties\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"custom-resolvers\", \"business-logic-merge\", \"domain-specific\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Custom resolver for Order aggregates\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver((current, attempted) => {\n                    var resolved = current Copy();\n                    // Merge line items additively\n                    foreach (var item in attempted Items) {\n                        if ( resolved Items Any(i => i ProductId == item ProductId)) {\n                            resolved AddItem(item);\n                        }\n                    }\n                    // Take latest shipping address\n                    if (attempted ShippingAddress = null) {\n                        resolved UpdateShippingAddress(attempted ShippingAddress);\n                    }\n                    return resolved;\n                }));\n    });\n});\n`\nAdvanced Conflict Resolution\nAccess full conflict context through policies:\n`csharp{title=\"Advanced Conflict Resolution\" description=\"Three-way merge using original version as merge base\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"three-way-merge\", \"advanced-resolution\", \"merge-base\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver((context) => {\n                    var current = context CurrentVersion;\n                    var attempted = context AttemptedVersion;\n                    var original = context",
        "startIndex": 10620,
        "preview": "{ // Last-write-wins for Order aggregates policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver(ConflictResolv..."
      },
      {
        "id": "proposals/concurrency-control-chunk-5",
        "text": "Conflict Resolution\" description=\"Three-way merge using original version as merge base\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"three-way-merge\", \"advanced-resolution\", \"merge-base\"] framework=\"NET8\"} services AddWhizbang(options => { options Policies(policies => { policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config SetConflictResolver((context) => { var current = context CurrentVersion; var attempted = context AttemptedVersion; var original = context OriginalVersion; // Version when load started\n                    // Three-way merge using original as base\n                    return ThreeWayMerge(original, current, attempted);\n                }));\n    });\n});\n});\n`\nImplementation Details\nConcurrency Exception Handling\n`csharp{title=\"Concurrency Exception Handling\" description=\"Detailed conflict information for debugging and error handling\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"exception-handling\", \"conflict-information\", \"debugging\"] framework=\"NET8\"}\npublic class ConcurrencyException : Exception {\n    public string StreamId { get; }\n    public int ExpectedVersion { get; }\n    public int ActualVersion { get; }\n    public Type AggregateType { get; }\n    public ConcurrencyException(string streamId, int expectedVersion, int actualVersion, Type aggregateType)\n        : base($\"Concurrency conflict in {aggregateType Name} stream {streamId} Expected version {expectedVersion}, but current version is {actualVersion}\") {\n        StreamId = streamId;\n        ExpectedVersion = expectedVersion;\n        ActualVersion = actualVersion;\n        AggregateType = aggregateType;\n    }\n}\n`\nRetry Logic\n`csharp{title=\"Retry Logic Configuration\" description=\"Exponential backoff and jitter for reducing contention\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"retry-logic\", \"exponential-backoff\", \"jitter\"] framework=\"NET8\"}\npublic class RetryPolicy {\n    public int MaxAttempts { get; set; } = 3;\n    public TimeSpan InitialDelay { get; set; } = TimeSpan FromMilliseconds(100);\n    public TimeSpan MaxDelay { get; set; } = TimeSpan FromSeconds(1);\n    public double BackoffMultiplier { get; set; } = 2 0;\n    public RetryJitter Jitter { get; set; } = RetryJitter",
        "startIndex": 12599,
        "preview": "Conflict Resolution\" description=\"Three-way merge using original version as merge base\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"..."
      },
      {
        "id": "proposals/concurrency-control-chunk-6",
        "text": "RetryPolicy { public int MaxAttempts { get; set; } = 3; public TimeSpan InitialDelay { get; set; } = TimeSpan FromMilliseconds(100); public TimeSpan MaxDelay { get; set; } = TimeSpan FromSeconds(1); public double BackoffMultiplier { get; set; } = 2 0; public RetryJitter Jitter { get; set; } = RetryJitter Random;\n}\n// Example retry sequence:\n// Attempt 1: 100ms + random(0-50ms)\n// Attempt 2: 200ms + random(0-100ms)  \n// Attempt 3: 400ms + random(0-200ms)\n`\nDriver Interface\n`csharp{title=\"Driver Interface\" description=\"Interface for implementing concurrency control strategies\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"concurrency\", \"driver-interface\", \"implementation\", \"strategies\"] framework=\"NET8\"}\npublic interface IConcurrencyDriver {\n    Task<T> Load<T>(string streamId, ConcurrencyOptions options) where T : Aggregate;\n    Task<(T Aggregate, ConcurrencyToken Token)> LoadWithToken<T>(string streamId) where T : Aggregate;\n    Task Save<T>(T aggregate, ConcurrencyCheck check) where T : Aggregate;\n    Task<SaveResult> TrySave<T>(T aggregate, ConcurrencyCheck check) where T : Aggregate;\n    Task<ConflictResolutionResult> ResolveConflict<T>(\n        T original, \n        T current, \n        T attempted, \n        ConflictResolver<T> resolver) where T : Aggregate;\n}\npublic class ConcurrencyCheck {\n    public ConcurrencyStrategy Strategy { get; set; }\n    public int ExpectedVersion { get; set; }\n    public DateTime IfNotModifiedSince { get; set; }\n    public ConcurrencyToken Token { get; set; }\n    public Expression<Func<object, bool>> Condition { get; set; }\n}\n`\nPerformance Considerations\nOptimizations\nVersion caching - Cache current versions to reduce round trips\nBatch operations - Group saves to reduce conflicts\nRead replicas - Load from read replicas to reduce load on primary\nConflict prediction - Use heuristics to predict likely conflicts\nMonitoring\n`csharp{title=\"Concurrency Monitoring\" description=\"Conflict logging and metrics for observability\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"concurrency\", \"monitoring\", \"metrics\", \"observability\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options UseOptimisticConcurrency(concurrency => {\n        concurrency OnConflict = (context) => {\n            // Log conflict for monitoring\n            logger LogWarning(\"Concurrency conflict in {StreamId}: {Conflict}\", \n                context StreamId, context ConflictDescription);\n            // Emit metrics\n            metrics IncrementCounter(\"whizbang concurrency conflicts\", \n                new[] { (\"aggregate_type\", context AggregateType Name) });\n        };\n        concurrency OnRetry = (context) => {\n            logger",
        "startIndex": 14361,
        "preview": "RetryPolicy { public int MaxAttempts { get; set; } = 3; public TimeSpan InitialDelay { get; set; } = TimeSpan FromMilliseconds(100); public TimeSpan M..."
      },
      {
        "id": "proposals/concurrency-control-chunk-7",
        "text": "AddWhizbang(options => { options UseOptimisticConcurrency(concurrency => { concurrency OnConflict = (context) => { // Log conflict for monitoring logger LogWarning(\"Concurrency conflict in {StreamId}: {Conflict}\", context StreamId, context ConflictDescription); // Emit metrics metrics IncrementCounter(\"whizbang concurrency conflicts\", new[] { (\"aggregate_type\", context AggregateType Name) }); }; concurrency OnRetry = (context) => { logger LogDebug(\"Retrying save for {StreamId}, attempt {Attempt}\", \n                context StreamId, context AttemptNumber);\n        };\n    });\n});\n`\nBest Practices\nStrategy Selection Guidelines\nExpected Version - Use for critical business operations requiring strict consistency\nTimestamp-Based - Use for user-facing operations where UX matters more than strict consistency\nAutomatic Retry - Use for high-contention scenarios with predictable merge strategies\nToken-Based - Use when integrating with external systems that provide tokens\nConditional - Use for operations that depend on specific business conditions\nConflict Resolution Guidelines\nKeep resolvers fast - Avoid heavy computation or I/O\nTest thoroughly - Ensure resolvers handle edge cases\nMake resolvers deterministic - Same inputs should produce same outputs\nLog conflicts - Track conflict patterns for optimization\nFallback to exceptions - Don't resolve conflicts you can't handle safely\n---\nRelated Documentation\nEvent Store & Projections - Storage architecture\nDomain Ownership - Command routing and ownership\nPerformance Optimization - Scaling strategies",
        "startIndex": 16741,
        "preview": "AddWhizbang(options => { options UseOptimisticConcurrency(concurrency => { concurrency OnConflict = (context) => { // Log conflict for monitoring logg..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/deployment-operations",
    "title": "Deployment & Operations",
    "category": "Architecture & Design",
    "url": "/docs/proposals/deployment-operations",
    "chunks": [
      {
        "id": "proposals/deployment-operations-chunk-0",
        "text": "Deployment & Operations\nWhizbang is designed as an embedded library that runs within developer services, providing comprehensive operational hooks for production deployment, monitoring, and lifecycle management Deployment Model\nEmbedded Library Architecture\nWhizbang runs embedded within your application, not as a separate service:\n`csharp{title=\"Embedded Library Setup\" description=\"Basic embedded library setup within ASP NET Core application\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"Design\", \"Deployment\", \"Embedded-Library\", \"ASP NET-Core\"] framework=\"NET8\"}\n// Your service with Whizbang embedded\npublic class Program {\n    public static void Main(string[] args) {\n        var builder = WebApplication CreateBuilder(args);\n        // Add your application services\n        builder Services AddControllers();\n        builder Services AddOrderService();\n        // Add Whizbang as embedded library\n        builder Services AddWhizbang(options => {\n            options UsePostgresEventStore(connectionString);\n            options UseKafkaMessageBroker(kafkaConfig);\n            options ConfigureDomains();\n        });\n        var app = builder Build();\n        // Configure your application pipeline\n        app MapControllers();\n        app MapWhizbangEndpoints(); // Optional: Expose Whizbang endpoints\n        app",
        "startIndex": 0,
        "preview": "Deployment & Operations\nWhizbang is designed as an embedded library that runs within developer services, providing comprehensive operational hooks for..."
      },
      {
        "id": "proposals/deployment-operations-chunk-1",
        "text": "CreateBuilder(args); // Add your application services builder Services AddControllers(); builder Services AddOrderService(); // Add Whizbang as embedded library builder Services AddWhizbang(options => { options UsePostgresEventStore(connectionString); options UseKafkaMessageBroker(kafkaConfig); options ConfigureDomains(); }); var app = builder Build(); // Configure your application pipeline app MapControllers(); app MapWhizbangEndpoints(); // Optional: Expose Whizbang endpoints app Run();\n    }\n}\n`\nService Architecture Patterns\nMultiple deployment patterns supported:\nMonolithic Deployment\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Kubernetes, Monolithic-Deployment]\ndescription: Kubernetes deployment configuration for monolithic service architecture\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecommerce-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ecommerce-service\n  template:\n    metadata:\n      labels:\n        app: ecommerce-service\n    spec:\n      containers:\nname: ecommerce-service\n        image: myapp/ecommerce-service:latest\n        ports:\ncontainerPort: 8080\n        env:\nname: WHIZBANG_EVENTSTORE_CONNECTION\n          valueFrom:\n            secretKeyRef:\n              name: database-secrets\n              key: connection-string\nname: WHIZBANG_MESSAGEBROKER_BOOTSTRAP_SERVERS\n          value: \"kafka:9092\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n`\nMicroservices Deployment\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Kubernetes, Microservices, Separation-of-Concerns]\ndescription: Kubernetes deployment for microservices with separated command and projection services\n---\nCommand Service\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-command-service\nspec:\n  replicas: 2\n  template:\n    spec:\n      containers:\nname: order-service\n        image: myapp/order-service:latest\n        env:\nname: WHIZBANG_DOMAIN\n          value: \"Orders\"\nname: WHIZBANG_PROJECTION_MODE\n          value: \"Disabled\" Command service doesn't run projections\n---\nProjection Worker Service  \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-projection-worker\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\nname: projection-worker\n        image: myapp/order-projection-worker:latest\n        env:\nname: WHIZBANG_DOMAIN\n          value: \"Orders\"\nname: WHIZBANG_COMMAND_MODE\n          value: \"Disabled\" Projection worker doesn't handle commands\nname: WHIZBANG_PROJECTIONS\n          value: \"OrderSummary,OrderHistory,OrderAnalytics\"\n`\nDomain-per-Service Deployment\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Kubernetes, Domain-per-Service]\ndescription: Domain-per-service deployment pattern with domain ownership configuration\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orders-service\nspec:\n  template:\n    spec:\n      containers:\nname: orders-service\n        image: myapp/orders-service:latest\n        env:\nname: WHIZBANG_OWNED_DOMAINS\n          value: \"Orders\"\n---\napiVersion: apps/v1  \nkind: Deployment\nmetadata:\n  name: inventory-service\nspec:\n  template:\n    spec:\n      containers:\nname: inventory-service\n        image: myapp/inventory-service:latest\n        env:\nname: WHIZBANG_OWNED_DOMAINS\n          value: \"Inventory\"\n`\nHealth Checks\nBuilt-in Health Check System\nComprehensive health monitoring ready for Kubernetes probes:\n`csharp{title=\"Health Check Configuration\" description=\"Comprehensive health check configuration for production readiness\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Health-Checks\", \"Monitoring\"] framework=\"NET8\"}\nservices",
        "startIndex": 1327,
        "preview": "CreateBuilder(args); // Add your application services builder Services AddControllers(); builder Services AddOrderService(); // Add Whizbang as embedd..."
      },
      {
        "id": "proposals/deployment-operations-chunk-2",
        "text": "kind: Deployment metadata: name: inventory-service spec: template: spec: containers: name: inventory-service image: myapp/inventory-service:latest env: name: WHIZBANG_OWNED_DOMAINS value: \"Inventory\" ` Health Checks Built-in Health Check System Comprehensive health monitoring ready for Kubernetes probes: `csharp{title=\"Health Check Configuration\" description=\"Comprehensive health check configuration for production readiness\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Health-Checks\", \"Monitoring\"] framework=\"NET8\"} services AddWhizbang(options => {\n    options HealthChecks(health => {\n        // Core infrastructure health\n        health CheckEventStoreConnection = true;\n        health CheckMessageBrokerConnection = true;\n        health CheckProjectionHealth = true;\n        // Operational thresholds\n        health ProjectionLagThreshold = TimeSpan FromMinutes(5);\n        health EventStoreLatencyThreshold = TimeSpan FromMilliseconds(100);\n        health MessageBrokerLatencyThreshold = TimeSpan FromMilliseconds(500);\n        // Custom health checks\n        health AddCheck<CustomBusinessLogicHealthCheck>();\n    });\n});\n// Register health check endpoints\napp MapHealthChecks(\"/health\", new HealthCheckOptions {\n    ResponseWriter = UIResponseWriter WriteHealthCheckUIResponse\n});\napp MapHealthChecks(\"/health/ready\", new HealthCheckOptions {\n    Predicate = check => check Tags Contains(\"ready\"),\n    ResponseWriter = UIResponseWriter WriteHealthCheckUIResponse\n});\napp MapHealthChecks(\"/health/live\", new HealthCheckOptions {\n    Predicate = check => check Tags Contains(\"live\")\n});\n`\nHealth Check Implementation\nDetailed health check implementation:\n`csharp{title=\"Health Check Implementation\" description=\"Detailed health check implementation for infrastructure components\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Health-Checks\", \"Implementation\"] framework=\"NET8\"}\npublic class WhizbangHealthCheck : IHealthCheck {\n    private readonly IEventStore _eventStore;\n    private readonly IMessageBroker _messageBroker;\n    private readonly IProjectionManager _projectionManager;\n    private readonly WhizbangHealthOptions _options;\n    public async Task<HealthCheckResult> CheckHealthAsync(HealthCheckContext context, CancellationToken cancellationToken = default) {\n        var checks = new List<(string name, bool healthy, string details)>();\n        // Event store connectivity\n        if (_options CheckEventStoreConnection) {\n            try {\n                await _eventStore HealthCheckAsync(cancellationToken);\n                checks Add((\"EventStore\", true, \"Connected\"));\n            } catch (Exception ex) {\n                checks Add((\"EventStore\", false, ex Message));\n            }\n        }\n        // Message broker connectivity\n        if (_options CheckMessageBrokerConnection) {\n            try {\n                await _messageBroker HealthCheckAsync(cancellationToken);\n                checks Add((\"MessageBroker\", true, \"Connected\"));\n            } catch (Exception ex) {\n                checks Add((\"MessageBroker\", false, ex Message));\n            }\n        }\n        // Projection health\n        if (_options CheckProjectionHealth) {\n            var projections = await _projectionManager GetAllProjectionsAsync(cancellationToken);\n            foreach (var projection in projections) {\n                var lag = await _projectionManager GetLagAsync(projection",
        "startIndex": 4791,
        "preview": "kind: Deployment metadata: name: inventory-service spec: template: spec: containers: name: inventory-service image: myapp/inventory-service:latest env..."
      },
      {
        "id": "proposals/deployment-operations-chunk-3",
        "text": "if (_options CheckMessageBrokerConnection) { try { await _messageBroker HealthCheckAsync(cancellationToken); checks Add((\"MessageBroker\", true, \"Connected\")); } catch (Exception ex) { checks Add((\"MessageBroker\", false, ex Message)); } } // Projection health if (_options CheckProjectionHealth) { var projections = await _projectionManager GetAllProjectionsAsync(cancellationToken); foreach (var projection in projections) { var lag = await _projectionManager GetLagAsync(projection Name, cancellationToken);\n                var healthy = lag <= _options ProjectionLagThreshold;\n                checks Add(($\"Projection:{projection Name}\", healthy, $\"Lag: {lag TotalSeconds}s\"));\n            }\n        }\n        // Determine overall health\n        var allHealthy = checks All(c => c healthy);\n        var status = allHealthy HealthStatus Healthy : HealthStatus Unhealthy;\n        var data = checks ToDictionary(c => c name, c => (object)new { \n            healthy = c healthy, \n            details = c details \n        });\n        return new HealthCheckResult(status, data: data);\n    }\n}\n`\nGraceful Shutdown NET Host Lifetime Integration\nProper integration with NET hosting lifetime for clean shutdown:\n`csharp{title=\"Graceful Shutdown Service\" description=\" NET hosted service integration with graceful shutdown support\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Graceful-Shutdown\", \"Hosting-Integration\"] framework=\"NET8\"}\npublic class WhizbangHostedService : IHostedService, IDisposable {\n    private readonly IWhizbangRuntime _runtime;\n    private readonly ILogger<WhizbangHostedService> _logger;\n    private readonly WhizbangOptions _options;\n    public async Task StartAsync(CancellationToken cancellationToken) {\n        _logger LogInformation(\"Starting Whizbang runtime\");\n        await _runtime StartAsync(cancellationToken);\n        _logger LogInformation(\"Whizbang runtime started\");\n    }\n    public async Task StopAsync(CancellationToken cancellationToken) {\n        _logger LogInformation(\"Stopping Whizbang runtime\");\n        try {\n            // Stop accepting new messages\n            await _runtime StopAcceptingMessagesAsync(cancellationToken);\n            _logger LogInformation(\"Stopped accepting new messages\");\n            // Drain in-flight messages with timeout\n            var drainTimeout = _options GracefulShutdownTimeout TimeSpan FromSeconds(30);\n            using var drainCts = CancellationTokenSource CreateLinkedTokenSource(cancellationToken);\n            drainCts CancelAfter(drainTimeout);\n            await _runtime DrainInFlightMessagesAsync(drainCts Token);\n            _logger LogInformation(\"Drained in-flight messages\");\n            // Stop projections\n            await _runtime StopProjectionsAsync(cancellationToken);\n            _logger LogInformation(\"Stopped projections\");\n            // Close connections\n            await _runtime CloseConnectionsAsync(cancellationToken);\n            _logger LogInformation(\"Closed connections\");\n        } catch (OperationCanceledException) {\n            _logger LogWarning(\"Graceful shutdown timed out, forcing shutdown\");\n        } catch (Exception ex) {\n            _logger LogError(ex, \"Error during graceful shutdown\");\n        }\n        _logger LogInformation(\"Whizbang runtime stopped\");\n    }\n    public void Dispose() {\n        _runtime",
        "startIndex": 7693,
        "preview": "if (_options CheckMessageBrokerConnection) { try { await _messageBroker HealthCheckAsync(cancellationToken); checks Add((\"MessageBroker\", true, \"Conne..."
      },
      {
        "id": "proposals/deployment-operations-chunk-4",
        "text": "Stop projections await _runtime StopProjectionsAsync(cancellationToken); _logger LogInformation(\"Stopped projections\"); // Close connections await _runtime CloseConnectionsAsync(cancellationToken); _logger LogInformation(\"Closed connections\"); } catch (OperationCanceledException) { _logger LogWarning(\"Graceful shutdown timed out, forcing shutdown\"); } catch (Exception ex) { _logger LogError(ex, \"Error during graceful shutdown\"); } _logger LogInformation(\"Whizbang runtime stopped\"); } public void Dispose() { _runtime Dispose();\n    }\n}\n`\nKubernetes Integration\nSIGTERM handling for Kubernetes graceful shutdown:\n`csharp{title=\"Kubernetes Graceful Shutdown\" description=\"Kubernetes SIGTERM handling with graceful shutdown and load balancer drain\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Deployment\", \"Graceful-Shutdown\", \"Kubernetes-Integration\"] framework=\"NET8\"}\npublic class GracefulShutdownService : BackgroundService {\n    private readonly IHostApplicationLifetime _applicationLifetime;\n    private readonly IWhizbangRuntime _runtime;\n    private readonly ILogger<GracefulShutdownService> _logger;\n    protected override async Task ExecuteAsync(CancellationToken stoppingToken) {\n        // Register for shutdown notification\n        _applicationLifetime ApplicationStopping Register(OnShutdown);\n        // Wait for shutdown\n        await Task Delay(Timeout Infinite, stoppingToken);\n    }\n    private void OnShutdown() {\n        _logger LogInformation(\"Received shutdown signal, initiating graceful shutdown\");\n        // Custom shutdown logic\n        Task Run(async () => {\n            try {\n                // Give projections time to finish current batch\n                await _runtime CompleteCurrentBatchAsync(TimeSpan FromSeconds(10));\n                // Signal readiness probe to fail (remove from load balancer)\n                _runtime MarkAsNotReady();\n                // Wait for load balancer to drain\n                await Task Delay(TimeSpan FromSeconds(5));\n                _logger LogInformation(\"Graceful shutdown preparation complete\");\n            } catch (Exception ex) {\n                _logger LogError(ex, \"Error during shutdown preparation\");\n            }\n        });\n    }\n}\n`\nConfiguration Management\nEnvironment-Specific Configuration\nFlexible configuration for different deployment environments:\n`json\n---\ncategory: Design\ndifficulty: BEGINNER\ntags: [Design, Deployment, Configuration, Environment-Management]\ndescription: Environment-specific configuration management with base and override files\n---\n// appsettings json (base configuration)\n{\n  \"Whizbang\": {\n    \"EventStore\": {\n      \"Driver\": \"Postgres\"\n    },\n    \"MessageBroker\": {\n      \"Driver\": \"Kafka\"\n    },\n    \"Projections\": {\n      \"DefaultStrategy\": \"Automatic\"\n    }\n  }\n}\n// appsettings Development json\n{\n  \"Whizbang\": {\n    \"EventStore\": {\n      \"ConnectionString\": \"Host=localhost;Database=whizbang_dev\",\n      \"EnableDetailedLogging\": true\n    },\n    \"MessageBroker\": {\n      \"BootstrapServers\": \"localhost:9092\",\n      \"EnableAutoCommit\": true\n    },\n    \"Observability\": {\n      \"Level\": \"Verbose\",\n      \"SampleRate\": 1 0\n    }\n  }\n}\n// appsettings Production",
        "startIndex": 10584,
        "preview": "Stop projections await _runtime StopProjectionsAsync(cancellationToken); _logger LogInformation(\"Stopped projections\"); // Close connections await _ru..."
      },
      {
        "id": "proposals/deployment-operations-chunk-5",
        "text": "{ \"Driver\": \"Postgres\" }, \"MessageBroker\": { \"Driver\": \"Kafka\" }, \"Projections\": { \"DefaultStrategy\": \"Automatic\" } } } // appsettings Development json { \"Whizbang\": { \"EventStore\": { \"ConnectionString\": \"Host=localhost;Database=whizbang_dev\", \"EnableDetailedLogging\": true }, \"MessageBroker\": { \"BootstrapServers\": \"localhost:9092\", \"EnableAutoCommit\": true }, \"Observability\": { \"Level\": \"Verbose\", \"SampleRate\": 1 0 } } } // appsettings Production json\n{\n  \"Whizbang\": {\n    \"EventStore\": {\n      \"ConnectionString\": \"\", // Set via environment variable\n      \"PoolSize\": 20,\n      \"CommandTimeout\": 30\n    },\n    \"MessageBroker\": {\n      \"BootstrapServers\": \"\", // Set via environment variable\n      \"SecurityProtocol\": \"SaslSsl\",\n      \"EnableIdempotence\": true\n    },\n    \"Observability\": {\n      \"Level\": \"Standard\",\n      \"SampleRate\": 0 1\n    },\n    \"HealthChecks\": {\n      \"ProjectionLagThresholdMinutes\": 5,\n      \"EventStoreLatencyThresholdMs\": 100\n    }\n  }\n}\n`\nSecret Management\nSecure credential handling:\n`csharp{title=\"Secret Management\" description=\"Secure credential handling with Azure Key Vault and Kubernetes secrets\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Security\", \"Secret-Management\"] framework=\"NET8\"}\n// Using Azure Key Vault\nbuilder Configuration AddAzureKeyVault(\n    new Uri(\"https://myapp-keyvault vault azure net/\"),\n    new DefaultAzureCredential()\n);\n// Using Kubernetes secrets\nservices AddWhizbang(options => {\n    // Connection string from Kubernetes secret\n    var connectionString = Environment GetEnvironmentVariable(\"WHIZBANG_EVENTSTORE_CONNECTION\") throw new InvalidOperationException(\"Event store connection string not configured\");\n    options UsePostgresEventStore(connectionString);\n    // Message broker configuration from environment\n    options UseKafkaMessageBroker(kafka => {\n        kafka BootstrapServers = Environment GetEnvironmentVariable(\"KAFKA_BOOTSTRAP_SERVERS\");\n        kafka SecurityProtocol = Enum Parse<SecurityProtocol>(\n            Environment GetEnvironmentVariable(\"KAFKA_SECURITY_PROTOCOL\") \"Plaintext\"\n        );\n        if (kafka SecurityProtocol = SecurityProtocol Plaintext) {\n            kafka SaslUsername = Environment GetEnvironmentVariable(\"KAFKA_SASL_USERNAME\");\n            kafka SaslPassword = Environment GetEnvironmentVariable(\"KAFKA_SASL_PASSWORD\");\n        }\n    });\n});\n`\nMonitoring and Alerting\nProduction Monitoring Setup\nComprehensive monitoring stack integration:\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Monitoring, Prometheus, Grafana]\ndescription: Production monitoring setup with Prometheus and Grafana dashboard configuration\n---\nPrometheus ServiceMonitor for metrics scraping\napiVersion: monitoring coreos com/v1\nkind: ServiceMonitor\nmetadata:\n  name: whizbang-metrics\nspec:\n  selector:\n    matchLabels:\n      app: ecommerce-service\n  endpoints:\nport: metrics\n    path: /metrics\n    interval: 30s\n    scrapeTimeout: 10s\n---\nGrafana dashboard ConfigMap\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: whizbang-dashboard\ndata:\n  dashboard",
        "startIndex": 13253,
        "preview": "{ \"Driver\": \"Postgres\" }, \"MessageBroker\": { \"Driver\": \"Kafka\" }, \"Projections\": { \"DefaultStrategy\": \"Automatic\" } } } // appsettings Development jso..."
      },
      {
        "id": "proposals/deployment-operations-chunk-6",
        "text": "monitoring setup with Prometheus and Grafana dashboard configuration --- Prometheus ServiceMonitor for metrics scraping apiVersion: monitoring coreos com/v1 kind: ServiceMonitor metadata: name: whizbang-metrics spec: selector: matchLabels: app: ecommerce-service endpoints: port: metrics path: /metrics interval: 30s scrapeTimeout: 10s --- Grafana dashboard ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: whizbang-dashboard data: dashboard json: |\n    {\n      \"dashboard\": {\n        \"title\": \"Whizbang Application Metrics\",\n        \"panels\": [\n          {\n            \"title\": \"Command Processing Rate\",\n            \"targets\": [\n              {\n                \"expr\": \"rate(whizbang_command_total[5m])\",\n                \"legendFormat\": \"{{command_type}}\"\n              }\n            ]\n          }\n        ]\n      }\n    }\n`\nLog Aggregation\nStructured logging for centralized log management:\n`csharp{title=\"Structured Logging\" description=\"Structured logging configuration for centralized log management\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Deployment\", \"Logging\", \"Structured-Logging\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Logging(logging => {\n        logging StructuredLogging = true;\n        logging IncludeCorrelationIds = true;\n        logging IncludeDomainContext = true;\n        logging SanitizeSensitiveData = true;\n        // Log levels by component\n        logging SetLogLevel(\"Whizbang Commands\", LogLevel Information);\n        logging SetLogLevel(\"Whizbang Events\", LogLevel Information);\n        logging SetLogLevel(\"Whizbang Projections\", LogLevel Warning);\n        logging SetLogLevel(\"Whizbang Policies\", LogLevel Debug);\n    });\n});\n// Example structured log output\n{\n  \"timestamp\": \"2024-01-01T10:00:00",
        "startIndex": 15925,
        "preview": "monitoring setup with Prometheus and Grafana dashboard configuration --- Prometheus ServiceMonitor for metrics scraping apiVersion: monitoring coreos ..."
      },
      {
        "id": "proposals/deployment-operations-chunk-7",
        "text": "StructuredLogging = true; logging IncludeCorrelationIds = true; logging IncludeDomainContext = true; logging SanitizeSensitiveData = true; // Log levels by component logging SetLogLevel(\"Whizbang Commands\", LogLevel Information); logging SetLogLevel(\"Whizbang Events\", LogLevel Information); logging SetLogLevel(\"Whizbang Projections\", LogLevel Warning); logging SetLogLevel(\"Whizbang Policies\", LogLevel Debug); }); }); // Example structured log output { \"timestamp\": \"2024-01-01T10:00:00 000Z\",\n  \"level\": \"Information\",\n  \"messageTemplate\": \"Command {CommandType} processed for domain {Domain}\",\n  \"properties\": {\n    \"CommandType\": \"PlaceOrder\",\n    \"Domain\": \"Orders\",\n    \"CorrelationId\": \"abc-123-def\",\n    \"TenantId\": \"tenant-456\",\n    \"ExecutionTimeMs\": 45,\n    \"Success\": true\n  }\n}\n`\nScaling Strategies\nHorizontal Scaling\nScale-out patterns for high throughput:\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Kubernetes, Auto-Scaling, HPA]\ndescription: Horizontal pod autoscaler configuration with custom metrics\n---\nHorizontal Pod Autoscaler\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: ecommerce-service-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: ecommerce-service\n  minReplicas: 2\n  maxReplicas: 20\n  metrics:\ntype: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\ntype: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\ntype: Pods\n    pods:\n      metric:\n        name: whizbang_projection_lag_seconds\n      target:\n        type: AverageValue\n        averageValue: \"300\" Scale when lag > 5 minutes\n`\nVertical Scaling\nResource optimization for different workloads:\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Deployment, Kubernetes, Resource-Optimization, Vertical-Scaling]\ndescription: Resource optimization configurations for different workload types\n---\nCommand-heavy service\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-command-service\nspec:\n  template:\n    spec:\n      containers:\nname: order-service\n        resources:\n          requests:\n            cpu: 500m      Higher CPU for command processing\n            memory: 512Mi\n          limits:\n            cpu: 2000m\n            memory: 1Gi\n---\nProjection-heavy service\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: analytics-projection-worker\nspec:\n  template:\n    spec:\n      containers:\nname: projection-worker\n        resources:\n          requests:\n            cpu: 200m\n            memory: 1Gi    Higher memory for projection state\n          limits:\n            cpu: 1000m\n            memory: 4Gi\n`\nBest Practices\nDeployment Guidelines\nStart simple - Begin with monolithic deployment, extract services as needed\nUse health checks - Implement comprehensive liveness and readiness probes\nPlan for scaling - Design with horizontal scaling in mind\nMonitor everything - Set up observability before going to production\nTest failure modes - Practice chaos engineering and disaster recovery\nConfiguration Management\nEnvironment parity - Keep development and production configs similar\nSecure secrets - Never store credentials in code or config files\nValidate on startup - Fail fast if configuration is invalid\nDocument settings - Maintain clear documentation of all configuration options\nVersion configurations - Track configuration changes alongside code\nOperational Excellence\nAutomate deployments - Use CI/CD pipelines for consistent deployments\nMonitor SLOs - Define and track service level objectives\nPlan for disasters - Regular backup and recovery testing\nCapacity planning - Monitor trends and plan for growth\nRegular maintenance - Schedule updates and maintenance windows\n---\nRelated Documentation\nObservability & Metrics - Production monitoring setup\nTesting & Development Tools - Testing deployment configurations\nAdvanced Features - Kubernetes operator features",
        "startIndex": 17257,
        "preview": "StructuredLogging = true; logging IncludeCorrelationIds = true; logging IncludeDomainContext = true; logging SanitizeSensitiveData = true; // Log leve..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/domain-ownership",
    "title": "Domain Ownership",
    "category": "Architecture & Design",
    "url": "/docs/proposals/domain-ownership",
    "chunks": [
      {
        "id": "proposals/domain-ownership-chunk-0",
        "text": "Domain Ownership\nWhizbang enforces explicit domain ownership to prevent distributed system chaos Every command and event has a clear owner, enabling proper routing, authorization, and system boundaries Ownership Determination Order\nDomain ownership is determined in user-configurable order, with this default precedence:\nNamespace Convention (highest priority)\nAttributes \nConfiguration-Driven (lowest priority)\nEach level can override previous levels, giving developers full control Namespace Convention (Default First)\nAutomatic ownership derived from namespace structure:\n`csharp{title=\"Namespace-Based Domain Ownership\" description=\"Automatic domain ownership derived from namespace structure\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"domain-ownership\", \"namespace-convention\", \"commands\", \"events\"] framework=\"NET8\"}\n// Orders domain\nnamespace MyApp Orders Commands {\n    public record PlaceOrder(Guid OrderId, Guid CustomerId, List<OrderItem> Items);\n    // Domain: \"Orders\" (extracted from namespace)\n}\nnamespace MyApp Orders Events {\n    public record OrderPlaced(Guid OrderId, Guid CustomerId, DateTimeOffset PlacedAt);\n    // Domain: \"Orders\"\n}\n// Inventory domain  \nnamespace MyApp Inventory Commands {\n    public record ReserveStock(Guid ProductId, int Quantity);\n    // Domain: \"Inventory\"\n}\n`\nNamespace Policy Configuration\n`csharp{title=\"Namespace Policy Configuration\" description=\"Configuring namespace extraction policies for domain ownership\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"configuration\", \"namespace-policy\", \"setup\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        // Configure namespace extraction policies\n        ownership NamespacePolicy(policy => {\n            // Default: Extract domain from namespace segment\n            policy ExtractDomainFromNamespace = true;\n            policy DomainNamespacePosition = 1; // MyApp [Domain] Commands\n            // Custom extraction function\n            policy DomainExtractor = (type) => {\n                var segments = type Namespace Split(' ');\n                if (segments Length >= 3 && segments[1] == \"Domains\") {\n                    return segments[2]; // MyApp Domains [Domain] Commands\n                }\n                return segments Length >= 2 segments[1] : \"Default\";\n            };\n            // Namespace patterns\n            policy CommandNamespacePattern = \"* Commands\";\n            policy EventNamespacePattern = \"* Events\";\n            policy QueryNamespacePattern = \"*",
        "startIndex": 0,
        "preview": "Domain Ownership\nWhizbang enforces explicit domain ownership to prevent distributed system chaos Every command and event has a clear owner, enabling p..."
      },
      {
        "id": "proposals/domain-ownership-chunk-1",
        "text": "segments = type Namespace Split(' '); if (segments Length >= 3 && segments[1] == \"Domains\") { return segments[2]; // MyApp Domains [Domain] Commands } return segments Length >= 2 segments[1] : \"Default\"; }; // Namespace patterns policy CommandNamespacePattern = \"* Commands\"; policy EventNamespacePattern = \"* Events\"; policy QueryNamespacePattern = \"* Queries\";\n        });\n    });\n});\n`\nAttribute-Based Ownership\nExplicit declaration using attributes:\n`csharp{title=\"Attribute-Based Domain Ownership\" description=\"Explicit domain ownership declaration using attributes\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"domain-ownership\", \"attributes\", \"explicit-declaration\", \"override\"] framework=\"NET8\"}\n[OwnedBy(\"Orders\")]\npublic record PlaceOrder(Guid OrderId, Guid CustomerId, List<OrderItem> Items);\n[OwnedBy(\"Orders\")]\npublic record OrderPlaced(Guid OrderId, Guid CustomerId, DateTimeOffset PlacedAt);\n// Override namespace convention\nnamespace MyApp Shared Commands {\n    [OwnedBy(\"Inventory\")] // Overrides \"Shared\" from namespace\n    public record ReserveStock(Guid ProductId, int Quantity);\n}\n`\nAttribute Policies\n`csharp{title=\"Attribute Policy Configuration\" description=\"Configuring attribute-based ownership policies\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"attribute-policy\", \"configuration\", \"custom-attributes\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership AttributePolicy(policy => {\n            // Require explicit ownership for certain patterns\n            policy RequireExplicitOwnership<ICommand>();\n            policy RequireExplicitOwnership(type => type Name EndsWith(\"Command\"));\n            // Default ownership for unattributed types\n            policy DefaultDomain = \"Shared\";\n            // Custom attribute types\n            policy RecognizeAttribute<DomainAttribute>();\n            policy RecognizeAttribute<BoundedContextAttribute>();\n        });\n    });\n});\n`\nConfiguration-Driven Ownership\nCentralized registration in Program cs:\n`csharp{title=\"Configuration-Driven Ownership\" description=\"Centralized domain registration with explicit ownership\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"configuration\", \"domain-registration\", \"centralized-config\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        // Register domains with explicit ownership\n        ownership RegisterDomain(\"Orders\", domain => {\n            domain OwnsCommand<PlaceOrder>();\n            domain OwnsCommand<UpdateOrder>();\n            domain OwnsEvent<OrderPlaced>();\n            domain OwnsEvent<OrderUpdated>();\n            // Override other declarations\n            domain OwnsCommand<SpecialSharedCommand>(); // Takes from \"Shared\"\n        });\n        ownership RegisterDomain(\"Inventory\", domain => {\n            domain OwnsCommand<ReserveStock>();\n            domain OwnsCommand<ReleaseStock>();\n            domain OwnsEvent<StockReserved>();\n            domain",
        "startIndex": 2564,
        "preview": "segments = type Namespace Split(' '); if (segments Length >= 3 && segments[1] == \"Domains\") { return segments[2]; // MyApp Domains [Domain] Commands }..."
      },
      {
        "id": "proposals/domain-ownership-chunk-2",
        "text": "services AddWhizbang(options => { options DomainOwnership(ownership => { // Register domains with explicit ownership ownership RegisterDomain(\"Orders\", domain => { domain OwnsCommand<PlaceOrder>(); domain OwnsCommand<UpdateOrder>(); domain OwnsEvent<OrderPlaced>(); domain OwnsEvent<OrderUpdated>(); // Override other declarations domain OwnsCommand<SpecialSharedCommand>(); // Takes from \"Shared\" }); ownership RegisterDomain(\"Inventory\", domain => { domain OwnsCommand<ReserveStock>(); domain OwnsCommand<ReleaseStock>(); domain OwnsEvent<StockReserved>(); domain OwnsEvent<StockReleased>();\n        });\n    });\n});\n`\nInterface and Inheritance Policies\nInterface-Based Ownership\n`csharp{title=\"Interface-Based Ownership\" description=\"Interface-based domain ownership with marker interfaces\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"interface-based\", \"marker-interfaces\", \"configuration\"] framework=\"NET8\"}\n// Domain marker interfaces\npublic interface IOrderCommand : ICommand { }\npublic interface IInventoryCommand : ICommand { }\npublic record PlaceOrder( ) : IOrderCommand;\npublic record ReserveStock( ) : IInventoryCommand;\n// Configure interface-based ownership\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership InterfacePolicy(policy => {\n            policy RegisterInterface<IOrderCommand>(\"Orders\");\n            policy RegisterInterface<IInventoryCommand>(\"Inventory\");\n            policy RegisterInterface<ISharedCommand>(\"Shared\");\n        });\n    });\n});\n`\nInheritance-Based Ownership\n`csharp{title=\"Inheritance-Based Ownership\" description=\"Inheritance-based domain ownership with base command classes\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"inheritance-based\", \"base-classes\", \"configuration\"] framework=\"NET8\"}\n// Base classes for domains\npublic abstract class OrderCommand : ICommand {\n    // Common order command properties\n}\npublic abstract class InventoryCommand : ICommand {\n    // Common inventory command properties  \n}\npublic class PlaceOrder : OrderCommand {\n    // Inherits \"Orders\" domain\n}\n// Configure inheritance-based ownership\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership InheritancePolicy(policy => {\n            policy RegisterBaseClass<OrderCommand>(\"Orders\");\n            policy RegisterBaseClass<InventoryCommand>(\"Inventory\");\n        });\n    });\n});\n`\nCustom Ownership Precedence\nDeveloper controls the order of ownership determination:\n`csharp{title=\"Custom Ownership Precedence\" description=\"Custom ownership precedence order configuration\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"precedence-order\", \"configuration\", \"custom-rules\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        // Custom precedence order\n        ownership PrecedenceOrder(\n            DomainOwnershipSource Attributes,        // Check attributes first\n            DomainOwnershipSource Configuration,     // Then explicit config\n            DomainOwnershipSource Interfaces,        // Then interfaces\n            DomainOwnershipSource Inheritance,       // Then inheritance\n            DomainOwnershipSource Namespace          // Finally namespace\n        );\n        // Or use fluent API\n        ownership CheckAttributesFirst() ThenConfiguration() ThenInterfaces() ThenInheritance()",
        "startIndex": 5266,
        "preview": "services AddWhizbang(options => { options DomainOwnership(ownership => { // Register domains with explicit ownership ownership RegisterDomain(\"Orders\"..."
      },
      {
        "id": "proposals/domain-ownership-chunk-3",
        "text": "=> { options DomainOwnership(ownership => { // Custom precedence order ownership PrecedenceOrder( DomainOwnershipSource Attributes, // Check attributes first DomainOwnershipSource Configuration, // Then explicit config DomainOwnershipSource Interfaces, // Then interfaces DomainOwnershipSource Inheritance, // Then inheritance DomainOwnershipSource Namespace // Finally namespace ); // Or use fluent API ownership CheckAttributesFirst() ThenConfiguration() ThenInterfaces() ThenInheritance() FinallyNamespace();\n    });\n});\n`\nComplex Policy Examples\nMulti-Level Namespace Extraction\n`csharp{title=\"Multi-Level Namespace Extraction\" description=\"Multi-level namespace extraction with complex custom logic\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"namespace-extraction\", \"multi-level\", \"custom-logic\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership NamespacePolicy(policy => {\n            policy DomainExtractor = (type) => {\n                var ns = type Namespace;\n                // MyApp Domains Orders Commands -> \"Orders\"\n                if (ns Contains(\" Domains \")) {\n                    var segments = ns Split(' ');\n                    var domainIndex = Array IndexOf(segments, \"Domains\") + 1;\n                    return domainIndex < segments Length segments[domainIndex] : \"Unknown\";\n                }\n                // MyApp Orders V2 Commands -> \"Orders\"\n                var parts = ns Split(' ');\n                if (parts Length >= 2) {\n                    return parts[1]; // Second segment is domain\n                }\n                return \"Default\";\n            };\n        });\n    });\n});\n`\nConditional Ownership Rules\n`csharp{title=\"Conditional Ownership Rules\" description=\"Conditional ownership rules based on type patterns and assemblies\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"conditional-rules\", \"assembly-based\", \"integration-events\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership ConditionalRules(rules => {\n            // Integration events are always \"Shared\"\n            rules When(type => type Name EndsWith(\"IntegrationEvent\")) AssignToDomain(\"Shared\");\n            // Commands from external assemblies go to \"External\"\n            rules When(type => type Assembly GetName() Name StartsWith(\"MyApp\")) AssignToDomain(\"External\");\n            // Saga commands inherit from the saga's domain\n            rules When(type => typeof(ISagaCommand) IsAssignableFrom(type)) ExtractDomainFromProperty(\"SagaDomain\");\n        });\n    });\n});\n`\nAssembly-Based Policies\n`csharp{title=\"Assembly-Based Policies\" description=\"Assembly-based domain ownership with naming conventions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"assembly-based\", \"assembly-mapping\", \"naming-convention\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options DomainOwnership(ownership => {\n        ownership AssemblyPolicy(policy => {\n            // Each assembly represents a domain\n            policy MapAssemblyToDomain(\"MyApp Orders\", \"Orders\");\n            policy MapAssemblyToDomain(\"MyApp Inventory\", \"Inventory\");\n            policy MapAssemblyToDomain(\"MyApp",
        "startIndex": 8208,
        "preview": "=> { options DomainOwnership(ownership => { // Custom precedence order ownership PrecedenceOrder( DomainOwnershipSource Attributes, // Check attribute..."
      },
      {
        "id": "proposals/domain-ownership-chunk-4",
        "text": "ExtractDomainFromProperty(\"SagaDomain\"); }); }); }); ` Assembly-Based Policies `csharp{title=\"Assembly-Based Policies\" description=\"Assembly-based domain ownership with naming conventions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"assembly-based\", \"assembly-mapping\", \"naming-convention\"] framework=\"NET8\"} services AddWhizbang(options => { options DomainOwnership(ownership => { ownership AssemblyPolicy(policy => { // Each assembly represents a domain policy MapAssemblyToDomain(\"MyApp Orders\", \"Orders\"); policy MapAssemblyToDomain(\"MyApp Inventory\", \"Inventory\"); policy MapAssemblyToDomain(\"MyApp Shipping\", \"Shipping\");\n            // Assembly naming convention\n            policy ExtractDomainFromAssemblyName = true;\n            policy AssemblyNamePattern = \"MyApp {Domain}\";\n        });\n    });\n});\n`\nRuntime Ownership Resolution\nOwnership Discovery API\n`csharp{title=\"Domain Ownership Resolver API\" description=\"Domain ownership resolver API for runtime discovery\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"runtime-resolution\", \"api\", \"interface\"] framework=\"NET8\"}\npublic interface IDomainOwnershipResolver {\n    string ResolveDomain<T>();\n    string ResolveDomain(Type type);\n    bool IsDomainOwner<T>(string domain);\n    IEnumerable<string> GetAllDomains();\n    IEnumerable<Type> GetDomainTypes(string domain);\n}\n// Usage\n`csharp{title=\"Using Domain Ownership Resolver\" description=\"Example of using domain ownership resolver in a controller\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"controllers\", \"usage-example\", \"resolver\"] framework=\"NET8\"}\npublic class OrderController : ControllerBase {\n    private readonly IDomainOwnershipResolver _ownership;\n    public OrderController(IDomainOwnershipResolver ownership) {\n        _ownership = ownership;\n    }\n    public async Task<IActionResult> PlaceOrder(PlaceOrderRequest request) {\n        var domain = _ownership ResolveDomain<PlaceOrder>();\n        // domain = \"Orders\"\n        var command = new PlaceOrder(request OrderId, request CustomerId, request Items);\n        await _mediator Send(command);\n        return Ok();\n    }\n}\n`\nCompile-Time Validation\nRoslyn analyzer enforces ownership rules:\n`csharp{title=\"Compile-Time Validation\" description=\"Compile-time validation of domain ownership rules with Roslyn analyzers\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"compile-time-validation\", \"roslyn-analyzers\", \"source-generators\"] framework=\"NET8\"}\n// This will generate a compile error\n[OwnedBy(\"Orders\")]\npublic record PlaceOrder( );\n// In different assembly/project\npublic class InventoryHandler : ICommandHandler<PlaceOrder> {\n    // ERROR: InventoryHandler cannot handle PlaceOrder - different domains\n    public async Task Handle(PlaceOrder command) { }\n}\n`\nSource Generator Support\n`csharp{title=\"Auto-Generated Domain Registry\" description=\"Auto-generated domain ownership registry for runtime lookups\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"source-generation\", \"code-generation\", \"registry\"] framework=\"NET8\"}\n// Generated at compile time\n[GeneratedCode(\"Whizbang",
        "startIndex": 11060,
        "preview": "ExtractDomainFromProperty(\"SagaDomain\"); }); }); }); ` Assembly-Based Policies `csharp{title=\"Assembly-Based Policies\" description=\"Assembly-based dom..."
      },
      {
        "id": "proposals/domain-ownership-chunk-5",
        "text": "public class InventoryHandler : ICommandHandler<PlaceOrder> { // ERROR: InventoryHandler cannot handle PlaceOrder - different domains public async Task Handle(PlaceOrder command) { } } ` Source Generator Support `csharp{title=\"Auto-Generated Domain Registry\" description=\"Auto-generated domain ownership registry for runtime lookups\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"domain-ownership\", \"source-generation\", \"code-generation\", \"registry\"] framework=\"NET8\"} // Generated at compile time [GeneratedCode(\"Whizbang SourceGenerator\")]\npublic static class DomainOwnershipRegistry {\n    public static readonly Dictionary<Type, string> TypeToDomain = new() {\n        { typeof(PlaceOrder), \"Orders\" },\n        { typeof(OrderPlaced), \"Orders\" },\n        { typeof(ReserveStock), \"Inventory\" },\n        { typeof(StockReserved), \"Inventory\" }\n    };\n    public static readonly Dictionary<string, HashSet<Type>> DomainToTypes = new() {\n        { \"Orders\", new HashSet<Type> { typeof(PlaceOrder), typeof(OrderPlaced) } },\n        { \"Inventory\", new HashSet<Type> { typeof(ReserveStock), typeof(StockReserved) } }\n    };\n}\n`\nCommand Routing Based on Ownership\nIn-Process Routing\n`csharp{title=\"In-Process Command Routing\" description=\"Local command routing within the same domain service\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"routing\", \"in-process-communication\", \"local-handling\"] framework=\"NET8\"}\n// Same domain - route locally\nvar command = new PlaceOrder( );\nvar domain = _ownership ResolveDomain<PlaceOrder>(); // \"Orders\"\nvar handler = _serviceProvider GetRequiredService<ICommandHandler<PlaceOrder>>();\nawait handler Handle(command);\n`\nCross-Service Routing\n`csharp{title=\"Cross-Service Command Routing\" description=\"Cross-service command routing based on domain ownership\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"routing\", \"cross-service-communication\", \"message-broker\"] framework=\"NET8\"}\n// Different domain - route via message broker\nvar command = new ReserveStock( );\nvar domain = _ownership ResolveDomain<ReserveStock>(); // \"Inventory\"\nif (domain = _currentDomain) {\n    // Send to remote service\n    await _messageBroker SendToService(domain, command);\n} else {\n    // Handle locally\n    await _localMediator",
        "startIndex": 13613,
        "preview": "public class InventoryHandler : ICommandHandler<PlaceOrder> { // ERROR: InventoryHandler cannot handle PlaceOrder - different domains public async Tas..."
      },
      {
        "id": "proposals/domain-ownership-chunk-6",
        "text": "category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"routing\", \"cross-service-communication\", \"message-broker\"] framework=\"NET8\"} // Different domain - route via message broker var command = new ReserveStock( ); var domain = _ownership ResolveDomain<ReserveStock>(); // \"Inventory\" if (domain = _currentDomain) { // Send to remote service await _messageBroker SendToService(domain, command); } else { // Handle locally await _localMediator Send(command);\n}\n`\nBest Practices\nOwnership Guidelines\nBe explicit - Prefer attributes over conventions for critical commands\nConsistent patterns - Use the same ownership style within a domain\nDocument policies - Make namespace and interface conventions clear\nValidate early - Use analyzers to catch ownership violations\nMonitor boundaries - Track cross-domain communication patterns\nPolicy Design\nStart simple - Begin with namespace conventions\nAdd specificity - Use attributes for exceptions\nCentralize overrides - Use configuration for edge cases\nTest policies - Ensure ownership resolution works as expected\nVersion carefully - Changing ownership affects routing\n---\nRelated Documentation\nEvent Store & Projections - Storage architecture\nConcurrency Control - Managing concurrent updates  \nMulti-Tenancy - Tenant isolation with domain ownership",
        "startIndex": 15381,
        "preview": "category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"domain-ownership\", \"routing\", \"cross-service-communication\", \"message-broker\"] framework=\"NET8\"} //..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/event-store-projections",
    "title": "Event Store & Projection Architecture",
    "category": "Architecture & Design",
    "url": "/docs/proposals/event-store-projections",
    "chunks": [
      {
        "id": "proposals/event-store-projections-chunk-0",
        "text": "Event Store & Projection Architecture\nWhizbang implements a hybrid event store and projection architecture that separates event persistence from projection storage, enabling flexible schema evolution and high-performance querying",
        "startIndex": 0,
        "preview": "Event Store & Projection Architecture\nWhizbang implements a hybrid event store and projection architecture that separates event persistence from proje..."
      },
      {
        "id": "proposals/event-store-projections-chunk-1",
        "text": "Event Store & Projection Architecture Whizbang implements a hybrid event store and projection architecture that separates event persistence from projection storage, enabling flexible schema evolution and high-performance querying Core Architecture\nHybrid Storage Design\nEvents Table (Immutable Event Stream):\n`sql\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Architecture, Event-Store, SQL, JSONB]\ndescription: SQL schema for events table with JSONB data storage\n---\nCREATE TABLE events (\n    event_id BIGSERIAL PRIMARY KEY,\n    stream_id VARCHAR(255) NOT NULL,\n    stream_version INT NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    event_data JSONB NOT NULL,\n    metadata JSONB,\n    tenant_id VARCHAR(100),\n    created_at TIMESTAMPTZ NOT NULL,\n    UNIQUE(stream_id, stream_version)\n);\nCREATE INDEX idx_stream ON events(stream_id);\nCREATE INDEX idx_type ON events(event_type);\nCREATE INDEX idx_tenant ON events(tenant_id) WHERE tenant_id IS NOT NULL;\n`\nProjections Tables (Mutable JSONB Documents):\n`sql\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Architecture, Projections, SQL, JSONB]\ndescription: SQL schema for projections table with mutable JSONB documents\n---\nCREATE TABLE projections (\n    projection_name VARCHAR(255) NOT NULL,\n    document_id VARCHAR(255) NOT NULL,\n    document JSONB NOT NULL,\n    tenant_id VARCHAR(100),\n    version BIGINT NOT NULL,\n    last_updated TIMESTAMPTZ NOT NULL,\n    PRIMARY KEY (projection_name, document_id, COALESCE(tenant_id, ''))\n);\nCREATE INDEX idx_projection_tenant ON projections(projection_name, tenant_id);\n`\nBenefits of Hybrid Approach\nEvents are immutable - Perfect audit trail, never changes\nProjections are mutable - Can be rebuilt, schema can evolve\nJSONB flexibility - No schema migrations for projection changes\nPerformance optimization - Events optimized for append, projections for queries\nIndependent scaling - Different databases/drivers for events vs projections\nProjection Management\nSchema-Free Evolution\n`csharp{\ntitle: \"Schema Evolution Example\",\ndescription: \"Schema evolution example showing projection changes without migrations\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Design\", \"Projections\", \"Schema-Evolution\", \"Domain-Models\"],\nframework: \"NET8\"\n}\n// V1 Projection\npublic class OrderSummaryProjection {\n    public Guid OrderId { get; set; }\n    public decimal Total { get; set; }\n    public OrderStatus Status { get; set; }\n}\n// V2 Projection - Add fields without migration\npublic class OrderSummaryProjection {\n    public Guid OrderId { get; set; }\n    public decimal Total { get; set; }\n    public OrderStatus Status { get; set; }\n    public DateTime EstimatedDelivery { get; set; }  // New field\n    public List<string> Tags { get; set; } = new();   // New collection\n}\n`\nNo database migration required - JSONB handles missing fields gracefully",
        "startIndex": 231,
        "preview": "Event Store & Projection Architecture Whizbang implements a hybrid event store and projection architecture that separates event persistence from proje..."
      },
      {
        "id": "proposals/event-store-projections-chunk-2",
        "text": "set; } public decimal Total { get; set; } public OrderStatus Status { get; set; } public DateTime EstimatedDelivery { get; set; } // New field public List<string> Tags { get; set; } = new(); // New collection } ` No database migration required - JSONB handles missing fields gracefully Atomic Projection Rebuilds\nWhizbang supports zero-downtime projection rebuilds using temporary table swapping:\n`csharp{\ntitle: \"Atomic Projection Rebuild Configuration\",\ndescription: \"Configuration for atomic projection rebuilds with zero downtime\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Design\", \"Projections\", \"Configuration\", \"Atomic-Operations\"],\nframework: \"NET8\"\n}\nservices AddProjection<OrderSummaryProjection>(options => {\n    options RebuildStrategy = RebuildStrategy AtomicSwap;\n});\n// Rebuild process:\n// 1 Create temporary table: projections_ordersummary_temp\n// 2 Build new projection in temp table from events\n// 3 Atomic swap: RENAME projections_ordersummary TO projections_ordersummary_old,\n//                  projections_ordersummary_temp TO projections_ordersummary\n// 4 Drop old table\n`\nProjection Drivers\nProjections use driver-based storage for flexibility:\n`csharp{\ntitle: \"Projection Driver Configuration\",\ndescription: \"Driver configuration for different projection storage backends\",\ncategory: \"Design\",\ndifficulty: \"BEGINNER\",\ntags: [\"Design\", \"Configuration\", \"Drivers\", \"PostgreSQL\", \"MongoDB\"],\nframework: \"NET8\"\n}\n// PostgreSQL JSONB Driver (default)\nservices AddWhizbang(options => {\n    options UsePostgresProjections(connectionString);\n});\n// SQL Server JSON Driver\nservices AddWhizbang(options => {\n    options UseSqlServerProjections(connectionString);\n});\n// MongoDB Driver\nservices AddWhizbang(options => {\n    options UseMongoProjections(connectionString);\n});\n// Custom Driver\nservices AddWhizbang(options => {\n    options",
        "startIndex": 2874,
        "preview": "set; } public decimal Total { get; set; } public OrderStatus Status { get; set; } public DateTime EstimatedDelivery { get; set; } // New field public ..."
      },
      {
        "id": "proposals/event-store-projections-chunk-3",
        "text": "[\"Design\", \"Configuration\", \"Drivers\", \"PostgreSQL\", \"MongoDB\"], framework: \"NET8\" } // PostgreSQL JSONB Driver (default) services AddWhizbang(options => { options UsePostgresProjections(connectionString); }); // SQL Server JSON Driver services AddWhizbang(options => { options UseSqlServerProjections(connectionString); }); // MongoDB Driver services AddWhizbang(options => { options UseMongoProjections(connectionString); }); // Custom Driver services AddWhizbang(options => { options UseProjectionDriver<MyCustomDriver>();\n});\n`\nSnapshotting\nSmart Replay with Snapshots\nWhizbang supports snapshot-assisted replays to reduce replay overhead:\n`csharp{\ntitle: \"Aggregate with Automatic Snapshotting\",\ndescription: \"Aggregate with automatic snapshotting for replay optimization\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Design\", \"Aggregates\", \"Snapshots\", \"Performance\"],\nframework: \"NET8\"\n}\npublic class OrderAggregate : Aggregate {\n    public Guid Id { get; private set; }\n    public decimal Total { get; private set; }\n    public List<OrderItem> Items { get; private set; } = new();\n    // Automatic snapshots every 100 events\n    [Snapshot(Every = 100)]\n    public OrderSnapshot CreateSnapshot() {\n        return new OrderSnapshot {\n            Id = Id,\n            Total = Total,\n            Items = Items ToList()\n        };\n    }\n    // Restore from snapshot\n    public void RestoreFromSnapshot(OrderSnapshot snapshot) {\n        Id = snapshot Id;\n        Total = snapshot Total;\n        Items = snapshot",
        "startIndex": 4459,
        "preview": "[\"Design\", \"Configuration\", \"Drivers\", \"PostgreSQL\", \"MongoDB\"], framework: \"NET8\" } // PostgreSQL JSONB Driver (default) services AddWhizbang(options..."
      },
      {
        "id": "proposals/event-store-projections-chunk-4",
        "text": "new(); // Automatic snapshots every 100 events [Snapshot(Every = 100)] public OrderSnapshot CreateSnapshot() { return new OrderSnapshot { Id = Id, Total = Total, Items = Items ToList() }; } // Restore from snapshot public void RestoreFromSnapshot(OrderSnapshot snapshot) { Id = snapshot Id; Total = snapshot Total; Items = snapshot Items;\n    }\n}\n`\nSnapshot Storage\n`sql\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Snapshots, SQL, Performance]\ndescription: SQL schema for snapshot storage with JSONB data\n---\nCREATE TABLE snapshots (\n    stream_id VARCHAR(255) NOT NULL,\n    snapshot_version BIGINT NOT NULL,\n    snapshot_data JSONB NOT NULL,\n    tenant_id VARCHAR(100),\n    created_at TIMESTAMPTZ NOT NULL,\n    PRIMARY KEY (stream_id, snapshot_version)\n);\n`\nReplay Strategy\nWhen replaying events for projection rebuilds:\nFind closest snapshot ‚â§ starting event number\nRestore snapshot if available\nReplay remaining events from snapshot version to target\nNon-atomic replays only - atomic replays always start from beginning\n`csharp{\ntitle: \"Smart Replay Strategy\",\ndescription: \"Smart replay strategy using snapshots to reduce event processing\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Design\", \"Snapshots\", \"Replay\", \"Performance-Optimization\"],\nframework: \"NET8\"\n}\n// Smart replay from event #50,000\nvar snapshot = await snapshotStore GetLatestBefore(streamId, eventNumber: 50000);\nif (snapshot = null && snapshot Version >= 49900) { // Within 100 events\n    aggregate RestoreFromSnapshot(snapshot);\n    var events = await eventStore ReadFrom(streamId, snapshot Version + 1, 50000);\n} else {\n    var events = await eventStore ReadFrom(streamId, 0, 50000);\n}\n`\nImplementation Details\nProjection Handler Registration\n`csharp{\ntitle: \"Projection Handler Implementation\",\ndescription: \"Projection handler implementation for multiple event types\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Design\", \"Projections\", \"Event-Handlers\", \"Domain-Logic\"],\nframework: \"NET8\"\n}\npublic class OrderSummaryProjection : IProjectionHandler<OrderPlaced>,\n                                     IProjectionHandler<OrderUpdated>,\n                                     IProjectionHandler<OrderShipped> {\n    public async Task Handle(OrderPlaced @event, ProjectionContext context) {\n        var summary = new OrderSummary {\n            OrderId = @event OrderId,\n            Total = @event Total,\n            Status = OrderStatus Placed,\n            CustomerId = @event CustomerId\n        };\n        await context Store(summary OrderId",
        "startIndex": 5498,
        "preview": "new(); // Automatic snapshots every 100 events [Snapshot(Every = 100)] public OrderSnapshot CreateSnapshot() { return new OrderSnapshot { Id = Id, Tot..."
      },
      {
        "id": "proposals/event-store-projections-chunk-5",
        "text": "[\"Design\", \"Projections\", \"Event-Handlers\", \"Domain-Logic\"], framework: \"NET8\" } public class OrderSummaryProjection : IProjectionHandler<OrderPlaced>, IProjectionHandler<OrderUpdated>, IProjectionHandler<OrderShipped> { public async Task Handle(OrderPlaced @event, ProjectionContext context) { var summary = new OrderSummary { OrderId = @event OrderId, Total = @event Total, Status = OrderStatus Placed, CustomerId = @event CustomerId }; await context Store(summary OrderId ToString(), summary);\n    }\n    public async Task Handle(OrderUpdated @event, ProjectionContext context) {\n        var summary = await context Load<OrderSummary>(@event OrderId ToString());\n        if (summary = null) {\n            summary Total = @event NewTotal;\n            summary Items = @event UpdatedItems;\n            await context Store(@event OrderId ToString(), summary);\n        }\n    }\n}\n`\nProjection Configuration\n`csharp{\ntitle: \"Advanced Projection Configuration\",\ndescription: \"Advanced projection configuration with partitioning and rebuild strategies\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Design\", \"Projections\", \"Configuration\", \"Multi-Tenancy\"],\nframework: \"NET8\"\n}\nservices AddProjection<OrderSummaryProjection>(projection => {\n    projection ProjectionName = \"order-summary\";\n    projection PartitionBy = order => order CustomerId; // Multi-tenant partitioning\n    projection SnapshotStrategy = SnapshotStrategy Automatic;\n    projection RebuildStrategy = RebuildStrategy AtomicSwap;\n    projection CheckpointStorage = CheckpointStorage SameDatabase;\n});\n`\nDriver Interface\n`csharp{\ntitle: \"Projection Driver Interface\",\ndescription: \"Projection driver interface for pluggable storage backends\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Design\", \"Drivers\", \"Interfaces\", \"Architecture\"],\nframework: \"NET8\"\n}\npublic interface IProjectionDriver {\n    Task Store<T>(string projectionName, string documentId, T document, string tenantId = null);\n    Task<T > Load<T>(string projectionName, string documentId, string tenantId = null);\n    Task Delete(string projectionName, string documentId, string tenantId = null);\n    // Querying support\n    Task<IEnumerable<T>> Query<T>(string projectionName, Expression<Func<T, bool>> predicate, string tenantId = null);\n    Task<IEnumerable<T>> QueryAll<T>(string projectionName, string tenantId = null);\n    // Rebuild support\n    Task<string> CreateTemporaryProjectionTable(string projectionName);\n    Task SwapProjectionTables(string projectionName, string temporaryTableName);\n    Task DropProjectionTable(string tableName);\n}\n`\nMulti-Database Support\nEvents and Projections in Different Databases\n`csharp{\ntitle: \"Multi-Database Configuration\",\ndescription: \"Configuration for separating events and projections across different databases\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Design\", \"Configuration\", \"Multi-Database\", \"Architecture\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    // Events in PostgreSQL\n    options",
        "startIndex": 7719,
        "preview": "[\"Design\", \"Projections\", \"Event-Handlers\", \"Domain-Logic\"], framework: \"NET8\" } public class OrderSummaryProjection : IProjectionHandler<OrderPlaced>..."
      },
      {
        "id": "proposals/event-store-projections-chunk-6",
        "text": "string temporaryTableName); Task DropProjectionTable(string tableName); } ` Multi-Database Support Events and Projections in Different Databases `csharp{ title: \"Multi-Database Configuration\", description: \"Configuration for separating events and projections across different databases\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Design\", \"Configuration\", \"Multi-Database\", \"Architecture\"], framework: \"NET8\" } services AddWhizbang(options => { // Events in PostgreSQL options UsePostgresEventStore(\"Host=events-db;Database=events\");\n    // Projections in MongoDB\n    options UseMongoProjections(\"mongodb://projections-cluster\");\n    // Or projections in separate PostgreSQL instance\n    options UsePostgresProjections(\"Host=projections-db;Database=projections\");\n});\n`\nPerformance Benefits\nEvents database optimized for writes (append-only)\nProjections database optimized for reads (complex queries)\nIndependent scaling of read vs write workloads\nDifferent drivers for different use cases\nBest Practices\nProjection Design\nKeep projections focused - One projection per use case\nDenormalize for queries - Include all needed data\nUse tenant partitioning - For multi-tenant scenarios\nVersion projections - For breaking changes\nSnapshot Guidelines\nSnapshot long-lived aggregates - Orders, customers, accounts\nDon't snapshot short-lived aggregates - Shopping carts, sessions\nConsider snapshot frequency - Balance storage vs replay speed\nTest snapshot restore - Ensure snapshots work correctly\nRebuild Strategies\nUse atomic swaps for production rebuilds\nUse in-place updates for development\nMonitor rebuild progress with checkpoints\nValidate rebuilt projections before swapping\n---\nRelated Documentation\nConcurrency Control - How concurrency is managed\nMulti-Tenancy - Tenant isolation strategies\nPerformance Optimization - Scaling and tuning",
        "startIndex": 10267,
        "preview": "string temporaryTableName); Task DropProjectionTable(string tableName); } ` Multi-Database Support Events and Projections in Different Databases `csha..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/flags-tags-system",
    "title": "Flags & Tags System",
    "category": "Architecture & Design",
    "url": "/docs/proposals/flags-tags-system",
    "chunks": [
      {
        "id": "proposals/flags-tags-system-chunk-0",
        "text": "Flags & Tags System\nWhizbang provides a sophisticated flags and tags system for message context, enabling dynamic behavior modification, cross-service debugging, and flexible routing throughout the entire message lifecycle Core Concepts\nFlags (Library-Defined)\nHardcoded enum flags provided by Whizbang for common scenarios:\n`csharp{title=\"WhizbangFlags Enum Definition\" description=\"Library-defined flags enum for common development and operational scenarios\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Message-Context\", \"Cross-Service-Communication\"] framework=\"NET8\"}\n[Flags]\npublic enum WhizbangFlags : long {\n    None = 0,\n    // Testing & Development\n    LoadTesting = 1 << 0,           // Don't replay these events\n    DryRun = 1 << 1,                // Execute handlers but don't persist\n    Development = 1 << 2,           // Development mode behaviors\n    TraceReplay = 1 << 3,           // Replay/trace mode\n    // Debugging & Inspection\n    VerboseLogging = 1 << 4,        // Increase logging verbosity\n    VerboseOtel = 1 << 5,           // Increase OpenTelemetry verbosity\n    IgnoreTimeouts = 1 << 6,        // Bypass timeouts for debugging\n    CursorMode = 1 << 7,            // IDE cursor/scrubbing mode\n    Breakpoint = 1 << 8,            // Trigger breakpoints\n    // Security & Compliance\n    SecurityBypass = 1 << 9,        // Bypass security checks (dangerous)\n    DataScrubbing = 1 << 10,        // Scrub sensitive data\n    ComplianceMode = 1 << 11,       // Extra compliance logging\n    // Routing & Delivery\n    AlternativeRouting = 1 << 12,   // Use alternative handlers\n    PriorityDelivery = 1 << 13,     // Expedite processing\n    DelayedProcessing = 1 << 14,    // Defer processing\n    // Environment & Lifecycle\n    Production = 1 << 15,           // Production environment\n    Staging = 1 << 16,              // Staging environment\n    QA = 1 << 17,                   // QA environment\n    Migration = 1 << 18,            // Data migration context\n    // Custom ranges for user-defined flags\n    UserDefined1 = 1 << 32,\n    UserDefined2 = 1 << 33,\n    //",
        "startIndex": 0,
        "preview": "Flags & Tags System\nWhizbang provides a sophisticated flags and tags system for message context, enabling dynamic behavior modification, cross-service..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-1",
        "text": "Production = 1 << 15, // Production environment Staging = 1 << 16, // Staging environment QA = 1 << 17, // QA environment Migration = 1 << 18, // Data migration context // Custom ranges for user-defined flags UserDefined1 = 1 << 32, UserDefined2 = 1 << 33, // up to 1 << 63\n}\n`\nTags (User-Defined)\nArbitrary string tags added by developers for custom scenarios:\n`csharp{title=\"MessageContext with Fluent API\" description=\"Message context class with fluent API for flags and tags management\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Message-Context\", \"Fluent-API\"] framework=\"NET8\"}\npublic class MessageContext {\n    public WhizbangFlags Flags { get; set; }\n    public HashSet<string> Tags { get; set; } = new();\n    public string CorrelationId { get; set; }\n    public string TenantId { get; set; }\n    public string Domain { get; set; }\n    // Fluent API for context building\n    public MessageContext WithTag(string tag) {\n        Tags Add(tag);\n        return this;\n    }\n    public MessageContext WithFlags(WhizbangFlags flags) {\n        Flags |= flags;\n        return this;\n    }\n    public MessageContext WithCorrelationId(string correlationId) {\n        CorrelationId = correlationId;\n        return this;\n    }\n    public bool HasFlag(WhizbangFlags flag) => (Flags & flag) == flag;\n    public bool HasTag(string tag) => Tags Contains(tag);\n    public bool HasAnyTag(params string[] tags) => tags Any(Tags Contains);\n    public bool HasAllTags(params string[] tags) => tags All(Tags Contains);\n}\n// Usage examples\ncontext WithTag(\"customer-priority\") WithTag(\"region-us-west\") WithTag(\"high-value-order\") WithFlags(WhizbangFlags VerboseLogging | WhizbangFlags PriorityDelivery) WithCorrelationId(\"debug-session-123\");\n`\nCross-Service Propagation\nAutomatic Flag Propagation\nFlags carry through entire message journey across service boundaries:\n`csharp{title=\"Cross-Service Flag Propagation\" description=\"Automatic flag and tag propagation across service boundaries\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Cross-Service-Propagation\", \"Debugging\"] framework=\"NET8\"}\n// Service 1: Initial command with debugging flags\nvar command = new PlaceOrder(orderId, customerId, items);\nawait _mediator Send(command, context => {\n    context WithFlags(WhizbangFlags VerboseLogging | WhizbangFlags TraceReplay) WithTag(\"debug-session-123\") WithTag(\"customer-vip\");\n});\n// Flags automatically propagate to:\n// 1 Command handler execution in Service 1\n// 2",
        "startIndex": 2124,
        "preview": "Production = 1 << 15, // Production environment Staging = 1 << 16, // Staging environment QA = 1 << 17, // QA environment Migration = 1 << 18, // Data..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-2",
        "text": "tags=[\"Design\", \"Flags-Tags\", \"Cross-Service-Propagation\", \"Debugging\"] framework=\"NET8\"} // Service 1: Initial command with debugging flags var command = new PlaceOrder(orderId, customerId, items); await _mediator Send(command, context => { context WithFlags(WhizbangFlags VerboseLogging | WhizbangFlags TraceReplay) WithTag(\"debug-session-123\") WithTag(\"customer-vip\"); }); // Flags automatically propagate to: // 1 Command handler execution in Service 1 // 2 Event publishing from Service 1\n// 3 Cross-service event delivery via message broker\n// 4 Event handler execution in Service 2\n// 5 Projection updates in Service 2\n// 6 Saga execution across services\n`csharp{title=\"Context-Aware Event Handler\" description=\"Event handler using propagated flags and tags for conditional processing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Event-Handlers\", \"Context-Aware-Processing\"] framework=\"NET8\"}\n// Service 2: Receives event with same flags and tags\npublic class InventoryHandler : IEventHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, EventContext context) {\n        // context Flags contains VerboseLogging | TraceReplay\n        // context Tags contains \"debug-session-123\", \"customer-vip\"\n        if (context HasFlag(WhizbangFlags VerboseLogging)) {\n            _logger LogInformation(\"Processing order with verbose logging enabled for debug session {DebugSession}\", \n                context Tags FirstOrDefault(t => t StartsWith(\"debug-session\")));\n        }\n        if (context HasTag(\"customer-vip\")) {\n            // Special handling for VIP customers\n            await _vipCustomerService NotifyOrderReceived(@event OrderId);\n        }\n    }\n}\n`\nMessage Context Serialization\nContext travels with messages across all transport mechanisms:\n`csharp{title=\"Message Envelope for Cross-Service Communication\" description=\"Message envelope with context serialization for cross-service communication\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Message-Serialization\", \"Cross-Service\"] framework=\"NET8\"}\n// Message envelope for cross-service communication\npublic class MessageEnvelope<T> {\n    public T Message { get; set; }\n    public MessageContext Context { get; set; }\n    public Dictionary<string, string> Headers { get; set; } = new();\n    public DateTimeOffset Timestamp { get; set; } = DateTimeOffset",
        "startIndex": 4441,
        "preview": "tags=[\"Design\", \"Flags-Tags\", \"Cross-Service-Propagation\", \"Debugging\"] framework=\"NET8\"} // Service 1: Initial command with debugging flags var comma..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-3",
        "text": "category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Message-Serialization\", \"Cross-Service\"] framework=\"NET8\"} // Message envelope for cross-service communication public class MessageEnvelope<T> { public T Message { get; set; } public MessageContext Context { get; set; } public Dictionary<string, string> Headers { get; set; } = new(); public DateTimeOffset Timestamp { get; set; } = DateTimeOffset UtcNow;\n}\n`csharp{title=\"Kafka Message Publisher\" description=\"Kafka message publisher with automatic context serialization\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Kafka\", \"Message-Brokers\"] framework=\"NET8\"}\n// Automatic context serialization in message brokers\npublic class KafkaMessagePublisher : IMessagePublisher {\n    public async Task PublishAsync<T>(T message, MessageContext context) {\n        var envelope = new MessageEnvelope<T> {\n            Message = message,\n            Context = context,\n            Headers = new Dictionary<string, string> {\n                [\"whizbang-flags\"] = ((long)context Flags) ToString(),\n                [\"whizbang-tags\"] = string Join(\",\", context Tags),\n                [\"whizbang-correlation-id\"] = context CorrelationId \"\",\n                [\"whizbang-tenant-id\"] = context TenantId \"\",\n                [\"whizbang-domain\"] = context Domain \"\"\n            }\n        };\n        await _kafkaProducer ProduceAsync(GetTopicName<T>(), envelope);\n    }\n}\n`\nDebugging and Development Features\nIDE Cursor/Scrubbing Mode\nInteractive debugging with state inspection:\n`csharp{title=\"IDE Cursor Mode Handler\" description=\"IDE integration for interactive debugging with state inspection\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"IDE-Integration\", \"Debugging\", \"Cursor-Mode\"] framework=\"NET8\"}\n// IDE integration for step-by-step debugging\npublic class CursorModeHandler : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        if (context HasFlag(WhizbangFlags CursorMode)) {\n            // Capture pre-execution state\n            var preState = await _stateCapture CaptureStateAsync(context);\n            // Notify IDE of execution point\n            await _ideNotificationService NotifyExecutionPoint(new ExecutionPoint {\n                MessageType = typeof(TRequest) Name,\n                HandlerType = context HandlerType Name,\n                CorrelationId = context CorrelationId,\n                State = preState,\n                CanStepForward = true,\n                CanStepBackward = true\n            });\n            // Wait for IDE to signal continue\n            await _ideNotificationService WaitForContinueSignal(context CorrelationId);\n        }\n        var response = await next(message, context);\n        if (context HasFlag(WhizbangFlags CursorMode)) {\n            // Capture post-execution state\n            var postState = await _stateCapture CaptureStateAsync(context);\n            await _ideNotificationService NotifyExecutionComplete(new ExecutionResult {\n                CorrelationId = context CorrelationId,\n                Response = response,\n                PostState = postState,\n                ExecutionTime = context",
        "startIndex": 6383,
        "preview": "category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Message-Serialization\", \"Cross-Service\"] framework=\"NET8\"} // Message envel..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-4",
        "text": "Wait for IDE to signal continue await _ideNotificationService WaitForContinueSignal(context CorrelationId); } var response = await next(message, context); if (context HasFlag(WhizbangFlags CursorMode)) { // Capture post-execution state var postState = await _stateCapture CaptureStateAsync(context); await _ideNotificationService NotifyExecutionComplete(new ExecutionResult { CorrelationId = context CorrelationId, Response = response, PostState = postState, ExecutionTime = context ExecutionTime\n            });\n        }\n        return response;\n    }\n}\n`\nBreakpoint System\nProgrammatic breakpoints triggered by flags:\n`csharp{title=\"Programmatic Breakpoint Handler\" description=\"Programmatic breakpoint system triggered by flags for debugging\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"Debugging\", \"Breakpoints\", \"Development-Tools\"] framework=\"NET8\"}\npublic class BreakpointHandler : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        if (context HasFlag(WhizbangFlags Breakpoint)) {\n            var breakpointContext = new BreakpointContext {\n                BreakpointId = Guid NewGuid(),\n                MessageType = typeof(TRequest) Name,\n                Message = message,\n                Context = context,\n                StackTrace = Environment StackTrace,\n                Timestamp = DateTimeOffset UtcNow\n            };\n            // Store breakpoint information\n            await _breakpointStore StoreBreakpointAsync(breakpointContext);\n            // Notify debugging tools\n            await _debuggerNotificationService NotifyBreakpointHit(breakpointContext);\n            // Optionally pause execution for attached debuggers\n            if (_debuggerService IsAttached) {\n                System Diagnostics Debugger Break();\n            }\n        }\n        return await next(message, context);\n    }\n}\n`\nData Scrubbing and Security\nAutomatic Data Scrubbing\nPolicy-driven data sanitization based on flags:\n`csharp{title=\"Data Scrubbing Interceptor\" description=\"Policy-driven data sanitization based on flags for security compliance\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"Data-Scrubbing\", \"Security\", \"Privacy\"] framework=\"NET8\"}\npublic class DataScrubbingInterceptor : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        TRequest processedMessage = message;\n        if (context HasFlag(WhizbangFlags DataScrubbing)) {\n            // Apply data scrubbing rules\n            processedMessage = await _dataScrubber ScrubAsync(message, new ScrubOptions {\n                ScrubPersonalData = true,\n                ScrubFinancialData = true,\n                ScrubSensitiveFields = true,\n                PreserveFunctionality = true,\n                AddScrubbedMarkers = true\n            });\n            // Add scrubbing metadata to context\n            context Tags Add(\"data-scrubbed\");\n            context Tags Add($\"scrubbed-at-{DateTimeOffset",
        "startIndex": 9298,
        "preview": "Wait for IDE to signal continue await _ideNotificationService WaitForContinueSignal(context CorrelationId); } var response = await next(message, conte..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-5",
        "text": "TRequest processedMessage = message; if (context HasFlag(WhizbangFlags DataScrubbing)) { // Apply data scrubbing rules processedMessage = await _dataScrubber ScrubAsync(message, new ScrubOptions { ScrubPersonalData = true, ScrubFinancialData = true, ScrubSensitiveFields = true, PreserveFunctionality = true, AddScrubbedMarkers = true }); // Add scrubbing metadata to context context Tags Add(\"data-scrubbed\"); context Tags Add($\"scrubbed-at-{DateTimeOffset UtcNow:yyyy-MM-dd-HH-mm-ss}\");\n        }\n        return await next(processedMessage, context);\n    }\n}\n`csharp{title=\"Order Data Scrubber Implementation\" description=\"Concrete data scrubber implementation for order data sanitization\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Data-Scrubbing\", \"Implementation\"] framework=\"NET8\"}\n// Data scrubbing rules\npublic class OrderDataScrubber : IDataScrubber<PlaceOrder> {\n    public async Task<PlaceOrder> ScrubAsync(PlaceOrder order, ScrubOptions options) {\n        return order with {\n            // Scrub customer email\n            CustomerEmail = options ScrubPersonalData ScrubEmail(order CustomerEmail) : order CustomerEmail,\n            // Scrub payment information\n            PaymentToken = options ScrubFinancialData \"[SCRUBBED-PAYMENT-TOKEN]\" : order PaymentToken,\n            // Preserve order structure but scrub sensitive data\n            Items = order Items Select(item => item with {\n                ProductName = options PreserveFunctionality item ProductName : $\"Product-{item ProductId ToString()[ 8]}\"\n            }) ToList()\n        };\n    }\n}\n`\nProduction to QA Data Flow\nSecure data replication with automatic scrubbing:\n`csharp{title=\"Production to QA Data Replicator\" description=\"Secure data replication from production to QA with automatic scrubbing\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"Production-to-QA\", \"Data-Replication\"] framework=\"NET8\"}\n// Handler that duplicates production messages to QA with scrubbing\npublic class ProductionToQAReplicator : IEventHandler<object> {\n    public async Task Handle(object @event, EventContext context) {\n        // Only replicate events tagged for QA replication\n        if (context HasTag(\"production-data\") && \n            context HasFlag(WhizbangFlags QA)) {\n            // Create a copy with scrubbing flag\n            var qaCopy = @event;\n            var qaContext = context Copy() WithFlag(WhizbangFlags DataScrubbing) WithTag(\"qa-replicated\") WithTag($\"replicated-from-production-{DateTimeOffset UtcNow:yyyy-MM-dd}\");\n            // Remove production-specific tags\n            qaContext Tags Remove(\"production-data\");\n            qaContext Tags Remove(\"customer-vip\"); // Don't carry VIP status to QA\n            // Route to QA environment\n            await _qaEventPublisher",
        "startIndex": 12060,
        "preview": "TRequest processedMessage = message; if (context HasFlag(WhizbangFlags DataScrubbing)) { // Apply data scrubbing rules processedMessage = await _dataS..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-6",
        "text": "&& context HasFlag(WhizbangFlags QA)) { // Create a copy with scrubbing flag var qaCopy = @event; var qaContext = context Copy() WithFlag(WhizbangFlags DataScrubbing) WithTag(\"qa-replicated\") WithTag($\"replicated-from-production-{DateTimeOffset UtcNow:yyyy-MM-dd}\"); // Remove production-specific tags qaContext Tags Remove(\"production-data\"); qaContext Tags Remove(\"customer-vip\"); // Don't carry VIP status to QA // Route to QA environment await _qaEventPublisher PublishAsync(qaCopy, qaContext);\n        }\n    }\n}\n`\nPerformance and Load Testing\nLoad Testing Flag Handling\nOptimize behavior for load testing scenarios:\n`csharp{title=\"Load Testing Optimizer\" description=\"Load testing optimization interceptor with flag-based behavior modification\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Load-Testing\", \"Performance-Optimization\"] framework=\"NET8\"}\npublic class LoadTestingOptimizer : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        if (context HasFlag(WhizbangFlags LoadTesting)) {\n            // Optimize for load testing\n            using var loadTestScope = _performanceOptimizer EnterLoadTestMode();\n            // Disable slow operations\n            context Tags Add(\"skip-audit-logging\");\n            context Tags Add(\"skip-analytics-tracking\");\n            context Tags Add(\"minimal-validation\");\n            // Add load test metadata\n            context Tags Add($\"load-test-batch-{GetLoadTestBatch()}\");\n            context Tags Add($\"load-test-thread-{Thread CurrentThread ManagedThreadId}\");\n            // Execute with load test optimizations\n            return await next(message, context);\n        }\n        return await next(message, context);\n    }\n    private string GetLoadTestBatch() {\n        // Identify which load test batch this belongs to\n        return Environment GetEnvironmentVariable(\"LOAD_TEST_BATCH_ID\") \"unknown\";\n    }\n}\n`\nAdvanced Routing Scenarios\nDynamic Handler Selection\nRoute to different handlers based on flags and tags:\n`csharp{title=\"Context-Aware Handler Factory\" description=\"Dynamic handler selection based on flags and tags for flexible routing\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"Dynamic-Routing\", \"Handler-Selection\"] framework=\"NET8\"}\n// Handler factory that selects implementation based on context\npublic class ContextAwareHandlerFactory<T> : ICommandHandler<T> where T : ICommand {\n    private readonly IServiceProvider _serviceProvider;\n    private readonly IHandlerRoutingRules _routingRules;\n    public async Task Handle(T command, MessageContext context) {\n        var handlerType = await _routingRules DetermineHandlerType<T>(context);\n        var handler = (ICommandHandler<T>)_serviceProvider GetRequiredService(handlerType);\n        return await handler",
        "startIndex": 14479,
        "preview": "&& context HasFlag(WhizbangFlags QA)) { // Create a copy with scrubbing flag var qaCopy = @event; var qaContext = context Copy() WithFlag(WhizbangFlag..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-7",
        "text": "framework=\"NET8\"} // Handler factory that selects implementation based on context public class ContextAwareHandlerFactory<T> : ICommandHandler<T> where T : ICommand { private readonly IServiceProvider _serviceProvider; private readonly IHandlerRoutingRules _routingRules; public async Task Handle(T command, MessageContext context) { var handlerType = await _routingRules DetermineHandlerType<T>(context); var handler = (ICommandHandler<T>)_serviceProvider GetRequiredService(handlerType); return await handler Handle(command, context);\n    }\n}\n`csharp{title=\"Handler Routing Rules\" description=\"Context-based routing rules for handler type determination\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Flags-Tags\", \"Routing-Rules\", \"Handler-Selection\"] framework=\"NET8\"}\n// Routing rules based on context\npublic class HandlerRoutingRules : IHandlerRoutingRules {\n    public async Task<Type> DetermineHandlerType<T>(MessageContext context) {\n        // VIP customers get premium handler\n        if (context HasTag(\"customer-vip\")) {\n            return typeof(PremiumOrderHandler);\n        }\n        // Load testing gets optimized handler\n        if (context HasFlag(WhizbangFlags LoadTesting)) {\n            return typeof(LoadTestOptimizedOrderHandler);\n        }\n        // Migration data gets special handler\n        if (context HasFlag(WhizbangFlags Migration)) {\n            return typeof(DataMigrationOrderHandler);\n        }\n        // Default handler\n        return typeof(StandardOrderHandler);\n    }\n}\n`\nConfiguration and Management\nFlag Management\nControl flag behavior through configuration:\n`csharp{title=\"Flag Management Configuration\" description=\"Flag management configuration with environment-based defaults and validation\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Configuration\", \"Environment-Management\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Flags(flags => {\n        // Environment-based flag defaults\n        if (_environment IsDevelopment()) {\n            flags DefaultFlags = WhizbangFlags Development | WhizbangFlags VerboseLogging;\n        } else if (_environment IsProduction()) {\n            flags DefaultFlags = WhizbangFlags Production;\n            flags RestrictedFlags = WhizbangFlags SecurityBypass | WhizbangFlags DataScrubbing;\n        }\n        // Flag validation rules\n        flags AddValidationRule(ctx => {\n            if (ctx HasFlag(WhizbangFlags SecurityBypass) && ctx HasTag(\"authorized-security-bypass\")) {\n                throw new UnauthorizedFlagException(\"SecurityBypass flag requires authorization\");\n            }\n        });\n        // Automatic flag addition based on context\n        flags AddAutoFlag(WhizbangFlags ComplianceMode, \n            condition: ctx => ctx HasTag(\"pci-data\") || ctx",
        "startIndex": 16969,
        "preview": "framework=\"NET8\"} // Handler factory that selects implementation based on context public class ContextAwareHandlerFactory<T> : ICommandHandler<T> wher..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-8",
        "text": "flags RestrictedFlags = WhizbangFlags SecurityBypass | WhizbangFlags DataScrubbing; } // Flag validation rules flags AddValidationRule(ctx => { if (ctx HasFlag(WhizbangFlags SecurityBypass) && ctx HasTag(\"authorized-security-bypass\")) { throw new UnauthorizedFlagException(\"SecurityBypass flag requires authorization\"); } }); // Automatic flag addition based on context flags AddAutoFlag(WhizbangFlags ComplianceMode, condition: ctx => ctx HasTag(\"pci-data\") || ctx HasTag(\"gdpr-data\"));\n    });\n});\n`\nTag Lifecycle Management\nManage tag propagation and cleanup:\n`csharp{title=\"Tag Lifecycle Manager\" description=\"Tag lifecycle management with automatic addition and cleanup\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Flags-Tags\", \"Tag-Lifecycle\", \"Management\"] framework=\"NET8\"}\npublic class TagLifecycleManager : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        // Add automatic tags\n        context Tags Add($\"processed-at-{Environment MachineName}\");\n        context Tags Add($\"handler-{typeof(TRequest) Name}\");\n        // Remove expired tags\n        var expiredTags = context Tags Where(tag => tag StartsWith(\"session-\") && IsSessionExpired(tag)) ToList();\n        foreach (var expiredTag in expiredTags) {\n            context Tags Remove(expiredTag);\n        }\n        var response = await next(message, context);\n        // Add response-based tags\n        if (response is ISuccessResult) {\n            context Tags Add(\"execution-success\");\n        } else if (response is IErrorResult error) {\n            context Tags Add($\"execution-error-{error ErrorCode}\");\n        }\n        return response;\n    }\n}\n`\nBest Practices\nFlag Usage Guidelines\nUse library flags first - Prefer built-in flags over custom tags when possible\nDocument custom flags - Make user-defined flags clear to the team\nBe conservative with propagation - Not all flags should cross service boundaries\nConsider flag lifetime - How long should flags persist in the system\nAudit flag usage - Track which flags are used and where\nTag Design Principles\nHierarchical naming - Use consistent naming conventions (e g",
        "startIndex": 19273,
        "preview": "flags RestrictedFlags = WhizbangFlags SecurityBypass | WhizbangFlags DataScrubbing; } // Flag validation rules flags AddValidationRule(ctx => { if (ct..."
      },
      {
        "id": "proposals/flags-tags-system-chunk-9",
        "text": "to the team Be conservative with propagation - Not all flags should cross service boundaries Consider flag lifetime - How long should flags persist in the system Audit flag usage - Track which flags are used and where Tag Design Principles Hierarchical naming - Use consistent naming conventions (e g , \"customer-vip\", \"region-us-west\")\nMeaningful values - Tags should be self-documenting\nAvoid high cardinality - Don't create too many unique tag combinations\nLifecycle awareness - Consider when tags should be added/removed\nSecurity sensitivity - Don't include sensitive data in tag names\nSecurity Considerations\nValidate flag sources - Ensure flags come from trusted sources\nLimit dangerous flags - SecurityBypass should be heavily restricted\nAudit flag changes - Log all flag modifications\nEncrypt sensitive tags - Some tags may contain sensitive information\nPrinciple of least privilege - Flags should grant minimal necessary permissions\n---\nRelated Documentation\nPolicy Engine - How policies use flags and tags for decision making\nObservability & Metrics - Flag-driven observability levels\nTesting & Development Tools - Testing with flags and tags",
        "startIndex": 21102,
        "preview": "to the team Be conservative with propagation - Not all flags should cross service boundaries Consider flag lifetime - How long should flags persist in..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/multi-tenancy",
    "title": "Multi-Tenancy",
    "category": "Architecture & Design",
    "url": "/docs/proposals/multi-tenancy",
    "chunks": [
      {
        "id": "proposals/multi-tenancy-chunk-0",
        "text": "Multi-Tenancy\nWhizbang provides comprehensive multi-tenancy support with flexible tenant isolation strategies, from single database with row-level security to complete database separation Tenant Isolation Strategies\nSingle Database with Tenant ID\nRow-level tenant isolation using tenant ID columns:\n`sql\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Multi-Tenancy, SQL, Row-Level-Security]\ndescription: SQL schema for tenant-isolated events table with row-level security\n---\n-- Events table with tenant isolation\nCREATE TABLE events (\n    event_id BIGSERIAL PRIMARY KEY,\n    stream_id VARCHAR(255) NOT NULL,\n    stream_version INT NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    event_data JSONB NOT NULL,\n    metadata JSONB,\n    tenant_id UUID NOT NULL,  -- Tenant isolation\n    created_at TIMESTAMPTZ NOT NULL,\n    UNIQUE(tenant_id, stream_id, stream_version)\n);\n-- Projections table with tenant isolation\nCREATE TABLE projections (\n    projection_name VARCHAR(255) NOT NULL,\n    document_id VARCHAR(255) NOT NULL,\n    document JSONB NOT NULL,\n    tenant_id UUID NOT NULL,  -- Tenant isolation\n    version BIGINT NOT NULL,\n    last_updated TIMESTAMPTZ NOT NULL,\n    PRIMARY KEY (projection_name, document_id, tenant_id)\n);\n-- Row-level security policies\nCREATE POLICY tenant_isolation_events ON events\n    USING (tenant_id = current_setting('app current_tenant_id')::UUID);\nCREATE POLICY tenant_isolation_projections ON projections  \n    USING (tenant_id = current_setting('app current_tenant_id')::UUID);\n`\nMultiple Databases\nComplete database separation per tenant:\n`csharp{\ntitle: \"Separate Database Configuration\",\ndescription: \"Configuration for complete database separation per tenant\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"Configuration\", \"Separate-Databases\", \"Database-Per-Tenant\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options MultiTenancy(tenancy => {\n        tenancy Strategy = TenancyStrategy SeparateDatabases;\n        tenancy DatabaseProvider = (tenantId) => {\n            return $\"Host=db-server;Database=tenant_{tenantId};Username=app;Password=secret\";\n        };\n        // Database creation for new tenants\n        tenancy AutoCreateDatabases = true;\n        tenancy",
        "startIndex": 0,
        "preview": "Multi-Tenancy\nWhizbang provides comprehensive multi-tenancy support with flexible tenant isolation strategies, from single database with row-level sec..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-1",
        "text": "complete database separation per tenant\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Multi-Tenancy\", \"Configuration\", \"Separate-Databases\", \"Database-Per-Tenant\"], framework: \"NET8\" } services AddWhizbang(options => { options MultiTenancy(tenancy => { tenancy Strategy = TenancyStrategy SeparateDatabases; tenancy DatabaseProvider = (tenantId) => { return $\"Host=db-server;Database=tenant_{tenantId};Username=app;Password=secret\"; }; // Database creation for new tenants tenancy AutoCreateDatabases = true; tenancy DatabaseTemplate = \"tenant_template\";\n    });\n});\n`\nSame Table with Partitioning\nTable partitioning by tenant for performance:\n`sql\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Multi-Tenancy, SQL, Table-Partitioning, Performance]\ndescription: Table partitioning by tenant for performance optimization\n---\n-- Partitioned events table\nCREATE TABLE events (\n    event_id BIGSERIAL,\n    stream_id VARCHAR(255) NOT NULL,\n    stream_version INT NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    event_data JSONB NOT NULL,\n    metadata JSONB,\n    tenant_id UUID NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL\n) PARTITION BY HASH (tenant_id);\n-- Create partitions\nCREATE TABLE events_p0 PARTITION OF events FOR VALUES WITH (MODULUS 4, REMAINDER 0);\nCREATE TABLE events_p1 PARTITION OF events FOR VALUES WITH (MODULUS 4, REMAINDER 1);\nCREATE TABLE events_p2 PARTITION OF events FOR VALUES WITH (MODULUS 4, REMAINDER 2);\nCREATE TABLE events_p3 PARTITION OF events FOR VALUES WITH (MODULUS 4, REMAINDER 3);\n`\nTenant ID Definition\nDefault Tenant ID Field\nStandard GUID-based tenant identification:\n`csharp{\ntitle: \"Default Tenant ID Definition\",\ndescription: \"Standard tenant ID definition using property conventions and strong types\",\ncategory: \"Design\",\ndifficulty: \"BEGINNER\",\ntags: [\"Multi-Tenancy\", \"Domain-Models\", \"Tenant-ID\", \"Strong-Types\"],\nframework: \"NET8\"\n}\n// Default: Look for TenantId property\npublic class Order : Aggregate {\n    public Guid Id { get; private set; }\n    public Guid TenantId { get; private set; } // Automatically detected\n    public decimal Total { get; private set; }\n    public Order(Guid tenantId, Guid id) {\n        TenantId = tenantId;\n        Id = id;\n    }\n}\n// Strong-typed tenant ID\npublic record TenantId(Guid Value) : StrongTypeId<Guid>(Value);\npublic class Order : Aggregate {\n    public Guid Id { get; private set; }\n    public TenantId TenantId { get; private set; } // Strong type detected\n    public decimal Total { get; private set; }\n}\n`\nComposite Tenant ID\nMulti-field tenant identification:\n`csharp{\ntitle: \"Composite Tenant ID Configuration\",\ndescription: \"Multi-field tenant identification for complex organizational structures\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Composite-Tenant-ID\", \"Configuration\", \"Organization-Structure\"],\nframework: \"NET8\"\n}\nservices",
        "startIndex": 2261,
        "preview": "complete database separation per tenant\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Multi-Tenancy\", \"Configuration\", \"Separate-Databases\", \"..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-2",
        "text": "private set; } // Strong type detected public decimal Total { get; private set; } } ` Composite Tenant ID Multi-field tenant identification: `csharp{ title: \"Composite Tenant ID Configuration\", description: \"Multi-field tenant identification for complex organizational structures\", category: \"Design\", difficulty: \"INTERMEDIATE\", tags: [\"Multi-Tenancy\", \"Composite-Tenant-ID\", \"Configuration\", \"Organization-Structure\"], framework: \"NET8\" } services AddWhizbang(options => {\n    options MultiTenancy(tenancy => {\n        tenancy TenantIdComposition<Order>(composition => {\n            composition FromFields(order => new { \n                order OrganizationId, \n                order DivisionId \n            });\n        });\n        tenancy TenantIdComposition<Customer>(composition => {\n            composition FromFields(customer => customer CompanyId);\n        });\n    });\n});\n// Usage in aggregates\npublic class Order : Aggregate {\n    public Guid Id { get; private set; }\n    public Guid OrganizationId { get; private set; } // Part of tenant ID\n    public Guid DivisionId { get; private set; }     // Part of tenant ID\n    public Guid CustomerId { get; private set; }\n}\n`\nCustom Tenant Resolution\nComplex tenant identification logic:\n`csharp{\ntitle: \"Custom Tenant Resolution\",\ndescription: \"Custom tenant identification logic for complex business scenarios\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"Custom-Resolution\", \"Business-Logic\", \"Configuration\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options MultiTenancy(tenancy => {\n        tenancy TenantResolver<Order>(order => {\n            // Custom logic to determine tenant\n            if (order OrganizationId == SpecialOrgId) {\n                return $\"special-{order DivisionId}\";\n            }\n            return order OrganizationId ToString();\n        });\n    });\n});\n`\nTenant Context Management\nTenant Context Propagation\n`csharp{\ntitle: \"Tenant Context Interface\",\ndescription: \"Interface for managing current tenant state and context\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Context-Management\", \"Interfaces\", \"State-Management\"],\nframework: \"NET8\"\n}\npublic interface ITenantContext {\n    string CurrentTenantId { get; }\n    void SetTenant(string tenantId);\n    void ClearTenant();\n    bool HasTenant { get; }\n}\n`csharp{\ntitle: \"Tenant Context Middleware\",\ndescription: \"ASP NET Core middleware for automatic tenant context propagation from multiple sources\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"ASP NET-Core\", \"Middleware\", \"Context-Propagation\"],\nframework: \"NET8\"\n}\n// ASP",
        "startIndex": 1875,
        "preview": "private set; } // Strong type detected public decimal Total { get; private set; } } ` Composite Tenant ID Multi-field tenant identification: `csharp{ ..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-3",
        "text": "{ string CurrentTenantId { get; } void SetTenant(string tenantId); void ClearTenant(); bool HasTenant { get; } } `csharp{ title: \"Tenant Context Middleware\", description: \"ASP NET Core middleware for automatic tenant context propagation from multiple sources\", category: \"Design\", difficulty: \"INTERMEDIATE\", tags: [\"Multi-Tenancy\", \"ASP NET-Core\", \"Middleware\", \"Context-Propagation\"], framework: \"NET8\" } // ASP NET Core middleware\npublic class TenantContextMiddleware {\n    public async Task InvokeAsync(HttpContext context, RequestDelegate next) {\n        var tenantId = ExtractTenantId(context);\n        if (tenantId = null) {\n            _tenantContext SetTenant(tenantId);\n        }\n        try {\n            await next(context);\n        } finally {\n            _tenantContext ClearTenant();\n        }\n    }\n    private string ExtractTenantId(HttpContext context) {\n        // From header\n        if (context Request Headers TryGetValue(\"X-Tenant-ID\", out var headerValue)) {\n            return headerValue;\n        }\n        // From subdomain\n        var host = context Request Host Host;\n        if (host Contains(' ')) {\n            var subdomain = host Split(' ')[0];\n            return subdomain = \"www\" subdomain : null;\n        }\n        // From route\n        if (context Request RouteValues TryGetValue(\"tenantId\", out var routeValue)) {\n            return routeValue ToString();\n        }\n        return null;\n    }\n}\n`\nTenant-Aware Command/Event Handling\n`csharp{\ntitle: \"Tenant-Aware Command Handler\",\ndescription: \"Command handler implementation with tenant context validation and isolation\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Command-Handlers\", \"Domain-Logic\", \"Context-Validation\"],\nframework: \"NET8\"\n}\npublic class PlaceOrderHandler : ICommandHandler<PlaceOrder> {\n    private readonly ITenantContext _tenantContext;\n    private readonly IOrderRepository _repository;\n    public async Task<OrderPlaced> Handle(PlaceOrder command) {\n        var tenantId = _tenantContext CurrentTenantId throw new InvalidOperationException(\"No tenant context\");\n        var order = new Order(\n            tenantId: Guid Parse(tenantId),\n            orderId: command OrderId,\n            customerId: command CustomerId,\n            items: command Items\n        );\n        await _repository Save(order);\n        return new OrderPlaced(\n            command OrderId,\n            command CustomerId,\n            DateTimeOffset UtcNow\n        ) {\n            TenantId = tenantId // Automatically added to event metadata\n        };\n    }\n}\n`\nTenant-Aware Projections\nProjection-Level Isolation\n`csharp{\ntitle: \"Tenant-Specific Projection\",\ndescription: \"Tenant-specific projection configuration with isolation controls\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Projections\", \"Tenant-Isolation\", \"Event-Handling\"],\nframework: \"NET8\"\n}\nservices AddProjection<OrderSummaryProjection>(options => {\n    options TenantIsolation(isolation => {\n        isolation",
        "startIndex": 6830,
        "preview": "{ string CurrentTenantId { get; } void SetTenant(string tenantId); void ClearTenant(); bool HasTenant { get; } } `csharp{ title: \"Tenant Context Middl..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-4",
        "text": "{ TenantId = tenantId // Automatically added to event metadata }; } } ` Tenant-Aware Projections Projection-Level Isolation `csharp{ title: \"Tenant-Specific Projection\", description: \"Tenant-specific projection configuration with isolation controls\", category: \"Design\", difficulty: \"INTERMEDIATE\", tags: [\"Multi-Tenancy\", \"Projections\", \"Tenant-Isolation\", \"Event-Handling\"], framework: \"NET8\" } services AddProjection<OrderSummaryProjection>(options => { options TenantIsolation(isolation => { isolation Strategy = ProjectionTenantStrategy TenantSpecific;\n        isolation AllowCrossTenantQueries = false;\n    });\n});\npublic class OrderSummaryProjection : IProjectionHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, ProjectionContext context) {\n        var tenantId = context TenantId; // Automatically extracted\n        var summary = new OrderSummary {\n            OrderId = @event OrderId,\n            TenantId = tenantId,\n            Total = @event Total\n        };\n        // Stored with tenant isolation\n        await context Store(@event OrderId ToString(), summary);\n    }\n}\n`\nCross-Tenant Projections\nGlobal projections that aggregate across tenants:\n`csharp{\ntitle: \"Cross-Tenant Analytics Projection\",\ndescription: \"Cross-tenant projection for global analytics and reporting across all tenants\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"Projections\", \"Cross-Tenant\", \"Analytics\", \"Global-Data\"],\nframework: \"NET8\"\n}\nservices AddProjection<GlobalAnalyticsProjection>(options => {\n    options TenantIsolation(isolation => {\n        isolation Strategy = ProjectionTenantStrategy CrossTenant;\n        isolation RequireExplicitTenantAccess = true;\n    });\n});\npublic class GlobalAnalyticsProjection : IProjectionHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, ProjectionContext context) {\n        // Access to all tenant data for analytics\n        var analytics = await context LoadGlobal<GlobalAnalytics>(\"summary\");\n        analytics = new GlobalAnalytics();\n        analytics TotalOrders++;\n        analytics TotalRevenue += @event Total;\n        analytics OrdersByTenant[context TenantId] = \n            analytics OrdersByTenant GetValueOrDefault(context TenantId) + 1;\n        await context StoreGlobal(\"summary\", analytics);\n    }\n}\n`\nDriver Support for Multi-Tenancy\nPostgreSQL Driver\n`csharp{\ntitle: \"PostgreSQL Tenant-Aware Driver\",\ndescription: \"PostgreSQL driver implementation with tenant isolation support for event storage\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"Drivers\", \"PostgreSQL\", \"Event-Store\", \"Data-Access\"],\nframework: \"NET8\"\n}\npublic class PostgresTenantDriver : IEventStoreDriver {\n    public async Task<IEnumerable<Event>> ReadEvents(string streamId, string tenantId = null) {\n        var sql = tenantId = null",
        "startIndex": 9462,
        "preview": "{ TenantId = tenantId // Automatically added to event metadata }; } } ` Tenant-Aware Projections Projection-Level Isolation `csharp{ title: \"Tenant-Sp..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-5",
        "text": "title: \"PostgreSQL Tenant-Aware Driver\", description: \"PostgreSQL driver implementation with tenant isolation support for event storage\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Multi-Tenancy\", \"Drivers\", \"PostgreSQL\", \"Event-Store\", \"Data-Access\"], framework: \"NET8\" } public class PostgresTenantDriver : IEventStoreDriver { public async Task<IEnumerable<Event>> ReadEvents(string streamId, string tenantId = null) { var sql = tenantId = null \"SELECT * FROM events WHERE stream_id = @streamId AND tenant_id = @tenantId ORDER BY stream_version\"\n            : \"SELECT * FROM events WHERE stream_id = @streamId ORDER BY stream_version\";\n        return await _connection QueryAsync<Event>(sql, new { streamId, tenantId });\n    }\n    public async Task AppendEvents(string streamId, IEnumerable<Event> events, string tenantId = null) {\n        if (tenantId == null) {\n            throw new InvalidOperationException(\"Tenant ID required for event storage\");\n        }\n        foreach (var @event in events) {\n            @event TenantId = tenantId;\n        }\n        await _connection ExecuteAsync(\n            \"INSERT INTO events (stream_id, stream_version, event_type, event_data, tenant_id, created_at) \" +\n            \"VALUES (@StreamId, @StreamVersion, @EventType, @EventData, @TenantId, @CreatedAt)\",\n            events\n        );\n    }\n}\n`\nAbstract Driver Interface\n`csharp{\ntitle: \"Tenant-Aware Driver Interface\",\ndescription: \"Abstract driver interface for tenant-aware data operations with cross-tenant support\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Drivers\", \"Interfaces\", \"Architecture\", \"Data-Access\"],\nframework: \"NET8\"\n}\npublic interface ITenantAwareDriver {\n    Task<T> Load<T>(string id, string tenantId = null);\n    Task Save<T>(T entity, string tenantId = null);\n    Task<IEnumerable<T>> Query<T>(Expression<Func<T, bool>> predicate, string tenantId = null);\n    // Cross-tenant operations (require special permissions)\n    Task<IEnumerable<T>> QueryAllTenants<T>(Expression<Func<T, bool>> predicate);\n    Task<Dictionary<string, IEnumerable<T>>> QueryByTenant<T>(Expression<Func<T, bool>> predicate);\n}\n`\nSecurity and Authorization\nTenant-Based Authorization\n`csharp{\ntitle: \"Tenant-Based Authorization\",\ndescription: \"Tenant-based authorization configuration with isolation enforcement and policies\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Security\", \"Authorization\", \"ASP NET-Core\", \"Policies\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options Authorization(auth => {\n        auth RequireTenantContext = true;\n        auth EnforceTenantIsolation = true;\n        auth AddPolicy(\"TenantAdmin\", policy => {\n            policy RequireClaim(\"tenant_id\");\n            policy RequireClaim(\"role\", \"admin\");\n        });\n        auth AddPolicy(\"CrossTenantRead\", policy => {\n            policy",
        "startIndex": 11827,
        "preview": "title: \"PostgreSQL Tenant-Aware Driver\", description: \"PostgreSQL driver implementation with tenant isolation support for event storage\", category: \"D..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-6",
        "text": "enforcement and policies\", category: \"Design\", difficulty: \"INTERMEDIATE\", tags: [\"Multi-Tenancy\", \"Security\", \"Authorization\", \"ASP NET-Core\", \"Policies\"], framework: \"NET8\" } services AddWhizbang(options => { options Authorization(auth => { auth RequireTenantContext = true; auth EnforceTenantIsolation = true; auth AddPolicy(\"TenantAdmin\", policy => { policy RequireClaim(\"tenant_id\"); policy RequireClaim(\"role\", \"admin\"); }); auth AddPolicy(\"CrossTenantRead\", policy => { policy RequireClaim(\"permission\", \"cross_tenant_read\");\n        });\n    });\n});\n[Authorize(\"TenantAdmin\")]\npublic class OrderController : ControllerBase {\n    [HttpGet]\n    public async Task<IActionResult> GetOrders() {\n        // Automatically filtered by tenant context\n        var orders = await _orderQuery GetOrdersForCurrentTenant();\n        return Ok(orders);\n    }\n    [HttpGet(\"all-tenants\")]\n    [Authorize(\"CrossTenantRead\")]\n    public async Task<IActionResult> GetOrdersAllTenants() {\n        // Requires special permission\n        var orders = await _orderQuery GetOrdersAllTenants();\n        return Ok(orders);\n    }\n}\n`\nRow-Level Security Integration\n`csharp{\ntitle: \"Row-Level Security Configuration\",\ndescription: \"PostgreSQL row-level security integration for automatic tenant isolation\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"PostgreSQL\", \"Row-Level-Security\", \"Configuration\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options UsePostgres(connectionString, postgres => {\n        postgres EnableRowLevelSecurity = true;\n        postgres TenantContextVariable = \"app current_tenant_id\";\n    });\n});\n`csharp{\ntitle: \"Tenant-Aware Connection Factory\",\ndescription: \"Database connection factory with automatic tenant context setting for RLS\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"PostgreSQL\", \"Connection-Factory\", \"Context-Propagation\"],\nframework: \"NET8\"\n}\n// Automatically sets tenant context for all database operations\npublic class PostgresTenantConnectionFactory : IDbConnectionFactory {\n    public async Task<IDbConnection> CreateConnection() {\n        var connection = new NpgsqlConnection(_connectionString);\n        await connection OpenAsync();\n        var tenantId = _tenantContext CurrentTenantId;\n        if (tenantId = null) {\n            await connection ExecuteAsync(\n                \"SET app current_tenant_id = @tenantId\", \n                new { tenantId }\n            );\n        }\n        return connection;\n    }\n}\n`\nConfiguration Examples\nComprehensive Multi-Tenancy Setup\n`csharp{\ntitle: \"Comprehensive Multi-Tenancy Setup\",\ndescription: \"Complete multi-tenancy configuration with all options and strategies\",\ncategory: \"Design\",\ndifficulty: \"ADVANCED\",\ntags: [\"Multi-Tenancy\", \"Configuration\", \"Comprehensive-Setup\", \"Production-Ready\"],\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options MultiTenancy(tenancy => {\n        // Tenant identification\n        tenancy TenantIdField = \"TenantId\";\n        tenancy TenantIdType = typeof(Guid);\n        // Storage strategy\n        tenancy Strategy = TenancyStrategy SingleDatabaseWithIsolation;\n        tenancy",
        "startIndex": 14276,
        "preview": "enforcement and policies\", category: \"Design\", difficulty: \"INTERMEDIATE\", tags: [\"Multi-Tenancy\", \"Security\", \"Authorization\", \"ASP NET-Core\", \"Polic..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-7",
        "text": "Setup\", description: \"Complete multi-tenancy configuration with all options and strategies\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Multi-Tenancy\", \"Configuration\", \"Comprehensive-Setup\", \"Production-Ready\"], framework: \"NET8\" } services AddWhizbang(options => { options MultiTenancy(tenancy => { // Tenant identification tenancy TenantIdField = \"TenantId\"; tenancy TenantIdType = typeof(Guid); // Storage strategy tenancy Strategy = TenancyStrategy SingleDatabaseWithIsolation; tenancy EnableRowLevelSecurity = true;\n        // Tenant context\n        tenancy TenantResolver = (httpContext) => {\n            return httpContext Request Headers[\"X-Tenant-ID\"] FirstOrDefault();\n        };\n        // Cross-tenant operations\n        tenancy AllowCrossTenantOperations = false;\n        tenancy RequireExplicitCrossTenantPermission = true;\n        // Database partitioning\n        tenancy UsePartitioning = true;\n        tenancy PartitionCount = 16;\n        // Tenant lifecycle\n        tenancy AutoCreateTenantData = true;\n        tenancy TenantDataTemplate = \"default_tenant_template\";\n    });\n    // Tenant-aware projections\n    options Projections(projections => {\n        projections DefaultTenantStrategy = ProjectionTenantStrategy TenantSpecific;\n        projections AllowGlobalProjections = true;\n        projections RequireExplicitCrossTenantAccess = true;\n    });\n});\n`\nTenant Onboarding Workflow\n`csharp{\ntitle: \"Tenant Onboarding Service\",\ndescription: \"Tenant onboarding workflow with resource provisioning and initialization\",\ncategory: \"Design\",\ndifficulty: \"INTERMEDIATE\",\ntags: [\"Multi-Tenancy\", \"Onboarding\", \"Tenant-Lifecycle\", \"Resource-Provisioning\"],\nframework: \"NET8\"\n}\npublic class TenantOnboardingService {\n    public async Task OnboardTenant(string tenantId, TenantConfiguration config) {\n        // Create tenant-specific database resources\n        await _tenantManager CreateTenantResources(tenantId);\n        // Initialize tenant data\n        await _tenantManager InitializeTenantData(tenantId, config);\n        // Set up tenant-specific projections\n        await _projectionManager CreateTenantProjections(tenantId);\n        // Emit tenant onboarded event\n        await _eventPublisher PublishAsync(new TenantOnboarded(\n            tenantId,\n            config,\n            DateTimeOffset",
        "startIndex": 16958,
        "preview": "Setup\", description: \"Complete multi-tenancy configuration with all options and strategies\", category: \"Design\", difficulty: \"ADVANCED\", tags: [\"Multi..."
      },
      {
        "id": "proposals/multi-tenancy-chunk-8",
        "text": "\"NET8\" } public class TenantOnboardingService { public async Task OnboardTenant(string tenantId, TenantConfiguration config) { // Create tenant-specific database resources await _tenantManager CreateTenantResources(tenantId); // Initialize tenant data await _tenantManager InitializeTenantData(tenantId, config); // Set up tenant-specific projections await _projectionManager CreateTenantProjections(tenantId); // Emit tenant onboarded event await _eventPublisher PublishAsync(new TenantOnboarded( tenantId, config, DateTimeOffset UtcNow\n        ));\n    }\n}\n`\nBest Practices\nTenant Design Guidelines\nDesign for isolation - Assume tenants can't see each other's data\nValidate tenant context - Always check tenant context in handlers\nUse consistent tenant IDs - Keep tenant identification simple\nPlan for scale - Design partitioning strategy from the start\nTest cross-tenant security - Verify isolation works correctly\nPerformance Considerations\nPartition by tenant - Use database partitioning for large tables\nIndex tenant columns - Include tenant_id in all indexes\nConnection pooling - Consider tenant-specific connection pools\nCache tenant data - Cache tenant configuration and permissions\nMonitor per-tenant usage - Track resource usage by tenant\nSecurity Best Practices\nDefense in depth - Use multiple layers of tenant isolation\nPrinciple of least privilege - Only grant necessary cross-tenant permissions\nAudit tenant access - Log all cross-tenant operations\nValidate tenant ownership - Check tenant context in all operations\nRegular security reviews - Audit tenant isolation regularly\n---\nRelated Documentation\nEvent Store & Projections - Storage architecture with tenant isolation\nDomain Ownership - How domain ownership works with tenants\nPerformance Optimization - Scaling multi-tenant systems",
        "startIndex": 18784,
        "preview": "\"NET8\" } public class TenantOnboardingService { public async Task OnboardTenant(string tenantId, TenantConfiguration config) { // Create tenant-specif..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/observability-metrics",
    "title": "Observability & Metrics",
    "category": "Architecture & Design",
    "url": "/docs/proposals/observability-metrics",
    "chunks": [
      {
        "id": "proposals/observability-metrics-chunk-0",
        "text": "Observability & Metrics\nWhizbang provides comprehensive observability with policy-driven metrics collection, OpenTelemetry integration, and custom field attributes for rich monitoring and debugging capabilities Metrics Architecture\nDefault Metrics (Always Enabled)\nCore performance and health metrics essential for operation:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Metrics, Default-Metrics]\ndescription: Core performance and health metrics essential for operation\n---\n// Command metrics\nwhizbang_command_duration_seconds{command_type, domain, handler_type, status}\nwhizbang_command_total{command_type, domain, status}\n// Event metrics  \nwhizbang_event_published_total{event_type, domain, source_handler}\nwhizbang_event_processing_duration_seconds{event_type, handler_type, status}\n// Projection metrics\nwhizbang_projection_lag_seconds{projection_name, partition}\nwhizbang_projection_events_processed_total{projection_name, event_type}\nwhizbang_projection_errors_total{projection_name, error_type}\n// Infrastructure metrics\nwhizbang_event_store_append_duration_seconds{driver_type, operation}\nwhizbang_message_broker_publish_duration_seconds{broker_type, topic}\nwhizbang_message_broker_consume_duration_seconds{broker_type, topic}\n// System health\nwhizbang_active_handlers_total{handler_type}\nwhizbang_memory_usage_bytes{component}\nwhizbang_cpu_usage_percent{component}\n`\nObservability Levels\nConfigurable detail levels for different scenarios:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Configuration, Observability-Levels]\ndescription: Configurable observability levels for different scenarios\n---\npublic enum ObservabilityLevel {\n    Minimal,    // Only essential metrics + errors\n    Standard,   // Default metrics + basic timing\n    Detailed,   // Additional context + custom fields  \n    Verbose,    // Everything + debug information\n    Debug       // Maximum detail for troubleshooting\n}\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Default observability configuration\n        policies When(ctx => true) // Matches all contexts Then(config => config SetObservabilityLevel(ObservabilityLevel Standard)) And(config => config EnableCustomFields());\n        // Environment-specific policies\n        policies When(ctx => ctx IsEnvironment(\"production\")) Then(config => config SetObservabilityLevel(ObservabilityLevel Standard)) And(config => config SetSampleRate(0 1)); // 10% sampling in production\n        policies When(ctx => ctx IsEnvironment(\"development\")) Then(config => config SetObservabilityLevel(ObservabilityLevel Verbose)) And(config => config SetSampleRate(1 0)); // Full sampling in development\n    });\n});\n`\nPolicy-Driven Observability\nContext-Aware Metrics Collection\nDynamic observability based on message context and policies:\n`csharp\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Observability, Context-Aware-Metrics, Dynamic-Configuration]\ndescription: Dynamic observability configuration based on message context and policies\n---\nservices AddWhizbang(options => {\n    options Observability(obs => {\n        obs Policies(policies => {\n            // Verbose logging for critical customer journeys\n            policies When(ctx => ctx",
        "startIndex": 0,
        "preview": "Observability & Metrics\nWhizbang provides comprehensive observability with policy-driven metrics collection, OpenTelemetry integration, and custom fie..."
      },
      {
        "id": "proposals/observability-metrics-chunk-1",
        "text": "on message context and policies: `csharp --- category: Design difficulty: ADVANCED tags: [Design, Observability, Context-Aware-Metrics, Dynamic-Configuration] description: Dynamic observability configuration based on message context and policies --- services AddWhizbang(options => { options Observability(obs => { obs Policies(policies => { // Verbose logging for critical customer journeys policies When(ctx => ctx HasTag(\"customer-vip\")) Then(action => action SetObservabilityLevel(ObservabilityLevel Verbose)) And(action => action CaptureCustomFields()) And(action => action EnableDistributedTracing());\n            // Detailed metrics for flagged debugging sessions\n            policies When(ctx => ctx HasFlag(WhizbangFlags VerboseOtel)) Then(action => action SetObservabilityLevel(ObservabilityLevel Debug)) And(action => action CaptureMethodParameters()) And(action => action CaptureReturnValues());\n            // Minimal overhead for load testing\n            policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(action => action SetObservabilityLevel(ObservabilityLevel Minimal)) And(action => action DisableSlowMetrics());\n            // Enhanced monitoring for production critical paths\n            policies When(ctx => ctx HasTag(\"critical-path\") && ctx HasFlag(WhizbangFlags Production)) Then(action => action SetObservabilityLevel(ObservabilityLevel Detailed)) And(action => action EnablePerformanceBudgetTracking()) And(action => action AlertOnAnomalies());\n        });\n    });\n});\n`\nAdaptive Sampling\nSmart sampling based on context and system load:\n`csharp\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Observability, Adaptive-Sampling, System-Load]\ndescription: Smart sampling based on context and system load for performance optimization\n---\npublic class AdaptiveObservabilityPolicy : IObservabilityPolicy {\n    public async Task<ObservabilityConfig> GetConfigAsync(MessageContext context) {\n        var config = new ObservabilityConfig();\n        // Always capture errors\n        if (context HasError) {\n            config Level = ObservabilityLevel Verbose;\n            config SampleRate = 1 0;\n            return config;\n        }\n        // Adaptive sampling based on system load\n        var systemLoad = await _systemMetrics GetCurrentLoadAsync();\n        if (systemLoad > 0 8) {\n            config SampleRate = 0 01; // 1% when system is under stress\n        } else if (systemLoad > 0 5) {\n            config SampleRate = 0 1;  // 10% when system is busy\n        } else {\n            config SampleRate = 0 5;  // 50% when system is idle\n        }\n        // VIP customers always get full tracking\n        if (context HasTag(\"customer-vip\")) {\n            config SampleRate = 1 0;\n            config",
        "startIndex": 3392,
        "preview": "on message context and policies: `csharp --- category: Design difficulty: ADVANCED tags: [Design, Observability, Context-Aware-Metrics, Dynamic-Config..."
      },
      {
        "id": "proposals/observability-metrics-chunk-2",
        "text": "else if (systemLoad > 0 5) { config SampleRate = 0 1; // 10% when system is busy } else { config SampleRate = 0 5; // 50% when system is idle } // VIP customers always get full tracking if (context HasTag(\"customer-vip\")) { config SampleRate = 1 0; config Level = ObservabilityLevel Detailed;\n        }\n        return config;\n    }\n}\n`\nCustom Field Attributes\nSource Generation for Rich Metrics\nAutomatically include relevant fields in metrics via attributes:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Custom-Fields, Source-Generation]\ndescription: Automatically include relevant fields in metrics via attributes\n---\n// Command with observability annotations\npublic record PlaceOrder(\n    Guid OrderId,\n    [ObservabilityField(MetricType Label)] \n    Guid CustomerId,    // Include as metric label\n    [ObservabilityField(MetricType Measure)] \n    decimal Total,      // Include as measured value\n    [ObservabilityField(MetricType Label, Transform = \"Range\")] \n    decimal Total2,     // Transform to range (0-100, 100-500, etc )\n    [ObservabilityField(MetricType Context)]\n    string Region,      // Include in trace context only\n    List<OrderItem> Items, // Not annotated - not included\n    [SensitiveData]\n    string PaymentToken // Marked sensitive - never included\n);\n// Generated metrics include custom fields\n// whizbang_command_total{command_type=\"PlaceOrder\", customer_id=\"123\", total_range=\"100-500\", region=\"us-west\"}\n// whizbang_command_duration_seconds{command_type=\"PlaceOrder\", customer_id=\"123\", total_range=\"100-500\"}\n`\nField Transformation Options\nSmart field transformations for better cardinality management:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Field-Transformations, Cardinality-Management]\ndescription: Smart field transformations for better metric cardinality management\n---\npublic enum FieldTransform {\n    None,           // Use raw value\n    Range,          // Convert numbers to ranges (0-100, 100-500, etc )\n    Hash,           // Hash sensitive identifiers\n    Truncate,       // Truncate long strings\n    Sanitize,       // Remove sensitive parts\n    Category        // Map to predefined categories\n}\n[ObservabilityField(MetricType Label, Transform = FieldTransform Range, Ranges = \"0,100,500,1000,5000\")]\npublic decimal Total { get; set; }\n[ObservabilityField(MetricType Label, Transform = FieldTransform Hash)]\npublic string CustomerId { get; set; } // Becomes hash for privacy\n[ObservabilityField(MetricType Label, Transform = FieldTransform",
        "startIndex": 5274,
        "preview": "else if (systemLoad > 0 5) { config SampleRate = 0 1; // 10% when system is busy } else { config SampleRate = 0 5; // 50% when system is idle } // VIP..."
      },
      {
        "id": "proposals/observability-metrics-chunk-3",
        "text": "// Remove sensitive parts Category // Map to predefined categories } [ObservabilityField(MetricType Label, Transform = FieldTransform Range, Ranges = \"0,100,500,1000,5000\")] public decimal Total { get; set; } [ObservabilityField(MetricType Label, Transform = FieldTransform Hash)] public string CustomerId { get; set; } // Becomes hash for privacy [ObservabilityField(MetricType Label, Transform = FieldTransform Category, \n    Categories = \"standard,premium,enterprise\")]\npublic string CustomerTier { get; set; }\n`\nGenerated Metric Collection\nSource generator creates metric collection code:\n`csharp\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Observability, Source-Generation, Metrics-Collection]\ndescription: Source generator creates metric collection code for annotated types\n---\n// Generated metric collection for PlaceOrder\n[GeneratedCode(\"Whizbang SourceGenerator\")]\npublic partial class PlaceOrderMetricsCollector {\n    public static void RecordCommandExecution(PlaceOrder command, CommandResult result, TimeSpan duration) {\n        var labels = new Dictionary<string, object> {\n            [\"command_type\"] = \"PlaceOrder\",\n            [\"customer_id\"] = command CustomerId ToString(),\n            [\"total_range\"] = TransformToRange(command Total, new[] { 0, 100, 500, 1000, 5000 }),\n            [\"region\"] = command Region,\n            [\"status\"] = result Success \"success\" : \"failure\"\n        };\n        _commandDurationHistogram Record(duration TotalSeconds, labels);\n        _commandTotalCounter Add(1, labels);\n        if ( result Success) {\n            _commandErrorsCounter Add(1, labels Concat(new[] {\n                new KeyValuePair<string, object>(\"error_type\", result ErrorType)\n            }));\n        }\n    }\n    private static string TransformToRange(decimal value, decimal[] ranges) {\n        for (int i = 0; i < ranges Length - 1; i++) {\n            if (value >= ranges[i] && value < ranges[i + 1]) {\n                return $\"{ranges[i]}-{ranges[i + 1]}\";\n            }\n        }\n        return $\"{ranges[^1]}+\";\n    }\n}\n`\nOpenTelemetry Integration\nComprehensive Instrumentation\nFull OpenTelemetry implementation with Whizbang-specific semantics:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, OpenTelemetry, Comprehensive-Instrumentation]\ndescription: Full OpenTelemetry implementation with Whizbang-specific semantics\n---\nservices AddWhizbang(options => {\n    options UseOpenTelemetry(otel => {\n        otel ConfigureTracing(tracing => {\n            tracing AddWhizbangInstrumentation() AddAspNetCoreInstrumentation() AddHttpClientInstrumentation() AddEntityFrameworkCoreInstrumentation();\n            // Whizbang-specific trace attributes\n            tracing SetSampler(new WhizbangAdaptiveSampler());\n            tracing AddProcessor<WhizbangSpanProcessor>();\n        });\n        otel ConfigureMetrics(metrics => {\n            metrics AddWhizbangInstrumentation() AddRuntimeInstrumentation() AddAspNetCoreInstrumentation();\n            // Custom metric providers\n            metrics AddMeter(\"Whizbang Commands\");\n            metrics AddMeter(\"Whizbang Events\");\n            metrics AddMeter(\"Whizbang",
        "startIndex": 8267,
        "preview": "// Remove sensitive parts Category // Map to predefined categories } [ObservabilityField(MetricType Label, Transform = FieldTransform Range, Ranges = ..."
      },
      {
        "id": "proposals/observability-metrics-chunk-4",
        "text": "Whizbang-specific semantics --- services AddWhizbang(options => { options UseOpenTelemetry(otel => { otel ConfigureTracing(tracing => { tracing AddWhizbangInstrumentation() AddAspNetCoreInstrumentation() AddHttpClientInstrumentation() AddEntityFrameworkCoreInstrumentation(); // Whizbang-specific trace attributes tracing SetSampler(new WhizbangAdaptiveSampler()); tracing AddProcessor<WhizbangSpanProcessor>(); }); otel ConfigureMetrics(metrics => { metrics AddWhizbangInstrumentation() AddRuntimeInstrumentation() AddAspNetCoreInstrumentation(); // Custom metric providers metrics AddMeter(\"Whizbang Commands\"); metrics AddMeter(\"Whizbang Events\"); metrics AddMeter(\"Whizbang Projections\");\n        });\n        otel ConfigureLogs(logs => {\n            logs AddWhizbangInstrumentation() AddConsoleExporter() AddOpenTelemetryProtocolExporter();\n        });\n    });\n});\n`\nSemantic Conventions\nWhizbang-specific OpenTelemetry semantic conventions:\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, OpenTelemetry, Semantic-Conventions]\ndescription: Whizbang-specific OpenTelemetry semantic conventions for consistency\n---\npublic static class WhizbangSemanticConventions {\n    // Span attributes\n    public const string CommandType = \"whizbang command type\";\n    public const string EventType = \"whizbang event type\";\n    public const string ProjectionName = \"whizbang projection name\";\n    public const string Domain = \"whizbang domain\";\n    public const string StreamId = \"whizbang stream id\";\n    public const string StreamVersion = \"whizbang stream version\";\n    public const string CorrelationId = \"whizbang correlation id\";\n    public const string TenantId = \"whizbang tenant id\";\n    // Metric attributes\n    public const string HandlerType = \"whizbang handler type\";\n    public const string DriverType = \"whizbang driver type\";\n    public const string PolicyName = \"whizbang policy name\";\n    public const string FlagValue = \"whizbang flags\";\n    // Resource attributes\n    public const string ServiceDomain = \"whizbang service domain\";\n    public const string ServiceVersion = \"whizbang service version\";\n    public const string LibraryVersion = \"whizbang library version\";\n}\n`csharp\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, OpenTelemetry, Command-Instrumentation]\ndescription: Command instrumentation with automatic attribute and custom field capture\n---\n// Usage in instrumentation\npublic class WhizbangCommandInstrumentation : IDisposable {\n    public Activity StartCommandActivity<T>(T command, MessageContext context) where T : ICommand {\n        var activity = Activity StartActivity($\"Command {typeof(T) Name}\");\n        activity SetTag(WhizbangSemanticConventions CommandType, typeof(T) Name);\n        activity SetTag(WhizbangSemanticConventions Domain, context Domain);\n        activity SetTag(WhizbangSemanticConventions CorrelationId, context CorrelationId);\n        if (context TenantId = null) {\n            activity SetTag(WhizbangSemanticConventions TenantId, context",
        "startIndex": 11137,
        "preview": "Whizbang-specific semantics --- services AddWhizbang(options => { options UseOpenTelemetry(otel => { otel ConfigureTracing(tracing => { tracing AddWhi..."
      },
      {
        "id": "proposals/observability-metrics-chunk-5",
        "text": "instrumentation public class WhizbangCommandInstrumentation : IDisposable { public Activity StartCommandActivity<T>(T command, MessageContext context) where T : ICommand { var activity = Activity StartActivity($\"Command {typeof(T) Name}\"); activity SetTag(WhizbangSemanticConventions CommandType, typeof(T) Name); activity SetTag(WhizbangSemanticConventions Domain, context Domain); activity SetTag(WhizbangSemanticConventions CorrelationId, context CorrelationId); if (context TenantId = null) { activity SetTag(WhizbangSemanticConventions TenantId, context TenantId);\n        }\n        // Add custom fields from annotations\n        AddCustomFields(activity, command);\n        return activity;\n    }\n}\n`\nPerformance Budget Integration\nBudget-Aware Observability\nAutomatic performance budget tracking with alerts:\n`csharp\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Observability, Performance-Budgets, Automatic-Tracking]\ndescription: Automatic performance budget tracking with alerts and dynamic observability\n---\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Performance budgets for specific handlers\n        policies When(ctx => ctx MatchesHandler<PlaceOrderHandler>()) Then(config => config SetPerformanceBudget(new PerformanceBudget {\n                    MaxLatency = TimeSpan FromMilliseconds(100),\n                    MaxMemoryMB = 10,\n                    MaxCpuMs = 50\n                })) And(config => config OnBudgetViolation(async (violation) => {\n                    // Increase observability for budget violations\n                    await _observabilityService IncreaseDetailLevel(\n                        violation HandlerType, \n                        ObservabilityLevel Debug,\n                        duration: TimeSpan FromMinutes(10)\n                    );\n                    // Alert on violations\n                    await _alerting SendBudgetViolationAlert(violation);\n                }));\n        // Default budget tracking settings\n        policies When(ctx => true) // Matches all contexts Then(config => config EnableBudgetTracking()) And(config => config SetBudgetViolationSampleRate(1 0)); // Always capture violations\n    });\n});\n// Generated budget tracking metrics\nwhizbang_performance_budget_violation_total{handler_type, budget_type, severity}\nwhizbang_performance_budget_utilization_ratio{handler_type, budget_type}\nwhizbang_performance_budget_headroom_seconds{handler_type}\n`\nDistributed Tracing\nW3C Trace Context Propagation\nStandards-compliant distributed tracing:\n`csharp\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, Observability, W3C-Trace-Context, Distributed-Tracing]\ndescription: Standards-compliant W3C trace context propagation implementation\n---\npublic class WhizbangTraceContextPropagator : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        // Extract W3C trace context from message headers\n        var traceParent = context Headers GetValueOrDefault(\"traceparent\");\n        var traceState = context Headers GetValueOrDefault(\"tracestate\");\n        Activity activity = null;\n        if (traceParent = null) {\n            // Continue existing trace\n            var traceContext = W3CTraceContext Parse(traceParent, traceState);\n            activity = Activity StartActivity($\"Handle {typeof(TRequest) Name}\");\n            activity SetParentId(traceContext",
        "startIndex": 13556,
        "preview": "instrumentation public class WhizbangCommandInstrumentation : IDisposable { public Activity StartCommandActivity<T>(T command, MessageContext context)..."
      },
      {
        "id": "proposals/observability-metrics-chunk-6",
        "text": "TResponse> next) { // Extract W3C trace context from message headers var traceParent = context Headers GetValueOrDefault(\"traceparent\"); var traceState = context Headers GetValueOrDefault(\"tracestate\"); Activity activity = null; if (traceParent = null) { // Continue existing trace var traceContext = W3CTraceContext Parse(traceParent, traceState); activity = Activity StartActivity($\"Handle {typeof(TRequest) Name}\"); activity SetParentId(traceContext TraceId, traceContext SpanId);\n        } else {\n            // Start new trace\n            activity = Activity StartActivity($\"Handle {typeof(TRequest) Name}\");\n        }\n        // Add Whizbang-specific context\n        activity SetTag(WhizbangSemanticConventions CommandType, typeof(TRequest) Name);\n        activity SetTag(WhizbangSemanticConventions CorrelationId, context CorrelationId);\n        activity SetTag(WhizbangSemanticConventions Domain, context Domain);\n        // Enhance trace state with Whizbang context\n        var enhancedTraceState = EnhanceTraceState(traceState, context);\n        activity SetTag(\"tracestate\", enhancedTraceState);\n        try {\n            var response = await next(message, context);\n            activity SetTag(\"status\", \"success\");\n            return response;\n        } catch (Exception ex) {\n            activity SetTag(\"status\", \"error\");\n            activity SetTag(\"error type\", ex GetType() Name);\n            activity SetTag(\"error message\", ex Message);\n            throw;\n        } finally {\n            activity Dispose();\n        }\n    }\n    private string EnhanceTraceState(string existingTraceState, MessageContext context) {\n        var whizbangState = new List<string>();\n        if (context CorrelationId = null) {\n            whizbangState Add($\"correlation-id:{context CorrelationId}\");\n        }\n        if (context Domain = null) {\n            whizbangState Add($\"domain:{context Domain}\");\n        }\n        if (context Flags = WhizbangFlags None) {\n            whizbangState Add($\"flags:{(long)context Flags}\");\n        }\n        var newTraceState = $\"whizbang={string Join(\",\", whizbangState)}\";\n        return string IsNullOrEmpty(existingTraceState)",
        "startIndex": 16593,
        "preview": "TResponse> next) { // Extract W3C trace context from message headers var traceParent = context Headers GetValueOrDefault(\"traceparent\"); var traceStat..."
      },
      {
        "id": "proposals/observability-metrics-chunk-7",
        "text": "EnhanceTraceState(string existingTraceState, MessageContext context) { var whizbangState = new List<string>(); if (context CorrelationId = null) { whizbangState Add($\"correlation-id:{context CorrelationId}\"); } if (context Domain = null) { whizbangState Add($\"domain:{context Domain}\"); } if (context Flags = WhizbangFlags None) { whizbangState Add($\"flags:{(long)context Flags}\"); } var newTraceState = $\"whizbang={string Join(\",\", whizbangState)}\"; return string IsNullOrEmpty(existingTraceState) newTraceState \n            : $\"{existingTraceState},{newTraceState}\";\n    }\n}\n`\nMonitoring Dashboards\nPre-built Dashboard Configurations\nReady-to-use monitoring dashboards for popular platforms:\n`json\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Grafana, Dashboard-Configuration]\ndescription: Ready-to-use Grafana dashboard configuration for Whizbang metrics\n---\n// Grafana dashboard configuration\n{\n  \"dashboard\": {\n    \"title\": \"Whizbang Application Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Command Processing Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(whizbang_command_total[5m])\",\n            \"legendFormat\": \"{{command_type}} ({{domain}})\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Projection Lag\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"whizbang_projection_lag_seconds\",\n            \"legendFormat\": \"{{projection_name}}\"\n          }\n        ],\n        \"thresholds\": [\n          { \"value\": 300, \"color\": \"yellow\" },\n          { \"value\": 600, \"color\": \"red\" }\n        ]\n      },\n      {\n        \"title\": \"Performance Budget Violations\",\n        \"type\": \"table\",\n        \"targets\": [\n          {\n            \"expr\": \"increase(whizbang_performance_budget_violation_total[1h])\",\n            \"format\": \"table\"\n          }\n        ]\n      }\n    ]\n  }\n}\n`\nAlert Rules\nProduction-ready alerting rules:\n`yaml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Observability, Prometheus, Alerting-Rules]\ndescription: Production-ready Prometheus alerting rules for Whizbang applications\n---\nPrometheus alerting rules\ngroups:\nname: whizbang rules\n    rules:\nalert: ProjectionLagHigh\n        expr: whizbang_projection_lag_seconds > 300\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Projection {{ $labels projection_name }} is lagging\"\n          description: \"Projection {{ $labels projection_name }} has been lagging behind by {{ $value }} seconds for more than 5 minutes\"\nalert: CommandErrorRateHigh\n        expr: rate(whizbang_command_errors_total[5m]) / rate(whizbang_command_total[5m]) > 0 05\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High command error rate for {{ $labels command_type }}\"\n          description: \"Command {{ $labels",
        "startIndex": 18339,
        "preview": "EnhanceTraceState(string existingTraceState, MessageContext context) { var whizbangState = new List<string>(); if (context CorrelationId = null) { whi..."
      },
      {
        "id": "proposals/observability-metrics-chunk-8",
        "text": "lagging\" description: \"Projection {{ $labels projection_name }} has been lagging behind by {{ $value }} seconds for more than 5 minutes\" alert: CommandErrorRateHigh expr: rate(whizbang_command_errors_total[5m]) / rate(whizbang_command_total[5m]) > 0 05 for: 2m labels: severity: critical annotations: summary: \"High command error rate for {{ $labels command_type }}\" description: \"Command {{ $labels command_type }} error rate is {{ $value | humanizePercentage }}\"\nalert: PerformanceBudgetViolation\n        expr: increase(whizbang_performance_budget_violation_total[10m]) > 5\n        for: 0m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Performance budget violations for {{ $labels handler_type }}\"\n          description: \"Handler {{ $labels handler_type }} has violated its performance budget {{ $value }} times in the last 10 minutes\"\n`\nBest Practices\nMetric Design\nControl cardinality - Avoid high-cardinality labels\nUse transformations - Convert IDs to ranges or categories\nStandardize naming - Follow OpenTelemetry conventions\nInclude context - Domain, tenant, and correlation information\nMonitor overhead - Track observability performance impact\nPolicy Configuration\nStart conservative - Begin with standard observability level\nUse adaptive sampling - Reduce overhead under load\nPrioritize critical paths - Enhanced monitoring for important flows\nHandle errors specially - Always capture error scenarios\nRegular review - Adjust policies based on insights\nDashboard Organization\nLayer dashboards - Overview ‚Üí Domain ‚Üí Handler specific\nUse SLOs - Define and track service level objectives\nAlert on trends - Early warning indicators\nInclude business metrics - Connect technical to business impact\nRegular maintenance - Keep dashboards current and useful\n---\nRelated Documentation\nPolicy Engine - How policies drive observability\nFlags & Tags System - Cross-service context propagation\nTesting & Development Tools - Testing observability features\nDeployment & Operations - Production monitoring setup",
        "startIndex": 20739,
        "preview": "lagging\" description: \"Projection {{ $labels projection_name }} has been lagging behind by {{ $value }} seconds for more than 5 minutes\" alert: Comman..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/open-questions",
    "title": "Open Design Questions - RESOLVED",
    "category": "Architecture & Design",
    "url": "/docs/proposals/open-questions",
    "chunks": [
      {
        "id": "proposals/open-questions-chunk-0",
        "text": "Open Design Questions - RESOLVED ‚úÖ\nStatus: All critical and important design questions have been resolved and documented in detailed specification documents This document previously captured open questions and architectural decisions for Whizbang All questions have now been resolved and documented in comprehensive specifications üî¥ Critical Decisions - ALL RESOLVED ‚úÖ\nAll critical decisions have been resolved and documented",
        "startIndex": 0,
        "preview": "Open Design Questions - RESOLVED ‚úÖ\nStatus: All critical and important design questions have been resolved and documented in detailed specification doc..."
      },
      {
        "id": "proposals/open-questions-chunk-1",
        "text": "and important design questions have been resolved and documented in detailed specification documents This document previously captured open questions and architectural decisions for Whizbang All questions have now been resolved and documented in comprehensive specifications üî¥ Critical Decisions - ALL RESOLVED ‚úÖ All critical decisions have been resolved and documented See the detailed specifications below:\nHandler Discovery Mechanism ‚úÖ RESOLVED\nDecision: Hybrid approach (Source Generators + Explicit Registration)\nDetailed Specification: Domain Ownership\nHandler Method Signature Conventions ‚úÖ RESOLVED\nDecision: Convention-based with Source Generator support\nDetailed Specification: Domain Ownership\nEvent Store Schema Design ‚úÖ RESOLVED\nDecision: Hybrid approach (Separate Events and Projections with JSONB)\nDetailed Specification: Event Store & Projections\nOptimistic Concurrency Strategy ‚úÖ RESOLVED\nDecision: Support all strategies (Expected Version, Timestamp-Based, Automatic Retry)\nDetailed Specification: Concurrency Control\nDomain Ownership Declaration ‚úÖ RESOLVED\nDecision: Configurable precedence order (Namespace ‚Üí Attributes ‚Üí Configuration)\nDetailed Specification: Domain Ownership\n---\nüü° Important Decisions - ALL RESOLVED ‚úÖ\nProjection Checkpoint Storage ‚úÖ RESOLVED\nDecision: Support both Same Database (default) and Separate Metadata Store\nDetailed Specification: Projection Management\nSnapshot Strategy ‚úÖ RESOLVED\nDecision: Support all strategies (Automatic, Manual, None with Automatic as default)\nDetailed Specification: Event Store & Projections\nProjection Backfilling API ‚úÖ RESOLVED\nDecision: Support both Declarative and Imperative with System Events\nDetailed Specification: Projection Management\nSaga State Persistence ‚úÖ RESOLVED\nDecision: Event-Sourced Sagas as primary pattern\nDetailed Specification: Event Store & Projections\n---\nüü¢ Future Considerations - DOCUMENTED ‚úÖ\nAll future considerations have been documented in the new specification files:\nMulti-Tenancy Support ‚úÖ DOCUMENTED\nComprehensive support for single/multiple databases and tenant isolation\nDetailed Specification: Multi-Tenancy\nSchema Evolution & Event Versioning ‚úÖ DOCUMENTED\nJSONB-based evolution with upcasting and schema registry support\nDetailed Specification: Schema Evolution\nBlue/Green Projection Deployments ‚úÖ DOCUMENTED\nDriver-level blue/green implementation with atomic table swapping\nDetailed Specification: Schema Evolution\nCross-Aggregate Transactions ‚úÖ DOCUMENTED\nUnit of Work pattern with saga fallback for complex operations\nDetailed Specification: Advanced Features\nOutbox/Inbox Table Schema ‚úÖ DOCUMENTED\nComprehensive outbox/inbox pattern implementation\nDetailed Specification: Event Store & Projections\nDistributed Tracing Context ‚úÖ DOCUMENTED\nW3C trace context headers with OpenTelemetry integration\nDetailed Specification: Advanced Features\nPerformance Budgets & SLOs ‚úÖ DOCUMENTED\nAttribute and programmatic performance budgets with OpenTelemetry\nDetailed Specification: Advanced Features\nKubernetes Operator Features ‚úÖ DOCUMENTED\nAuto-scaling, partition-aware placement, and blue/green deployments\nDetailed Specification: Advanced Features\nDebugging & Development Tools ‚úÖ DOCUMENTED\nOpenTelemetry journey visualization, replay, and state inspection\nDetailed Specification: Advanced Features\n---\nImplementation Status\nAll architectural questions have been resolved and documented in comprehensive specification files",
        "startIndex": 431,
        "preview": "and important design questions have been resolved and documented in detailed specification documents This document previously captured open questions ..."
      },
      {
        "id": "proposals/open-questions-chunk-2",
        "text": "Specification: Advanced Features Kubernetes Operator Features ‚úÖ DOCUMENTED Auto-scaling, partition-aware placement, and blue/green deployments Detailed Specification: Advanced Features Debugging & Development Tools ‚úÖ DOCUMENTED OpenTelemetry journey visualization, replay, and state inspection Detailed Specification: Advanced Features --- Implementation Status All architectural questions have been resolved and documented in comprehensive specification files The library design is now ready for implementation Next Steps\nReview specifications - Study the detailed documentation for each area\nCreate ADRs - Document key decisions in Architecture Decision Records\nBegin implementation - Start building based on the specifications\nValidate with prototypes - Build proof-of-concepts to validate designs\nFor Contributors\nAll major architectural decisions have been made Contributors should:\nRead the specifications before starting work\nFollow the documented patterns in implementation\nPropose changes via GitHub Discussions if specifications need updates\nFor Maintainers\nFocus on:\nImplementation planning - Break down specifications into development tasks\nPrototype validation - Build key components to validate architectural decisions\nDocumentation updates - Keep specifications current as implementation progresses\n---\nComplete Specification Suite\nCore Architecture\nEvent Store & Projections - Storage architecture and JSONB projections\nDomain Ownership - Handler discovery and ownership policies\nConcurrency Control - Multiple concurrency strategies\nAdvanced Features\nProjection Management - Checkpoints, snapshots, and backfilling\nMulti-Tenancy - Comprehensive tenant isolation strategies\nSchema Evolution - JSONB evolution and versioning\nPolicy Engine - Universal configuration scoping mechanism\nFlags & Tags System - Cross-service context propagation\nAdvanced Features - Cross-aggregate transactions, K8s operators, debugging\nImplementation & Tooling\nSource Generation & IDE Integration - Incremental generation and navigation service\nTesting & Development Tools - Comprehensive testing framework and CLI tools\nObservability & Metrics - Policy-driven monitoring and OpenTelemetry\nDeployment & Operations - Production deployment and operational patterns\nFoundation Documents\nPhilosophy - Core principles and design philosophy\nArchitecture - Overall system architecture\n---\nReady to implement",
        "startIndex": 3496,
        "preview": "Specification: Advanced Features Kubernetes Operator Features ‚úÖ DOCUMENTED Auto-scaling, partition-aware placement, and blue/green deployments Detaile..."
      },
      {
        "id": "proposals/open-questions-chunk-3",
        "text": "generation and navigation service Testing & Development Tools - Comprehensive testing framework and CLI tools Observability & Metrics - Policy-driven monitoring and OpenTelemetry Deployment & Operations - Production deployment and operational patterns Foundation Documents Philosophy - Core principles and design philosophy Architecture - Overall system architecture --- Ready to implement All questions resolved, specifications complete, design decisions documented ---\nüÜï New Questions Emerging from Implementation Planning\nAs we dive deeper into the specifications, new architectural questions have emerged that need resolution:\nüî¥ Critical Implementation Questions\nSource Generator Architecture ‚úÖ RESOLVED\nDecision: Single incremental generator with pipeline architecture\nKey Requirements:\nIncremental generation - Only regenerate what changed\nIDE integration - Analyzer errors/fixes + navigation service\nMulti-project support - Aggregate generated code across project dependencies\nDebug transparency - No \"magic\", clear generated code + metadata\nBuild observability - Detailed logging and timing for optimization\nImplementation Approach:\n`csharp{\ntitle: \"Incremental Source Generator Implementation\"\ndescription: \"Shows how to implement an incremental source generator with pipeline architecture for Whizbang code generation\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"source-generation\", \"incremental\", \"ide-integration\", \"pipeline\"]\nframework: \"NET8\"\n}\n[Generator]\npublic class WhizbangSourceGenerator : IIncrementalGenerator {\n    public void Initialize(IncrementalGeneratorInitializationContext context) {\n        // Pipeline stages with timing/logging\n        var handlersPipeline = context SyntaxProvider CreateSyntaxProvider( );\n        var domainOwnershipPipeline = context SyntaxProvider CreateSyntaxProvider( );\n        var projectionsPipeline = context SyntaxProvider CreateSyntaxProvider( );\n        // Combine all sources for cross-project aggregation\n        var combinedPipeline = handlersPipeline Combine(domainOwnershipPipeline) Combine(projectionsPipeline);\n        context RegisterSourceOutput(combinedPipeline, GenerateCode);\n        context",
        "startIndex": 5432,
        "preview": "generation and navigation service Testing & Development Tools - Comprehensive testing framework and CLI tools Observability & Metrics - Policy-driven ..."
      },
      {
        "id": "proposals/open-questions-chunk-4",
        "text": "IIncrementalGenerator { public void Initialize(IncrementalGeneratorInitializationContext context) { // Pipeline stages with timing/logging var handlersPipeline = context SyntaxProvider CreateSyntaxProvider( ); var domainOwnershipPipeline = context SyntaxProvider CreateSyntaxProvider( ); var projectionsPipeline = context SyntaxProvider CreateSyntaxProvider( ); // Combine all sources for cross-project aggregation var combinedPipeline = handlersPipeline Combine(domainOwnershipPipeline) Combine(projectionsPipeline); context RegisterSourceOutput(combinedPipeline, GenerateCode); context RegisterSourceOutput(combinedPipeline, GenerateMetadata); // For IDE service\n    }\n}\n// Generated metadata for IDE navigation service\npublic class WhizbangNavigationMetadata {\n    public Dictionary<string, EventStreamInfo> EventStreams { get; set; }\n    public Dictionary<string, HandlerInfo> Handlers { get; set; }\n    public Dictionary<string, ProjectionInfo> Projections { get; set; }\n    public Dictionary<string, DomainInfo> Domains { get; set; }\n}\n`\nIDE Integration Features:\nGitLens-style event stream navigation\nCommand ‚Üí Handler ‚Üí Events ‚Üí Projections flow visualization\nAnalyzer errors for misconfigured ownership/handlers\nCode fixes for common patterns\n---\nDriver Loading & Plugin Architecture ‚úÖ RESOLVED\nDecision: Option A - Explicit registration for simplicity and predictability\nImplementation:\n`csharp{\ntitle: \"Driver Registration Configuration\"\ndescription: \"Demonstrates explicit driver registration with type safety for Event Store, Projections, and Message Broker\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"configuration\", \"drivers\", \"dependency-injection\"]\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options UseEventStoreDriver<PostgresDriver>(\"connection-string\");\n    options UseProjectionDriver<MongoDriver>(\"mongo-connection\");\n    options UseMessageBrokerDriver<KafkaDriver>(kafka => {\n        kafka BootstrapServers = \"localhost:9092\";\n        kafka EnableIdempotence = true;\n    });\n});\n`\nBenefits:\nClear, explicit dependencies\nCompile-time safety\nPredictable behavior\nEasy to reason about and debug\nWorks well with dependency injection\n---\nMessage Serialization Strategy ‚úÖ RESOLVED\nDecision: Duck-typed serialization with System Text Json default + abstraction layer\nKey Principles:\nDecoupled microservices - No shared dependencies required\nDuck typing - Service1 EventA can deserialize to Service5",
        "startIndex": 7249,
        "preview": "IIncrementalGenerator { public void Initialize(IncrementalGeneratorInitializationContext context) { // Pipeline stages with timing/logging var handler..."
      },
      {
        "id": "proposals/open-questions-chunk-5",
        "text": "Compile-time safety Predictable behavior Easy to reason about and debug Works well with dependency injection --- Message Serialization Strategy ‚úÖ RESOLVED Decision: Duck-typed serialization with System Text Json default + abstraction layer Key Principles: Decoupled microservices - No shared dependencies required Duck typing - Service1 EventA can deserialize to Service5 EventC if shapes match\nInterface support - Both duck-typed and pure-shared interfaces\nPure type sharing - Support shared Domain Models libraries when desired\nZero-copy optimization - When applicable through adapters\nCompression support - Through driver adapters\nImplementation Architecture:\n`csharp{\ntitle: \"Duck-Typed Message Serialization Configuration\"\ndescription: \"Demonstrates duck-typed serialization allowing cross-service message compatibility without shared dependencies\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"serialization\", \"duck-typing\", \"microservices\", \"configuration\"]\nframework: \"NET8\"\n}\n// Duck-typed serialization example\n// Service 1 publishes:\npublic record OrderPlaced(Guid OrderId, string CustomerName, decimal Total);\n// Service 5 receives as:\npublic record OrderReceived(Guid OrderId, string CustomerName, decimal Total);\n// Works automatically via duck typing\n// Interface-based approach (optional)\npublic interface IOrderEvent {\n    Guid OrderId { get; }\n    string CustomerName { get; }\n    decimal Total { get; }\n}\n// Both services can implement the interface\npublic record OrderPlaced( ) : IOrderEvent;\npublic record OrderReceived( ) : IOrderEvent;\n// Serialization configuration\nservices AddWhizbang(options => {\n    options Serialization(serialization => {\n        serialization DefaultSerializer = SystemTextJsonSerializer Default;\n        serialization EnableDuckTyping = true;\n        serialization EnableInterfaceMapping = true;\n        serialization EnableZeroCopy = true; // When supported by driver\n        // Driver-specific optimizations\n        serialization ForDriver<PostgresDriver>() UseJsonOptimizations(jsonb: true);\n        serialization ForDriver<KafkaDriver>() UseCompression(CompressionType",
        "startIndex": 9103,
        "preview": "Compile-time safety Predictable behavior Easy to reason about and debug Works well with dependency injection --- Message Serialization Strategy ‚úÖ RESO..."
      },
      {
        "id": "proposals/open-questions-chunk-6",
        "text": "IOrderEvent; public record OrderReceived( ) : IOrderEvent; // Serialization configuration services AddWhizbang(options => { options Serialization(serialization => { serialization DefaultSerializer = SystemTextJsonSerializer Default; serialization EnableDuckTyping = true; serialization EnableInterfaceMapping = true; serialization EnableZeroCopy = true; // When supported by driver // Driver-specific optimizations serialization ForDriver<PostgresDriver>() UseJsonOptimizations(jsonb: true); serialization ForDriver<KafkaDriver>() UseCompression(CompressionType Gzip);\n    });\n});\n`\nDuck Typing Implementation:\n`csharp{\ntitle: \"Duck-Typing Message Serializer Implementation\"\ndescription: \"Shows implementation of duck-typing serializer that can convert between compatible message types without shared contracts\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"serialization\", \"duck-typing\", \"json\", \"type-conversion\"]\nframework: \"NET8\"\n}\npublic interface IMessageSerializer {\n    T Deserialize<T>(byte[] data, Type sourceType);\n    byte[] Serialize<T>(T message);\n    bool CanDuckType(Type source, Type target);\n}\npublic class DuckTypingJsonSerializer : IMessageSerializer {\n    public T Deserialize<T>(byte[] data, Type sourceType) {\n        if (typeof(T) == sourceType) {\n            return JsonSerializer Deserialize<T>(data);\n        }\n        // Duck typing: deserialize to JObject then convert\n        var json = JsonSerializer Deserialize<JsonObject>(data);\n        return json Deserialize<T>();\n    }\n}\n`\n---\nError Handling & Resilience Patterns ‚úÖ RESOLVED\nDecision: Use Polly as the resilience framework with Whizbang-specific defaults and policies\nCore Principle: Never lose data - prefer backing up streams over discarding messages\nImplementation Strategy:\n`csharp{\ntitle: \"Resilience Policy Configuration with Polly\"\ndescription: \"Demonstrates comprehensive error handling and resilience patterns using Polly with data integrity safeguards\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"resilience\", \"polly\", \"error-handling\", \"circuit-breaker\", \"retry\"]\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options Resilience(resilience => {\n        // Default policies (can be overridden)\n        resilience DefaultRetryPolicy = Policy Handle<TransientException>() WaitAndRetryAsync(3, retryAttempt => \n                TimeSpan FromSeconds(Math Pow(2, retryAttempt)));\n        resilience DefaultCircuitBreakerPolicy = Policy Handle<Exception>() CircuitBreakerAsync(5, TimeSpan FromMinutes(1));\n        // Data integrity first - back up rather than lose\n        resilience OnMaxRetriesExceeded = (context, exception) => {\n            // Back up the stream, don't discard\n            return ResilienceAction BackupAndHold;\n        };\n        // Per-event/interface/pattern customization\n        resilience ForEvent<OrderPlaced>() UseRetryPolicy(customOrderRetryPolicy);\n        resilience ForInterface<IProjectionHandler>() UseCircuitBreaker(projectionCircuitBreaker);\n        resilience ForPattern(type => type Name EndsWith(\"Command\")) UseTimeout(TimeSpan",
        "startIndex": 10891,
        "preview": "IOrderEvent; public record OrderReceived( ) : IOrderEvent; // Serialization configuration services AddWhizbang(options => { options Serialization(seri..."
      },
      {
        "id": "proposals/open-questions-chunk-7",
        "text": "= Policy Handle<Exception>() CircuitBreakerAsync(5, TimeSpan FromMinutes(1)); // Data integrity first - back up rather than lose resilience OnMaxRetriesExceeded = (context, exception) => { // Back up the stream, don't discard return ResilienceAction BackupAndHold; }; // Per-event/interface/pattern customization resilience ForEvent<OrderPlaced>() UseRetryPolicy(customOrderRetryPolicy); resilience ForInterface<IProjectionHandler>() UseCircuitBreaker(projectionCircuitBreaker); resilience ForPattern(type => type Name EndsWith(\"Command\")) UseTimeout(TimeSpan FromSeconds(30));\n    });\n});\n`\nDefault Behaviors with Safety Warnings:\n`csharp{\ntitle: \"Safe Default Resilience Policies\"\ndescription: \"Defines safe default resilience policies that prioritize data integrity with warnings for dangerous overrides\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"resilience\", \"safety\", \"data-integrity\", \"defaults\"]\nframework: \"NET8\"\n}\n// Safe defaults\npublic static class DefaultResiliencePolicies {\n    public static ResiliencePolicy SafeDefault => new() {\n        MaxRetries = 3,\n        BackoffStrategy = BackoffStrategy ExponentialWithJitter,\n        OnFailure = ResilienceAction BackupAndHold, // SAFE: Don't lose data\n        CircuitBreakerThreshold = 5,\n        CircuitBreakerDuration = TimeSpan FromMinutes(1)\n    };\n    // Dangerous overrides (with warnings)\n    [Obsolete(\"WARNING: This policy may result in data loss Use SafeDefault unless you understand the risks \")]\n    public static ResiliencePolicy DangerousDiscardOnFailure => new() {\n        OnFailure = ResilienceAction Discard // DANGEROUS: May lose data\n    };\n}\n`\nCustomizable Hooks:\n`csharp{\ntitle: \"Resilience Failure Hooks Configuration\"\ndescription: \"Shows how to configure global hooks for handling transient and permanent failures with logging and alerting\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"resilience\", \"hooks\", \"logging\", \"alerting\", \"dead-letter\"]\nframework: \"NET8\"\n}\n// Global hooks\nresilience OnTransientFailure = async (context, exception) => {\n    await _logger LogWarningAsync($\"Transient failure in {context HandlerType}: {exception Message}\");\n};\nresilience OnPermanentFailure = async (context, exception) => {\n    await _alerting SendCriticalAlert($\"Permanent failure in {context HandlerType}: {exception Message}\");\n    await _deadLetterQueue SendAsync(context",
        "startIndex": 13501,
        "preview": "= Policy Handle<Exception>() CircuitBreakerAsync(5, TimeSpan FromMinutes(1)); // Data integrity first - back up rather than lose resilience OnMaxRetri..."
      },
      {
        "id": "proposals/open-questions-chunk-8",
        "text": "tags: [\"resilience\", \"hooks\", \"logging\", \"alerting\", \"dead-letter\"] framework: \"NET8\" } // Global hooks resilience OnTransientFailure = async (context, exception) => { await _logger LogWarningAsync($\"Transient failure in {context HandlerType}: {exception Message}\"); }; resilience OnPermanentFailure = async (context, exception) => { await _alerting SendCriticalAlert($\"Permanent failure in {context HandlerType}: {exception Message}\"); await _deadLetterQueue SendAsync(context Message, exception);\n};\n`\n---\nConfiguration Management Strategy ‚úÖ RESOLVED\nDecision: Hybrid approach - Options B & C (fluent + configuration) with Policy Engine integration\nImplementation Strategy:\n`csharp{\ntitle: \"Hybrid Configuration Strategy\"\ndescription: \"Demonstrates fluent builder pattern combined with policy-driven configuration for type safety and flexibility\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"configuration\", \"fluent-api\", \"policies\", \"multi-environment\"]\nframework: \"NET8\"\n}\n// Fluent builder for type safety and discoverability\nservices AddWhizbang(options => {\n    options UseEventStore<PostgresDriver>(\"connection-string\") UseProjections(proj => proj DefaultStrategy = SnapshotStrategy Automatic) UseDomainOwnership(dom => dom PrecedenceOrder(\"Namespace\", \"Attributes\")) UseMultiTenancy(mt => mt DefaultStrategy = TenancyStrategy SingleDatabase);\n    // Policy-driven configuration\n    options Policies(policies => {\n        policies ForEnvironment(\"Production\") LoadFromConfiguration(\"ProductionPolicies\");\n        policies ForEnvironment(\"Development\") Apply(DevelopmentPolicies Default);\n    });\n});\n// Configuration sections for environment-specific overrides\n{\n  \"Whizbang\": {\n    \"EventStore\": { \"Driver\": \"Postgres\", \"ConnectionString\": \" \" },\n    \"Projections\": { \"DefaultStrategy\": \"Automatic\" },\n    \"Policies\": {\n      \"Production\": [ ],\n      \"Development\": [ ]\n    }\n  }\n}\n`\nBenefits:\nType safety through fluent builder\nFlexibility through configuration sections\nPolicy-driven behavior for environment adaptation\nValidation at startup with clear error messages\n---\nTesting Strategy & Test Helpers ‚úÖ RESOLVED\nDecision: Provide comprehensive testing library including suggested helpers\nImplementation:\n`csharp{\ntitle: \"Comprehensive Testing Framework\"\ndescription: \"Shows the testing library with Given/When/Then pattern, projection testing, and in-memory drivers for fast unit tests\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"testing\", \"given-when-then\", \"unit-tests\", \"in-memory\", \"projections\"]\nframework: \"NET8\"\n}\n// Whizbang",
        "startIndex": 15314,
        "preview": "tags: [\"resilience\", \"hooks\", \"logging\", \"alerting\", \"dead-letter\"] framework: \"NET8\" } // Global hooks resilience OnTransientFailure = async (context..."
      },
      {
        "id": "proposals/open-questions-chunk-9",
        "text": "Test Helpers ‚úÖ RESOLVED Decision: Provide comprehensive testing library including suggested helpers Implementation: `csharp{ title: \"Comprehensive Testing Framework\" description: \"Shows the testing library with Given/When/Then pattern, projection testing, and in-memory drivers for fast unit tests\" category: \"Design\" difficulty: \"INTERMEDIATE\" tags: [\"testing\", \"given-when-then\", \"unit-tests\", \"in-memory\", \"projections\"] framework: \"NET8\" } // Whizbang Testing package\npublic class WhizbangTestFixture {\n    public GivenEventsBuilder Given(params object[] events);\n    public WhenCommandBuilder When(ICommand command);\n    public ThenEventsBuilder Then();\n    // Projection testing\n    public ProjectionTestBuilder ForProjection<TProjection>();\n    // Policy testing\n    public PolicyTestBuilder ForPolicy(string policyName);\n}\n// Usage in tests\n[Test]\npublic async Task PlaceOrder_ShouldEmitOrderPlaced() {\n    await _fixture Given(new CustomerRegistered(customerId, \"John Doe\")) When(new PlaceOrder(orderId, customerId, items)) Then() ShouldEmitEvent<OrderPlaced>() WithProperty(e => e CustomerId, customerId);\n}\n// In-memory drivers for testing\nservices AddWhizbang(options => {\n    options UseInMemoryEventStore()  // For unit tests UseInMemoryProjections() UseInMemoryMessageBroker();\n});\n`\nFeatures:\nIn-memory drivers for fast unit testing\nGiven/When/Then fluent test API\nProjection test helpers with event feeding\nPolicy testing for complex rule validation\nIntegration test helpers with test containers\n---\nMetrics & Observability Data Model ‚úÖ RESOLVED\nDecision: Configurable metrics with policy-driven verbosity and custom field attributes\nDefault Metrics (Always Enabled):\n`csharp{\ntitle: \"Default Observability Metrics\"\ndescription: \"Defines the core performance and infrastructure health metrics that are always enabled in Whizbang\"\ncategory: \"Design\"\ndifficulty: \"BEGINNER\"\ntags: [\"observability\", \"metrics\", \"performance\", \"monitoring\"]\nframework: \"NET8\"\n}\n// Core performance metrics\nwhizbang_command_duration_seconds{command_type, domain, handler_type}\nwhizbang_command_total{command_type, domain, status}\nwhizbang_event_processing_duration_seconds{event_type, handler_type}\nwhizbang_projection_lag_seconds{projection_name}\n// Infrastructure health\nwhizbang_event_store_append_duration_seconds{driver_type}\nwhizbang_message_broker_publish_duration_seconds{broker_type}\n`\nPolicy-Driven Observability:\n`csharp{\ntitle: \"Policy-Driven Observability Configuration\"\ndescription: \"Shows how to configure observability levels using policies based on flags and tags for dynamic monitoring\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"observability\", \"policies\", \"monitoring\", \"telemetry\", \"conditional\"]\nframework: \"NET8\"\n}\nservices AddWhizbang(options => {\n    options Observability(obs => {\n        obs DefaultLevel = ObservabilityLevel Standard;\n        // Policy-based observability levels\n        obs Policies(policies => {\n            policies When(ctx => ctx HasFlag(WhizbangFlags VerboseOtel)) Then(action => action SetObservabilityLevel(ObservabilityLevel",
        "startIndex": 17479,
        "preview": "Test Helpers ‚úÖ RESOLVED Decision: Provide comprehensive testing library including suggested helpers Implementation: `csharp{ title: \"Comprehensive Tes..."
      },
      {
        "id": "proposals/open-questions-chunk-10",
        "text": "flags and tags for dynamic monitoring\" category: \"Design\" difficulty: \"ADVANCED\" tags: [\"observability\", \"policies\", \"monitoring\", \"telemetry\", \"conditional\"] framework: \"NET8\" } services AddWhizbang(options => { options Observability(obs => { obs DefaultLevel = ObservabilityLevel Standard; // Policy-based observability levels obs Policies(policies => { policies When(ctx => ctx HasFlag(WhizbangFlags VerboseOtel)) Then(action => action SetObservabilityLevel(ObservabilityLevel Verbose));\n            policies When(ctx => ctx HasTag(\"critical-path\")) Then(action => action EnableDetailedMetrics()) And(action => action CaptureCustomFields());\n        });\n    });\n});\n`\nCustom Field Attributes for Source Generation:\n`csharp{\ntitle: \"Custom Observability Fields with Attributes\"\ndescription: \"Demonstrates using attributes to include specific event fields in generated metrics for enhanced observability\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"observability\", \"attributes\", \"source-generation\", \"metrics\", \"events\"]\nframework: \"NET8\"\n}\n// Add fields to metadata via attributes\npublic record OrderPlaced(\n    Guid OrderId,\n    [ObservabilityField] Guid CustomerId,    // Include in metrics\n    [ObservabilityField] decimal Total,      // Include in metrics\n    List<OrderItem> Items\n);\n// Generated metric includes custom fields\nwhizbang_event_published_total{event_type=\"OrderPlaced\", customer_id=\"123\", total_range=\"1000-5000\"}\n`\n---\nDevelopment Experience & Tooling ‚úÖ RESOLVED\nDecision: Comprehensive tooling suite as outlined\nPlanned Tools:\n`bash\nCLI tool (whizbang-cli)\nwhizbang new --template microservice --name OrderService\nwhizbang add projection --name OrderSummary --events OrderPlaced,OrderShipped\nwhizbang migrate --from 1 0 --to 2",
        "startIndex": 20193,
        "preview": "flags and tags for dynamic monitoring\" category: \"Design\" difficulty: \"ADVANCED\" tags: [\"observability\", \"policies\", \"monitoring\", \"telemetry\", \"condi..."
      },
      {
        "id": "proposals/open-questions-chunk-11",
        "text": "); // Generated metric includes custom fields whizbang_event_published_total{event_type=\"OrderPlaced\", customer_id=\"123\", total_range=\"1000-5000\"} ` --- Development Experience & Tooling ‚úÖ RESOLVED Decision: Comprehensive tooling suite as outlined Planned Tools: `bash CLI tool (whizbang-cli) whizbang new --template microservice --name OrderService whizbang add projection --name OrderSummary --events OrderPlaced,OrderShipped whizbang migrate --from 1 0 --to 2 0\nwhizbang dashboard --port 5000\nwhizbang replay --stream orders --from 2024-01-01\nVisual Studio integration\ndotnet new whizbang-service --name MyService\ndotnet new whizbang-projection --name OrderSummary\n`\nIDE Extensions:\nNavigation service for GitLens-style event stream traversal\nCode analyzers for ownership and pattern validation\nLive templates for commands, events, projections, sagas\nDebugging tools with state inspection and replay\nWeb Dashboard:\nReal-time projection lag monitoring\nEvent stream visualization\nPolicy rule testing and validation\nPerformance metrics and alerting\nDocumentation: Dedicated tools page and documentation section\n---\nDeployment & Operations Patterns ‚úÖ RESOLVED\nDecision: Embedded library with comprehensive operational hooks\nDeployment Model:\nEmbedded library - Runs within developer's service\nBuilt-in health checks - Ready for Kubernetes probes\nGraceful shutdown - Message draining support NET integration - Hooks into NET hosting lifetime\nImplementation:\n`csharp{\ntitle: \"Deployment Health Checks and Graceful Shutdown\"\ndescription: \"Shows built-in health checks for Kubernetes probes and graceful shutdown with message draining support\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"deployment\", \"health-checks\", \"graceful-shutdown\", \"kubernetes\", \"operations\"]\nframework: \"NET8\"\n}\n// Built-in health checks\nservices AddWhizbang(options => {\n    options HealthChecks(health => {\n        health CheckEventStoreConnection = true;\n        health CheckProjectionLag = true;\n        health CheckMessageBrokerConnection = true;\n        health ProjectionLagThreshold = TimeSpan FromMinutes(5);\n    });\n});\n// Graceful shutdown integration\npublic class WhizbangHostedService : IHostedService {\n    public async Task StopAsync(CancellationToken cancellationToken) {\n        // Drain in-flight messages\n        await _messageProcessor DrainAsync(cancellationToken);\n        // Stop accepting new messages\n        await _messageSubscriptions",
        "startIndex": 21515,
        "preview": "); // Generated metric includes custom fields whizbang_event_published_total{event_type=\"OrderPlaced\", customer_id=\"123\", total_range=\"1000-5000\"} ` -..."
      },
      {
        "id": "proposals/open-questions-chunk-12",
        "text": "{ health CheckEventStoreConnection = true; health CheckProjectionLag = true; health CheckMessageBrokerConnection = true; health ProjectionLagThreshold = TimeSpan FromMinutes(5); }); }); // Graceful shutdown integration public class WhizbangHostedService : IHostedService { public async Task StopAsync(CancellationToken cancellationToken) { // Drain in-flight messages await _messageProcessor DrainAsync(cancellationToken); // Stop accepting new messages await _messageSubscriptions StopAsync(cancellationToken);\n    }\n}\n`\n---\nüü¢ Future Enhancement Questions\nEvent Store Scaling Patterns ‚úÖ RESOLVED\nDecision: All suggested scaling patterns should be available as options\nScaling Options:\nSharding strategies - By tenant, aggregate type, time, or custom logic\nRead replicas - For query load distribution\nEvent archiving - Automated cold storage migration\nCross-shard projections - With aggregation support\nAdvanced Saga Patterns\nQuestion: Should Whizbang support more sophisticated saga patterns Considerations:\nSaga compensation - Automatic rollback workflows\nSaga timeouts - What happens when sagas get stuck\nNested sagas - Sagas that spawn other sagas\nSaga state queries - Query current saga states\nReal-time Features\nQuestion: How should Whizbang support real-time scenarios Considerations:\nLive projections - Real-time projection updates\nEvent streaming - WebSocket/SSE event feeds\nPush notifications - Mobile/web notifications\nLive dashboards - Real-time metrics and monitoring\n---\nDecision Process for New Questions\nPrioritize by impact - Focus on critical implementation blockers first\nPrototype when uncertain - Build spikes to validate approaches\nConsider ecosystem integration - How do decisions affect NET ecosystem fit\nBalance simplicity vs power - Don't over-engineer early decisions\nDocument decisions - Update specifications as decisions are made\nNext Steps: Review and prioritize these questions for the implementation phase",
        "startIndex": 23495,
        "preview": "{ health CheckEventStoreConnection = true; health CheckProjectionLag = true; health CheckMessageBrokerConnection = true; health ProjectionLagThreshold..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/policy-engine",
    "title": "Policy Engine",
    "category": "Architecture & Design",
    "url": "/docs/proposals/policy-engine",
    "chunks": [
      {
        "id": "proposals/policy-engine-chunk-0",
        "text": "Policy Engine\nWhizbang includes a sophisticated policy engine that enables flexible, rule-based configuration for routing, behavior modification, and system adaptation across the entire message lifecycle Core Architecture\nThe Policy Engine is the universal configuration scoping mechanism for Whizbang Rather than having separate configuration systems for each feature, policies provide a unified way to apply configuration based on context, conditions, and scope Every configurable aspect of Whizbang can use policies to determine when and how configuration should be applied:\nConcurrency strategies - Which concurrency approach to use based on message type/context\nObservability levels - How much detail to capture based on flags/environment\nPerformance budgets - Different performance expectations for different scenarios\nSerialization formats - Which serializer to use for different drivers/contexts\nMulti-tenancy isolation - Tenant-specific behavior and storage strategies\nDomain ownership - Dynamic ownership rules based on context\nError handling - Different resilience policies for different message types\nRouting decisions - Which handlers to use based on flags/tags\nSecurity policies - Authentication/authorization rules based on context\nPolicies can evaluate any aspect of the system state:\nMessage content - Properties, types, values within commands/events\nMessage context - Flags, tags, correlation IDs, tenant information\nSystem state - Current load, resource utilization, error rates\nEnvironment - Development, staging, production, feature flags\nUser context - Authentication, authorization, user roles\nTime-based conditions - Business hours, maintenance windows, seasons\nDomain context - Which domain owns the message, cross-domain interactions\nInfrastructure state - Database health, message broker status\nCustom conditions - Any developer-defined evaluation criteria\n> üìã Message Context: While policies can evaluate any system aspect, the Flags & Tags System provides a convenient way to carry context through message flows",
        "startIndex": 0,
        "preview": "Policy Engine\nWhizbang includes a sophisticated policy engine that enables flexible, rule-based configuration for routing, behavior modification, and ..."
      },
      {
        "id": "proposals/policy-engine-chunk-1",
        "text": "context - Which domain owns the message, cross-domain interactions Infrastructure state - Database health, message broker status Custom conditions - Any developer-defined evaluation criteria > üìã Message Context: While policies can evaluate any system aspect, the Flags & Tags System provides a convenient way to carry context through message flows Configuration Architecture Principles\nPolicy-Based vs Direct Configuration\nPolicies handle behavioral configuration that varies by context, environment, message type, or runtime conditions:\n`csharp{title=\"Policy-Based vs Direct Configuration\" description=\"Policy-based vs direct configuration showing separation of infrastructure and behavioral settings\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Configuration\", \"Behavioral-Configuration\"] framework=\"NET8\"}\n---\nservices AddWhizbang(options => {\n    // INFRASTRUCTURE CONFIGURATION (Direct)\n    // - Connection strings, driver selection, basic setup\n    options UseEventStoreDriver<PostgresDriver>(connectionString);\n    options UseMessageBrokerDriver<KafkaDriver>(kafkaConfig);\n    // BEHAVIORAL CONFIGURATION (Policy-Based)\n    // - Strategies, levels, rules that change based on context\n    options Policies(policies => {\n        // Environment-based behavior\n        policies When(ctx => ctx IsEnvironment(\"production\")) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetObservabilityLevel(ObservabilityLevel Standard));\n        // Message type-based behavior\n        policies WhenMessageName(name => name Contains(\"Payment\")) Then(config => config SetStrictSecurity()) And(config => config EnableDetailedAuditing());\n        // Load/context-based behavior\n        policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(config => config",
        "startIndex": 2046,
        "preview": "context - Which domain owns the message, cross-domain interactions Infrastructure state - Database health, message broker status Custom conditions - A..."
      },
      {
        "id": "proposals/policy-engine-chunk-2",
        "text": "Policies(policies => { // Environment-based behavior policies When(ctx => ctx IsEnvironment(\"production\")) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetObservabilityLevel(ObservabilityLevel Standard)); // Message type-based behavior policies WhenMessageName(name => name Contains(\"Payment\")) Then(config => config SetStrictSecurity()) And(config => config EnableDetailedAuditing()); // Load/context-based behavior policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(config => config UseOptimizedForThroughput());\n    });\n});\n`\nWhen to use Policies vs Direct Configuration:\n| Configuration Type | Use Policies | Use Direct |\n|-------------------|-------------|------------|\n| Concurrency Strategies | ‚úÖ Context-dependent | ‚ùå |\n| Observability Levels | ‚úÖ Environment/load dependent | ‚ùå |\n| Security Policies | ‚úÖ Message/tenant dependent | ‚ùå |\n| Performance Budgets | ‚úÖ Handler/context dependent | ‚ùå |\n| Multi-tenancy Strategy | ‚úÖ Tenant-type dependent | ‚ùå |\n| Connection Strings | ‚ùå | ‚úÖ Infrastructure |\n| Driver Selection | ‚úÖ Environment dependent | ‚úÖ Simple cases |\n| Basic DI Registration | ‚ùå | ‚úÖ Infrastructure |\nPolicy Engine Architecture\nUniversal Configuration via Policies\nAll Whizbang configuration can be scoped using policies:\n`csharp{title=\"Universal Configuration via Policies\" description=\"Comprehensive example showing all Whizbang features configured through unified policy system\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Universal-Configuration\", \"Complex-Policies\"] framework=\"NET8\"}\n---\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // === CONCURRENCY STRATEGY POLICIES ===\n        policies When(ctx => ctx MatchesMessage<HighVolumeCommand>()) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry)) And(config => config SetMaxRetries(5));\n        policies When(ctx => ctx HasTag(\"critical-transaction\")) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy ExpectedVersion)) And(config => config SetIsolationLevel(IsolationLevel Serializable));\n        // === OBSERVABILITY POLICIES ===\n        policies When(ctx => ctx HasFlag(WhizbangFlags Production)) Then(config => config SetObservabilityLevel(ObservabilityLevel Standard)) And(config => config SetSampleRate(0 1));\n        policies When(ctx => ctx HasTag(\"customer-vip\") || ctx HasFlag(WhizbangFlags VerboseLogging)) Then(config => config SetObservabilityLevel(ObservabilityLevel Verbose)) And(config => config SetSampleRate(1 0)) And(config => config EnableCustomFields());\n        // === PERFORMANCE BUDGET POLICIES ===\n        policies WhenMessageName(name => name EndsWith(\"Command\")) Then(config => config SetPerformanceBudget(new PerformanceBudget {\n                    MaxLatency = TimeSpan",
        "startIndex": 3627,
        "preview": "Policies(policies => { // Environment-based behavior policies When(ctx => ctx IsEnvironment(\"production\")) Then(config => config UseConcurrencyStrateg..."
      },
      {
        "id": "proposals/policy-engine-chunk-3",
        "text": "SetObservabilityLevel(ObservabilityLevel Standard)) And(config => config SetSampleRate(0 1)); policies When(ctx => ctx HasTag(\"customer-vip\") || ctx HasFlag(WhizbangFlags VerboseLogging)) Then(config => config SetObservabilityLevel(ObservabilityLevel Verbose)) And(config => config SetSampleRate(1 0)) And(config => config EnableCustomFields()); // === PERFORMANCE BUDGET POLICIES === policies WhenMessageName(name => name EndsWith(\"Command\")) Then(config => config SetPerformanceBudget(new PerformanceBudget { MaxLatency = TimeSpan FromMilliseconds(500),\n                    MaxMemoryMB = 10\n                }));\n        policies When(ctx => ctx HasTag(\"real-time\")) Then(config => config SetPerformanceBudget(new PerformanceBudget {\n                    MaxLatency = TimeSpan FromMilliseconds(50),\n                    AlertOnViolation = true\n                }));\n        // === SERIALIZATION POLICIES ===\n        policies WhenDriverType<KafkaDriver>() Then(config => config UseSerializer<AvroSerializer>()) And(config => config EnableCompression(CompressionType Gzip));\n        policies WhenDriverType<PostgresDriver>() Then(config => config UseSerializer<JsonSerializer>()) And(config => config EnableJsonbOptimizations());\n        // === MULTI-TENANCY POLICIES ===\n        policies When(ctx => ctx TenantId = null && ctx HasTag(\"enterprise-tenant\")) Then(config => config UseTenancyStrategy(TenancyStrategy SeparateDatabases)) And(config => config EnableTenantIsolation());\n        policies When(ctx => ctx TenantId = null && ctx HasTag(\"startup-tenant\")) Then(config => config UseTenancyStrategy(TenancyStrategy SingleDatabaseWithIsolation)) And(config => config EnableSharedResources());\n        // === ERROR HANDLING POLICIES ===\n        policies WhenMessageName(name => name Contains(\"Payment\")) Then(config => config UseResiliencePolicy(StrictRetryPolicy)) And(config => config SetMaxRetries(3)) And(config => config EnableCircuitBreaker());\n        policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(config => config UseResiliencePolicy(FastFailPolicy)) And(config => config DisableRetries());\n        // === ROUTING POLICIES ===\n        policies When(ctx => ctx HasTag(\"customer-vip\")) Then(config => config RouteToHandler<PremiumOrderHandler>()) And(config => config SetPriority(MessagePriority High));\n        policies When(ctx => ctx SystemLoad > 0 8) Then(config => config RouteToHandler<LightweightOrderHandler>()) And(config => config DeferNonCriticalProcessing());\n        // === SECURITY POLICIES ===\n        policies When(ctx => ctx HasTag(\"pci-data\") || ctx HasTag(\"sensitive\")) Then(config => config RequireEncryption()) And(config => config EnableAuditLogging()) And(config => config RequireAuthorization(\"pci-access\"));\n        policies When(ctx => ctx IsEnvironment(\"production\") && ctx HasTag(\"external-api\")) Then(config => config EnableRateLimiting(100, TimeSpan FromMinutes(1))) And(config => config RequireApiKey());\n    });\n});\n`\nPolicy Combination Strategies\n`csharp{title=\"Policy Combination Strategies\" description=\"Advanced policy combination strategies using intersection, union, and exclusion operations\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Policy-Combination\", \"Venn-Diagrams\"] framework=\"NET8\"}\n---\n// Venn diagram-style policy combinations\npolicies Combine(\n    // Policy A: High-priority customers\n    policies",
        "startIndex": 6089,
        "preview": "SetObservabilityLevel(ObservabilityLevel Standard)) And(config => config SetSampleRate(0 1)); policies When(ctx => ctx HasTag(\"customer-vip\") || ctx H..."
      },
      {
        "id": "proposals/policy-engine-chunk-4",
        "text": "Then(config => config EnableRateLimiting(100, TimeSpan FromMinutes(1))) And(config => config RequireApiKey()); }); }); ` Policy Combination Strategies `csharp{title=\"Policy Combination Strategies\" description=\"Advanced policy combination strategies using intersection, union, and exclusion operations\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Policy-Combination\", \"Venn-Diagrams\"] framework=\"NET8\"} --- // Venn diagram-style policy combinations policies Combine( // Policy A: High-priority customers policies When(ctx => ctx HasTag(\"customer-vip\")),\n    // Policy B: Large orders with custom condition\n    policies When(ctx => ctx MatchesEvent<OrderPlaced>() && ctx GetEvent<OrderPlaced>() Total > 10000),\n    // Combination strategies\n    CombinationStrategy Intersection  // Both A AND B\n);\npolicies Combine(\n    policies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)),\n    policies When(ctx => ctx HasFlag(WhizbangFlags DryRun)),\n    CombinationStrategy Union        // Either A OR B\n);\npolicies Combine(\n    policies When(ctx => ctx HasTag(\"batch-import\")),\n    policies When(ctx => ctx HasFlag(WhizbangFlags Migration)),\n    CombinationStrategy Exclusion    // A XOR B (one but not both)\n);\n`\nCanned/Static Policies\n`csharp{title=\"Canned/Static Policies\" description=\"Pre-defined reusable policies for common scenarios with override capabilities\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Canned-Policies\", \"Reusable-Patterns\"] framework=\"NET8\"}\n---\n// Pre-defined policies for common scenarios\npublic static class WhizbangPolicies {\n    public static Policy LoadTestingPolicy => new PolicyBuilder() When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(action => action SkipProjections()) And(action => action DisableSlowOperations()) And(action => action AddTag(\"load-test-ignored\")) Build();\n    public static Policy ProductionSafetyPolicy => new PolicyBuilder() When(ctx => ctx HasFlag(WhizbangFlags Production)) Then(action => action EnableDataScrubbing()) And(action => action EnforceRateLimits()) And(action => action EnableAuditLogging()) Build();\n    public static Policy DevelopmentDebuggingPolicy => new PolicyBuilder() When(ctx => ctx HasFlag(WhizbangFlags Development)) Then(action => action EnableVerboseLogging()) And(action => action EnableBreakpoints()) And(action => action DisableTimeouts()) Build();\n}\n// Apply canned policies\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        policies Apply(WhizbangPolicies LoadTestingPolicy);\n        policies Apply(WhizbangPolicies ProductionSafetyPolicy);\n        policies Apply(WhizbangPolicies DevelopmentDebuggingPolicy);\n        // Custom policies can override or extend canned policies\n        policies When(ctx => ctx HasTag(\"special-case\")) OverridePolicy(WhizbangPolicies ProductionSafetyPolicy) Then(action => action",
        "startIndex": 3013,
        "preview": "Then(config => config EnableRateLimiting(100, TimeSpan FromMinutes(1))) And(config => config RequireApiKey()); }); }); ` Policy Combination Strategies..."
      },
      {
        "id": "proposals/policy-engine-chunk-5",
        "text": "And(action => action EnableBreakpoints()) And(action => action DisableTimeouts()) Build(); } // Apply canned policies services AddWhizbang(options => { options Policies(policies => { policies Apply(WhizbangPolicies LoadTestingPolicy); policies Apply(WhizbangPolicies ProductionSafetyPolicy); policies Apply(WhizbangPolicies DevelopmentDebuggingPolicy); // Custom policies can override or extend canned policies policies When(ctx => ctx HasTag(\"special-case\")) OverridePolicy(WhizbangPolicies ProductionSafetyPolicy) Then(action => action DisableDataScrubbing()); // Override for this case\n    });\n});\n`\nAdvanced Policy Scenarios\nCross-Service Flag Propagation\nFlags carry through entire message journey:\n`csharp{title=\"Cross-Service Flag Propagation\" description=\"Flag propagation across service boundaries maintaining context through entire message journey\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Cross-Service-Propagation\", \"Debugging\"] framework=\"NET8\"}\n---\n// Initial command with debugging flags\nvar command = new PlaceOrder(orderId, customerId, items);\nawait _mediator Send(command, context => {\n    context WithFlags(WhizbangFlags VerboseLogging | WhizbangFlags TraceReplay) WithTag(\"debug-session-123\");\n});\n// Flags automatically propagate to:\n// 1 Command handler execution\n// 2 Event publishing\n// 3 Cross-service event delivery\n// 4 Projection updates\n// 5 Saga execution\n// Service 2 receives event with same flags\npublic class InventoryHandler : IEventHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, EventContext context) {\n        // context Flags contains VerboseLogging | TraceReplay\n        // context Tags contains \"debug-session-123\"\n        if (context HasFlag(WhizbangFlags VerboseLogging)) {\n            _logger LogInformation(\"Processing order with verbose logging enabled\");\n        }\n    }\n}\n`\nData Scrubbing with Policy-Based Duplication\n`csharp{title=\"Data Scrubbing with Policy-Based Duplication\" description=\"Policy-based data scrubbing when promoting production data to QA environment\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Data-Scrubbing\", \"Environment-Promotion\"] framework=\"NET8\"}\n---\n// Production to QA data flow with scrubbing\npolicies When(ctx => ctx HasTag(\"production-data\") && ctx HasFlag(WhizbangFlags QA)) Then(action => action DuplicateMessage()) And(action => action ScrubSensitiveData()) And(action => action AddFlag(WhizbangFlags DataScrubbing)) And(action => action RouteToEnvironment(\"qa\"));\n// Handler that applies scrubbing\npublic class DataScrubbingHandler : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message, \n        MessageContext context, \n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        if (context HasFlag(WhizbangFlags DataScrubbing)) {\n            message = _dataScrubber",
        "startIndex": 11874,
        "preview": "And(action => action EnableBreakpoints()) And(action => action DisableTimeouts()) Build(); } // Apply canned policies services AddWhizbang(options => ..."
      },
      {
        "id": "proposals/policy-engine-chunk-6",
        "text": "QA)) Then(action => action DuplicateMessage()) And(action => action ScrubSensitiveData()) And(action => action AddFlag(WhizbangFlags DataScrubbing)) And(action => action RouteToEnvironment(\"qa\")); // Handler that applies scrubbing public class DataScrubbingHandler : IMessageInterceptor { public async Task<TResponse> Intercept<TRequest, TResponse>( TRequest message, MessageContext context, MessageHandlerDelegate<TRequest, TResponse> next) { if (context HasFlag(WhizbangFlags DataScrubbing)) { message = _dataScrubber Scrub(message);\n        }\n        return await next(message, context);\n    }\n}\n`\nDynamic Handler Routing\n`csharp{title=\"Dynamic Handler Routing\" description=\"Dynamic handler routing based on flags and tags with conditional registration\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Dynamic-Routing\", \"Handler-Selection\"] framework=\"NET8\"}\n---\n// Route to different handlers based on flags/tags\npolicies When(ctx => ctx HasTag(\"high-value-customer\")) Then(action => action RouteToHandler<PremiumOrderHandler>()) Else(action => action RouteToHandler<StandardOrderHandler>());\npolicies When(ctx => ctx HasFlag(WhizbangFlags LoadTesting)) Then(action => action RouteToHandler<LoadTestOrderHandler>()) And(action => action SkipProjections());\n// Alternative handler registration\nservices AddWhizbang(options => {\n    options RegisterHandler<PlaceOrder, StandardOrderHandler>(); // Default\n    options RegisterHandler<PlaceOrder, PremiumOrderHandler>(\n        condition: ctx => ctx Tags Contains(\"high-value-customer\"));\n    options RegisterHandler<PlaceOrder, LoadTestOrderHandler>(\n        condition: ctx => ctx Flags HasFlag(WhizbangFlags LoadTesting));\n});\n`\nIDE Debugging Support\n`csharp{title=\"IDE Debugging Support\" description=\"Advanced debugging support with IDE integration, breakpoints, and state inspection\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"IDE-Integration\", \"Debugging\", \"Time-Travel\"] framework=\"NET8\"}\n---\n// IDE cursor/scrubbing mode\npolicies When(ctx => ctx HasFlag(WhizbangFlags CursorMode)) Then(action => action EnableStepByStepExecution()) And(action => action CaptureStateSnapshots()) And(action => action AllowTimeTravel());\n// Breakpoint support\npolicies When(ctx => ctx HasFlag(WhizbangFlags Breakpoint)) Then(action => action PauseExecution()) And(action => action NotifyIDE()) And(action => action CaptureFullContext());\n// State inspection\npublic class StateInspectionInterceptor : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        if (context HasFlag(WhizbangFlags CursorMode)) {\n            await _stateCapture CapturePreExecutionState(message, context);\n        }\n        var response = await next(message, context);\n        if (context HasFlag(WhizbangFlags CursorMode)) {\n            await _stateCapture",
        "startIndex": 14302,
        "preview": "QA)) Then(action => action DuplicateMessage()) And(action => action ScrubSensitiveData()) And(action => action AddFlag(WhizbangFlags DataScrubbing)) A..."
      },
      {
        "id": "proposals/policy-engine-chunk-7",
        "text": "NotifyIDE()) And(action => action CaptureFullContext()); // State inspection public class StateInspectionInterceptor : IMessageInterceptor { public async Task<TResponse> Intercept<TRequest, TResponse>( TRequest message, MessageContext context, MessageHandlerDelegate<TRequest, TResponse> next) { if (context HasFlag(WhizbangFlags CursorMode)) { await _stateCapture CapturePreExecutionState(message, context); } var response = await next(message, context); if (context HasFlag(WhizbangFlags CursorMode)) { await _stateCapture CapturePostExecutionState(response, context);\n        }\n        return response;\n    }\n}\n`\nPolicy Engine Implementation\nCore Interfaces\n`csharp{title=\"Core Interfaces\" description=\"Core policy engine interfaces and action types for implementing the policy system\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Core-Interfaces\", \"Implementation\"] framework=\"NET8\"}\n---\npublic interface IPolicyEngine {\n    Task<PolicyResult> EvaluateAsync<T>(T message, MessageContext context);\n    void RegisterPolicy(IPolicy policy);\n    void RegisterPolicies(IEnumerable<IPolicy> policies);\n    IPolicy CombinePolicies(IEnumerable<IPolicy> policies, CombinationStrategy strategy);\n}\npublic interface IPolicy {\n    string Name { get; }\n    int Priority { get; }\n    Task<bool> ShouldApplyAsync<T>(T message, MessageContext context);\n    Task<PolicyAction[]> GetActionsAsync<T>(T message, MessageContext context);\n}\npublic abstract class PolicyAction {\n    public abstract Task ExecuteAsync<T>(T message, MessageContext context);\n}\n// Specific policy actions\npublic class RouteToHandlerAction<THandler> : PolicyAction { }\npublic class AddFlagAction : PolicyAction { }\npublic class AddTagAction : PolicyAction { }\npublic class SkipProjectionsAction : PolicyAction { }\npublic class EnableVerboseLoggingAction : PolicyAction { }\npublic class ScrubDataAction : PolicyAction { }\n`\nTyped Policy Methods\nContext provides strongly-typed matching methods:\n`csharp{title=\"Typed Policy Methods\" description=\"Typed policy methods with strongly-typed context matching and clean policy configuration\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Message-Context\", \"Strongly-Typed\"] framework=\"NET8\"}\n---\npublic class MessageContext {\n    // Core properties\n    public string CorrelationId { get; set; }\n    public WhizbangFlags Flags { get; set; }\n    public HashSet<string> Tags { get; set; }\n    public string Environment { get; set; }\n    public string TenantId { get; set; }\n    public Type MessageType { get; set; }\n    public Type AggregateType { get; set; }\n    public Type HandlerType { get; set; }\n    // Strongly-typed matching methods (for types)\n    public bool MatchesMessage<T>() => MessageType == typeof(T);\n    public bool MatchesEvent<T>() where T : IEvent => MessageType == typeof(T);\n    public bool MatchesCommand<T>() where T : ICommand => MessageType == typeof(T);\n    public bool MatchesAggregate<T>() where T : Aggregate => AggregateType == typeof(T);\n    public bool MatchesHandler<T>() => HandlerType == typeof(T);\n    public bool MatchesDriver<T>() => DriverType == typeof(T);\n    // Convenience methods\n    public bool HasFlag(WhizbangFlags flag) => Flags",
        "startIndex": 16860,
        "preview": "NotifyIDE()) And(action => action CaptureFullContext()); // State inspection public class StateInspectionInterceptor : IMessageInterceptor { public as..."
      },
      {
        "id": "proposals/policy-engine-chunk-8",
        "text": "IEvent => MessageType == typeof(T); public bool MatchesCommand<T>() where T : ICommand => MessageType == typeof(T); public bool MatchesAggregate<T>() where T : Aggregate => AggregateType == typeof(T); public bool MatchesHandler<T>() => HandlerType == typeof(T); public bool MatchesDriver<T>() => DriverType == typeof(T); // Convenience methods public bool HasFlag(WhizbangFlags flag) => Flags HasFlag(flag);\n    public bool HasTag(string tag) => Tags Contains(tag);\n    public bool IsEnvironment(string env) => Environment Equals(env, StringComparison OrdinalIgnoreCase);\n}\n// Simple policy builder\npublic interface IPolicyBuilder {\n    IPolicyBuilder When(Func<MessageContext, bool> condition);\n    IPolicyBuilder Then(Action<ConfigurationBuilder> action);\n    IPolicyBuilder And(Action<ConfigurationBuilder> action);\n}\n// Clean, readable policy configuration\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Type matching using context methods\n        policies When(ctx => ctx MatchesMessage<PlaceOrder>()) Then(config => config SetPerformanceBudget(orderBudget));\n        policies When(ctx => ctx MatchesAggregate<Order>()) Then(config => config UseConcurrencyStrategy(ConcurrencyStrategy AutomaticRetry));\n        policies When(ctx => ctx MatchesHandler<PaymentHandler>()) Then(config => config RequireEncryption());\n        // Conditional type matching with additional checks\n        policies When(ctx => ctx MatchesEvent<OrderPlaced>() && \n                             ctx GetEvent<OrderPlaced>() Total > 10000) Then(config => config EnableDetailedAuditing());\n        // Pattern matching on message names\n        policies When(ctx => ctx MessageType Name EndsWith(\"Command\")) Then(config => config SetMaxLatency(TimeSpan FromSeconds(1)));\n        // Flag and tag conditions\n        policies When(ctx => ctx HasFlag(WhizbangFlags Production)) Then(config => config SetObservabilityLevel(ObservabilityLevel Standard));\n        policies When(ctx => ctx HasTag(\"critical-path\") && ctx IsEnvironment(\"production\")) Then(config => config SetObservabilityLevel(ObservabilityLevel Detailed));\n        // Complex tenant conditions\n        policies When(ctx => ctx TenantId = null && ctx HasTag(\"enterprise\")) Then(config => config UseTenancyStrategy(TenancyStrategy",
        "startIndex": 19574,
        "preview": "IEvent => MessageType == typeof(T); public bool MatchesCommand<T>() where T : ICommand => MessageType == typeof(T); public bool MatchesAggregate<T>() ..."
      },
      {
        "id": "proposals/policy-engine-chunk-9",
        "text": "config SetMaxLatency(TimeSpan FromSeconds(1))); // Flag and tag conditions policies When(ctx => ctx HasFlag(WhizbangFlags Production)) Then(config => config SetObservabilityLevel(ObservabilityLevel Standard)); policies When(ctx => ctx HasTag(\"critical-path\") && ctx IsEnvironment(\"production\")) Then(config => config SetObservabilityLevel(ObservabilityLevel Detailed)); // Complex tenant conditions policies When(ctx => ctx TenantId = null && ctx HasTag(\"enterprise\")) Then(config => config UseTenancyStrategy(TenancyStrategy SeparateDatabases));\n    });\n});\n`\nPolicy Hashing & Tracing\nEvery policy generates a deterministic hash for tracing and debugging:\n`csharp{title=\"Policy Hashing & Tracing\" description=\"Policy hashing and tracing infrastructure for debugging and policy identification\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Policy-Hashing\", \"Debugging\", \"Tracing\"] framework=\"NET8\"}\n---\npublic interface IPolicy {\n    string Name { get; }\n    int Priority { get; }\n    string PolicyHash { get; } // Deterministic hash of policy conditions & actions\n    Task<bool> ShouldApplyAsync<T>(T message, MessageContext context);\n    Task<PolicyAction[]> GetActionsAsync<T>(T message, MessageContext context);\n}\n// Policy hash generation\npublic class PolicyBuilder {\n    public string GeneratePolicyHash() {\n        var hashInput = new {\n            Conditions = _conditions Select(c => c ToHashString()),\n            Actions = _actions Select(a => a ToHashString()),\n            Priority = _priority\n        };\n        using var sha = SHA256 Create();\n        var bytes = sha ComputeHash(Encoding UTF8 GetBytes(JsonSerializer Serialize(hashInput)));\n        return Convert ToBase64String(bytes)[",
        "startIndex": 21614,
        "preview": "config SetMaxLatency(TimeSpan FromSeconds(1))); // Flag and tag conditions policies When(ctx => ctx HasFlag(WhizbangFlags Production)) Then(config => ..."
      },
      {
        "id": "proposals/policy-engine-chunk-10",
        "text": "hash generation public class PolicyBuilder { public string GeneratePolicyHash() { var hashInput = new { Conditions = _conditions Select(c => c ToHashString()), Actions = _actions Select(a => a ToHashString()), Priority = _priority }; using var sha = SHA256 Create(); var bytes = sha ComputeHash(Encoding UTF8 GetBytes(JsonSerializer Serialize(hashInput))); return Convert ToBase64String(bytes)[ 8]; // Short hash for readability\n    }\n}\n// Context carries applied policies\npublic class MessageContext {\n    public string CorrelationId { get; set; }\n    public WhizbangFlags Flags { get; set; }\n    public HashSet<string> Tags { get; set; }\n    // Policy tracking for debugging\n    public List<AppliedPolicy> AppliedPolicies { get; set; } = new();\n    public string ActivePolicyHash { get; set; } // Currently executing policy\n    public Dictionary<string, object> PolicyDecisions { get; set; } = new();\n}\npublic class AppliedPolicy {\n    public string PolicyHash { get; set; }\n    public string PolicyName { get; set; }\n    public DateTimeOffset AppliedAt { get; set; }\n    public Dictionary<string, object> Decisions { get; set; }\n    public TimeSpan EvaluationTime { get; set; }\n}\n`\nDistributed Tracing Integration\nPolicy decisions are traced through OpenTelemetry:\n`csharp{title=\"Distributed Tracing Integration\" description=\"Distributed tracing integration showing policy decisions in OpenTelemetry traces\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Distributed-Tracing\", \"OpenTelemetry\"] framework=\"NET8\"}\n---\npublic class PolicyTracingInterceptor : IMessageInterceptor {\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        using var activity = Activity StartActivity(\"PolicyEvaluation\");\n        // Evaluate applicable policies\n        var policies = await _policyEngine EvaluateAsync(message, context);\n        foreach (var policy in policies) {\n            // Add policy hash to trace\n            activity SetTag(\"whizbang policy hash\", policy PolicyHash);\n            activity SetTag(\"whizbang policy name\", policy Name);\n            // Track in context for debugging\n            context AppliedPolicies Add(new AppliedPolicy {\n                PolicyHash = policy PolicyHash,\n                PolicyName = policy Name,\n                AppliedAt = DateTimeOffset UtcNow,\n                Decisions = policy GetDecisions()\n            });\n        }\n        // Include policy hashes in trace state\n        var traceState = $\"policies={string Join(',', policies Select(p => p",
        "startIndex": 22820,
        "preview": "hash generation public class PolicyBuilder { public string GeneratePolicyHash() { var hashInput = new { Conditions = _conditions Select(c => c ToHashS..."
      },
      {
        "id": "proposals/policy-engine-chunk-11",
        "text": "SetTag(\"whizbang policy name\", policy Name); // Track in context for debugging context AppliedPolicies Add(new AppliedPolicy { PolicyHash = policy PolicyHash, PolicyName = policy Name, AppliedAt = DateTimeOffset UtcNow, Decisions = policy GetDecisions() }); } // Include policy hashes in trace state var traceState = $\"policies={string Join(',', policies Select(p => p PolicyHash))}\";\n        activity SetTag(\"tracestate\", traceState);\n        return await next(message, context);\n    }\n}\n// Policy decisions visible in traces\n// Trace: PlaceOrder -> OrderHandler\n//   Tags:\n//     whizbang policy hash: \"Ab3d9F2x\"\n//     whizbang policy name: \"HighValueOrderPolicy\"\n//     whizbang decisions: { \"concurrency\": \"ExpectedVersion\", \"observability\": \"Verbose\" }\n`\nIDE Integration via Source Generation\nSource generator creates policy metadata for IDE tooling:\n`csharp{title=\"IDE Integration via Source Generation\" description=\"Source-generated metadata enabling IDE navigation and policy impact analysis\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"Source-Generation\", \"IDE-Integration\"] framework=\"NET8\"}\n---\n// Generated policy metadata for IDE navigation\n[GeneratedCode(\"Whizbang SourceGenerator\")]\npublic static class PolicyMetadata {\n    // Map of types to affecting policies\n    public static readonly Dictionary<Type, List<PolicyInfo>> TypePolicies = new() {\n        [typeof(Order)] = new List<PolicyInfo> {\n            new(\"Ab3d9F2x\", \"OrderConcurrencyPolicy\", PolicyEffect ConcurrencyStrategy),\n            new(\"Cd5e8G3y\", \"OrderObservabilityPolicy\", PolicyEffect ObservabilityLevel),\n            new(\"Ef7h2K4z\", \"OrderPerformanceBudget\", PolicyEffect PerformanceBudget)\n        },\n        [typeof(OrderPlaced)] = new List<PolicyInfo> {\n            new(\"Gh9j4M5a\", \"EventRoutingPolicy\", PolicyEffect Routing),\n            new(\"Ij2k6N7b\", \"EventSerializationPolicy\", PolicyEffect Serialization)\n        },\n        [typeof(OrderSummaryProjection)] = new List<PolicyInfo> {\n            new(\"Kl4m8P9c\", \"ProjectionLagPolicy\", PolicyEffect Performance),\n            new(\"Mn6o2Q1d\", \"ProjectionPartitioningPolicy\", PolicyEffect Partitioning)\n        }\n    };\n    // Reverse mapping for \"what does this policy affect \"\n    public static readonly Dictionary<string, List<AffectedType>> PolicyEffects = new() {\n        [\"Ab3d9F2x\"] = new List<AffectedType> {\n            new(typeof(Order), \"Aggregate\", \"Sets concurrency to ExpectedVersion\"),\n            new(typeof(PlaceOrder), \"Command\", \"Inherits aggregate concurrency\"),\n            new(typeof(UpdateOrder), \"Command\", \"Inherits aggregate concurrency\")\n        }\n    };\n    // Policy evaluation paths for debugging\n    public static readonly Dictionary<string, PolicyEvaluationPath> PolicyPaths = new() {\n        [\"Ab3d9F2x\"] = new PolicyEvaluationPath {\n            Conditions = new[] { \"AggregateType == Order\" },\n            Actions = new[] { \"SetConcurrencyStrategy(ExpectedVersion)\" },\n            Priority = 100,\n            Source = \"OrderConcurrencyPolicy",
        "startIndex": 25076,
        "preview": "SetTag(\"whizbang policy name\", policy Name); // Track in context for debugging context AppliedPolicies Add(new AppliedPolicy { PolicyHash = policy Pol..."
      },
      {
        "id": "proposals/policy-engine-chunk-12",
        "text": "\"Inherits aggregate concurrency\"), new(typeof(UpdateOrder), \"Command\", \"Inherits aggregate concurrency\") } }; // Policy evaluation paths for debugging public static readonly Dictionary<string, PolicyEvaluationPath> PolicyPaths = new() { [\"Ab3d9F2x\"] = new PolicyEvaluationPath { Conditions = new[] { \"AggregateType == Order\" }, Actions = new[] { \"SetConcurrencyStrategy(ExpectedVersion)\" }, Priority = 100, Source = \"OrderConcurrencyPolicy cs:line 15\"\n        }\n    };\n}\n`\nGitLens-Style IDE Experience\nVisual Studio/Rider extension shows policy effects inline:\n`csharp{title=\"GitLens-Style IDE Experience\" description=\"Visual Studio/Rider extension shows policy effects inline\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Policy-Engine\", \"IDE-Experience\", \"Visual-Annotations\"] framework=\"NET8\"}\n// OrderAggregate cs\npublic class Order : Aggregate { // üìã 3 policies affect this aggregate [hover for details]\n    // PolicyLens: Ab3d9F2x (Concurrency: ExpectedVersion)\n    // PolicyLens: Cd5e8G3y (Observability: Verbose for orders > $1000)  \n    // PolicyLens: Ef7h2K4z (Performance Budget: 100ms max latency)\n    public void PlaceOrder(CustomerId customerId, List<OrderItem> items) {\n        // PolicyLens: This method triggers policies Ab3d9F2x, Gh9j4M5a\n        Apply(new OrderPlaced( ));\n    }\n}\n// OrderSummaryProjection cs  \npublic class OrderSummaryProjection { // üìã 2 policies affect this projection\n    // PolicyLens: Kl4m8P9c (Max lag: 5 minutes before alert)\n    // PolicyLens: Mn6o2Q1d (Partitioned by CustomerId)\n    public void Handle(OrderPlaced @event) { // PolicyLens: Routed by policy Gh9j4M5a\n        // Update projection }\n}\n`\nPolicy Debugging Commands\nIDE commands for policy investigation:\n`csharp{title=\"Policy Debugging Commands\" description=\"IDE commands for policy investigation\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"IDE-Commands\", \"Debugging\"] framework=\"NET8\"}\n// Right-click on any type/method in IDE:\n// > Whizbang: Show Affecting Policies\n// > Whizbang: Trace Policy Evaluation  \n// > Whizbang: Simulate Policy Changes\n// > Whizbang: Show Policy History (git blame for policies)\n// Command palette:\n// > Whizbang: What policies affect Order aggregate // > Whizbang: What does policy Ab3d9F2x affect",
        "startIndex": 27753,
        "preview": "\"Inherits aggregate concurrency\"), new(typeof(UpdateOrder), \"Command\", \"Inherits aggregate concurrency\") } }; // Policy evaluation paths for debugging..."
      },
      {
        "id": "proposals/policy-engine-chunk-13",
        "text": "type/method in IDE: // > Whizbang: Show Affecting Policies // > Whizbang: Trace Policy Evaluation // > Whizbang: Simulate Policy Changes // > Whizbang: Show Policy History (git blame for policies) // Command palette: // > Whizbang: What policies affect Order aggregate // > Whizbang: What does policy Ab3d9F2x affect // > Whizbang: Show policy evaluation for PlaceOrder command\n// > Whizbang: Compare policies between environments\n`\nRuntime Policy Debugging\nAccess policy decisions at runtime:\n`csharp{title=\"Runtime Policy Debugging\" description=\"Runtime policy debugging middleware exposing policy decisions through HTTP headers\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Runtime-Debugging\", \"HTTP-Headers\"] framework=\"NET8\"}\n---\npublic class PolicyDebugMiddleware {\n    public async Task InvokeAsync(HttpContext context, RequestDelegate next) {\n        // Inject policy debug header\n        context Response OnStarting(() => {\n            var messageContext = context GetMessageContext();\n            if (messageContext AppliedPolicies Any() == true) {\n                var policyHashes = string Join(\",\", \n                    messageContext AppliedPolicies Select(p => p PolicyHash));\n                context Response Headers[\"X-Whizbang-Policies\"] = policyHashes;\n                // Debug mode: include full policy decisions\n                if (context Request Headers ContainsKey(\"X-Debug-Policies\")) {\n                    context Response Headers[\"X-Whizbang-Policy-Decisions\"] = \n                        JsonSerializer Serialize(messageContext PolicyDecisions);\n                }\n            }\n            return Task CompletedTask;\n        });\n        await next(context);\n    }\n}\n// HTTP Response Headers:\n// X-Whizbang-Policies: Ab3d9F2x,Cd5e8G3y,Ef7h2K4z\n// X-Whizbang-Policy-Decisions: {\"concurrency\":\"ExpectedVersion\",\"observability\":\"Verbose\"}\n`\nPolicy Evaluation Pipeline\n`csharp{title=\"Policy Evaluation Pipeline\" description=\"Policy evaluation pipeline with pre and post-execution action application\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Pipeline\", \"Pre-Post-Execution\"] framework=\"NET8\"}\n---\npublic class PolicyEvaluationPipeline : IMessageInterceptor {\n    private readonly IPolicyEngine _policyEngine;\n    public async Task<TResponse> Intercept<TRequest, TResponse>(\n        TRequest message,\n        MessageContext context,\n        MessageHandlerDelegate<TRequest, TResponse> next) {\n        // Evaluate policies before handler execution\n        var policyResult = await _policyEngine EvaluateAsync(message, context);\n        // Apply pre-execution actions\n        foreach (var action in policyResult PreExecutionActions) {\n            await action ExecuteAsync(message, context);\n        }\n        // Execute handler (might be changed by policy)\n        var response = await next(message, context);\n        // Apply post-execution actions\n        foreach (var action in policyResult PostExecutionActions) {\n            await action",
        "startIndex": 29609,
        "preview": "type/method in IDE: // > Whizbang: Show Affecting Policies // > Whizbang: Trace Policy Evaluation // > Whizbang: Simulate Policy Changes // > Whizbang..."
      },
      {
        "id": "proposals/policy-engine-chunk-14",
        "text": "var policyResult = await _policyEngine EvaluateAsync(message, context); // Apply pre-execution actions foreach (var action in policyResult PreExecutionActions) { await action ExecuteAsync(message, context); } // Execute handler (might be changed by policy) var response = await next(message, context); // Apply post-execution actions foreach (var action in policyResult PostExecutionActions) { await action ExecuteAsync(response, context);\n        }\n        return response;\n    }\n}\n`\nConfiguration Integration\n`csharp{title=\"Configuration Integration\" description=\"Environment-based policy loading with configuration integration and team-specific policies\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Policy-Engine\", \"Configuration-Integration\", \"Environment-Based\"] framework=\"NET8\"}\n---\n// Environment-based policy loading\nservices AddWhizbang(options => {\n    options Policies(policies => {\n        // Load environment-specific policies\n        if (_environment IsProduction()) {\n            policies LoadFromConfiguration(\"Production\");\n            policies Apply(WhizbangPolicies ProductionSafetyPolicy);\n        } else if (_environment IsDevelopment()) {\n            policies LoadFromConfiguration(\"Development\");\n            policies Apply(WhizbangPolicies DevelopmentDebuggingPolicy);\n        }\n        // Load custom policies from configuration\n        policies LoadFromSection(\"CustomPolicies\");\n        // Team-specific canned policies\n        policies Apply(TeamPolicies DataTeamStandardPolicies);\n        policies Apply(TeamPolicies",
        "startIndex": 32325,
        "preview": "var policyResult = await _policyEngine EvaluateAsync(message, context); // Apply pre-execution actions foreach (var action in policyResult PreExecutio..."
      },
      {
        "id": "proposals/policy-engine-chunk-15",
        "text": "services AddWhizbang(options => { options Policies(policies => { // Load environment-specific policies if (_environment IsProduction()) { policies LoadFromConfiguration(\"Production\"); policies Apply(WhizbangPolicies ProductionSafetyPolicy); } else if (_environment IsDevelopment()) { policies LoadFromConfiguration(\"Development\"); policies Apply(WhizbangPolicies DevelopmentDebuggingPolicy); } // Load custom policies from configuration policies LoadFromSection(\"CustomPolicies\"); // Team-specific canned policies policies Apply(TeamPolicies DataTeamStandardPolicies); policies Apply(TeamPolicies SecurityTeamCompliancePolicies);\n    });\n});\n// Configuration example\n{\n  \"Whizbang\": {\n    \"Policies\": {\n      \"Production\": [\n        {\n          \"Name\": \"ProductionDataScrubbing\",\n          \"Condition\": \"HasFlag('Production') && HasTag('sensitive-data')\",\n          \"Actions\": [\n            { \"Type\": \"ScrubData\", \"Fields\": [\"SSN\", \"CreditCard\"] },\n            { \"Type\": \"AddTag\", \"Value\": \"scrubbed\" }\n          ]\n        }\n      ]\n    }\n  }\n}\n`\nBest Practices\nPolicy Design Guidelines\nKeep policies focused - One policy per concern\nUse clear naming - Policy names should describe their purpose\nDocument side effects - Policies can change behavior significantly\nTest policy interactions - Multiple policies can interact unexpectedly\nMonitor policy performance - Complex policies can impact performance\nFlag Usage Guidelines\nUse library flags first - Prefer built-in flags over custom tags\nDocument custom flags - Make user-defined flags clear to the team\nBe conservative with propagation - Not all flags should cross service boundaries\nConsider flag lifetime - How long should flags persist in the system\nAudit flag usage - Track which flags are used and where\nSecurity Considerations\nValidate flag sources - Ensure flags come from trusted sources\nLimit dangerous flags - SecurityBypass should be heavily restricted\nAudit policy changes - Log all policy modifications\nEncrypt sensitive tags - Some tags may contain sensitive information\nPrinciple of least privilege - Policies should grant minimal necessary permissions\n---\nRelated Documentation\nEvent Store & Projections - How policies affect storage and projections\nDomain Ownership - Policy-based routing and ownership\nAdvanced Features - Debugging and development tools integration",
        "startIndex": 33482,
        "preview": "services AddWhizbang(options => { options Policies(policies => { // Load environment-specific policies if (_environment IsProduction()) { policies Loa..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/projection-management",
    "title": "Projection Management",
    "category": "Architecture & Design",
    "url": "/docs/proposals/projection-management",
    "chunks": [
      {
        "id": "proposals/projection-management-chunk-0",
        "text": "Projection Management\nWhizbang provides comprehensive projection management including checkpoints, backfilling strategies, system events for on-demand rebuilds, and flexible storage options Checkpoint Storage\nProjections track their progress through checkpoint storage, supporting multiple strategies:\nA Same Database (Default)\nTransactional consistency - checkpoints and projections updated together:\n`csharp{title=\"Transactional Checkpoint Storage Configuration\" description=\"Configuration for transactional checkpoint storage with projections\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"checkpoints\", \"configuration\", \"transactions\"] framework=\"NET8\"}\nservices AddProjection<OrderSummaryProjection>(options => {\n    options CheckpointStorage = CheckpointStorage SameDatabase;\n});\n// Implementation: Single transaction\nawait using var transaction = await database BeginTransactionAsync();\nawait projectionStore UpdateProjection(orderSummary, transaction);\nawait checkpointStore SaveCheckpoint(position, transaction);\nawait transaction CommitAsync();\n`\nBenefits:\n‚úÖ Exactly-once processing guarantee\n‚úÖ Simple consistency model\n‚úÖ No external dependencies\nDrawbacks:\n‚ùå Tight coupling to projection database\n‚ùå Limited to single database systems\nB Separate Metadata Store\nFlexible checkpoint storage separate from projection data:\n`csharp{title=\"Separate Checkpoint Storage Configuration\" description=\"Configuration for separate checkpoint storage using Redis or other stores\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"checkpoints\", \"redis\", \"eventually-consistent\"] framework=\"NET8\"}\nservices AddProjection<OrderSummaryProjection>(options => {\n    options CheckpointStorage = CheckpointStorage Separate;\n    options CheckpointStore = CheckpointStore Redis; // or CosmosDB, DynamoDB\n});\n// Implementation: Two-phase with compensation\ntry {\n    await projectionStore UpdateProjection(orderSummary);\n    await checkpointStore SaveCheckpoint(position);\n} catch {\n    // Compensation: projection will be updated again on replay\n    // Idempotent handlers ensure correctness\n}\n`\nBenefits:\n‚úÖ Optimized checkpoint storage (Redis, DynamoDB)\n‚úÖ Cross-database projections supported\n‚úÖ Better performance for high-throughput scenarios\nDrawbacks:\n‚ùå Eventually consistent\n‚ùå Requires idempotent projection handlers\nCheckpoint Configuration\n`csharp{title=\"Global Checkpoint Configuration\" description=\"Global checkpoint configuration and storage options\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"configuration\", \"global-settings\", \"checkpoints\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options Projections(projections => {\n        // Global checkpoint settings\n        projections DefaultCheckpointStorage = CheckpointStorage SameDatabase;\n        projections CheckpointFrequency = CheckpointFrequency EveryEvent; // or EveryNEvents(10)\n        // Checkpoint stores\n        projections UseRedisCheckpoints(\"localhost:6379\");\n        projections UseCosmosCheckpoints(\"connection-string\");\n        projections UseSqlCheckpoints(\"connection-string\");\n    });\n});\n`\nSnapshot Management\nA",
        "startIndex": 0,
        "preview": "Projection Management\nWhizbang provides comprehensive projection management including checkpoints, backfilling strategies, system events for on-demand..."
      },
      {
        "id": "proposals/projection-management-chunk-1",
        "text": "and storage options\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"configuration\", \"global-settings\", \"checkpoints\"] framework=\"NET8\"} services AddWhizbang(options => { options Projections(projections => { // Global checkpoint settings projections DefaultCheckpointStorage = CheckpointStorage SameDatabase; projections CheckpointFrequency = CheckpointFrequency EveryEvent; // or EveryNEvents(10) // Checkpoint stores projections UseRedisCheckpoints(\"localhost:6379\"); projections UseCosmosCheckpoints(\"connection-string\"); projections UseSqlCheckpoints(\"connection-string\"); }); }); ` Snapshot Management A Automatic Snapshots (Default)\nConfigurable automatic snapshotting for projections:\n`csharp{title=\"Automatic Snapshot Configuration\" description=\"Automatic snapshot configuration with frequency and retention policies\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"snapshots\", \"automatic-management\"] framework=\"NET8\"}\nservices AddProjection<CustomerSummaryProjection>(options => {\n    options Snapshots(snapshots => {\n        snapshots Strategy = SnapshotStrategy Automatic;\n        snapshots Frequency = SnapshotFrequency EveryNEvents(1000);\n        snapshots RetentionPolicy = SnapshotRetention KeepLast(5);\n    });\n});\n`\nB Manual Snapshots\nDeveloper-controlled snapshotting:\n`csharp{title=\"Manual Snapshot Control\" description=\"Manual snapshot control with custom triggers and restoration logic\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"snapshots\", \"manual-control\", \"triggers\"] framework=\"NET8\"}\npublic class CustomerSummaryProjection : IProjectionHandler<CustomerRegistered>,\n                                        IProjectionHandler<CustomerUpdated>,\n                                        ISnapshotProvider<CustomerSummarySnapshot> {\n    public CustomerSummary State { get; private set; }\n    public async Task Handle(CustomerRegistered @event, ProjectionContext context) {\n        State = new CustomerSummary {\n            CustomerId = @event CustomerId,\n            Name = @event Name,\n            Email = @event Email,\n            RegisteredAt = @event RegisteredAt\n        };\n        await context Store(@event CustomerId ToString(), State);\n    }\n    // Manual snapshot creation\n    [Snapshot(TriggerOn = typeof(CustomerMilestoneReached))]\n    public CustomerSummarySnapshot CreateSnapshot() {\n        return new CustomerSummarySnapshot {\n            CustomerId = State CustomerId,\n            Name = State Name,\n            TotalOrders = State TotalOrders,\n            LifetimeValue = State LifetimeValue,\n            SnapshotVersion = State Version\n        };\n    }\n    public void RestoreFromSnapshot(CustomerSummarySnapshot snapshot) {\n        State = new CustomerSummary {\n            CustomerId = snapshot CustomerId,\n            Name = snapshot Name,\n            TotalOrders = snapshot TotalOrders,\n            LifetimeValue = snapshot LifetimeValue,\n            Version = snapshot SnapshotVersion\n        };\n    }\n}\n`\nC No Snapshots\nOpt out of snapshotting for simple projections:\n`csharp{title=\"Disable Snapshots Configuration\" description=\"Disabling snapshots for simple projections that don't need them\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"projections\", \"snapshots\", \"simple-projections\"] framework=\"NET8\"}\nservices AddProjection<SimpleEventLogProjection>(options => {\n    options Snapshots(snapshots => {\n        snapshots Strategy = SnapshotStrategy None;\n    });\n});\n`\nBackfilling Strategies\nA",
        "startIndex": 3156,
        "preview": "and storage options\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"configuration\", \"global-settings\", \"checkpoints\"] framework=\"NE..."
      },
      {
        "id": "proposals/projection-management-chunk-2",
        "text": "} } ` C No Snapshots Opt out of snapshotting for simple projections: `csharp{title=\"Disable Snapshots Configuration\" description=\"Disabling snapshots for simple projections that don't need them\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"projections\", \"snapshots\", \"simple-projections\"] framework=\"NET8\"} services AddProjection<SimpleEventLogProjection>(options => { options Snapshots(snapshots => { snapshots Strategy = SnapshotStrategy None; }); }); ` Backfilling Strategies A Declarative Backfilling\nSimple configuration-based backfilling:\n`csharp{title=\"Declarative Backfilling Configuration\" description=\"Declarative backfilling configuration with date ranges and batch settings\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"backfilling\", \"declarative-configuration\"] framework=\"NET8\"}\nservices AddProjection<OrderHistoryProjection>(options => {\n    options Backfill(backfill => {\n        backfill StartFrom = DateTimeOffset Parse(\"2024-01-01\");\n        backfill AutoStart = true;\n        backfill BatchSize = 1000;\n        backfill MaxConcurrency = 4;\n    });\n});\n// Or backfill everything\nservices AddProjection<NewAnalyticsProjection>(options => {\n    options BackfillFromBeginning();\n});\n`\nB Imperative Backfilling\nProgrammatic control over backfilling:\n`csharp{title=\"Programmatic Backfilling REST API\" description=\"REST API controller for programmatic projection backfilling\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"backfilling\", \"rest-api\", \"controller\"] framework=\"NET8\"}\npublic class BackfillController : ControllerBase {\n    private readonly IProjectionManager _projectionManager;\n    [HttpPost(\"projections/{projectionName}/backfill\")]\n    public async Task<IActionResult> BackfillProjection(\n        string projectionName,\n        BackfillRequest request) {\n        var options = new BackfillOptions {\n            FromDate = request FromDate,\n            ToDate = request ToDate,\n            BatchSize = request BatchSize 1000,\n            IsAtomic = request IsAtomic false,\n            OnProgress = (progress) => {\n                // Real-time progress updates via SignalR\n                _hubContext Clients All SendAsync(\"BackfillProgress\", progress);\n            }\n        };\n        var result = await _projectionManager BackfillAsync(projectionName, options);\n        return Ok(result);\n    }\n}\n`\nSystem Events for On-Demand Backfilling\nEvent-driven backfill requests:\n`csharp{title=\"System Events for Backfilling\" description=\"System events for on-demand projection backfilling with criteria\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"system-events\", \"event-driven-backfill\"] framework=\"NET8\"}\n// System event to trigger backfilling\npublic record ProjectionBackfillRequested(\n    string ProjectionName,\n    DateTimeOffset FromDate,\n    DateTimeOffset",
        "startIndex": 6032,
        "preview": "} } ` C No Snapshots Opt out of snapshotting for simple projections: `csharp{title=\"Disable Snapshots Configuration\" description=\"Disabling snapshots ..."
      },
      {
        "id": "proposals/projection-management-chunk-3",
        "text": "= await _projectionManager BackfillAsync(projectionName, options); return Ok(result); } } ` System Events for On-Demand Backfilling Event-driven backfill requests: `csharp{title=\"System Events for Backfilling\" description=\"System events for on-demand projection backfilling with criteria\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"system-events\", \"event-driven-backfill\"] framework=\"NET8\"} // System event to trigger backfilling public record ProjectionBackfillRequested( string ProjectionName, DateTimeOffset FromDate, DateTimeOffset ToDate,\n    bool IsAtomic,\n    BackfillCriteria Criteria,\n    string RequestedBy\n) : ISystemEvent;\n`csharp{title=\"Backfill System Event Handler\" description=\"System event handler for processing backfill requests\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"system-events\", \"event-handlers\", \"backfilling\"] framework=\"NET8\"}\n// System event handler\npublic class ProjectionBackfillHandler : ISystemEventHandler<ProjectionBackfillRequested> {\n    public async Task Handle(ProjectionBackfillRequested @event, SystemEventContext context) {\n        var options = new BackfillOptions {\n            FromDate = @event FromDate,\n            ToDate = @event ToDate,\n            IsAtomic = @event IsAtomic,\n            Criteria = @event Criteria,\n            RequestId = context CorrelationId\n        };\n        await _projectionManager BackfillAsync(@event ProjectionName, options);\n        // Emit completion event\n        await context PublishSystemEvent(new ProjectionBackfillCompleted(\n            @event ProjectionName,\n            options FromDate,\n            options ToDate,\n            context CorrelationId\n        ));\n    }\n}\n// Trigger backfill via system event\nawait _systemEventPublisher PublishAsync(new ProjectionBackfillRequested(\n    ProjectionName: \"order-summary\",\n    FromDate: DateTimeOffset Parse(\"2024-01-01\"),\n    ToDate: null, // To current\n    IsAtomic: true,\n    Criteria: BackfillCriteria FullRebuild,\n    RequestedBy: \"admin-user\"\n));\n`\nBackfill Criteria Options\n`csharp{title=\"Backfill Criteria Options\" description=\"Comprehensive backfill criteria options for different scenarios\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"backfilling\", \"criteria-options\"] framework=\"NET8\"}\npublic enum BackfillCriteria {\n    // Date-based backfill\n    DateRange,              // Specific date range\n    FromDate,               // From date to current\n    LastNDays,              // Last N days only\n    // Event-based backfill  \n    EventNumberRange,       // Specific event number range\n    FromEventNumber,        // From event number to current\n    LastNEvents,            // Last N events only\n    // Full rebuild options\n    FullRebuild,            // Complete rebuild from beginning\n    IncrementalUpdate,      // Only missing/updated events\n    // Custom criteria\n    CustomPredicate         // Custom filter expression\n}\n// Usage examples\nservices AddProjection<OrderSummaryProjection>(options => {\n    options Backfill(backfill => {\n        backfill Criteria = BackfillCriteria LastNDays;\n        backfill CriteriaValue = 30; // Last 30 days\n    });\n});\n// System event with custom criteria\nawait _systemEvents",
        "startIndex": 8404,
        "preview": "= await _projectionManager BackfillAsync(projectionName, options); return Ok(result); } } ` System Events for On-Demand Backfilling Event-driven backf..."
      },
      {
        "id": "proposals/projection-management-chunk-4",
        "text": "from beginning IncrementalUpdate, // Only missing/updated events // Custom criteria CustomPredicate // Custom filter expression } // Usage examples services AddProjection<OrderSummaryProjection>(options => { options Backfill(backfill => { backfill Criteria = BackfillCriteria LastNDays; backfill CriteriaValue = 30; // Last 30 days }); }); // System event with custom criteria await _systemEvents PublishAsync(new ProjectionBackfillRequested(\n    ProjectionName: \"analytics\",\n    FromDate: null,\n    ToDate: null,\n    IsAtomic: false,\n    Criteria: BackfillCriteria CustomPredicate,\n    RequestedBy: \"system\"\n) {\n    CustomPredicate = @event => @event EventType StartsWith(\"Order\") && \n                               @event Metadata[\"source\"] == \"web-api\"\n});\n`\nAdvanced Backfill Features\nParallel Processing\n`csharp{title=\"Parallel Backfill Processing\" description=\"Parallel backfill processing with partitioning and concurrency control\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"backfilling\", \"parallel-processing\", \"concurrency\"] framework=\"NET8\"}\nservices AddProjection<AnalyticsProjection>(options => {\n    options Backfill(backfill => {\n        backfill Strategy = BackfillStrategy Parallel;\n        backfill PartitionBy = @event => @event StreamId GetHashCode() % 8;\n        backfill MaxConcurrency = 8;\n        backfill BatchSize = 500;\n    });\n});\n`\nProgress Tracking\n`csharp{title=\"Backfill Progress Tracking\" description=\"Real-time progress tracking for backfill operations\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"backfilling\", \"progress-tracking\"] framework=\"NET8\"}\npublic class BackfillProgressTracker {\n    public async Task TrackProgress(string projectionName, CancellationToken cancellationToken) {\n        await foreach (var progress in _projectionManager GetBackfillProgress(projectionName, cancellationToken)) {\n            Console WriteLine($\"Backfill progress: {progress EventsProcessed}/{progress TotalEvents} \" +\n                            $\"({progress PercentComplete:F1}%) - ETA: {progress EstimatedTimeRemaining}\");\n        }\n    }\n}\n`\nRollback Support\n`csharp{title=\"Backfill Rollback Support\" description=\"Rollback support for failed backfill operations with backup creation\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"backfilling\", \"rollback-support\", \"backup\"] framework=\"NET8\"}\n// Rollback to previous version if backfill fails\nservices AddProjection<OrderSummaryProjection>(options => {\n    options Backfill(backfill => {\n        backfill EnableRollback = true;\n        backfill RollbackOnFailure = true;\n        backfill CreateBackupBeforeBackfill = true;\n    });\n});\n// Manual rollback API\nawait _projectionManager",
        "startIndex": 11072,
        "preview": "from beginning IncrementalUpdate, // Only missing/updated events // Custom criteria CustomPredicate // Custom filter expression } // Usage examples se..."
      },
      {
        "id": "proposals/projection-management-chunk-5",
        "text": "for failed backfill operations with backup creation\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"backfilling\", \"rollback-support\", \"backup\"] framework=\"NET8\"} // Rollback to previous version if backfill fails services AddProjection<OrderSummaryProjection>(options => { options Backfill(backfill => { backfill EnableRollback = true; backfill RollbackOnFailure = true; backfill CreateBackupBeforeBackfill = true; }); }); // Manual rollback API await _projectionManager RollbackProjection(\"order-summary\", toVersion: previousVersion);\n`\nSystem Event Integration\nBuilt-in System Events\n`csharp{title=\"Projection Lifecycle System Events\" description=\"Built-in system events for projection lifecycle monitoring\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"system-events\", \"lifecycle-management\"] framework=\"NET8\"}\n// Projection lifecycle events\npublic record ProjectionStarted(string ProjectionName, DateTimeOffset StartedAt);\npublic record ProjectionStopped(string ProjectionName, DateTimeOffset StoppedAt);\npublic record ProjectionFailed(string ProjectionName, Exception Error, DateTimeOffset FailedAt);\n// Backfill events\npublic record ProjectionBackfillStarted(string ProjectionName, BackfillOptions Options);\npublic record ProjectionBackfillProgress(string ProjectionName, BackfillProgress Progress);\npublic record ProjectionBackfillCompleted(string ProjectionName, BackfillResult Result);\npublic record ProjectionBackfillFailed(string ProjectionName, Exception Error);\n// Checkpoint events\npublic record ProjectionCheckpointSaved(string ProjectionName, long Position);\npublic record ProjectionCheckpointRestored(string ProjectionName, long Position);\n// Snapshot events\npublic record ProjectionSnapshotCreated(string ProjectionName, long EventVersion);\npublic record ProjectionSnapshotRestored(string ProjectionName, long EventVersion);\n`\nCustom System Event Handlers\n`csharp{title=\"Projection Monitoring Event Handlers\" description=\"Custom system event handlers for projection monitoring and alerting\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"system-events\", \"monitoring\", \"alerting\"] framework=\"NET8\"}\npublic class ProjectionMonitoringHandler : \n    ISystemEventHandler<ProjectionFailed>,\n    ISystemEventHandler<ProjectionBackfillCompleted> {\n    public async Task Handle(ProjectionFailed @event, SystemEventContext context) {\n        // Alert on projection failures\n        await _alerting SendAlert($\"Projection {@event ProjectionName} failed: {@event Error Message}\");\n        // Automatic retry for transient failures\n        if (IsTransientError(@event Error)) {\n            await context PublishSystemEvent(new ProjectionRestartRequested(\n                @event ProjectionName,\n                retryAttempt: context GetRetryAttempt() + 1\n            ));\n        }\n    }\n    public async Task Handle(ProjectionBackfillCompleted @event, SystemEventContext context) {\n        // Update projection metadata\n        await _projectionMetadata MarkBackfillComplete(@event ProjectionName, @event Result);\n        // Notify stakeholders\n        await _notifications NotifyBackfillComplete(@event",
        "startIndex": 13391,
        "preview": "for failed backfill operations with backup creation\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"projections\", \"backfilling\", \"rollback-support\", \"..."
      },
      {
        "id": "proposals/projection-management-chunk-6",
        "text": "Error Message}\"); // Automatic retry for transient failures if (IsTransientError(@event Error)) { await context PublishSystemEvent(new ProjectionRestartRequested( @event ProjectionName, retryAttempt: context GetRetryAttempt() + 1 )); } } public async Task Handle(ProjectionBackfillCompleted @event, SystemEventContext context) { // Update projection metadata await _projectionMetadata MarkBackfillComplete(@event ProjectionName, @event Result); // Notify stakeholders await _notifications NotifyBackfillComplete(@event ProjectionName);\n    }\n}\n`\nAPI Reference\nIProjectionManager Interface\n`csharp{title=\"IProjectionManager Interface\" description=\"Comprehensive projection management API interface\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"management-api\", \"interfaces\"] framework=\"NET8\"}\npublic interface IProjectionManager {\n    // Lifecycle management\n    Task StartProjection(string projectionName);\n    Task StopProjection(string projectionName);\n    Task RestartProjection(string projectionName);\n    // Backfilling\n    Task<BackfillResult> BackfillAsync(string projectionName, BackfillOptions options);\n    IAsyncEnumerable<BackfillProgress> GetBackfillProgress(string projectionName, CancellationToken cancellationToken);\n    Task CancelBackfill(string projectionName);\n    // Snapshots\n    Task<SnapshotResult> CreateSnapshot(string projectionName);\n    Task<SnapshotResult> RestoreFromSnapshot(string projectionName, long snapshotVersion);\n    Task<IEnumerable<SnapshotInfo>> GetSnapshots(string projectionName);\n    // Checkpoints\n    Task<long> GetCurrentCheckpoint(string projectionName);\n    Task ResetCheckpoint(string projectionName, long position);\n    // Status and monitoring\n    Task<ProjectionStatus> GetStatus(string projectionName);\n    Task<IEnumerable<ProjectionInfo>> GetAllProjections();\n    Task<ProjectionHealth> GetHealth(string projectionName);\n}\n`\nConfiguration Extensions\n`csharp{title=\"Projection Configuration Extensions\" description=\"Extension methods for fluent projection configuration API\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"projections\", \"extension-methods\", \"fluent-api\"] framework=\"NET8\"}\npublic static class ProjectionConfigurationExtensions {\n    public static IProjectionBuilder<T> BackfillFromBeginning<T>(this IProjectionBuilder<T> builder) \n        where T : class;\n    public static IProjectionBuilder<T> BackfillFrom<T>(this IProjectionBuilder<T> builder, DateTimeOffset from) \n        where T : class;\n    public static IProjectionBuilder<T> WithSnapshots<T>(this IProjectionBuilder<T> builder, \n        Action<SnapshotConfiguration> configure) where T : class;\n    public static IProjectionBuilder<T> WithCheckpoints<T>(this IProjectionBuilder<T> builder, \n        Action<CheckpointConfiguration> configure) where T : class;\n    public static IProjectionBuilder<T> OnSystemEvent<T, TEvent>(this IProjectionBuilder<T> builder, \n        Func<TEvent, Task> handler) where T : class where TEvent : ISystemEvent;\n}\n`\nBest Practices\nProjection Design\nKeep projections focused - One projection per query need\nMake handlers idempotent - Support replay scenarios\nHandle missing data gracefully - Events may be out of order\nVersion projection schemas - Enable evolution over time\nBackfill Planning\nTest backfills in staging - Verify performance and correctness\nUse atomic rebuilds for critical projections\nMonitor resource usage during large backfills\nPlan for rollback scenarios if backfill fails\nCheckpoint Strategy\nUse same-database checkpoints for consistency-critical projections\nUse separate checkpoints for high-throughput scenarios\nCheckpoint frequently to minimize replay overhead\nMonitor checkpoint lag for early failure detection\n---\nRelated Documentation\nEvent Store & Projections - Core storage architecture\nMulti-Tenancy - Tenant-aware projection management\nPerformance Optimization - Scaling projection processing",
        "startIndex": 16063,
        "preview": "Error Message}\"); // Automatic retry for transient failures if (IsTransientError(@event Error)) { await context PublishSystemEvent(new ProjectionResta..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/schema-evolution",
    "title": "Schema Evolution & Event Versioning",
    "category": "Architecture & Design",
    "url": "/docs/proposals/schema-evolution",
    "chunks": [
      {
        "id": "proposals/schema-evolution-chunk-0",
        "text": "Schema Evolution & Event Versioning\nWhizbang provides robust schema evolution capabilities using JSONB storage and flexible driver interfaces, allowing events and projections to evolve over time without breaking existing systems JSONB-Based Schema Evolution\nFlexible Event Schema\nEvents stored in JSONB format naturally support schema evolution:\n`csharp{title=\"Event Schema Evolution\" description=\"Event schema evolution from V1 to V3 with backward-compatible changes\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Schema-Evolution\", \"Event-Versioning\", \"Backward-Compatibility\"] framework=\"NET8\"}\n// V1 Event\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId\n);\n// V2 Event - Add field (backward compatible)\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    DateTimeOffset PlacedAt = null  // Optional for backward compatibility\n);\n// V3 Event - Add collection (backward compatible)\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    DateTimeOffset PlacedAt = null,\n    List<string> Tags = null         // Null-safe collection\n) {\n    // Ensure collections are never null\n    public List<string> Tags { get; init; } = Tags new List<string>();\n}\n`\nJSONB benefits:\n‚úÖ Missing fields handled gracefully\n‚úÖ Extra fields ignored during deserialization\n‚úÖ No database schema migrations required\n‚úÖ Query flexibility with JSON operators\nProjection Schema Evolution\nProjections can evolve independently of events:\n`csharp{title=\"Projection Schema Evolution\" description=\"Projection schema evolution without database migrations using JSONB\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Schema-Evolution\", \"Projections\", \"JSONB-Storage\"] framework=\"NET8\"}\n// V1 Projection\npublic class OrderSummary {\n    public Guid OrderId { get; set; }\n    public decimal Total { get; set; }\n    public OrderStatus Status { get; set; }\n}\n// V2 Projection - Add fields without migration\npublic class OrderSummary {\n    public Guid OrderId { get; set; }\n    public decimal Total { get; set; }\n    public OrderStatus Status { get; set; }\n    // New fields with sensible defaults\n    public DateTime EstimatedDelivery { get; set; } = DateTime",
        "startIndex": 0,
        "preview": "Schema Evolution & Event Versioning\nWhizbang provides robust schema evolution capabilities using JSONB storage and flexible driver interfaces, allowin..."
      },
      {
        "id": "proposals/schema-evolution-chunk-1",
        "text": "} } // V2 Projection - Add fields without migration public class OrderSummary { public Guid OrderId { get; set; } public decimal Total { get; set; } public OrderStatus Status { get; set; } // New fields with sensible defaults public DateTime EstimatedDelivery { get; set; } = DateTime MinValue;\n    public List<string> Tags { get; set; } = new();\n    public CustomerInfo Customer { get; set; } = new();\n}\n// Projection rebuild handles missing data gracefully\npublic class OrderSummaryProjection : IProjectionHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, ProjectionContext context) {\n        var summary = await context Load<OrderSummary>(@event OrderId ToString()) new OrderSummary();\n        summary OrderId = @event OrderId;\n        summary Total = @event Total;\n        // Handle optional V2+ fields\n        if (@event PlacedAt HasValue) {\n            summary EstimatedDelivery = @event PlacedAt Value AddDays(7);\n        }\n        if (@event Tags Any() == true) {\n            summary Tags = @event Tags;\n        }\n        await context Store(@event OrderId ToString(), summary);\n    }\n}\n`\nEvent Versioning Strategies\nA Upcasting (Recommended)\nConvert old events to new schema on read:\n`csharp{title=\"Event Upcaster Interface\" description=\"Event upcasting interface for converting old events to new schemas\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Upcasting\", \"Event-Transformation\", \"Interface\"] framework=\"NET8\"}\npublic interface IEventUpcaster<TOld, TNew> {\n    TNew Upcast(TOld oldEvent);\n    bool CanUpcast(Type eventType, int version);\n}\n`csharp{title=\"Concrete Upcaster Implementation\" description=\"Concrete upcaster implementation for event version migration\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Upcasting\", \"Implementation\", \"Registration\"] framework=\"NET8\"}\n// Upcast V1 OrderPlaced to V2\npublic class OrderPlacedV1ToV2Upcaster : IEventUpcaster<OrderPlacedV1, OrderPlaced> {\n    public OrderPlaced Upcast(OrderPlacedV1 oldEvent) {\n        return new OrderPlaced(\n            oldEvent OrderId,\n            oldEvent CustomerId,\n            PlacedAt: DateTimeOffset UtcNow, // Best guess for missing data\n            Tags: new List<string>()         // Default to empty\n        );\n    }\n    public bool CanUpcast(Type eventType, int version) {\n        return eventType == typeof(OrderPlacedV1) && version == 1;\n    }\n}\n// Registration\nservices AddWhizbang(options => {\n    options EventVersioning(versioning => {\n        versioning AddUpcaster<OrderPlacedV1ToV2Upcaster>();\n        versioning AddUpcaster<OrderPlacedV2ToV3Upcaster>();\n    });\n});\n`\nB",
        "startIndex": 2183,
        "preview": "} } // V2 Projection - Add fields without migration public class OrderSummary { public Guid OrderId { get; set; } public decimal Total { get; set; } p..."
      },
      {
        "id": "proposals/schema-evolution-chunk-2",
        "text": "// Best guess for missing data Tags: new List<string>() // Default to empty ); } public bool CanUpcast(Type eventType, int version) { return eventType == typeof(OrderPlacedV1) && version == 1; } } // Registration services AddWhizbang(options => { options EventVersioning(versioning => { versioning AddUpcaster<OrderPlacedV1ToV2Upcaster>(); versioning AddUpcaster<OrderPlacedV2ToV3Upcaster>(); }); }); ` B Multiple Versions Supported Simultaneously\nKeep multiple event versions active:\n`csharp{title=\"Multiple Version Handlers\" description=\"Supporting multiple event versions simultaneously with separate handlers\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Multiple-Versions\", \"Event-Handlers\", \"Registration\"] framework=\"NET8\"}\n// Multiple handlers for different versions\npublic class OrderPlacedV1Handler : IEventHandler<OrderPlacedV1> {\n    public async Task Handle(OrderPlacedV1 @event, EventContext context) {\n        // Handle legacy V1 events\n        var order = await _repository Load<Order>(@event OrderId);\n        order MarkAsPlaced(placedAt: DateTimeOffset UtcNow); // Default timestamp\n        await _repository Save(order);\n    }\n}\npublic class OrderPlacedV2Handler : IEventHandler<OrderPlaced> {\n    public async Task Handle(OrderPlaced @event, EventContext context) {\n        // Handle current V2+ events\n        var order = await _repository Load<Order>(@event OrderId);\n        order MarkAsPlaced(@event PlacedAt DateTimeOffset UtcNow);\n        await _repository Save(order);\n    }\n}\n// Router determines which handler to use based on event version\nservices AddWhizbang(options => {\n    options EventVersioning(versioning => {\n        versioning RouteByVersion = true;\n        versioning RegisterHandler<OrderPlacedV1Handler>(version: 1);\n        versioning RegisterHandler<OrderPlacedV2Handler>(version: 2);\n    });\n});\n`\nC Schema Registry\nCentralized schema management:\n`csharp{title=\"Schema Registry Configuration\" description=\"Centralized schema registry configuration for schema management\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Schema-Registry\", \"Centralized-Management\", \"Configuration\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options EventVersioning(versioning => {\n        versioning UseSchemaRegistry(registry => {\n            registry ConnectionString = \"https://schema-registry company com\";\n            registry AutoRegisterSchemas = true;\n            registry ValidateOnWrite = true;\n            registry CompatibilityLevel = CompatibilityLevel Backward;\n        });\n    });\n});\n// Events automatically registered with schema registry\n[SchemaRegistration(subject: \"order-placed\", version: 2)]\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    DateTimeOffset",
        "startIndex": 4572,
        "preview": "// Best guess for missing data Tags: new List<string>() // Default to empty ); } public bool CanUpcast(Type eventType, int version) { return eventType..."
      },
      {
        "id": "proposals/schema-evolution-chunk-3",
        "text": "{ options EventVersioning(versioning => { versioning UseSchemaRegistry(registry => { registry ConnectionString = \"https://schema-registry company com\"; registry AutoRegisterSchemas = true; registry ValidateOnWrite = true; registry CompatibilityLevel = CompatibilityLevel Backward; }); }); }); // Events automatically registered with schema registry [SchemaRegistration(subject: \"order-placed\", version: 2)] public record OrderPlaced( Guid OrderId, Guid CustomerId, DateTimeOffset PlacedAt = null\n);\n`\nDriver Interface for Schema Evolution\nAbstract Driver Interface\n`csharp{title=\"Schema Evolution Driver Interface\" description=\"Driver interface for schema evolution with versioning and upcasting support\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Driver-Interface\", \"Serialization\", \"Versioning\"] framework=\"NET8\"}\npublic interface ISchemaEvolutionDriver {\n    // Serialization with versioning\n    Task<byte[]> Serialize<T>(T @event, int version = null);\n    Task<T> Deserialize<T>(byte[] data, int version);\n    Task<object> DeserializeToLatestVersion(byte[] data, Type eventType, int storedVersion);\n    // Schema registration\n    Task RegisterSchema(Type eventType, int version);\n    Task<SchemaInfo> GetSchema(Type eventType, int version);\n    Task<IEnumerable<SchemaInfo>> GetSchemaEvolution(Type eventType);\n    // Upcasting support\n    Task<T> UpcastToLatest<T>(object oldEvent, int fromVersion);\n    bool CanUpcast(Type eventType, int fromVersion, int toVersion);\n}\npublic class SchemaInfo {\n    public Type EventType { get; set; }\n    public int Version { get; set; }\n    public string Schema { get; set; }\n    public DateTime RegisteredAt { get; set; }\n    public CompatibilityLevel Compatibility { get; set; }\n}\n`\nPostgreSQL JSONB Driver Implementation\n`csharp{title=\"PostgreSQL Schema Evolution Driver\" description=\"PostgreSQL JSONB implementation of schema evolution driver with serialization and upcasting\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"PostgreSQL\", \"JSONB-Implementation\", \"Driver\"] framework=\"NET8\"}\npublic class PostgresSchemaEvolutionDriver : ISchemaEvolutionDriver {\n    public async Task<byte[]> Serialize<T>(T @event, int version = null) {\n        var eventType = typeof(T);\n        var currentVersion = version await GetLatestVersion(eventType);\n        var eventData = new {\n            EventType = eventType FullName,\n            Version = currentVersion,\n            Data = @event\n        };\n        return JsonSerializer SerializeToUtf8Bytes(eventData);\n    }\n    public async Task<T> Deserialize<T>(byte[] data, int version) {\n        var eventData = JsonSerializer Deserialize<dynamic>(data);\n        var storedVersion = (int)eventData Version;\n        if (storedVersion == version) {\n            return JsonSerializer Deserialize<T>(eventData Data);\n        }\n        // Need to upcast\n        var oldEvent = DeserializeToVersion(eventData",
        "startIndex": 6952,
        "preview": "{ options EventVersioning(versioning => { versioning UseSchemaRegistry(registry => { registry ConnectionString = \"https://schema-registry company com\"..."
      },
      {
        "id": "proposals/schema-evolution-chunk-4",
        "text": "= eventType FullName, Version = currentVersion, Data = @event }; return JsonSerializer SerializeToUtf8Bytes(eventData); } public async Task<T> Deserialize<T>(byte[] data, int version) { var eventData = JsonSerializer Deserialize<dynamic>(data); var storedVersion = (int)eventData Version; if (storedVersion == version) { return JsonSerializer Deserialize<T>(eventData Data); } // Need to upcast var oldEvent = DeserializeToVersion(eventData Data, typeof(T), storedVersion);\n        return await UpcastToLatest<T>(oldEvent, storedVersion);\n    }\n    public async Task<object> DeserializeToLatestVersion(byte[] data, Type eventType, int storedVersion) {\n        var latestVersion = await GetLatestVersion(eventType);\n        if (storedVersion == latestVersion) {\n            // Already latest version\n            return JsonSerializer Deserialize(data, eventType);\n        }\n        // Upcast to latest\n        var oldEvent = DeserializeToVersion(data, eventType, storedVersion);\n        return await UpcastToLatest(oldEvent, eventType, storedVersion, latestVersion);\n    }\n}\n`\nLINQ Support Evolution\nDriver-Specific LINQ Implementation\n`csharp{title=\"Query Evolution Driver Interface\" description=\"Driver interface for schema-aware LINQ querying across versions\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"LINQ-Support\", \"Querying\", \"Interface\"] framework=\"NET8\"}\npublic interface IQueryEvolutionDriver {\n    IQueryable<T> Query<T>() where T : class;\n    IQueryable<T> QueryVersion<T>(int version) where T : class;\n    IQueryable<object> QueryAllVersions(Type eventType);\n}\n`csharp{title=\"PostgreSQL Query Driver Implementation\" description=\"PostgreSQL implementation with JSONB operators for evolved schemas\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"PostgreSQL\", \"JSONB-Queries\", \"EF-Core\"] framework=\"NET8\"}\n// PostgreSQL implementation with JSONB operators\npublic class PostgresQueryDriver : IQueryEvolutionDriver {\n    public IQueryable<T> Query<T>() where T : class {\n        return _context Events Where(e => e EventType == typeof(T) Name) Select(e => JsonSerializer Deserialize<T>(e EventData)) AsQueryable();\n    }\n    // JSONB path queries for evolved schemas\n    public IQueryable<OrderSummary> QueryOrdersWithTags() {\n        return _context Projections Where(p => p ProjectionName == \"order-summary\") Where(p => EF Functions JsonExists(p Document, \"$ Tags\"))  // Has tags field Select(p => JsonSerializer Deserialize<OrderSummary>(p Document)) AsQueryable();\n    }\n    // Query across schema versions\n    public IQueryable<decimal> QueryOrderTotals() {\n        return _context Events Where(e => e EventType == \"OrderPlaced\") Select(e => EF Functions JsonExtract<decimal>(e EventData, \"$ Total\"))",
        "startIndex": 9408,
        "preview": "= eventType FullName, Version = currentVersion, Data = @event }; return JsonSerializer SerializeToUtf8Bytes(eventData); } public async Task<T> Deseria..."
      },
      {
        "id": "proposals/schema-evolution-chunk-5",
        "text": "=> p ProjectionName == \"order-summary\") Where(p => EF Functions JsonExists(p Document, \"$ Tags\")) // Has tags field Select(p => JsonSerializer Deserialize<OrderSummary>(p Document)) AsQueryable(); } // Query across schema versions public IQueryable<decimal> QueryOrderTotals() { return _context Events Where(e => e EventType == \"OrderPlaced\") Select(e => EF Functions JsonExtract<decimal>(e EventData, \"$ Total\")) AsQueryable();\n    }\n}\n`\nSchema-Aware Query Extensions\n`csharp{title=\"Schema-Aware Query Extensions\" description=\"Extension methods for schema-aware querying and filtering across versions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Schema-Evolution\", \"LINQ-Extensions\", \"Query-Helpers\", \"Extensions\"] framework=\"NET8\"}\npublic static class SchemaQueryExtensions {\n    public static IQueryable<T> WhereSchemaVersion<T>(this IQueryable<T> query, int version) {\n        // Filter by schema version\n        return query Where(/ version filter logic /);\n    }\n    public static IQueryable<T> WhereHasField<T>(this IQueryable<T> query, string fieldPath) {\n        // Filter by field existence (JSONB support)\n        return query Where(/ field existence logic /);\n    }\n    public static IQueryable<TResult> SelectEvolved<T, TResult>(\n        this IQueryable<T> query, \n        Expression<Func<T, TResult>> selector,\n        SchemaEvolutionOptions options = null) {\n        // Schema-aware projection\n        return query Select(/ evolved selector logic /);\n    }\n}\n// Usage\nvar recentOrdersWithTags = await _context Query<OrderSummary>() WhereHasField(\"Tags\") Where(o => o PlacedAt > DateTime UtcNow AddDays(-30)) ToListAsync();\n`\nBlue/Green Deployment Support\nDriver-Level Blue/Green Implementation\n`csharp{title=\"Blue/Green Deployment Driver\" description=\"Driver interface and implementation for blue/green projection deployments\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Blue-Green-Deployment\", \"Driver-Interface\", \"PostgreSQL\"] framework=\"NET8\"}\npublic interface IBlueGreenDriver {\n    Task<string> CreateGreenDeployment(string projectionName);\n    Task BuildGreenProjection(string projectionName, string greenVersion);\n    Task ValidateGreenProjection(string projectionName, string greenVersion);\n    Task SwitchToGreen(string projectionName, string greenVersion);\n    Task CleanupBlueVersion(string projectionName);\n}\npublic class PostgresBlueGreenDriver : IBlueGreenDriver {\n    public async Task<string> CreateGreenDeployment(string projectionName) {\n        var greenVersion = Guid NewGuid() ToString(\"N\")[ 8];\n        var greenTableName = $\"{projectionName}_green_{greenVersion}\";\n        // Create green table with same schema as blue\n        await _connection",
        "startIndex": 11854,
        "preview": "=> p ProjectionName == \"order-summary\") Where(p => EF Functions JsonExists(p Document, \"$ Tags\")) // Has tags field Select(p => JsonSerializer Deseria..."
      },
      {
        "id": "proposals/schema-evolution-chunk-6",
        "text": "string greenVersion); Task ValidateGreenProjection(string projectionName, string greenVersion); Task SwitchToGreen(string projectionName, string greenVersion); Task CleanupBlueVersion(string projectionName); } public class PostgresBlueGreenDriver : IBlueGreenDriver { public async Task<string> CreateGreenDeployment(string projectionName) { var greenVersion = Guid NewGuid() ToString(\"N\")[ 8]; var greenTableName = $\"{projectionName}_green_{greenVersion}\"; // Create green table with same schema as blue await _connection ExecuteAsync($\"\"\"\n            CREATE TABLE {greenTableName} (LIKE {projectionName} INCLUDING ALL);\n            CREATE INDEX CONCURRENTLY idx_{greenTableName}_tenant \n                ON {greenTableName}(tenant_id) WHERE tenant_id IS NOT NULL;\n        \"\"\");\n        return greenVersion;\n    }\n    public async Task BuildGreenProjection(string projectionName, string greenVersion) {\n        var greenTableName = $\"{projectionName}_green_{greenVersion}\";\n        // Rebuild projection in green table from events\n        await _projectionBuilder RebuildInTable(projectionName, greenTableName);\n    }\n    public async Task SwitchToGreen(string projectionName, string greenVersion) {\n        var greenTableName = $\"{projectionName}_green_{greenVersion}\";\n        var blueBackupName = $\"{projectionName}_blue_backup_{DateTimeOffset UtcNow:yyyyMMdd_HHmmss}\";\n        // Atomic table swap\n        await _connection ExecuteAsync($\"\"\"\n            BEGIN;\n            ALTER TABLE {projectionName} RENAME TO {blueBackupName};\n            ALTER TABLE {greenTableName} RENAME TO {projectionName};\n            COMMIT;\n        \"\"\");\n    }\n}\n`\nConfiguration and Best Practices\nComprehensive Schema Evolution Setup\n`csharp{title=\"Comprehensive Schema Evolution Setup\" description=\"Complete schema evolution configuration with all features enabled\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Schema-Evolution\", \"Configuration\", \"Comprehensive-Setup\", \"Best-Practices\"] framework=\"NET8\"}\nservices AddWhizbang(options => {\n    options SchemaEvolution(evolution => {\n        // Storage format\n        evolution UseJsonb = true;\n        evolution StoreSchemaVersion = true;\n        evolution ValidateOnWrite = false; // Allow forward compatibility\n        // Versioning strategy\n        evolution VersioningStrategy = VersioningStrategy Upcasting;\n        evolution AutoRegisterUpcasterts = true;\n        evolution UpcastOnRead = true;\n        // Schema registry\n        evolution UseSchemaRegistry(registry => {\n            registry Url = \"https://schema-registry internal\";\n            registry AutoRegister = true;\n            registry CompatibilityLevel = CompatibilityLevel Backward;\n        });\n        // Blue/Green deployments\n        evolution BlueGreen(blueGreen => {\n            blueGreen ValidationThreshold = 0 99; // 99% accuracy required\n            blueGreen WarmupPeriod = TimeSpan FromMinutes(5);\n            blueGreen AutoSwitch = false; // Manual approval required\n        });\n    });\n});\n`\nEvent Versioning Best Practices\n`csharp{title=\"Event Versioning Best Practices\" description=\"Best practices for event versioning and backward-compatible schema evolution\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Schema-Evolution\", \"Best-Practices\", \"Backward-Compatibility\", \"Versioning\"] framework=\"NET8\"}\n// 1",
        "startIndex": 14170,
        "preview": "string greenVersion); Task ValidateGreenProjection(string projectionName, string greenVersion); Task SwitchToGreen(string projectionName, string green..."
      },
      {
        "id": "proposals/schema-evolution-chunk-7",
        "text": "= 0 99; // 99% accuracy required blueGreen WarmupPeriod = TimeSpan FromMinutes(5); blueGreen AutoSwitch = false; // Manual approval required }); }); }); ` Event Versioning Best Practices `csharp{title=\"Event Versioning Best Practices\" description=\"Best practices for event versioning and backward-compatible schema evolution\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Schema-Evolution\", \"Best-Practices\", \"Backward-Compatibility\", \"Versioning\"] framework=\"NET8\"} // 1 Always make fields optional when adding them\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    DateTimeOffset PlacedAt = null,      // Optional - added in V2\n    List<string> Tags = null             // Optional - added in V3\n);\n// 2 Use wrapper types for complex evolution\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderMetadata Metadata = null        // Wrapper for evolving fields\n);\npublic record OrderMetadata(\n    DateTimeOffset PlacedAt = null,\n    List<string> Tags = null,\n    CustomerInfo Customer = null\n);\n// 3 Never remove fields - mark as obsolete\npublic record OrderPlaced(\n    Guid OrderId,\n    Guid CustomerId,\n    [Obsolete(\"Use Metadata PlacedAt instead\")]\n    DateTimeOffset PlacedAt = null,      // Keep for backward compatibility\n    OrderMetadata Metadata = null\n);\n// 4 Use semantic versioning for breaking changes\n[EventVersion(\"order-placed\", \"1 0 0\")]\npublic record OrderPlacedV1(Guid OrderId, Guid CustomerId);\n[EventVersion(\"order-placed\", \"1 1 0\")]  // Minor version - additive\npublic record OrderPlaced(Guid OrderId, Guid CustomerId, DateTimeOffset PlacedAt = null);\n[EventVersion(\"order-placed\", \"2 0 0\")]  // Major version - breaking change\npublic record OrderPlacedV2(Guid OrderId, CustomerId CustomerId, DateTimeOffset PlacedAt);\n`\nProjection Evolution Guidelines\nAdd fields with defaults - New fields should have sensible default values\nRebuild for major changes - Use blue/green deployment for breaking changes\nTest evolution paths - Verify old events work with new projections\nMonitor data quality - Track schema evolution impact on data\nDocument changes - Keep clear records of schema evolution decisions\n---\nRelated Documentation\nEvent Store & Projections - Core storage architecture\nProjection Management - Backfilling and rebuilding strategies\nAdvanced Features - Cross-aggregate transactions and distributed tracing",
        "startIndex": 16982,
        "preview": "= 0 99; // 99% accuracy required blueGreen WarmupPeriod = TimeSpan FromMinutes(5); blueGreen AutoSwitch = false; // Manual approval required }); }); }..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/source-generation-ide",
    "title": "Source Generation & IDE Integration",
    "category": "Architecture & Design",
    "url": "/docs/proposals/source-generation-ide",
    "chunks": [
      {
        "id": "proposals/source-generation-ide-chunk-0",
        "text": "Source Generation & IDE Integration\nWhizbang uses advanced source generation and IDE integration to provide a seamless developer experience with compile-time validation, intelligent navigation, and powerful debugging tools Source Generator Architecture\nSingle Pipeline Generator\nIncremental source generator with orchestrated pipeline stages for optimal performance:\n`csharp{\ntitle: \"Incremental Source Generator\"\ndescription: \"Single incremental source generator with orchestrated pipeline stages\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"Source-Generation\", \"Incremental-Generation\", \"Pipeline-Architecture\"]\nframework: \"NET8\"\n}\n[Generator]\npublic class WhizbangSourceGenerator : IIncrementalGenerator {\n    public void Initialize(IncrementalGeneratorInitializationContext context) {\n        // Stage 1: Handler Discovery Pipeline\n        var handlersPipeline = context SyntaxProvider CreateSyntaxProvider(\n            predicate: (node, _) => IsHandlerCandidate(node),\n            transform: (ctx, _) => ExtractHandlerInfo(ctx)\n        ) Where(info => info = null);\n        // Stage 2: Domain Ownership Pipeline  \n        var domainOwnershipPipeline = context SyntaxProvider CreateSyntaxProvider(\n            predicate: (node, _) => IsDomainCandidate(node),\n            transform: (ctx, _) => ExtractDomainInfo(ctx)\n        );\n        // Stage 3: Projection Pipeline\n        var projectionsPipeline = context SyntaxProvider CreateSyntaxProvider(\n            predicate: (node, _) => IsProjectionCandidate(node),\n            transform: (ctx, _) => ExtractProjectionInfo(ctx)\n        );\n        // Stage 4: Policy Pipeline\n        var policiesPipeline = context SyntaxProvider CreateSyntaxProvider(\n            predicate: (node, _) => IsPolicyCandidate(node),\n            transform: (ctx, _) => ExtractPolicyInfo(ctx)\n        );\n        // Combine all sources for cross-project aggregation\n        var combinedPipeline = handlersPipeline Combine(domainOwnershipPipeline) Combine(projectionsPipeline) Combine(policiesPipeline);\n        // Generate code\n        context RegisterSourceOutput(combinedPipeline, GenerateWhizbangRegistry);\n        // Generate metadata for IDE service\n        context RegisterSourceOutput(combinedPipeline, GenerateNavigationMetadata);\n        // Generate analyzer data\n        context RegisterSourceOutput(combinedPipeline, GenerateAnalyzerData);\n    }\n}\n`\nBuild Performance & Logging\nDetailed timing and logging for optimization:\n`csharp{\ntitle: \"Performance Tracker\"\ndescription: \"Performance tracking for source generation stages with detailed timing\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"Design\", \"Source-Generation\", \"Performance-Tracking\", \"Build-Optimization\"]\nframework: \"NET8\"\n}\npublic class GenerationPerformanceTracker {\n    private readonly Dictionary<string, Stopwatch> _stageTimers = new();\n    public void StartStage(string stageName) {\n        _stageTimers[stageName] = Stopwatch StartNew();\n        LogInformation($\"Starting stage: {stageName}\");\n    }\n    public void EndStage(string stageName) {\n        if (_stageTimers TryGetValue(stageName, out var timer)) {\n            timer Stop();\n            LogInformation($\"Completed stage: {stageName} in {timer",
        "startIndex": 0,
        "preview": "Source Generation & IDE Integration\nWhizbang uses advanced source generation and IDE integration to provide a seamless developer experience with compi..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-1",
        "text": "[\"Design\", \"Source-Generation\", \"Performance-Tracking\", \"Build-Optimization\"] framework: \"NET8\" } public class GenerationPerformanceTracker { private readonly Dictionary<string, Stopwatch> _stageTimers = new(); public void StartStage(string stageName) { _stageTimers[stageName] = Stopwatch StartNew(); LogInformation($\"Starting stage: {stageName}\"); } public void EndStage(string stageName) { if (_stageTimers TryGetValue(stageName, out var timer)) { timer Stop(); LogInformation($\"Completed stage: {stageName} in {timer ElapsedMilliseconds}ms\");\n        }\n    }\n    public void LogSummary() {\n        var totalTime = _stageTimers Values Sum(t => t ElapsedMilliseconds);\n        LogInformation($\"Total generation time: {totalTime}ms\");\n        foreach (var (stage, timer) in _stageTimers) {\n            var percentage = (timer ElapsedMilliseconds / (double)totalTime) * 100;\n            LogInformation($\"  {stage}: {timer ElapsedMilliseconds}ms ({percentage:F1}%)\");\n        }\n    }\n}\n`\nMulti-Project Aggregation\nCross-assembly handler discovery and registration:\n`csharp{\ntitle: \"Cross-Project Registry\"\ndescription: \"Generated registry that aggregates handlers across multiple projects\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"Source-Generation\", \"Multi-Project-Aggregation\", \"Code-Generation\"]\nframework: \"NET8\"\n}\n// Generated registry aggregates across projects\n[GeneratedCode(\"Whizbang SourceGenerator\")]\npublic static class WhizbangGeneratedRegistry {\n    public static void RegisterAll(IServiceCollection services) {\n        // Handlers from current project\n        RegisterLocalHandlers(services);\n        // Handlers from referenced projects\n        RegisterReferencedHandlers(services);\n        // Domain ownership from all projects\n        RegisterDomainOwnership(services);\n        // Policies from all projects\n        RegisterPolicies(services);\n    }\n    private static void RegisterLocalHandlers(IServiceCollection services) {\n        services AddScoped<ICommandHandler<PlaceOrder>, PlaceOrderHandler>();\n        services AddScoped<IEventHandler<OrderPlaced>, OrderSummaryProjection>();\n        // other local handlers\n    }\n    private static void RegisterReferencedHandlers(IServiceCollection services) {\n        // Handlers discovered from referenced assemblies\n        SharedLibrary WhizbangRegistry RegisterHandlers(services);\n        CoreDomain WhizbangRegistry",
        "startIndex": 3279,
        "preview": "[\"Design\", \"Source-Generation\", \"Performance-Tracking\", \"Build-Optimization\"] framework: \"NET8\" } public class GenerationPerformanceTracker { private ..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-2",
        "text": "projects RegisterReferencedHandlers(services); // Domain ownership from all projects RegisterDomainOwnership(services); // Policies from all projects RegisterPolicies(services); } private static void RegisterLocalHandlers(IServiceCollection services) { services AddScoped<ICommandHandler<PlaceOrder>, PlaceOrderHandler>(); services AddScoped<IEventHandler<OrderPlaced>, OrderSummaryProjection>(); // other local handlers } private static void RegisterReferencedHandlers(IServiceCollection services) { // Handlers discovered from referenced assemblies SharedLibrary WhizbangRegistry RegisterHandlers(services); CoreDomain WhizbangRegistry RegisterHandlers(services);\n    }\n}\n`\nIDE Navigation Service\nEvent Stream Navigation\nGitLens-style navigation through event streams and handlers:\n`csharp{\ntitle: \"Navigation Service\"\ndescription: \"Navigation service interface for GitLens-style event stream traversal\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"Design\", \"IDE-Integration\", \"Navigation-Service\", \"Event-Stream-Navigation\"]\nframework: \"NET8\"\n}\npublic interface IWhizbangNavigationService {\n    Task<EventStreamInfo> GetEventStreamAsync(string streamId);\n    Task<IEnumerable<HandlerInfo>> GetHandlersForEventAsync(Type eventType);\n    Task<IEnumerable<ProjectionInfo>> GetProjectionsForEventAsync(Type eventType);\n    Task<EventFlowDiagram> GetEventFlowAsync(Type commandType);\n    Task<DomainMap> GetDomainMapAsync();\n}\n// Event flow visualization\npublic class EventFlowDiagram {\n    public CommandInfo Command { get; set; }\n    public HandlerInfo CommandHandler { get; set; }\n    public List<EventInfo> EmittedEvents { get; set; }\n    public Dictionary<EventInfo, List<HandlerInfo>> EventHandlers { get; set; }\n    public Dictionary<EventInfo, List<ProjectionInfo>> EventProjections { get; set; }\n    public List<SagaInfo> TriggeredSagas { get; set; }\n}\n`csharp{\ntitle: \"Code Lens Provider\"\ndescription: \"Code lens provider for displaying event flow information in IDE\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"IDE-Integration\", \"Code-Lens-Provider\", \"Event-Flow-Visualization\"]\nframework: \"NET8\"\n}\n// Usage in IDE extension\npublic class WhizbangCodeLensProvider : CodeLensProvider {\n    public override async Task<CodeLens[]> ProvideCodeLensesAsync(Document document) {\n        var semanticModel = await document GetSemanticModelAsync();\n        var root = await document GetSyntaxRootAsync();\n        var codeLenses = new List<CodeLens>();\n        // Find command handlers\n        foreach (var handlerClass in root DescendantNodes() OfType<ClassDeclarationSyntax>()) {\n            if (IsCommandHandler(handlerClass, semanticModel)) {\n                var commandType = GetCommandType(handlerClass, semanticModel);\n                var eventFlow = await _navigationService GetEventFlowAsync(commandType);\n                codeLenses Add(new CodeLens {\n                    Range = GetRange(handlerClass),\n                    Command = new Command {\n                        Title = $\"Emits {eventFlow EmittedEvents Count} events, triggers {eventFlow EventHandlers Count} handlers\",\n                        Arguments = new object[] { eventFlow }\n                    }\n                });\n            }\n        }\n        return codeLenses",
        "startIndex": 5166,
        "preview": "projects RegisterReferencedHandlers(services); // Domain ownership from all projects RegisterDomainOwnership(services); // Policies from all projects ..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-3",
        "text": "semanticModel)) { var commandType = GetCommandType(handlerClass, semanticModel); var eventFlow = await _navigationService GetEventFlowAsync(commandType); codeLenses Add(new CodeLens { Range = GetRange(handlerClass), Command = new Command { Title = $\"Emits {eventFlow EmittedEvents Count} events, triggers {eventFlow EventHandlers Count} handlers\", Arguments = new object[] { eventFlow } } }); } } return codeLenses ToArray();\n    }\n}\n`\nGenerated Metadata\nRich metadata for IDE integration:\n`json\n// Generated metadata file: WhizbangMetadata json\n{\n  \"eventStreams\": {\n    \"Order-{orderId}\": {\n      \"aggregateType\": \"Order\",\n      \"domain\": \"Orders\",\n      \"events\": [\"OrderPlaced\", \"OrderUpdated\", \"OrderShipped\"],\n      \"handlers\": [\"OrderSummaryProjection\", \"OrderHistoryProjection\"],\n      \"sagas\": [\"OrderFulfillmentSaga\"]\n    }\n  },\n  \"handlers\": {\n    \"PlaceOrderHandler\": {\n      \"handlerType\": \"Command\",\n      \"inputType\": \"PlaceOrder\",\n      \"outputTypes\": [\"OrderPlaced\"],\n      \"domain\": \"Orders\",\n      \"sourceLocation\": \"OrderService/Handlers/PlaceOrderHandler cs:15\"\n    }\n  },\n  \"projections\": {\n    \"OrderSummaryProjection\": {\n      \"projectionName\": \"order-summary\",\n      \"subscribedEvents\": [\"OrderPlaced\", \"OrderUpdated\", \"OrderShipped\"],\n      \"domain\": \"Orders\",\n      \"sourceLocation\": \"OrderService/Projections/OrderSummaryProjection cs:8\"\n    }\n  },\n  \"domains\": {\n    \"Orders\": {\n      \"commands\": [\"PlaceOrder\", \"UpdateOrder\", \"ShipOrder\"],\n      \"events\": [\"OrderPlaced\", \"OrderUpdated\", \"OrderShipped\"],\n      \"handlers\": [\"PlaceOrderHandler\", \"UpdateOrderHandler\"],\n      \"projections\": [\"OrderSummaryProjection\", \"OrderHistoryProjection\"]\n    }\n  }\n}\n`\nCode Analyzers & Fixes\nDomain Ownership Validation\nCompile-time enforcement of domain ownership rules:\n`csharp{\ntitle: \"Domain Ownership Analyzer\"\ndescription: \"Roslyn analyzer for compile-time domain ownership validation\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"Code-Analyzers\", \"Domain-Ownership\", \"Compile-Time-Validation\"]\nframework: \"NET8\"\n}\n[DiagnosticAnalyzer(LanguageNames CSharp)]\npublic class DomainOwnershipAnalyzer : DiagnosticAnalyzer {\n    public static readonly DiagnosticDescriptor CrossDomainHandlerRule = new(\n        \"WB001\",\n        \"Handler cannot handle command/event from different domain\",\n        \"Handler '{0}' in domain '{1}' cannot handle '{2}' from domain '{3}'\",\n        \"Domain Ownership\",\n        DiagnosticSeverity Error,\n        isEnabledByDefault: true\n    );\n    public override void Initialize(AnalysisContext context) {\n        context RegisterSyntaxNodeAction(AnalyzeHandlerClass, SyntaxKind ClassDeclaration);\n    }\n    private void AnalyzeHandlerClass(SyntaxNodeAnalysisContext context) {\n        var classDeclaration = (ClassDeclarationSyntax)context Node;\n        var semanticModel = context SemanticModel;\n        var handlerDomain = GetHandlerDomain(classDeclaration, semanticModel);\n        var handledTypes = GetHandledTypes(classDeclaration, semanticModel);\n        foreach (var handledType in handledTypes) {\n            var messageDomain = GetMessageDomain(handledType, semanticModel);\n            if (handlerDomain = messageDomain) {\n                var diagnostic = Diagnostic Create(\n                    CrossDomainHandlerRule,\n                    classDeclaration GetLocation(),\n                    classDeclaration Identifier ValueText,\n                    handlerDomain,\n                    handledType Name,\n                    messageDomain\n                );\n                context",
        "startIndex": 7795,
        "preview": "semanticModel)) { var commandType = GetCommandType(handlerClass, semanticModel); var eventFlow = await _navigationService GetEventFlowAsync(commandTyp..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-4",
        "text": "(ClassDeclarationSyntax)context Node; var semanticModel = context SemanticModel; var handlerDomain = GetHandlerDomain(classDeclaration, semanticModel); var handledTypes = GetHandledTypes(classDeclaration, semanticModel); foreach (var handledType in handledTypes) { var messageDomain = GetMessageDomain(handledType, semanticModel); if (handlerDomain = messageDomain) { var diagnostic = Diagnostic Create( CrossDomainHandlerRule, classDeclaration GetLocation(), classDeclaration Identifier ValueText, handlerDomain, handledType Name, messageDomain ); context ReportDiagnostic(diagnostic);\n            }\n        }\n    }\n}\n`\nCode Fixes\nAutomatic fixes for common patterns:\n`csharp{\ntitle: \"Code Fix Provider\"\ndescription: \"Code fix provider for automatic domain ownership attribute addition\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"Code-Fixes\", \"Domain-Ownership\", \"Automatic-Fixes\"]\nframework: \"NET8\"\n}\n[ExportCodeFixProvider(LanguageNames CSharp)]\npublic class AddDomainOwnershipCodeFixProvider : CodeFixProvider {\n    public override async Task RegisterCodeFixesAsync(CodeFixContext context) {\n        var diagnostic = context Diagnostics FirstOrDefault(d => d Id == \"WB002\");\n        if (diagnostic == null) return;\n        var document = context Document;\n        var root = await document GetSyntaxRootAsync(context CancellationToken);\n        var declaration = root FindNode(diagnostic Location SourceSpan);\n        // Offer to add [OwnedBy] attribute\n        var codeAction = CodeAction Create(\n            title: \"Add [OwnedBy] attribute\",\n            createChangedDocument: c => AddOwnedByAttribute(document, declaration, c),\n            equivalenceKey: \"AddOwnedBy\"\n        );\n        context RegisterCodeFix(codeAction, diagnostic);\n    }\n    private async Task<Document> AddOwnedByAttribute(Document document, SyntaxNode declaration, CancellationToken cancellationToken) {\n        var root = await document GetSyntaxRootAsync(cancellationToken);\n        var inferredDomain = InferDomainFromNamespace(declaration);\n        var attribute = SyntaxFactory Attribute(\n            SyntaxFactory IdentifierName(\"OwnedBy\"),\n            SyntaxFactory AttributeArgumentList(\n                SyntaxFactory SingletonSeparatedList(\n                    SyntaxFactory AttributeArgument(\n                        SyntaxFactory LiteralExpression(SyntaxKind StringLiteralExpression, \n                            SyntaxFactory Literal(inferredDomain))\n                    )\n                )\n            )\n        );\n        var newDeclaration = AddAttributeToDeclaration(declaration, attribute);\n        var newRoot = root ReplaceNode(declaration, newDeclaration);\n        return document WithSyntaxRoot(newRoot);\n    }\n}\n`\nDebugging Integration\nTransparent Generated Code\nClear, debuggable generated code with source maps:\n`csharp{\ntitle: \"Debuggable Generated Code\"\ndescription: \"Clear, debuggable generated code with source maps and metadata\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"Design\", \"Source-Generation\", \"Transparent-Code\", \"Debug-Experience\"]\nframework: \"NET8\"\n}\n// Generated handler registry with clear structure\n[GeneratedCode(\"Whizbang SourceGenerator\", \"1 0 0\")]\npublic static partial class OrderServiceHandlerRegistry {\n    // Source: OrderService/Handlers/PlaceOrderHandler cs\n    public static void RegisterPlaceOrderHandler(IServiceCollection services) {\n        services",
        "startIndex": 10929,
        "preview": "(ClassDeclarationSyntax)context Node; var semanticModel = context SemanticModel; var handlerDomain = GetHandlerDomain(classDeclaration, semanticModel)..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-5",
        "text": "\"Clear, debuggable generated code with source maps and metadata\" category: \"Design\" difficulty: \"INTERMEDIATE\" tags: [\"Design\", \"Source-Generation\", \"Transparent-Code\", \"Debug-Experience\"] framework: \"NET8\" } // Generated handler registry with clear structure [GeneratedCode(\"Whizbang SourceGenerator\", \"1 0 0\")] public static partial class OrderServiceHandlerRegistry { // Source: OrderService/Handlers/PlaceOrderHandler cs public static void RegisterPlaceOrderHandler(IServiceCollection services) { services AddScoped<ICommandHandler<PlaceOrder>, PlaceOrderHandler>();\n        // Generated metadata for debugging\n        services AddSingleton(new HandlerMetadata {\n            HandlerType = typeof(PlaceOrderHandler),\n            MessageType = typeof(PlaceOrder),\n            SourceFile = \"OrderService/Handlers/PlaceOrderHandler cs\",\n            SourceLine = 15,\n            Domain = \"Orders\",\n            GeneratedAt = DateTimeOffset Parse(\"2024-01-01T10:00:00Z\")\n        });\n    }\n    // Source: OrderService/Projections/OrderSummaryProjection cs  \n    public static void RegisterOrderSummaryProjection(IServiceCollection services) {\n        services AddScoped<IProjectionHandler<OrderPlaced>, OrderSummaryProjection>();\n        services AddScoped<IProjectionHandler<OrderUpdated>, OrderSummaryProjection>();\n        services AddScoped<IProjectionHandler<OrderShipped>, OrderSummaryProjection>();\n        // Register projection metadata\n        services AddSingleton(new ProjectionMetadata {\n            ProjectionType = typeof(OrderSummaryProjection),\n            ProjectionName = \"order-summary\",\n            SubscribedEvents = new[] { typeof(OrderPlaced), typeof(OrderUpdated), typeof(OrderShipped) },\n            SourceFile = \"OrderService/Projections/OrderSummaryProjection cs\",\n            SourceLine = 8,\n            Domain = \"Orders\"\n        });\n    }\n}\n`\nDebug Experience Enhancements\nNo \"magic\" - clear understanding of what's happening:\n`csharp{\ntitle: \"Debug-Friendly Registration\"\ndescription: \"Debug-friendly service registration with detailed logging\"\ncategory: \"Design\"\ndifficulty: \"INTERMEDIATE\"\ntags: [\"Design\", \"Source-Generation\", \"Debug-Experience\", \"Service-Registration\"]\nframework: \"NET8\"\n}\n// Debug-friendly service registration\npublic static class WhizbangServiceCollectionExtensions {\n    public static IServiceCollection AddWhizbangGeneratedServices(this IServiceCollection services) {\n        if (IsDebugMode()) {\n            // In debug mode, show detailed registration logging\n            services AddSingleton<IHandlerRegistrationLogger, DetailedHandlerRegistrationLogger>();\n        }\n        // Call generated registration methods\n        OrderServiceHandlerRegistry RegisterAll(services);\n        return services;\n    }\n}\npublic class DetailedHandlerRegistrationLogger : IHandlerRegistrationLogger {\n    public void LogHandlerRegistration<TMessage, THandler>(string sourceFile, int sourceLine) {\n        Console WriteLine($\"Registering handler {typeof(THandler) Name} for {typeof(TMessage) Name}\");\n        Console WriteLine($\"  Source: {sourceFile}:{sourceLine}\");\n        Console",
        "startIndex": 13789,
        "preview": "\"Clear, debuggable generated code with source maps and metadata\" category: \"Design\" difficulty: \"INTERMEDIATE\" tags: [\"Design\", \"Source-Generation\", \"..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-6",
        "text": "// In debug mode, show detailed registration logging services AddSingleton<IHandlerRegistrationLogger, DetailedHandlerRegistrationLogger>(); } // Call generated registration methods OrderServiceHandlerRegistry RegisterAll(services); return services; } } public class DetailedHandlerRegistrationLogger : IHandlerRegistrationLogger { public void LogHandlerRegistration<TMessage, THandler>(string sourceFile, int sourceLine) { Console WriteLine($\"Registering handler {typeof(THandler) Name} for {typeof(TMessage) Name}\"); Console WriteLine($\" Source: {sourceFile}:{sourceLine}\"); Console WriteLine($\"  Service lifetime: Scoped\");\n    }\n}\n`\nPerformance Optimizations\nIncremental Generation\nOnly regenerate what changed for fast incremental builds:\n`csharp{\ntitle: \"Incremental Generation Context\"\ndescription: \"Incremental generation context for tracking file changes and optimization\"\ncategory: \"Design\"\ndifficulty: \"ADVANCED\"\ntags: [\"Design\", \"Source-Generation\", \"Incremental-Generation\", \"Performance-Optimization\"]\nframework: \"NET8\"\n}\npublic class IncrementalGenerationContext {\n    private readonly ConcurrentDictionary<string, string> _fileHashes = new();\n    public bool HasFileChanged(string filePath, string content) {\n        var currentHash = ComputeHash(content);\n        var previousHash = _fileHashes GetValueOrDefault(filePath);\n        if (currentHash",
        "startIndex": 16401,
        "preview": "// In debug mode, show detailed registration logging services AddSingleton<IHandlerRegistrationLogger, DetailedHandlerRegistrationLogger>(); } // Call..."
      },
      {
        "id": "proposals/source-generation-ide-chunk-7",
        "text": "\"Incremental generation context for tracking file changes and optimization\" category: \"Design\" difficulty: \"ADVANCED\" tags: [\"Design\", \"Source-Generation\", \"Incremental-Generation\", \"Performance-Optimization\"] framework: \"NET8\" } public class IncrementalGenerationContext { private readonly ConcurrentDictionary<string, string> _fileHashes = new(); public bool HasFileChanged(string filePath, string content) { var currentHash = ComputeHash(content); var previousHash = _fileHashes GetValueOrDefault(filePath); if (currentHash = previousHash) {\n            _fileHashes[filePath] = currentHash;\n            return true;\n        }\n        return false;\n    }\n    public void TrackGeneratedOutput(string outputKey, string content) {\n        // Track what we generated so we can skip unchanged outputs\n        _generatedOutputs[outputKey] = ComputeHash(content);\n    }\n}\n`\nCompilation Performance\nOptimize for IDE experience:\nSyntax-only analysis for most validations\nSemantic analysis only when necessary\nCaching of expensive operations\nParallel processing of independent analysis\nEarly termination when errors are found\nBest Practices\nGenerator Design\nKeep generators focused - Single responsibility per generator stage\nMinimize semantic model usage - Use syntax analysis when possible\nCache expensive operations - Avoid redundant analysis\nProvide clear diagnostics - Help developers understand issues\nGenerate debuggable code - Include source references and metadata\nIDE Integration\nResponsive navigation - Fast lookups and searches\nContextual information - Show relevant details for current location\nClear visualizations - Easy to understand flow diagrams\nHelpful code lenses - Actionable information overlays\nIntelligent suggestions - Context-aware code completion\nDebug Experience\nNo hidden magic - Everything should be discoverable\nClear error messages - Point to exact problems and solutions\nSource mapping - Connect generated code to source\nMetadata preservation - Keep debug information through compilation\nPerformance transparency - Show timing and costs\n---\nRelated Documentation\nDomain Ownership - How ownership affects source generation\nPolicy Engine - Policy-based code generation\nFlags & Tags System - Cross-service context propagation\nTesting & Development Tools - Testing the generated code",
        "startIndex": 17182,
        "preview": "\"Incremental generation context for tracking file changes and optimization\" category: \"Design\" difficulty: \"ADVANCED\" tags: [\"Design\", \"Source-Generat..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "proposals/testing-development-tools",
    "title": "Testing & Development Tools",
    "category": "Architecture & Design",
    "url": "/docs/proposals/testing-development-tools",
    "chunks": [
      {
        "id": "proposals/testing-development-tools-chunk-0",
        "text": "Testing & Development Tools\nWhizbang provides comprehensive testing utilities and development tools to ensure a productive developer experience from local development to production deployment Testing Framework\nWhizbang Testing Package\nComprehensive testing library with fluent APIs for all Whizbang scenarios:\n`csharp{title=\"Installing Whizbang Testing Package\" description=\"Installing and setting up the Whizbang testing package\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"Design\", \"Testing\", \"Package-Installation\", \"Setup\"] framework=\"NET8\"}\n// Install the testing package\ndotnet add package Whizbang Testing\n`csharp{title=\"Test Fixture Setup\" description=\"Test fixture setup with in-memory drivers for fast unit testing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Test-Fixtures\", \"In-Memory-Drivers\"] framework=\"NET8\"}\n// Test fixture setup\npublic class OrderServiceTests {\n    private readonly WhizbangTestFixture _fixture;\n    public OrderServiceTests() {\n        _fixture = new WhizbangTestFixture() UseInMemoryEventStore() UseInMemoryProjections() UseInMemoryMessageBroker() ConfigureServices(services => {\n                services AddScoped<IOrderService, OrderService>();\n                services AddScoped<ICustomerService, MockCustomerService>();\n            });\n    }\n}\n`\nEvent Sourcing Test Helpers\nGiven/When/Then fluent API for event sourcing scenarios:\n`csharp{title=\"Given/When/Then Event Sourcing Tests\" description=\"Given/When/Then fluent API for event sourcing test scenarios\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Given-When-Then\", \"Event-Sourcing\"] framework=\"NET8\"}\n[Test]\npublic async Task PlaceOrder_WithValidCustomer_ShouldEmitOrderPlaced() {\n    // Arrange & Act & Assert in fluent chain\n    await _fixture Given(\n            new CustomerRegistered(customerId, \"John Doe\", \"john@example com\"),\n            new ProductCreated(productId, \"Widget\", 10 00m)\n        ) When(new PlaceOrder(orderId, customerId, new[] { \n            new OrderItem(productId, 2, 10 00m) \n        })) Then() ShouldEmitEvent<OrderPlaced>() WithProperty(e => e OrderId, orderId) WithProperty(e => e CustomerId, customerId) WithProperty(e => e Total, 20 00m) And() ShouldNotEmitEvent<OrderRejected>();\n}\n`csharp{title=\"Error Scenario Testing\" description=\"Testing error scenarios with event validation assertions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Error-Scenarios\", \"Event-Validation\"] framework=\"NET8\"}\n[Test]\npublic async Task PlaceOrder_WithInvalidCustomer_ShouldEmitOrderRejected() {\n    await _fixture Given() // No customer registered When(new PlaceOrder(orderId, customerId, items)) Then() ShouldEmitEvent<OrderRejected>() WithProperty(e => e Reason, \"Customer not found\") And() ShouldNotEmitEvent<OrderPlaced>();\n}\n`\nProjection Testing\nFeed events and assert projection state:\n`csharp{title=\"Projection Lifecycle Testing\" description=\"Projection testing with event feeding and state assertions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Projections\", \"Lifecycle-Testing\"] framework=\"NET8\"}\n[Test]\npublic async Task OrderSummaryProjection_ShouldTrackOrderLifecycle() {\n    await _fixture ForProjection<OrderSummaryProjection>()",
        "startIndex": 0,
        "preview": "Testing & Development Tools\nWhizbang provides comprehensive testing utilities and development tools to ensure a productive developer experience from l..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-1",
        "text": "customerId, items)) Then() ShouldEmitEvent<OrderRejected>() WithProperty(e => e Reason, \"Customer not found\") And() ShouldNotEmitEvent<OrderPlaced>(); } ` Projection Testing Feed events and assert projection state: `csharp{title=\"Projection Lifecycle Testing\" description=\"Projection testing with event feeding and state assertions\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Projections\", \"Lifecycle-Testing\"] framework=\"NET8\"} [Test] public async Task OrderSummaryProjection_ShouldTrackOrderLifecycle() { await _fixture ForProjection<OrderSummaryProjection>() GivenEvents(\n            new OrderPlaced(orderId, customerId, 100 00m, DateTimeOffset UtcNow),\n            new OrderShipped(orderId, \"TRACK123\", DateTimeOffset UtcNow AddDays(1))\n        ) WhenProjectionRuns() ThenProjection<OrderSummary>(orderId ToString()) ShouldExist() ShouldHaveProperty(s => s Status, OrderStatus Shipped) ShouldHaveProperty(s => s Total, 100 00m) ShouldHaveProperty(s => s TrackingNumber, \"TRACK123\");\n}\n[Test]\npublic async Task OrderSummaryProjection_WithMissingEvents_ShouldHandleGracefully() {\n    await _fixture ForProjection<OrderSummaryProjection>() GivenEvents(\n            new OrderShipped(orderId, \"TRACK123\", DateTimeOffset UtcNow) // No OrderPlaced\n        ) WhenProjectionRuns() ThenProjection<OrderSummary>(orderId ToString()) ShouldNotExist(); // Projection should handle missing OrderPlaced gracefully\n}\n`\nPolicy Testing\nTest policy rules and combinations:\n`csharp{title=\"Policy Rule Testing\" description=\"Testing policy rules and their effects on system behavior\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Testing\", \"Policy-Testing\", \"Load-Testing\"] framework=\"NET8\"}\n[Test]\npublic async Task LoadTestingPolicy_ShouldSkipProjections() {\n    await _fixture ForPolicy(\"LoadTestingPolicy\") GivenContext(ctx => ctx WithFlag(WhizbangFlags LoadTesting)) GivenMessage(new OrderPlaced(orderId, customerId, 100 00m)) WhenPolicyEvaluates() ThenActions() ShouldContain<SkipProjectionsAction>() ShouldContain<AddTagAction>(action => action Tag == \"load-test-processed\");\n}\n[Test]\npublic async Task VIPCustomerPolicy_ShouldRouteToSpecialHandler() {\n    await _fixture ForPolicy(\"VIPCustomerPolicy\") GivenContext(ctx => ctx WithTag(\"customer-vip\")) GivenMessage(new PlaceOrder(orderId, customerId, items)) WhenPolicyEvaluates() ThenActions() ShouldContain<RouteToHandlerAction<VIPOrderHandler>>();\n}\n`\nSaga Testing\nTest long-running process coordination:\n`csharp{title=\"Saga Workflow Testing\" description=\"Testing long-running saga workflows with command coordination\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Testing\", \"Sagas\", \"Workflow-Coordination\"] framework=\"NET8\"}\n[Test]\npublic async Task OrderFulfillmentSaga_ShouldCoordinateFullWorkflow() {\n    await _fixture ForSaga<OrderFulfillmentSaga>() GivenEvents(\n            new OrderPlaced(orderId, customerId, items)\n        ) WhenSagaRuns() ThenCommands() ShouldContain<ReserveInventory>(cmd => cmd OrderId == orderId) And() WhenEvent(new InventoryReserved(orderId, items)) ThenCommands() ShouldContain<ChargePayment>(cmd => cmd OrderId == orderId) And() WhenEvent(new PaymentCharged(orderId, 100 00m)) ThenCommands() ShouldContain<ShipOrder>(cmd => cmd",
        "startIndex": 3484,
        "preview": "customerId, items)) Then() ShouldEmitEvent<OrderRejected>() WithProperty(e => e Reason, \"Customer not found\") And() ShouldNotEmitEvent<OrderPlaced>();..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-2",
        "text": "category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Testing\", \"Sagas\", \"Workflow-Coordination\"] framework=\"NET8\"} [Test] public async Task OrderFulfillmentSaga_ShouldCoordinateFullWorkflow() { await _fixture ForSaga<OrderFulfillmentSaga>() GivenEvents( new OrderPlaced(orderId, customerId, items) ) WhenSagaRuns() ThenCommands() ShouldContain<ReserveInventory>(cmd => cmd OrderId == orderId) And() WhenEvent(new InventoryReserved(orderId, items)) ThenCommands() ShouldContain<ChargePayment>(cmd => cmd OrderId == orderId) And() WhenEvent(new PaymentCharged(orderId, 100 00m)) ThenCommands() ShouldContain<ShipOrder>(cmd => cmd OrderId == orderId);\n}\n`\nIntegration Testing\nReal drivers with test containers:\n`csharp{title=\"Integration Testing with TestContainers\" description=\"Integration testing with real infrastructure using TestContainers\" category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Testing\", \"Integration-Testing\", \"TestContainers\"] framework=\"NET8\"}\n[Test]\npublic async Task OrderService_IntegrationTest_WithRealDatabase() {\n    // Uses TestContainers for real PostgreSQL\n    await using var fixture = new WhizbangIntegrationTestFixture() UseTestContainerPostgres() UseTestContainerKafka() ConfigureServices(services => {\n            services AddOrderService();\n            services AddInventoryService();\n        });\n    await fixture StartAsync();\n    // Test with real infrastructure\n    var result = await fixture Given(/ setup data in real database /) When(new PlaceOrder(orderId, customerId, items)) Then() ShouldEmitEvent<OrderPlaced>() And() ShouldHaveProjection<OrderSummary>(orderId ToString()) InDatabase(); // Verify in real database\n}\n`\nDevelopment Tools Suite\nCLI Tool (whizbang-cli)\nComprehensive command-line interface for project management:\n`bash\n---\ncategory: Design\ndifficulty: BEGINNER\ntags: [Design, CLI, Project-Scaffolding, Templates]\ndescription: CLI commands for project scaffolding and code generation\n---\nProject scaffolding\nwhizbang new --template microservice --name OrderService\nwhizbang new --template monolith --name ECommerceApp\nwhizbang new --template projection-worker --name AnalyticsWorker\nCode generation\nwhizbang add command --name PlaceOrder --domain Orders\nwhizbang add event --name OrderPlaced --domain Orders  \nwhizbang add projection --name OrderSummary --events OrderPlaced,OrderShipped\nwhizbang add saga --name OrderFulfillment --triggers OrderPlaced\nDevelopment utilities\nwhizbang validate --project /OrderService --check-ownership\nwhizbang generate --project /OrderService --watch\nwhizbang dashboard --port 5000 --project /OrderService\nEvent store utilities\nwhizbang events list --stream \"Order-*\" --from 2024-01-01\nwhizbang events replay --stream \"Order-123\" --to-projection OrderSummary\nwhizbang events export --stream \"Order-*\" --format json --output orders json\nMigration utilities\nwhizbang migrate --from 1 0 --to 2",
        "startIndex": 6486,
        "preview": "category=\"Design\" difficulty=\"ADVANCED\" tags=[\"Design\", \"Testing\", \"Sagas\", \"Workflow-Coordination\"] framework=\"NET8\"} [Test] public async Task OrderF..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-3",
        "text": "--project /OrderService --check-ownership whizbang generate --project /OrderService --watch whizbang dashboard --port 5000 --project /OrderService Event store utilities whizbang events list --stream \"Order-*\" --from 2024-01-01 whizbang events replay --stream \"Order-123\" --to-projection OrderSummary whizbang events export --stream \"Order-*\" --format json --output orders json Migration utilities whizbang migrate --from 1 0 --to 2 0 --dry-run\nwhizbang migrate --apply --backup\n`\nCLI Implementation Architecture\n`csharp{title=\"CLI Command Structure\" description=\"CLI command structure implementation with subcommands\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"CLI\", \"Command-Structure\", \"Implementation\"] framework=\"NET8\"}\n// CLI command structure\n[Command(\"whizbang\")]\npublic class WhizbangCliCommand {\n    [Command(\"new\")]\n    public class NewCommand {\n        [Option(\"--template\", Description = \"Project template\")]\n        public string Template { get; set; } = \"microservice\";\n        [Option(\"--name\", Description = \"Project name\")]\n        public string Name { get; set; }\n        public async Task<int> ExecuteAsync() {\n            var templateEngine = new ProjectTemplateEngine();\n            await templateEngine CreateProjectAsync(Template, Name);\n            return 0;\n        }\n    }\n    [Command(\"add\")]\n    public class AddCommand {\n        [Command(\"command\")]\n        public class AddCommandCommand {\n            [Option(\"--name\")] public string Name { get; set; }\n            [Option(\"--domain\")] public string Domain { get; set; }\n            public async Task<int> ExecuteAsync() {\n                var generator = new CodeGenerator();\n                await generator GenerateCommandAsync(Name, Domain);\n                return 0;\n            }\n        }\n    }\n}\n`\nVisual Studio Integration\nTemplates and extensions for rapid development:\n`xml\n---\ncategory: Design\ndifficulty: INTERMEDIATE\ntags: [Design, Templates, Visual-Studio, Project-Templates]\ndescription: Visual Studio template configuration for rapid development\n---\n< -- dotnet new templates -->\n<Project Sdk=\"Microsoft NET Sdk\">\n  <PropertyGroup>\n    <PackageType>Template</PackageType>\n    <PackageVersion>1 0 0</PackageVersion>\n    <PackageId>Whizbang",
        "startIndex": 8841,
        "preview": "--project /OrderService --check-ownership whizbang generate --project /OrderService --watch whizbang dashboard --port 5000 --project /OrderService Eve..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-4",
        "text": "} } } } ` Visual Studio Integration Templates and extensions for rapid development: `xml --- category: Design difficulty: INTERMEDIATE tags: [Design, Templates, Visual-Studio, Project-Templates] description: Visual Studio template configuration for rapid development --- < -- dotnet new templates --> <Project Sdk=\"Microsoft NET Sdk\"> <PropertyGroup> <PackageType>Template</PackageType> <PackageVersion>1 0 0</PackageVersion> <PackageId>Whizbang Templates</PackageId>\n    <Title>Whizbang Project Templates</Title>\n    <Description>Templates for Whizbang applications</Description>\n    <IncludeContentInPack>true</IncludeContentInPack>\n    <IncludeBuildOutput>false</IncludeBuildOutput>\n    <ContentTargetFolders>content</ContentTargetFolders>\n  </PropertyGroup>\n</Project>\n`\nLive Templates for common patterns:\n`csharp{title=\"Live Code Templates\" description=\"Live templates for common Whizbang patterns and boilerplate\" category=\"Design\" difficulty=\"BEGINNER\" tags=[\"Design\", \"Live-Templates\", \"Code-Generation\", \"Commands\"] framework=\"NET8\"}\n// Command template\npublic record $COMMAND_NAME$(\n    $PARAMETERS$\n) : ICommand;\n// Event template  \npublic record $EVENT_NAME$(\n    $PARAMETERS$\n) : IEvent;\n// Handler template\npublic class $HANDLER_NAME$ : ICommandHandler<$COMMAND_TYPE$> {\n    public async Task<IEvent[]> Handle($COMMAND_TYPE$ command) {\n        $HANDLER_LOGIC$\n        return new IEvent[] {\n            new $EVENT_TYPE$($EVENT_PARAMETERS$)\n        };\n    }\n}\n// Projection template\npublic class $PROJECTION_NAME$ : IProjectionHandler<$EVENT_TYPE$> {\n    public async Task Handle($EVENT_TYPE$ @event, ProjectionContext context) {\n        var projection = await context Load<$PROJECTION_MODEL$>(@event $KEY_FIELD$ ToString()) new $PROJECTION_MODEL$ { $KEY_FIELD$ = @event $KEY_FIELD$ };\n        $PROJECTION_LOGIC$\n        await context Store(@event $KEY_FIELD$ ToString(), projection);\n    }\n}\n`\nWeb Dashboard\nReal-time monitoring and debugging interface:\n`csharp{title=\"Web Dashboard Configuration\" description=\"Web dashboard configuration for real-time monitoring and debugging\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"Web-Dashboard\", \"Real-Time-Monitoring\", \"Configuration\"] framework=\"NET8\"}\n// Dashboard startup\npublic class WhizbangDashboard {\n    public static void ConfigureDashboard(WebApplicationBuilder builder) {\n        builder Services AddWhizbangDashboard(options => {\n            options EnableRealTimeUpdates = true;\n            options EventRetentionHours = 24;\n            options ProjectionLagAlertThreshold = TimeSpan FromMinutes(5);\n        });\n    }\n    public static void MapDashboardEndpoints(WebApplication app) {\n        app MapWhizbangDashboard(\"/dashboard\");\n        // API endpoints for dashboard\n        app MapGet(\"/api/whizbang/projections\", GetProjectionStatus);\n        app MapGet(\"/api/whizbang/events/{streamId}\", GetEventStream);\n        app MapPost(\"/api/whizbang/replay\", TriggerReplay);\n        app MapGet(\"/api/whizbang/policies\", GetActivePolicies);\n        app",
        "startIndex": 10662,
        "preview": "} } } } ` Visual Studio Integration Templates and extensions for rapid development: `xml --- category: Design difficulty: INTERMEDIATE tags: [Design, ..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-5",
        "text": "void ConfigureDashboard(WebApplicationBuilder builder) { builder Services AddWhizbangDashboard(options => { options EnableRealTimeUpdates = true; options EventRetentionHours = 24; options ProjectionLagAlertThreshold = TimeSpan FromMinutes(5); }); } public static void MapDashboardEndpoints(WebApplication app) { app MapWhizbangDashboard(\"/dashboard\"); // API endpoints for dashboard app MapGet(\"/api/whizbang/projections\", GetProjectionStatus); app MapGet(\"/api/whizbang/events/{streamId}\", GetEventStream); app MapPost(\"/api/whizbang/replay\", TriggerReplay); app MapGet(\"/api/whizbang/policies\", GetActivePolicies); app MapPost(\"/api/whizbang/policies/test\", TestPolicy);\n    }\n}\n`\nDashboard Features:\nReal-time Projection Monitoring\nProjection lag visualization\nEvent processing rates\nError rates and alerts\nCheckpoint status\nEvent Stream Visualization\nStream browsing and filtering\nEvent details and metadata\nCross-stream correlation\nFlow diagrams\nPolicy Rule Testing\nPolicy condition testing\nAction preview\nRule combination visualization\nPerformance impact analysis\nPerformance Metrics\nHandler execution times\nThroughput measurements\nResource utilization\nBottleneck identification\nIDE Extensions\nVisual Studio Code Extension with advanced features:\n`typescript\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, IDE-Extensions, VSCode, Event-Stream-Navigation]\ndescription: VSCode extension implementation for advanced Whizbang development features\n---\n// VSCode extension main functionality\nexport function activate(context: vscode ExtensionContext) {\n    // Register command for event stream navigation\n    const navigateCommand = vscode commands registerCommand(\n        'whizbang navigateEventStream',\n        async () => {\n            const streamId = await vscode window showInputBox({\n                prompt: 'Enter stream ID or pattern'\n            });\n            if (streamId) {\n                const events = await whizbangService getEventStream(streamId);\n                showEventStreamPanel(events);\n            }\n        }\n    );\n    // Register hover provider for command/event info\n    const hoverProvider = vscode languages registerHoverProvider(\n        'csharp',\n        new WhizbangHoverProvider()\n    );\n    // Register code lens provider for handler flow\n    const codeLensProvider = vscode languages registerCodeLensProvider(\n        'csharp',\n        new WhizbangCodeLensProvider()\n    );\n    context subscriptions push(navigateCommand, hoverProvider, codeLensProvider);\n}\n`typescript\n---\ncategory: Design\ndifficulty: ADVANCED\ntags: [Design, IDE-Extensions, Hover-Provider, Type-Metadata]\ndescription: Hover provider implementation for type metadata and handler information\n---\nclass WhizbangHoverProvider implements vscode HoverProvider {\n    async provideHover(document: vscode TextDocument, position: vscode Position): Promise<vscode Hover | undefined> {\n        const word = document getWordRangeAtPosition(position);\n        if ( word) return;\n        const wordText = document",
        "startIndex": 13281,
        "preview": "void ConfigureDashboard(WebApplicationBuilder builder) { builder Services AddWhizbangDashboard(options => { options EnableRealTimeUpdates = true; opti..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-6",
        "text": "Design difficulty: ADVANCED tags: [Design, IDE-Extensions, Hover-Provider, Type-Metadata] description: Hover provider implementation for type metadata and handler information --- class WhizbangHoverProvider implements vscode HoverProvider { async provideHover(document: vscode TextDocument, position: vscode Position): Promise<vscode Hover | undefined> { const word = document getWordRangeAtPosition(position); if ( word) return; const wordText = document getText(word);\n        // Check if it's a Whizbang command/event\n        const metadata = await whizbangService getTypeMetadata(wordText);\n        if (metadata) {\n            const contents = new vscode MarkdownString();\n            contents appendMarkdown(${metadata type}: ${metadata name}\\n\\n);\n            contents appendMarkdown(Domain: ${metadata domain}\\n\\n);\n            if (metadata handlers) {\n                contents appendMarkdown(Handlers:\\n);\n                metadata handlers forEach(h => {\n                    contents appendMarkdown(- ${h name} (${h domain})\\n);\n                });\n            }\n            return new vscode Hover(contents, word);\n        }\n    }\n}\n`\nIn-Memory Drivers for Testing\nFast Unit Test Infrastructure\nOptimized in-memory implementations for rapid testing:\n`csharp{title=\"In-Memory Event Store\" description=\"In-memory event store implementation optimized for unit testing\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"In-Memory-Drivers\", \"Unit-Testing\", \"Fast-Testing\"] framework=\"NET8\"}\n// In-memory event store\npublic class InMemoryEventStore : IEventStoreDriver {\n    private readonly ConcurrentDictionary<string, List<StoredEvent>> _streams = new();\n    public async Task AppendEventsAsync(string streamId, IEnumerable<IEvent> events, int expectedVersion) {\n        var streamEvents = _streams GetOrAdd(streamId, _ => new List<StoredEvent>());\n        lock (streamEvents) {\n            if (streamEvents Count = expectedVersion) {\n                throw new ConcurrencyException(streamId, expectedVersion, streamEvents Count);\n            }\n            foreach (var @event in events) {\n                streamEvents Add(new StoredEvent {\n                    StreamId = streamId,\n                    EventId = Guid NewGuid(),\n                    EventType = @event GetType() Name,\n                    EventData = JsonSerializer Serialize(@event),\n                    Version = streamEvents Count + 1,\n                    Timestamp = DateTimeOffset UtcNow\n                });\n            }\n        }\n    }\n    public async Task<IEnumerable<StoredEvent>> ReadEventsAsync(string streamId, int fromVersion = 0) {\n        var streamEvents = _streams GetOrAdd(streamId, _ => new List<StoredEvent>());\n        return streamEvents Where(e => e Version > fromVersion)",
        "startIndex": 15678,
        "preview": "Design difficulty: ADVANCED tags: [Design, IDE-Extensions, Hover-Provider, Type-Metadata] description: Hover provider implementation for type metadata..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-7",
        "text": "EventType = @event GetType() Name, EventData = JsonSerializer Serialize(@event), Version = streamEvents Count + 1, Timestamp = DateTimeOffset UtcNow }); } } } public async Task<IEnumerable<StoredEvent>> ReadEventsAsync(string streamId, int fromVersion = 0) { var streamEvents = _streams GetOrAdd(streamId, _ => new List<StoredEvent>()); return streamEvents Where(e => e Version > fromVersion) ToList();\n    }\n}\n`csharp{title=\"In-Memory Projection Store\" description=\"In-memory projection store for fast unit test execution\" category=\"Design\" difficulty=\"INTERMEDIATE\" tags=[\"Design\", \"In-Memory-Drivers\", \"Projection-Testing\", \"Fast-Testing\"] framework=\"NET8\"}\n// In-memory projection store\npublic class InMemoryProjectionStore : IProjectionDriver {\n    private readonly ConcurrentDictionary<string, Dictionary<string, object>> _projections = new();\n    public async Task Store<T>(string projectionName, string documentId, T document, string tenantId = null) {\n        var key = tenantId = null $\"{projectionName}_{tenantId}\" : projectionName;\n        var projectionData = _projections GetOrAdd(key, _ => new Dictionary<string, object>());\n        lock (projectionData) {\n            projectionData[documentId] = document;\n        }\n    }\n    public async Task<T > Load<T>(string projectionName, string documentId, string tenantId = null) {\n        var key = tenantId = null $\"{projectionName}_{tenantId}\" : projectionName;\n        if (_projections TryGetValue(key, out var projectionData)) {\n            lock (projectionData) {\n                if (projectionData",
        "startIndex": 18000,
        "preview": "EventType = @event GetType() Name, EventData = JsonSerializer Serialize(@event), Version = streamEvents Count + 1, Timestamp = DateTimeOffset UtcNow }..."
      },
      {
        "id": "proposals/testing-development-tools-chunk-8",
        "text": "= _projections GetOrAdd(key, _ => new Dictionary<string, object>()); lock (projectionData) { projectionData[documentId] = document; } } public async Task<T > Load<T>(string projectionName, string documentId, string tenantId = null) { var key = tenantId = null $\"{projectionName}_{tenantId}\" : projectionName; if (_projections TryGetValue(key, out var projectionData)) { lock (projectionData) { if (projectionData TryGetValue(documentId, out var document)) {\n                    return (T)document;\n                }\n            }\n        }\n        return default(T);\n    }\n}\n`\nTesting Best Practices\nTest Organization\nSeparate test categories:\nUnit tests - Fast, isolated, use in-memory drivers\nIntegration tests - Real infrastructure with test containers\nEnd-to-end tests - Full system testing\nPerformance tests - Load and stress testing\nTest data management:\nBuilders for complex test data construction\nFixtures for reusable test scenarios\nCleanup strategies for integration tests\nAssertion patterns:\nFluent assertions for readability\nCustom matchers for domain concepts\nError scenarios testing\nDevelopment Workflow\nTDD-friendly - Tests before implementation\nFast feedback - Sub-second unit test execution\nIDE integration - Run tests from code editor\nContinuous testing - Watch mode for automatic test runs\nCoverage tracking - Identify untested code paths\n---\nRelated Documentation\nSource Generation & IDE Integration - How testing integrates with generated code\nPolicy Engine - Testing policy rules and combinations\nFlags & Tags System - Cross-service context propagation\nObservability & Metrics - Testing observability features",
        "startIndex": 19179,
        "preview": "= _projections GetOrAdd(key, _ => new Dictionary<string, object>()); lock (projectionData) { projectionData[documentId] = document; } } public async T..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/FEATURE-EVOLUTION",
    "title": "Feature Evolution Matrix",
    "category": "Roadmap",
    "url": "/docs/roadmap/FEATURE-EVOLUTION",
    "chunks": [
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-0",
        "text": "Feature Evolution Matrix\nOverview\nThis matrix tracks how each Whizbang feature evolves across versions, showing clear progression from foundation to production-ready implementations Legend\n:::new New - Feature introduced in this version\n:::updated Enhanced - Feature improved from previous version\n:::updated{type=\"major\"} Major Update - Significant enhancement\n:::deprecated Deprecated - Feature being phased out\n:::planned Planned - Coming in future version\n- No changes in this version\nCore Components Evolution\nDispatcher\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ In-memory routing<br/>‚Ä¢ Source-generated dispatch tables<br/>‚Ä¢ Basic pipeline | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Parallel dispatch<br/>‚Ä¢ Batch operations<br/>‚Ä¢ Enhanced context | None | View ‚Üí |\n| v0 3 0 | :::updated Enhanced | ‚Ä¢ Event store integration<br/>‚Ä¢ Replay support | None | View ‚Üí |\n| v0 4 0 | :::updated Enhanced | ‚Ä¢ Database persistence<br/>‚Ä¢ Transaction support | None | View ‚Üí |\n| v0 5 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Distributed routing<br/>‚Ä¢ Saga coordination | None | View ‚Üí |\nReceptors\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Stateless receptors<br/>‚Ä¢ Basic interface<br/>‚Ä¢ Command handling | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Validation attributes<br/>‚Ä¢ Parameter injection<br/>‚Ä¢ Async support | None | View ‚Üí |\n| v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Stateful receptors<br/>‚Ä¢ Event sourcing<br/>‚Ä¢ State hydration | None | View ‚Üí |\n| v0 4 0 | - | No changes | - | - |\n| v0 5",
        "startIndex": 0,
        "preview": "Feature Evolution Matrix\nOverview\nThis matrix tracks how each Whizbang feature evolves across versions, showing clear progression from foundation to p..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-1",
        "text": "Validation attributes<br/>‚Ä¢ Parameter injection<br/>‚Ä¢ Async support | None | View ‚Üí | | v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Stateful receptors<br/>‚Ä¢ Event sourcing<br/>‚Ä¢ State hydration | None | View ‚Üí | | v0 4 0 | - | No changes | - | - | | v0 5 0 | :::updated Enhanced | ‚Ä¢ Distributed execution<br/>‚Ä¢ Remote receptors | None | View ‚Üí |\nPerspectives\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Event handling<br/>‚Ä¢ In-memory updates<br/>‚Ä¢ Basic interface | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Batch updates<br/>‚Ä¢ Parallel execution<br/>‚Ä¢ Error handling | None | View ‚Üí |\n| v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Projection support<br/>‚Ä¢ Rebuild capability<br/>‚Ä¢ Checkpoints | None | View ‚Üí |\n| v0 4 0 | :::updated Enhanced | ‚Ä¢ Database backing<br/>‚Ä¢ Optimized queries | None | View ‚Üí |\n| v0 5 0 | :::updated Enhanced | ‚Ä¢ Distributed perspectives<br/>‚Ä¢ Partitioned processing | None | View ‚Üí |\nLenses\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Query interface<br/>‚Ä¢ Focus, View, Glimpse<br/>‚Ä¢ In-memory queries | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Pagination<br/>‚Ä¢ Async enumeration<br/>‚Ä¢ Query optimization | None | View ‚Üí |\n| v0 3 0 | :::updated Enhanced | ‚Ä¢ Projection queries<br/>‚Ä¢ Time-travel queries | None | View ‚Üí |\n| v0 4 0 | :::updated{type=\"major\"} Major | ‚Ä¢ SQL generation<br/>‚Ä¢ Index usage<br/>‚Ä¢ Query caching | None | View ‚Üí |\n| v0 5",
        "startIndex": 1759,
        "preview": "Validation attributes<br/>‚Ä¢ Parameter injection<br/>‚Ä¢ Async support | None | View ‚Üí | | v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Stateful receptors..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-2",
        "text": "optimization | None | View ‚Üí | | v0 3 0 | :::updated Enhanced | ‚Ä¢ Projection queries<br/>‚Ä¢ Time-travel queries | None | View ‚Üí | | v0 4 0 | :::updated{type=\"major\"} Major | ‚Ä¢ SQL generation<br/>‚Ä¢ Index usage<br/>‚Ä¢ Query caching | None | View ‚Üí | | v0 5 0 | :::updated Enhanced | ‚Ä¢ Distributed queries<br/>‚Ä¢ Federated lenses | None | View ‚Üí |\nPolicy Engine\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Retry<br/>‚Ä¢ Timeout<br/>‚Ä¢ Cache<br/>‚Ä¢ CircuitBreaker | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Bulkhead<br/>‚Ä¢ Rate limiting<br/>‚Ä¢ Policy composition | None | View ‚Üí |\n| v0 3 0 | :::updated Enhanced | ‚Ä¢ Stateful policies<br/>‚Ä¢ Policy persistence | None | View ‚Üí |\n| v0 4 0 | - | No changes | - | - |\n| v0 5 0 | :::updated Enhanced | ‚Ä¢ Distributed policies<br/>‚Ä¢ Policy synchronization | None | View ‚Üí |\n| v0 6 0 | :::planned Planned | ‚Ä¢ Authorization<br/>‚Ä¢ Audit policies<br/>‚Ä¢ Compliance policies | None | View ‚Üí |\nLedger (Event Store)\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Event store interface<br/>‚Ä¢ In-memory storage<br/>‚Ä¢ Basic streams | - | View ‚Üí |\n| v0 2 0 | :::updated Enhanced | ‚Ä¢ Event metadata<br/>‚Ä¢ Stream categories | None | View ‚Üí |\n| v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Snapshots<br/>‚Ä¢ Projections<br/>‚Ä¢ Event versioning | None | View ‚Üí |\n| v0 4 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Database persistence<br/>‚Ä¢ JSONB storage<br/>‚Ä¢ Indexes | None | View ‚Üí |\n| v0 5",
        "startIndex": 3139,
        "preview": "optimization | None | View ‚Üí | | v0 3 0 | :::updated Enhanced | ‚Ä¢ Projection queries<br/>‚Ä¢ Time-travel queries | None | View ‚Üí | | v0 4 0 | :::updated..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-3",
        "text": "Stream categories | None | View ‚Üí | | v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Snapshots<br/>‚Ä¢ Projections<br/>‚Ä¢ Event versioning | None | View ‚Üí | | v0 4 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Database persistence<br/>‚Ä¢ JSONB storage<br/>‚Ä¢ Indexes | None | View ‚Üí | | v0 5 0 | :::updated Enhanced | ‚Ä¢ Distributed streams<br/>‚Ä¢ Partitioning | None | View ‚Üí |\nDrivers\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Driver interface<br/>‚Ä¢ In-memory driver | - | View ‚Üí |\n| v0 2 0 | - | No changes | - | - |\n| v0 3 0 | :::updated Enhanced | ‚Ä¢ Transaction support<br/>‚Ä¢ Batch operations | None | View ‚Üí |\n| v0 4 0 | :::updated{type=\"major\"} Major | ‚Ä¢ PostgreSQL driver<br/>‚Ä¢ SQL Server driver<br/>‚Ä¢ SQLite driver | None | View ‚Üí |\n| v0 5 0 | :::updated Enhanced | ‚Ä¢ Connection pooling<br/>‚Ä¢ Failover support | None | View ‚Üí |\nTransports\n| Version | Status | Key Features | Breaking Changes | Documentation |\n|---------|--------|--------------|------------------|---------------|\n| v0 1 0 | :::new New | ‚Ä¢ Transport interface<br/>‚Ä¢ In-memory transport | - | View ‚Üí |\n| v0 2 0 | - | No changes | - | - |\n| v0 3 0 | - | No changes | - | - |\n| v0 4 0 | :::updated Enhanced | ‚Ä¢ Outbox pattern prep | None | View ‚Üí |\n| v0 5 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Kafka transport<br/>‚Ä¢ RabbitMQ transport<br/>‚Ä¢ Azure Service Bus | None | View ‚Üí |\nDeveloper Experience Evolution\nSource Generators\n| Version | Features | Performance Impact |\n|---------|----------|-------------------|\n| v0 1",
        "startIndex": 4536,
        "preview": "Stream categories | None | View ‚Üí | | v0 3 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Snapshots<br/>‚Ä¢ Projections<br/>‚Ä¢ Event versioning | None | View ‚Üí |..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-4",
        "text": "| ‚Ä¢ Outbox pattern prep | None | View ‚Üí | | v0 5 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Kafka transport<br/>‚Ä¢ RabbitMQ transport<br/>‚Ä¢ Azure Service Bus | None | View ‚Üí | Developer Experience Evolution Source Generators | Version | Features | Performance Impact | |---------|----------|-------------------| | v0 1 0 | ‚Ä¢ Handler discovery<br/>‚Ä¢ Routing tables<br/>‚Ä¢ Service registration | < 1s for 1000 handlers |\n| v0 2 0 | ‚Ä¢ Validation generation<br/>‚Ä¢ Policy weaving | < 1 5s for 1000 handlers |\n| v0 3 0 | ‚Ä¢ Serialization generation<br/>‚Ä¢ State machines | < 2s for 1000 handlers |\n| v0 4 0 | ‚Ä¢ SQL generation<br/>‚Ä¢ Migration scripts | < 2 5s for 1000 handlers |\n| v0 5 0 | ‚Ä¢ Message contracts<br/>‚Ä¢ Saga orchestration | < 3s for 1000 handlers |\nIDE Tools\n| Version | Features | Enhancements |\n|---------|----------|--------------|\n| v0 1 0 | ‚Ä¢ CodeLens references<br/>‚Ä¢ Basic navigation<br/>‚Ä¢ Analyzer warnings | Foundation |\n| v0 2 0 | ‚Ä¢ Enhanced traceability<br/>‚Ä¢ Quick fixes<br/>‚Ä¢ Refactoring support | +50% features |\n| v0 3 0 | ‚Ä¢ Time-travel debugging<br/>‚Ä¢ Event replay<br/>‚Ä¢ State inspection | +30% features |\n| v0 4 0 | ‚Ä¢ Query optimization hints<br/>‚Ä¢ Index suggestions | +20% features |\n| v0 5 0 | ‚Ä¢ Distributed tracing<br/>‚Ä¢ Message flow viz | +40% features |\nTesting Support\n| Version | Features | Test Types |\n|---------|----------|------------|\n| v0 1 0 | ‚Ä¢ TUnit integration<br/>‚Ä¢ Bogus scenarios<br/>‚Ä¢ In-memory doubles | Unit, Integration |\n| v0 2 0 | ‚Ä¢ Behavior specs<br/>‚Ä¢ Property testing | + BDD, Property |\n| v0 3 0 | ‚Ä¢ Event sourcing helpers<br/>‚Ä¢ Time travel testing | + Event Testing |\n| v0 4 0 | ‚Ä¢ Database testing<br/>‚Ä¢ Migration testing | + Database |\n| v0 5",
        "startIndex": 5862,
        "preview": "| ‚Ä¢ Outbox pattern prep | None | View ‚Üí | | v0 5 0 | :::updated{type=\"major\"} Major | ‚Ä¢ Kafka transport<br/>‚Ä¢ RabbitMQ transport<br/>‚Ä¢ Azure Service B..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-5",
        "text": "| | v0 2 0 | ‚Ä¢ Behavior specs<br/>‚Ä¢ Property testing | + BDD, Property | | v0 3 0 | ‚Ä¢ Event sourcing helpers<br/>‚Ä¢ Time travel testing | + Event Testing | | v0 4 0 | ‚Ä¢ Database testing<br/>‚Ä¢ Migration testing | + Database | | v0 5 0 | ‚Ä¢ Distributed testing<br/>‚Ä¢ Chaos engineering | + Distributed |\nMigration Complexity\nVersion Upgrade Paths\n| From ‚Üí To | Complexity | Breaking Changes | Migration Guide |\n|-----------|------------|------------------|-----------------|\n| v0 1 0 ‚Üí v0 2 0 | ‚≠ê Easy | None | Guide ‚Üí |\n| v0 2 0 ‚Üí v0 3 0 | ‚≠ê‚≠ê Moderate | None | Guide ‚Üí |\n| v0 3 0 ‚Üí v0 4 0 | ‚≠ê‚≠ê Moderate | None | Guide ‚Üí |\n| v0 4 0 ‚Üí v0 5 0 | ‚≠ê‚≠ê‚≠ê Complex | None | Guide ‚Üí |\nFeature Adoption Timeline\n`mermaid\ngantt\n    title Feature Adoption Timeline\n    dateFormat YYYY-MM\n    section Foundation\n    Core Components     :done, 2025-01, 2025-02\n    Source Generators   :done, 2025-01, 2025-02\n    IDE Tools          :done, 2025-01, 2025-02\n    section Enhancement\n    Validation         :active, 2025-03, 2025-04\n    Policies           :active, 2025-03, 2025-04\n    section Event Sourcing\n    Stateful Receptors :2025-05, 2025-06\n    Projections        :2025-05, 2025-06\n    section Persistence\n    Database Drivers   :2025-07, 2025-08\n    Migrations         :2025-07, 2025-08\n    section Distributed\n    Message Transports :2025-09, 2025-10\n    Sagas             :2025-09, 2025-10\n`\nSuccess Metrics by Version\n| Version | Adoption Target | Performance Target | Quality Target |\n|---------|----------------|-------------------|----------------|\n| v0 1 0 | 100+ developers | < 1ms operations | 100% test coverage |\n| v0 2 0 | 500+ developers | < 1ms operations | 100% test coverage |\n| v0 3 0 | 1,000+ developers | < 10ms operations | 95% test coverage |\n| v0 4 0 | 5,000+ developers | < 10ms operations | 95% test coverage |\n| v0 5",
        "startIndex": 7239,
        "preview": "| | v0 2 0 | ‚Ä¢ Behavior specs<br/>‚Ä¢ Property testing | + BDD, Property | | v0 3 0 | ‚Ä¢ Event sourcing helpers<br/>‚Ä¢ Time travel testing | + Event Testi..."
      },
      {
        "id": "roadmap/FEATURE-EVOLUTION-chunk-6",
        "text": "v0 2 0 | 500+ developers | < 1ms operations | 100% test coverage | | v0 3 0 | 1,000+ developers | < 10ms operations | 95% test coverage | | v0 4 0 | 5,000+ developers | < 10ms operations | 95% test coverage | | v0 5 0 | 10,000+ developers | < 100ms operations | 90% test coverage |\nNavigation\nBack to Roadmap\nv0 1 0 Documentation\nSuccess Metrics\nSession Context",
        "startIndex": 8835,
        "preview": "v0 2 0 | 500+ developers | < 1ms operations | 100% test coverage | | v0 3 0 | 1,000+ developers | < 10ms operations | 95% test coverage | | v0 4 0 | 5..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/README",
    "title": "Whizbang Implementation Roadmap",
    "category": "Roadmap",
    "url": "/docs/roadmap/README",
    "chunks": [
      {
        "id": "roadmap/README-chunk-0",
        "text": "Whizbang Implementation Roadmap\nOverview\nThis roadmap outlines the complete implementation plan for Whizbang, a unified event-sourced data and messaging runtime for NET We follow a breadth-first approach, establishing thin implementations of ALL major components early, then iteratively enhancing each component Core Principles\nZero Reflection: Everything discovered and wired at compile time via source generators\nIDE-First Development: Developer tools and traceability from day one\nTest-Driven: Comprehensive testing with TUnit and Bogus from the start\nProgressive Enhancement: Start simple, enhance iteratively\nIn-Memory First: All components start with in-memory implementations that become test doubles\nVersion Overview\nüöÄ v0 1 0 - Foundation\nStatus: Planning  \nGoal: Minimal working implementation of EVERY major component\nAll core interfaces and abstractions\nSource generators and analyzers\nIDE tools with CodeLens-style references\nTraceability and debugging foundation\nComplete testing framework with TUnit and Bogus\nIn-memory implementations for all components\nüìà v0 2 0 - Event-Driven Enhancement\nStatus: Planning  \nGoal: Deepen event-driven capabilities\nEnhanced receptors with validation\nRich event metadata and correlation\nMultiple perspectives per event\nAdvanced lens query methods\nPolicy engine enhancements\nüíæ v0 3 0 - Event Sourcing\nStatus: Planning  \nGoal: Add stateful capabilities\nStateful receptors\nTraditional aggregates\nEvent store implementation\nProjections and snapshots\nOptimistic concurrency\nüóÑÔ∏è v0 4 0 - Real Persistence\nStatus: Planning  \nGoal: Production-ready persistence\nPostgreSQL driver with JSONB\nSQL Server driver with JSON columns\nSQLite driver for edge scenarios\nSchema migrations\nMulti-tenancy support\nüì° v0 5 0 - Distributed Systems\nStatus: Planning  \nGoal: Enable distributed messaging\nKafka transport\nRabbitMQ transport\nOutbox/Inbox patterns\nSaga orchestration\nDistributed tracing\nüîÆ Future Versions\nv0 6 0 - Production Hardening (Observability, Security, Compliance)\nv0 7 0 - Performance & Scale (Zero allocation, AOT support)\nv0 8 0 - Cloud Native (Kubernetes, Serverless)\nv0 9 0 - Innovation (Effect system, AI integration)\nComponent Architecture\nCore Components Present from v0 1",
        "startIndex": 0,
        "preview": "Whizbang Implementation Roadmap\nOverview\nThis roadmap outlines the complete implementation plan for Whizbang, a unified event-sourced data and messagi..."
      },
      {
        "id": "roadmap/README-chunk-1",
        "text": "Distributed tracing üîÆ Future Versions v0 6 0 - Production Hardening (Observability, Security, Compliance) v0 7 0 - Performance & Scale (Zero allocation, AOT support) v0 8 0 - Cloud Native (Kubernetes, Serverless) v0 9 0 - Innovation (Effect system, AI integration) Component Architecture Core Components Present from v0 1 0\n| Component | Purpose | Starting Implementation |\n|-----------|---------|------------------------|\n| Dispatcher | Message routing and coordination | In-memory routing with generated mappings |\n| Receptors | Command receivers and decision makers | Stateless with parameter injection |\n| Perspectives | Event handlers and write models | In-memory state updates |\n| Lenses | Query interfaces and read models | In-memory LINQ queries |\n| Policy Engine | Cross-cutting concerns | Retry, Timeout, Cache, CircuitBreaker |\n| Ledger | Event store abstraction | In-memory event streams |\n| Drivers | Storage abstraction | In-memory storage |\n| Transports | Message broker abstraction | In-memory pub/sub |\nDeveloper Experience from Day One\n| Feature | Purpose | Available From |\n|---------|---------|----------------|\n| Source Generators | Zero-reflection handler discovery | v0 1 0 |\n| Analyzers | Compile-time validation | v0 1 0 |\n| IDE Tools | CodeLens references, navigation | v0 1 0 |\n| Traceability | Message flow visualization | v0 1 0 |\n| Time-Travel Debugging | Step through message history | v0 1 0 |\n| Test Framework | TUnit with Bogus scenarios | v0 1",
        "startIndex": 2229,
        "preview": "Distributed tracing üîÆ Future Versions v0 6 0 - Production Hardening (Observability, Security, Compliance) v0 7 0 - Performance & Scale (Zero allocati..."
      },
      {
        "id": "roadmap/README-chunk-2",
        "text": "1 0 | | IDE Tools | CodeLens references, navigation | v0 1 0 | | Traceability | Message flow visualization | v0 1 0 | | Time-Travel Debugging | Step through message history | v0 1 0 | | Test Framework | TUnit with Bogus scenarios | v0 1 0 |\nSuccess Metrics\nTechnical Goals\nZero reflection throughout the entire library\nSub-millisecond in-memory operations\n<10ms p99 for database operations\n<100ms p99 for distributed operations\n100% backward compatibility within major versions\nQuality Goals\n100% test coverage of public APIs\nAll code examples compile and run\nComplete documentation for every public API\nAnalyzers catch common mistakes at compile time\nDeveloper Experience Goals\nIntelliSense for all configuration options\nOne-click navigation between related components\nVisual debugging of message flow\nComprehensive error messages with fixes\nGetting Started\nRead the Philosophy - Understand our core principles\nReview the Architecture - See how components fit together\nStart with v0 1 0 - Begin with the foundation\nCheck Success Metrics - Understand how we measure progress\nContributing\nThis roadmap is a living document Each version's documentation contains:\nDetailed specifications for each component\nCode examples and patterns\nTesting requirements\nMigration guides from previous versions\nNavigation\nBy Version\nv0 1 0 - Foundation\nv0 2 0 - Event-Driven\nv0 3 0 - Event Sourcing\nv0 4 0 - Persistence\nv0 5 0 - Distributed\nFuture Versions\nBy Topic\nCore Philosophy\nArchitecture Overview\nSuccess Metrics\nTesting Strategy\nDeveloper Experience",
        "startIndex": 3386,
        "preview": "1 0 | | IDE Tools | CodeLens references, navigation | v0 1 0 | | Traceability | Message flow visualization | v0 1 0 | | Time-Travel Debugging | Step t..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/SESSION-CONTEXT",
    "title": "Session Context for Claude",
    "category": "Roadmap",
    "url": "/docs/roadmap/SESSION-CONTEXT",
    "chunks": [
      {
        "id": "roadmap/SESSION-CONTEXT-chunk-0",
        "text": "Session Context for Claude\nQuick Start for New Sessions\nCopy this to Claude when starting a new session:\n> I'm working on implementing the Whizbang NET library Please read the SESSION-CONTEXT md file in src/assets/docs/roadmap/ for full context We're building a zero-reflection, event-driven/event-sourced messaging runtime with source generators and comprehensive IDE support from day one Project Overview\nWhat is Whizbang Whizbang is a unified event-sourced data and messaging runtime for NET that combines the best aspects of MediatR, Wolverine, MassTransit, and NServiceBus into a single, cohesive platform with progressive enhancement Current Status\nPhase: Implementation planning and documentation\nCurrent Version: v0 1 0 (Foundation) - Planning\nDocumentation: Located in src/assets/docs/\nOld Docs: Previous versions prefixed with old- for reference\nCore Implementation Principles\nNon-Negotiable Rules\nZERO REFLECTION - Everything via source generators, no exceptions\nIDE-First - CodeLens, traceability, and debugging from day one\nTest-Driven - TUnit + Bogus for all components\nBreadth-First - All components exist from v0 1 0, even if simple\nIn-Memory First - All components start with in-memory implementations\nArchitecture Components (All in v0 1 0)\nDispatcher - Message routing coordination\nReceptors - Command receivers (not handlers)\nPerspectives - Event handlers (not projections initially)\nLenses - Read-only query interfaces\nPolicy Engine - Cross-cutting concerns\nLedger - Event store abstraction\nDrivers - Storage abstraction\nTransports - Message broker abstraction\nUnique Terminology\nReceptors instead of Handlers (emphasizes decision-making)\nPerspectives instead of Projections (more general, handles all writes)\nLenses for queries (composable, functional)\nLedger instead of Event Store (cleaner abstraction)\nDocumentation Structure\n`\nsrc/assets/docs/\n‚îú‚îÄ‚îÄ roadmap/                    Implementation roadmap\n‚îÇ   ‚îú‚îÄ‚îÄ README md              Main roadmap navigation\n‚îÇ   ‚îú‚îÄ‚îÄ philosophy md          Core principles\n‚îÇ   ‚îú‚îÄ‚îÄ architecture md        Component relationships\n‚îÇ   ‚îú‚îÄ‚îÄ success-metrics md     How we measure success\n‚îÇ   ‚îî‚îÄ‚îÄ SESSION-CONTEXT md     This file\n‚îú‚îÄ‚îÄ v0 1",
        "startIndex": 0,
        "preview": "Session Context for Claude\nQuick Start for New Sessions\nCopy this to Claude when starting a new session:\n> I'm working on implementing the Whizbang NE..."
      },
      {
        "id": "roadmap/SESSION-CONTEXT-chunk-1",
        "text": "instead of Event Store (cleaner abstraction) Documentation Structure ` src/assets/docs/ ‚îú‚îÄ‚îÄ roadmap/ Implementation roadmap ‚îÇ ‚îú‚îÄ‚îÄ README md Main roadmap navigation ‚îÇ ‚îú‚îÄ‚îÄ philosophy md Core principles ‚îÇ ‚îú‚îÄ‚îÄ architecture md Component relationships ‚îÇ ‚îú‚îÄ‚îÄ success-metrics md How we measure success ‚îÇ ‚îî‚îÄ‚îÄ SESSION-CONTEXT md This file ‚îú‚îÄ‚îÄ v0 1 0/                    Foundation release (current focus)\n‚îÇ   ‚îú‚îÄ‚îÄ components/            Component specifications\n‚îÇ   ‚îú‚îÄ‚îÄ developer-experience/  IDE, source generators, debugging\n‚îÇ   ‚îú‚îÄ‚îÄ testing/              Testing strategy\n‚îÇ   ‚îî‚îÄ‚îÄ examples/             Code examples\n‚îú‚îÄ‚îÄ v0 2 0/ through v0 5 0/    Future versions\n‚îú‚îÄ‚îÄ future/                    Long-term vision (v0 6 0+)\n‚îî‚îÄ‚îÄ old-*/                     Previous documentation for reference\n`\nCurrent Implementation Focus\nv0 1 0 Goals\n[ ] All 8 core components with interfaces\n[ ] Source generators for zero-reflection discovery\n[ ] IDE tools with CodeLens-style references\n[ ] Traceability and time-travel debugging foundation\n[ ] Complete testing framework (TUnit + Bogus)\n[ ] In-memory implementations (become test doubles)\nKey Files to Review\n/roadmap/philosophy md - Core principles and anti-patterns\n/roadmap/architecture md - Component relationships\n/v0 1 0/README md - Current version details\n/v0 1 0/components/dispatcher md - Example component spec\nDevelopment Patterns\nSource Generator Pattern\n`csharp\n[WhizbangHandler]  // Source generator discovers this\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    public OrderCreated Receive(CreateOrder cmd) { }\n}\n`\nPolicy Pattern\n`csharp\n[Retry(3)]\n[Timeout(5000)]\n[Cache(300)]\npublic class PaymentReceptor : IReceptor<ProcessPayment> { }\n`\nTesting Pattern\n`csharp\n[Test]\n[MethodDataSource(nameof(OrderScenarios))]  // Bogus generates scenarios\npublic async Task CreateOrder_ShouldEmitOrderCreated(OrderScenario scenario) { }\n`\nVersion Progression\nv0 1 0 - Foundation (all components, in-memory)\nv0 2 0 - Event-Driven Enhancement (validation, rich events)\nv0 3 0 - Event Sourcing (stateful receptors, aggregates)\nv0 4 0 - Real Persistence (PostgreSQL, SQL Server, SQLite)\nv0 5 0 - Distributed Systems (Kafka, RabbitMQ, Sagas)\nv0 6",
        "startIndex": 2193,
        "preview": "instead of Event Store (cleaner abstraction) Documentation Structure ` src/assets/docs/ ‚îú‚îÄ‚îÄ roadmap/ Implementation roadmap ‚îÇ ‚îú‚îÄ‚îÄ README md Main roadm..."
      },
      {
        "id": "roadmap/SESSION-CONTEXT-chunk-2",
        "text": "` Version Progression v0 1 0 - Foundation (all components, in-memory) v0 2 0 - Event-Driven Enhancement (validation, rich events) v0 3 0 - Event Sourcing (stateful receptors, aggregates) v0 4 0 - Real Persistence (PostgreSQL, SQL Server, SQLite) v0 5 0 - Distributed Systems (Kafka, RabbitMQ, Sagas) v0 6 0+ - Production, Performance, Cloud, Innovation\nCommon Tasks\nAdding a New Component Spec\nCreate file in /v0 1 0/components/[component] md\nInclude: Interface, In-Memory Implementation, Source Generation, Testing, IDE Integration\nUpdate /v0 1 0/components/README md navigation\nAdding a New Version\nCreate folder /v0 X 0/\nAdd _folder md with metadata\nCreate README md with version overview\nAdd migration-guide md from previous version\nWorking on Specific Topics\nComponents: Focus on /v0 1 0/components/\nTesting: Focus on /v0 1 0/testing/\nIDE Features: Focus on /v0 1 0/developer-experience/\nExamples: Focus on /v0 1 0/examples/\nKey Decisions Made\nNo Reflection Ever - Source generators from day one\nBreadth First - All components in v0 1 0\nTUnit over xUnit/NUnit - Modern, fast, better DX\nBogus for Test Data - Realistic scenario generation\nIn-Memory as Test Doubles - Not throwaway code\nPolicies over Aspects - Explicit, composable, testable\nQuestions/Discussions in Progress\n[ ] Exact IDE overlay visualization format\n[ ] Specific OpenTelemetry integration points\n[ ] Dashboard technology (Blazor vs React)\n[ ] Package naming conventions\n[ ] CI/CD pipeline structure\nWorking Conventions\nCode Examples\nAlways show complete, compilable examples\nInclude using statements\nShow both simple and advanced usage\nInclude testing examples\nDocumentation Style\nUse clear headings and sections\nInclude code examples with syntax highlighting\nProvide \"why\" not just \"what\"\nLink between related documents\nFile Naming\nComponents: [component-name] md\nGuides: [topic]-guide md\nExamples: [scenario]-example",
        "startIndex": 4038,
        "preview": "` Version Progression v0 1 0 - Foundation (all components, in-memory) v0 2 0 - Event-Driven Enhancement (validation, rich events) v0 3 0 - Event Sourc..."
      },
      {
        "id": "roadmap/SESSION-CONTEXT-chunk-3",
        "text": "Examples Always show complete, compilable examples Include using statements Show both simple and advanced usage Include testing examples Documentation Style Use clear headings and sections Include code examples with syntax highlighting Provide \"why\" not just \"what\" Link between related documents File Naming Components: [component-name] md Guides: [topic]-guide md Examples: [scenario]-example md\nAlways lowercase with hyphens\nConcepts & Patterns Documentation\nPattern Documentation Standards\nAll pattern files in /src/assets/patterns/ follow this proven structure (based on successful Receptor Pattern template):\nRequired Structure\nFront-matter - Standard metadata (title, category, order, description, tags)\nTitle & Tagline - Pattern name with memorable quote  \nEvolution (Early in document - key placement )\nPattern Roadmap\nVersion Timeline (Mermaid flowchart showing v0 1 0 ‚Üí v0 5 0)\nCapability Growth by Version\nCode examples for each version with enhanced front-matter metadata\nProgressive complexity from foundation to distributed\nEvolution Benefits\nMigration Path\nCapability Matrix (Mermaid diagram showing evolution timeline)\nPattern Overview\nWhat is [Pattern] Key Characteristics  \nIndustry Pattern Comparisons (embedded, no separate header):\nTraditional Pattern Name - Similarity: and Difference:\nMultiple comparisons showing how this pattern relates to existing approaches\nWhen to Use [Pattern]\nImplementation - Technical details and core concepts\nCode Examples - Progressive complexity with full metadata\nWhen to Use This Pattern - Clear guidance and anti-patterns\nCommon Misconceptions - Address typical confusion points\nImplementation Checklist - Practical step-by-step guidance\nExample: [Specific Scenario] - Complete working implementation\nBenefits - For developers and systems\nNext Steps - Links to related patterns\nKey Standards\nEvolution section placement: Position #3 (early), not late in document\nIndustry comparisons: Use Similarity: and Difference: format (bold text renders automatically)\nCode examples: All must have enhanced front-matter with metadata including:\ntitle, description, framework, category, difficulty\ntags, nugetPackages, filename, testFile, testMethod, usingStatements\nMermaid diagrams: Use consistent color schemes across all patterns\nVersion progression: Always follows v0",
        "startIndex": 5624,
        "preview": "Examples Always show complete, compilable examples Include using statements Show both simple and advanced usage Include testing examples Documentation..."
      },
      {
        "id": "roadmap/SESSION-CONTEXT-chunk-4",
        "text": "not late in document Industry comparisons: Use Similarity: and Difference: format (bold text renders automatically) Code examples: All must have enhanced front-matter with metadata including: title, description, framework, category, difficulty tags, nugetPackages, filename, testFile, testMethod, usingStatements Mermaid diagrams: Use consistent color schemes across all patterns Version progression: Always follows v0 1 0 ‚Üí v0 2 0 ‚Üí v0 3 0 ‚Üí v0 4 0 ‚Üí v0 5 0\nCross-references: Use relative links between related patterns\nContent Quality Requirements\nAll code examples must be complete and compilable\nProgressive complexity from simple to distributed scenarios\nClear explanations of \"why\" not just \"what\"\nTestable examples with accompanying test methods\nConsistent terminology aligned with Whizbang's unique vocabulary\nSession Handoff Notes\nFor next session, current priorities are:\nComplete remaining v0 1 0 component specifications\nDetail out testing foundation with TUnit/Bogus\nSpecify source generator implementation\nCreate developer experience documentation\nAdd concrete examples for each component\nRecent work completed:\nRenamed old version folders to old-*\nCreated complete roadmap documentation structure\nEstablished v0 1 0 through v0 5 0 version folders\nDocumented philosophy and architecture\nCreated success metrics framework\nQuick Commands\n`bash\nNavigate to docs\ncd /Users/philcarbone/src/whizbang-lib github io/src/assets/docs\nView structure\nls -la roadmap/ v0 1 0/\nFind all component docs\nfind -name \"component md\"\nSearch for specific patterns\ngrep -r \"IReceptor\" --include=\"* md\"\n`\nContact/Questions\nGitHub: https://github com/whizbang/whizbang\nDiscussions: Use GitHub Discussions for design questions\nDocumentation Site: This site (whizbang-lib github io)\n---\nRemember: We're building the future of NET messaging - zero reflection, exceptional DX, progressive enhancement",
        "startIndex": 731,
        "preview": "not late in document Industry comparisons: Use Similarity: and Difference: format (bold text renders automatically) Code examples: All must have enhan..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/architecture",
    "title": "Architecture Overview",
    "category": "Roadmap",
    "url": "/docs/roadmap/architecture",
    "chunks": [
      {
        "id": "roadmap/architecture-chunk-0",
        "text": "Architecture Overview\nComponent Architecture\n`mermaid\ngraph TB\n    subgraph \"Message Flow\"\n        CMD[Command] --> DISP[Dispatcher]\n        DISP --> REC[Receptor]\n        REC --> EVT[Event]\n        EVT --> DISP2[Dispatcher]\n        DISP2 --> PERSP[Perspectives]\n    end\n    subgraph \"Query Flow\"\n        QUERY[Query] --> LENS[Lens]\n        LENS --> STORE[(Storage)]\n    end\n    subgraph \"Cross-Cutting\"\n        POLICY[Policy Engine] - ->|Applies to| REC\n        POLICY - ->|Applies to| PERSP\n        TRACE[Traceability] - ->|Observes| DISP\n        TRACE -",
        "startIndex": 0,
        "preview": "Architecture Overview\nComponent Architecture\n`mermaid\ngraph TB\n    subgraph \"Message Flow\"\n        CMD[Command] --> DISP[Dispatcher]\n        DISP --> ..."
      },
      {
        "id": "roadmap/architecture-chunk-1",
        "text": "graph TB subgraph \"Message Flow\" CMD[Command] --> DISP[Dispatcher] DISP --> REC[Receptor] REC --> EVT[Event] EVT --> DISP2[Dispatcher] DISP2 --> PERSP[Perspectives] end subgraph \"Query Flow\" QUERY[Query] --> LENS[Lens] LENS --> STORE[(Storage)] end subgraph \"Cross-Cutting\" POLICY[Policy Engine] - ->|Applies to| REC POLICY - ->|Applies to| PERSP TRACE[Traceability] - ->|Observes| DISP TRACE - ->|Observes| DISP2\n    end\n    PERSP --> STORE\n    LEDGER[(Event Store)] --> STORE\n    style CMD fill:#e1f5fe\n    style EVT fill:#fff3e0\n    style STORE fill:#f3e5f5\n    style POLICY fill:#e8f5e9\n`\nCore Components\nDispatcher\nThe nervous system of Whizbang\n`csharp\npublic interface IDispatcher {\n    // Commands go to exactly one receptor\n    Task<TResult> Send<TResult>(ICommand<TResult> command);\n    // Events go to all interested perspectives\n    Task Publish<TEvent>(TEvent @event);\n    // Queries go through lenses\n    TLens GetLens<TLens>() where TLens : ILens;\n}\n`\nThe Dispatcher:\nRoutes messages based on compile-time generated tables\nManages execution pipeline\nApplies policies\nTracks correlation and causation\nProvides traceability hooks\nReceptors\nCommand receivers and decision makers\n`csharp\npublic interface IReceptor<TCommand> {\n    object Receive(TCommand command);\n}\n`\nReceptors:\nReceive commands from the dispatcher\nMake decisions based on business rules\nEmit events representing decisions\nCan be stateless (Event-Driven) or stateful (Event-Sourced)\nNever perform side effects directly\nPerspectives\nEvent handlers that update views\n`csharp\npublic interface IPerspectiveOf<TEvent> {\n    Task Update(TEvent @event);\n}\n`\nPerspectives:\nReact to events from receptors\nUpdate databases, caches, search indexes\nMaintain different views of the same data\nExecute all write operations\nCan be synchronous or asynchronous\nLenses\nRead-only query interfaces\n`csharp\npublic interface ILens {\n    T Focus<T>(object id);                              // Single item\n    IEnumerable<T> View<T>(Expression<Func<T, bool>> filter);  // Filtered set\n    TSummary Glimpse<TSummary>(object id);             // Partial view\n    bool Exists(object id);                            // Existence check\n    IAsyncEnumerable<T> Scan<T>();                     // Full scan\n}\n`\nLenses:\nProvide read-only access to data\nFocus on specific query needs\nAbstract storage mechanism\nSupport different view shapes\nEnable query optimization\nPolicy Engine\nCross-cutting concerns as composable policies\n`csharp\n[Retry(3, BackoffStrategy",
        "startIndex": 557,
        "preview": "graph TB subgraph \"Message Flow\" CMD[Command] --> DISP[Dispatcher] DISP --> REC[Receptor] REC --> EVT[Event] EVT --> DISP2[Dispatcher] DISP2 --> PERSP..."
      },
      {
        "id": "roadmap/architecture-chunk-2",
        "text": "TSummary Glimpse<TSummary>(object id); // Partial view bool Exists(object id); // Existence check IAsyncEnumerable<T> Scan<T>(); // Full scan } ` Lenses: Provide read-only access to data Focus on specific query needs Abstract storage mechanism Support different view shapes Enable query optimization Policy Engine Cross-cutting concerns as composable policies `csharp [Retry(3, BackoffStrategy Exponential)]\n[Timeout(5000)]\n[Cache(Duration = 300)]\n[CircuitBreaker(0 5, 10)]\npublic class PaymentReceptor : IReceptor<ProcessPayment> { }\n`\nPolicies include:\nResilience: Retry, Circuit Breaker, Timeout, Fallback\nPerformance: Cache, Batch, Throttle\nSecurity: Authorize, Audit, Encrypt\nObservability: Trace, Metric, Log\nLedger (Event Store)\nThe source of truth for events\n`csharp\npublic interface ILedger {\n    // Append events to a stream\n    Task<long> Append(string stream, IEnumerable<object> events, long expectedVersion = null);\n    // Load events from a stream\n    IAsyncEnumerable<IEvent> Load(string stream, long from = 0);\n    // Subscribe to events\n    IDisposable Subscribe(string stream, Func<IEvent, Task> handler);\n    // Snapshot support\n    Task SaveSnapshot(string stream, object snapshot);\n    Task<T",
        "startIndex": 2666,
        "preview": "TSummary Glimpse<TSummary>(object id); // Partial view bool Exists(object id); // Existence check IAsyncEnumerable<T> Scan<T>(); // Full scan } ` Lens..."
      },
      {
        "id": "roadmap/architecture-chunk-3",
        "text": "interface ILedger { // Append events to a stream Task<long> Append(string stream, IEnumerable<object> events, long expectedVersion = null); // Load events from a stream IAsyncEnumerable<IEvent> Load(string stream, long from = 0); // Subscribe to events IDisposable Subscribe(string stream, Func<IEvent, Task> handler); // Snapshot support Task SaveSnapshot(string stream, object snapshot); Task<T > LoadSnapshot<T>(string stream);\n}\n`\nDrivers\nStorage abstraction layer\n`csharp\npublic interface IDriver {\n    // Execute queries\n    Task<T> Query<T>(IQuery<T> query);\n    // Execute commands\n    Task Execute(ICommand command);\n    // Transaction support\n    Task<T> Transaction<T>(Func<ITransaction, Task<T>> action);\n    // Migration support\n    Task Migrate(IMigration migration);\n}\n`\nDrivers available:\nInMemoryDriver: Development and testing\nPostgreSQLDriver: JSONB support\nSqlServerDriver: JSON columns\nSQLiteDriver: Edge scenarios\nCustom: Implement IDriver\nTransports\nMessage broker abstraction\n`csharp\npublic interface ITransport {\n    // Send messages\n    Task Send<T>(string destination, T message);\n    // Subscribe to messages\n    IDisposable Subscribe<T>(string source, Func<T, Task> handler);\n    // Request-Reply pattern\n    Task<TResponse> Request<TRequest, TResponse>(string destination, TRequest request);\n}\n`\nTransports available:\nInMemoryTransport: Development and testing\nKafkaTransport: High-throughput streaming\nRabbitMQTransport: Reliable messaging\nAzureServiceBusTransport: Cloud-native\nCustom: Implement ITransport\nMessage Flow Patterns\nCommand Flow (Event-Driven Mode)\n`\nCommand ‚Üí Dispatcher ‚Üí Receptor ‚Üí Event ‚Üí Perspectives ‚Üí Storage\n                          ‚Üì\n                        Lens ‚Üê Query\n`\nCommand Flow (Event-Sourced Mode)\n`\nCommand ‚Üí Dispatcher ‚Üí Receptor ‚Üí Event ‚Üí Ledger\n                                     ‚Üì\n                              Perspectives ‚Üí Read Models\n                                     ‚Üì\n                                   Lens ‚Üê Query\n`\nQuery Flow\n`\nQuery ‚Üí Lens ‚Üí Storage ‚Üí Result\n`\nSaga Flow\n`\nEvent ‚Üí Saga Coordinator ‚Üí Command ‚Üí Receptor\n          ‚Üì                   ‚Üì\n      Saga State          New Event ‚Üí Continue/Complete\n`\nProgressive Enhancement Path\nLevel 1: In-Process Event-Driven\n`csharp\nservices AddWhizbang() UseInMemory();  // Everything in-memory\n`\nCommands ‚Üí Receptors ‚Üí Events ‚Üí Perspectives\nAll synchronous, in-process\nPerfect for development\nLevel 2: Event-Sourced\n`csharp\nservices AddWhizbang() UseEventSourcing() UseInMemory();  // In-memory event store\n`\nAdd event store (Ledger)\nSupport stateful receptors\nEnable projections\nLevel 3: Persistent\n`csharp\nservices AddWhizbang() UseEventSourcing()",
        "startIndex": 3488,
        "preview": "interface ILedger { // Append events to a stream Task<long> Append(string stream, IEnumerable<object> events, long expectedVersion = null); // Load ev..."
      },
      {
        "id": "roadmap/architecture-chunk-4",
        "text": "`csharp services AddWhizbang() UseInMemory(); // Everything in-memory ` Commands ‚Üí Receptors ‚Üí Events ‚Üí Perspectives All synchronous, in-process Perfect for development Level 2: Event-Sourced `csharp services AddWhizbang() UseEventSourcing() UseInMemory(); // In-memory event store ` Add event store (Ledger) Support stateful receptors Enable projections Level 3: Persistent `csharp services AddWhizbang() UseEventSourcing() UsePostgreSQL(\"connection-string\");\n`\nReal database persistence\nProduction-ready storage\nSchema migrations\nLevel 4: Distributed\n`csharp\nservices AddWhizbang() UseEventSourcing() UsePostgreSQL(\"connection-string\") UseKafka(\"bootstrap-servers\");\n`\nDistributed messaging\nMicroservices ready\nSaga orchestration\nComponent Relationships\nCompile-Time Relationships\nSource Generators discover and wire components\nAnalyzers validate relationships\nGenerated Code creates efficient dispatch tables\nRuntime Relationships\nDispatcher coordinates all message flow\nPolicy Engine wraps component execution\nTraceability observes all operations\nLedger persists all events\nTesting Relationships\nIn-Memory Implementations serve as test doubles\nTest Harness provides scenario execution\nVerification uses recorded interactions\nKey Design Decisions\nWhy Receptors Instead of Handlers Receptors emphasize decision-making over handling\nThey're the same interface for stateless and stateful\nThey make the event-driven nature explicit\nThey separate concerns better than traditional handlers\nWhy Perspectives Instead of Projections Perspectives are more general than projections\nThey handle all write operations, not just read models\nThey can update multiple stores\nThey emphasize the \"view\" nature of the data\nWhy Lenses for Queries Lenses are composable\nThey're purely functional\nThey separate query concerns from storage\nThey enable query optimization\nWhy Policies Instead of Aspects",
        "startIndex": 5798,
        "preview": "`csharp services AddWhizbang() UseInMemory(); // Everything in-memory ` Commands ‚Üí Receptors ‚Üí Events ‚Üí Perspectives All synchronous, in-process Perfe..."
      },
      {
        "id": "roadmap/architecture-chunk-5",
        "text": "general than projections They handle all write operations, not just read models They can update multiple stores They emphasize the \"view\" nature of the data Why Lenses for Queries Lenses are composable They're purely functional They separate query concerns from storage They enable query optimization Why Policies Instead of Aspects Policies are more explicit\nThey're composable and configurable\nThey're testable in isolation\nThey avoid AOP magic\nExtension Points\nCustom Components\nImplement IReceptor<T> for custom command handling\nImplement IPerspectiveOf<T> for custom event handling\nImplement ILens for custom queries\nImplement IPolicyOf<T> for custom policies\nCustom Drivers\nImplement IDriver for new databases\nImplement ITransport for new message brokers\nImplement ILedger for custom event stores\nSource Generator Extensions\nAdd custom attributes for discovery\nGenerate specialized dispatch code\nCreate domain-specific optimizations\nPerformance Architecture\nCompile-Time Optimizations\nGenerated dispatch tables (no reflection)\nInlined serialization code\nPre-compiled expressions\nAOT-friendly code\nRuntime Optimizations\nObject pooling for messages\nZero-allocation patterns\nEfficient async state machines\nMinimal boxing/unboxing\nStorage Optimizations\nBatch operations\nPrepared statements\nConnection pooling\nQuery plan caching\nThis architecture provides a solid foundation that scales from simple in-process messaging to complex distributed event-sourced systems, all while maintaining the same programming model",
        "startIndex": 7274,
        "preview": "general than projections They handle all write operations, not just read models They can update multiple stores They emphasize the \"view\" nature of th..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/philosophy",
    "title": "Implementation Philosophy",
    "category": "Roadmap",
    "url": "/docs/roadmap/philosophy",
    "chunks": [
      {
        "id": "roadmap/philosophy-chunk-0",
        "text": "Implementation Philosophy\nCore Principles\nZero Reflection - Compile-Time Everything\nWe never use reflection Ever All handler discovery happens at compile time via source generators\nAll routing tables are generated during compilation\nAll serialization code is generated, not reflected\nType information is captured at compile time, not runtime\n`csharp\n// ‚ùå NEVER THIS\nvar handlers = Assembly GetExecutingAssembly() GetTypes() Where(t => t IsAssignableTo(typeof(IHandler)));\n// ‚úÖ ALWAYS THIS\n[WhizbangHandler]  // Source generator finds this at compile time\npublic class OrderHandler : IReceptor<CreateOrder> { }\n`\nIDE-First Development\nThe IDE experience is not an afterthought - it's foundational From day one, we provide:\nCodeLens-style references: See handler counts, event publishers, consumers\nTraceability overlays: Visualize message flow inline\nTime-travel debugging: Step through message history\nSmart navigation: Jump between commands, handlers, and events\nCompile-time validation: Catch errors before runtime\n`csharp\n// The IDE shows: \"3 handlers | 2 perspectives | Last: 50ms ago\"\npublic record OrderCreated(Guid OrderId);  \n// The IDE shows: \"Handles: CreateOrder | Publishes: OrderCreated\"\npublic class OrderReceptor : IReceptor<CreateOrder> { }\n`\nTest-Driven from the Start\nTesting is not bolted on - it's built in TUnit for modern, fast, parallel testing\nBogus for realistic scenario generation\nBehavior Specs for BDD-style testing\nIn-Memory Doubles that become production test doubles\nProperty-Based Testing for edge case discovery\n`csharp\n[Test]\n[MethodDataSource(nameof(OrderScenarios))]  // Bogus generates scenarios\npublic async Task CreateOrder_ShouldEmitExpectedEvents(OrderScenario scenario) {\n    // Every component is testable from day one\n    var result = await dispatcher Send(scenario Command);\n    await Verify That(result) Matches(scenario Expected);\n}\n`\nProgressive Enhancement\nStart simple, enhance iteratively, maintain compatibility `csharp\n// v0 1 0 - Simple in-memory\nservices AddWhizbang() UseInMemory();\n// v0 3 0 - Add event sourcing (same code still works )\nservices AddWhizbang() UseEventSourcing() UseInMemory();\n// v0 4 0 - Add persistence (same code still works )\nservices AddWhizbang() UseEventSourcing() UsePostgreSQL();\n// v0",
        "startIndex": 0,
        "preview": "Implementation Philosophy\nCore Principles\nZero Reflection - Compile-Time Everything\nWe never use reflection Ever All handler discovery happens at comp..."
      },
      {
        "id": "roadmap/philosophy-chunk-1",
        "text": "enhance iteratively, maintain compatibility `csharp // v0 1 0 - Simple in-memory services AddWhizbang() UseInMemory(); // v0 3 0 - Add event sourcing (same code still works ) services AddWhizbang() UseEventSourcing() UseInMemory(); // v0 4 0 - Add persistence (same code still works ) services AddWhizbang() UseEventSourcing() UsePostgreSQL(); // v0 5 0 - Add distribution (same code still works )\nservices AddWhizbang() UseEventSourcing() UsePostgreSQL() UseKafka();\n`\nBreadth-First Implementation\nAll components exist from day one, even if simple We don't build deep, then wide We build wide, then deep:\nv0 1 0 has EVERY component (dispatcher, receptors, perspectives, lenses, policies, ledger, drivers, transports)\nEach component starts thin but functional\nWe enhance all components together, maintaining consistency\nNo component is \"coming later\" - everything is always available\nIn-Memory First\nEverything starts in-memory, which becomes our testing foundation In-memory implementations are not throwaway code\nThey become the test doubles for unit testing\nThey provide fast feedback during development\nThey enable offline development\nThey're always available as a fallback\n`csharp\n// In-memory implementations are first-class citizens\npublic class InMemoryLedger : ILedger {\n    // This becomes our test double AND our development database\n}\n`\nPerformance by Design\nPerformance is not an optimization - it's a requirement Zero allocation patterns from the start\nSource generation for hot paths\nCompile-time optimization via generators\nAOT compatibility from day one\nBenchmark everything with BenchmarkDotNet\n`csharp\n// Generated code is faster than runtime reflection\n[Generated]\npublic static class OrderHandlerDispatcher {\n    // Source-generated dispatch table - zero reflection, zero allocation\n    public static readonly Dictionary<Type, Delegate> Handlers = new() {\n        [typeof(CreateOrder)] = OrderReceptor Handle_CreateOrder\n    };\n}\n`\nDeveloper Experience is User Experience\nFor a library, developers ARE the users",
        "startIndex": 1093,
        "preview": "enhance iteratively, maintain compatibility `csharp // v0 1 0 - Simple in-memory services AddWhizbang() UseInMemory(); // v0 3 0 - Add event sourcing ..."
      },
      {
        "id": "roadmap/philosophy-chunk-2",
        "text": "Generated code is faster than runtime reflection [Generated] public static class OrderHandlerDispatcher { // Source-generated dispatch table - zero reflection, zero allocation public static readonly Dictionary<Type, Delegate> Handlers = new() { [typeof(CreateOrder)] = OrderReceptor Handle_CreateOrder }; } ` Developer Experience is User Experience For a library, developers ARE the users Clear, actionable error messages with suggested fixes\nComprehensive IntelliSense documentation\nAnalyzers that guide not just validate\nCode fixes for common patterns\nVisual debugging tools built-in\n`csharp\n// Analyzer: \"OrderCreated event is not handled by any perspective\"\n// Code Fix: \"Generate OrderPerspective class\"\n// Quick Action: \"Add handler for OrderCreated\"\n`\nPolicies as First-Class Citizens\nCross-cutting concerns are not aspects - they're policies Policies are:\nComposable\nTestable\nMeasurable\nConfigurable\nDiscoverable\n`csharp\n[Retry(3)]\n[Timeout(5000)]\n[Cache(300)]\n[Authorize(\"OrderAdmin\")]\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    // Policies are composed and applied via source generation\n}\n`\nTraceability Built-In\nEvery message is traceable, every decision is observable From v0 1 0:\nCorrelation IDs flow automatically\nCausation chains are tracked\nTiming information is captured\nDecision points are recorded\nOpenTelemetry hooks are everywhere\n`csharp\n// Every message carries its history\npublic interface IMessageContext {\n    Guid CorrelationId { get; }\n    Guid CausationId { get; }\n    DateTimeOffset Timestamp { get; }\n    Dictionary<string, object> Metadata { get; }\n    ISpan Span { get; }  // OpenTelemetry span\n}\n`\nAnti-Patterns We Avoid\n‚ùå No Reflection\nNo assembly scanning\nNo runtime type discovery\nNo dynamic invocation\nNo expression tree compilation at runtime\n‚ùå No Magic\nExplicit over implicit\nConvention with configuration\nDiscoverable behavior\nNo hidden side effects\n‚ùå No Framework Lock-In\nAbstractions over implementations\nSwappable components\nStandard interfaces\nMinimal dependencies\n‚ùå No Untestable Code\nEverything has an interface\nEverything has a test double\nEverything is observable\nEverything is measurable\nImplementation Strategy\nPhase 1: Foundation (v0 1",
        "startIndex": 3974,
        "preview": "Generated code is faster than runtime reflection [Generated] public static class OrderHandlerDispatcher { // Source-generated dispatch table - zero re..."
      },
      {
        "id": "roadmap/philosophy-chunk-3",
        "text": "over implicit Convention with configuration Discoverable behavior No hidden side effects ‚ùå No Framework Lock-In Abstractions over implementations Swappable components Standard interfaces Minimal dependencies ‚ùå No Untestable Code Everything has an interface Everything has a test double Everything is observable Everything is measurable Implementation Strategy Phase 1: Foundation (v0 1 0)\nBuild wide - every component exists, even if simple Phase 2: Enhancement (v0 2 0-v0 3 0)\nBuild deep - enhance each component iteratively Phase 3: Production (v0 4 0-v0 5 0)\nBuild real - replace in-memory with production implementations Phase 4: Scale (v0 6 0+)\nBuild up - add enterprise features and optimizations Measuring Success\nWe measure success by:\nZero reflection in production code\n100% test coverage of public APIs\nSub-millisecond in-memory operations\nSingle-digit millisecond database operations\nNo breaking changes within major versions\nCompile-time safety for all operations\nDeveloper satisfaction via feedback\nThe Whizbang Promise\nWhen you use Whizbang, you get:\nPerformance without complexity\nSafety without ceremony\nPower without lock-in\nFlexibility without magic\nObservability without overhead\nThis is not just a messaging library This is a new way of building NET applications",
        "startIndex": 5791,
        "preview": "over implicit Convention with configuration Discoverable behavior No hidden side effects ‚ùå No Framework Lock-In Abstractions over implementations Swap..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "roadmap/success-metrics",
    "title": "Success Metrics",
    "category": "Roadmap",
    "url": "/docs/roadmap/success-metrics",
    "chunks": [
      {
        "id": "roadmap/success-metrics-chunk-0",
        "text": "Success Metrics\nOverview\nSuccess is measured across multiple dimensions: technical performance, code quality, developer experience, and adoption Each version has specific success criteria that must be met before moving forward Version-Specific Success Criteria\nv0 1 0 - Foundation Success\nCore Functionality\n‚úÖ All 8 core components have working implementations\n‚úÖ Source generators discover and wire all handlers\n‚úÖ Zero reflection in production code\n‚úÖ All components work with in-memory implementations\n‚úÖ Basic policy engine with 4+ policies working\nDeveloper Experience\n‚úÖ IDE shows handler references via CodeLens\n‚úÖ Analyzers catch 5+ common mistakes\n‚úÖ Code fixes available for all analyzer warnings\n‚úÖ IntelliSense works for all public APIs\n‚úÖ Traceability shows message flow\nTesting\n‚úÖ TUnit integration complete\n‚úÖ Bogus generates 10+ scenario types\n‚úÖ Behavior specs framework working\n‚úÖ 100% test coverage of public APIs\n‚úÖ All in-memory implementations usable as test doubles\nPerformance\n‚úÖ < 1ms for in-memory message dispatch\n‚úÖ < 100Œºs for handler invocation\n‚úÖ Zero allocations in hot path\n‚úÖ Source generator < 1s for 1000 handlers\nv0 2 0 - Event-Driven Enhancement Success\nFunctionality\n‚úÖ Validation attributes work on all commands\n‚úÖ Multiple perspectives can handle same event\n‚úÖ Lens methods support pagination\n‚úÖ Policy composition works correctly\n‚úÖ Batch operations supported\nPerformance\n‚úÖ < 1ms for event publishing to 10 perspectives\n‚úÖ Parallel perspective execution where safe\n‚úÖ Query optimization via generated SQL\nv0 3 0 - Event Sourcing Success\nFunctionality\n‚úÖ Stateful receptors maintain state correctly\n‚úÖ Event store supports optimistic concurrency\n‚úÖ Projections can rebuild from events\n‚úÖ Snapshots improve load time by 10x\n‚úÖ Version conflicts detected and handled\nPerformance\n‚úÖ < 10ms to load aggregate with 100 events\n‚úÖ < 1ms with snapshot\n‚úÖ < 100ms to rebuild projection with 1000 events\nv0 4",
        "startIndex": 0,
        "preview": "Success Metrics\nOverview\nSuccess is measured across multiple dimensions: technical performance, code quality, developer experience, and adoption Each ..."
      },
      {
        "id": "roadmap/success-metrics-chunk-1",
        "text": "Event store supports optimistic concurrency ‚úÖ Projections can rebuild from events ‚úÖ Snapshots improve load time by 10x ‚úÖ Version conflicts detected and handled Performance ‚úÖ < 10ms to load aggregate with 100 events ‚úÖ < 1ms with snapshot ‚úÖ < 100ms to rebuild projection with 1000 events v0 4 0 - Real Persistence Success\nFunctionality\n‚úÖ All 3 database drivers pass same test suite\n‚úÖ Migrations work across all databases\n‚úÖ Multi-tenancy isolation verified\n‚úÖ Indexes improve query performance by 10x\nPerformance\n‚úÖ < 10ms for single event append\n‚úÖ < 50ms for batch of 100 events\n‚úÖ < 5ms for indexed queries\n‚úÖ Connection pooling reduces latency by 50%\nv0 5",
        "startIndex": 1909,
        "preview": "Event store supports optimistic concurrency ‚úÖ Projections can rebuild from events ‚úÖ Snapshots improve load time by 10x ‚úÖ Version conflicts detected an..."
      },
      {
        "id": "roadmap/success-metrics-chunk-2",
        "text": "test suite ‚úÖ Migrations work across all databases ‚úÖ Multi-tenancy isolation verified ‚úÖ Indexes improve query performance by 10x Performance ‚úÖ < 10ms for single event append ‚úÖ < 50ms for batch of 100 events ‚úÖ < 5ms for indexed queries ‚úÖ Connection pooling reduces latency by 50% v0 5 0 - Distributed Systems Success\nFunctionality\n‚úÖ All transports pass same test suite\n‚úÖ Outbox pattern prevents message loss\n‚úÖ Saga orchestration handles failures\n‚úÖ Distributed tracing works end-to-end\nPerformance\n‚úÖ < 100ms p99 for distributed operations\n‚úÖ Kafka: > 10,000 msg/sec throughput\n‚úÖ RabbitMQ: < 10ms latency\n‚úÖ Saga compensation < 1s\nPerformance Benchmarks\nBaseline Performance Targets\n`csharp\n[Benchmark]\npublic class DispatcherBenchmarks {\n    // Target: < 100ns\n    [Benchmark]\n    public Task DirectHandlerInvocation() { }\n    // Target: < 1Œºs\n    [Benchmark]\n    public Task DispatchedHandlerInvocation() { }\n    // Target: < 10Œºs\n    [Benchmark]\n    public Task DispatchWithPolicies() { }\n}\n`\nMemory Allocation Targets\n| Operation | Target Allocation |\n|-----------|------------------|\n| Message Dispatch | 0 bytes |\n| Handler Invocation | 0 bytes |\n| Event Publishing | 0 bytes |\n| Simple Query | < 1KB |\n| Complex Query | < 10KB |\n| Aggregate Load | < Size of Events |\nThroughput Targets\n| Component | Target Throughput |\n|-----------|------------------|\n| In-Memory Dispatcher | > 1M msg/sec |\n| In-Memory Event Store | > 100K events/sec |\n| PostgreSQL Driver | > 10K events/sec |\n| Kafka Transport | > 100K msg/sec |\n| RabbitMQ Transport | > 10K msg/sec |\nLatency Targets (p99)\n| Operation | In-Memory | Database | Distributed |\n|-----------|-----------|----------|-------------|\n| Command Dispatch | < 1ms | < 10ms | < 100ms |\n| Event Publishing | < 1ms | < 10ms | < 100ms |\n| Query Execution | < 1ms | < 5ms | < 50ms |\n| Aggregate Load | < 1ms | < 10ms | N/A |\n| Projection Update | < 1ms | < 10ms | < 100ms |\nCode Quality Metrics\nTest Coverage Requirements\n| Component | Unit Test | Integration Test | Coverage |\n|-----------|-----------|------------------|----------|\n| Core Interfaces | Required | Required | 100% |\n| Source Generators | Required | Required | 100% |\n| Public APIs | Required | Required | 100% |\n| Internal Code | Required | Optional | > 90% |\n| Generated Code | Optional | Required | > 80% |\nDocumentation Requirements\n‚úÖ Every public type has XML documentation\n‚úÖ Every public method has examples\n‚úÖ Every configuration option documented\n‚úÖ Architecture decisions recorded\n‚úÖ Migration guides for version upgrades\nCode Analysis Metrics\n| Metric | Target |\n|--------|--------|\n| Cyclomatic Complexity | < 10 |\n| Maintainability Index | > 80 |\n| Code Coverage | > 95% |\n| Technical Debt Ratio | < 5% |\n| Duplicated Code | < 3% |\nDeveloper Experience Metrics\nIDE Integration\n‚úÖ IntelliSense response < 100ms\n‚úÖ Code fixes available < 500ms\n‚úÖ Navigation works in < 100ms\n‚úÖ Refactoring preserves correctness\n‚úÖ Debugging symbols always available\nError Messages\nQuality criteria for error messages:\nActionable: Tell the developer what to do\nContextual: Include relevant information\nLinkable: Link to documentation\nFixable: Provide code fixes where possible\nExample:\n`\nError WB0001: Handler signature mismatch\n  The handler 'OrderHandler",
        "startIndex": 2270,
        "preview": "test suite ‚úÖ Migrations work across all databases ‚úÖ Multi-tenancy isolation verified ‚úÖ Indexes improve query performance by 10x Performance ‚úÖ < 10ms f..."
      },
      {
        "id": "roadmap/success-metrics-chunk-3",
        "text": "in < 100ms ‚úÖ Refactoring preserves correctness ‚úÖ Debugging symbols always available Error Messages Quality criteria for error messages: Actionable: Tell the developer what to do Contextual: Include relevant information Linkable: Link to documentation Fixable: Provide code fixes where possible Example: ` Error WB0001: Handler signature mismatch The handler 'OrderHandler Handle' has an invalid signature Expected: Task<OrderCreated> Handle(CreateOrder command, IOrderLens lens)\n  Actual: OrderCreated Handle(CreateOrder command)\n  Fix: Add async Task<> return type and IOrderLens parameter\n  Docs: https://whizbang dev/errors/WB0001\n  Quick Fix Available: Press Ctrl+ to apply\n`\nBuild Time Metrics\n| Operation | Target Time |\n|-----------|------------|\n| Clean Build | < 10s |\n| Incremental Build | < 2s |\n| Source Generator | < 1s per 1000 types |\n| Analyzer Execution | < 500ms |\n| Test Execution | < 5s for 1000 tests |\nAdoption Metrics\nCommunity Engagement\nTarget metrics for community health:\nGitHub Stars: > 1,000 in year 1\nContributors: > 50 unique contributors\nIssues Response: < 24 hours\nPR Review: < 48 hours\nDocumentation Traffic: > 10,000 monthly views\nProduction Readiness\nChecklist for production readiness:\n‚úÖ Used in 10+ production applications\n‚úÖ Processing > 1M messages/day in production\n‚úÖ 99 99% uptime achieved\n‚úÖ Security audit passed\n‚úÖ Performance benchmarks published\nPackage Metrics\n| Package | Target Downloads (Year 1) |\n|---------|---------------------------|\n| Whizbang Core | > 100,000 |\n| Whizbang Generators | > 100,000 |\n| Whizbang PostgreSQL | > 50,000 |\n| Whizbang Kafka | > 25,000 |\n| Whizbang",
        "startIndex": 5234,
        "preview": "in < 100ms ‚úÖ Refactoring preserves correctness ‚úÖ Debugging symbols always available Error Messages Quality criteria for error messages: Actionable: Te..."
      },
      {
        "id": "roadmap/success-metrics-chunk-4",
        "text": "achieved ‚úÖ Security audit passed ‚úÖ Performance benchmarks published Package Metrics | Package | Target Downloads (Year 1) | |---------|---------------------------| | Whizbang Core | > 100,000 | | Whizbang Generators | > 100,000 | | Whizbang PostgreSQL | > 50,000 | | Whizbang Kafka | > 25,000 | | Whizbang Testing | > 75,000 |\nContinuous Monitoring\nAutomated Metrics Collection\n`yaml\nCI/CD Pipeline Metrics\non:\n  push:\n    branches: [main]\njobs:\n  metrics:\n    steps:\nname: Performance Benchmarks\n        run: dotnet run -c Release --project benchmarks\nname: Code Coverage\n        run: dotnet test --collect:\"XPlat Code Coverage\"\nname: Static Analysis\n        run: dotnet analyze\nname: API Compatibility\n        run: dotnet apicompat\nname: Package Size\n        run: dotnet pack --measure-size\n`\nDashboard Metrics\nReal-time dashboard tracking:\nBuild success rate\nTest pass rate\nPerformance regression detection\nCode coverage trends\nAPI breaking changes\nPackage download stats\nIssue/PR velocity\nDocumentation coverage\nSuccess Evaluation\nVersion Release Criteria\nA version is ready for release when:\nAll success criteria are met\nNo critical bugs remain\nPerformance targets achieved\nDocumentation complete\nMigration guide written\nBreaking changes documented\nAll tests passing\nSecurity scan clean\nGo/No-Go Decision Matrix\n| Criterion | Weight | v0 1 0 | v0 2 0 | v0 3 0 | v0 4 0 | v0 5 0 |\n|-----------|--------|--------|--------|--------|--------|--------|\n| Functionality | 30% | ‚úÖ | - | - | - | - |\n| Performance | 25% | ‚úÖ | - | - | - | - |\n| Quality | 20% | ‚úÖ | - | - | - | - |\n| Documentation | 15% | ‚úÖ | - | - | - | - |\n| Developer Experience | 10% | ‚úÖ | - | - | - | - |\nRetrospective Questions\nAfter each version:\nWhat succeeded beyond expectations What fell short of targets What surprised us",
        "startIndex": 6494,
        "preview": "achieved ‚úÖ Security audit passed ‚úÖ Performance benchmarks published Package Metrics | Package | Target Downloads (Year 1) | |---------|---------------..."
      },
      {
        "id": "roadmap/success-metrics-chunk-5",
        "text": "- | | Documentation | 15% | ‚úÖ | - | - | - | - | | Developer Experience | 10% | ‚úÖ | - | - | - | - | Retrospective Questions After each version: What succeeded beyond expectations What fell short of targets What surprised us What should we change What should we keep Long-Term Success Metrics\nYear 1 Goals\n5+ production deployments\n1,000+ GitHub stars\n100,000+ NuGet downloads\n0 security vulnerabilities\n< 5% technical debt\nYear 2 Goals\n50+ production deployments\n5,000+ GitHub stars\n1M+ NuGet downloads\nIndustry recognition\nCase studies published\nUltimate Success\nWhizbang becomes the default choice for event-driven and event-sourced systems in NET, known for:\nZero-reflection performance\nExceptional developer experience\nProgressive enhancement model\nProduction reliability\nComprehensive testing support",
        "startIndex": 7987,
        "preview": "- | | Documentation | 15% | ‚úÖ | - | - | - | - | | Developer Experience | 10% | ‚úÖ | - | - | - | - | Retrospective Questions After each version: What su..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/README",
    "title": "Version 0.1.0 - Foundation Release",
    "category": "Implementation",
    "url": "/docs/v0.1.0/README",
    "chunks": [
      {
        "id": "v0.1.0/README-chunk-0",
        "text": "Version 0 1 0 - Foundation Release\nOverview\nVersion 0 1 0 is the foundation release of Whizbang, establishing a complete skeleton of all major components with in-memory implementations This version prioritizes breadth over depth, ensuring every component exists and works together from day one Release Goals\nPrimary Goals\nComplete Component Set: All 8 core components implemented and working\nZero Reflection: Everything wired via source generators\nIDE Integration: Full developer experience from day one\nTesting Foundation: Comprehensive testing with TUnit and Bogus\nIn-Memory Everything: Fast development and testing cycle\nSuccess Criteria\n‚úÖ All components have basic working implementations\n‚úÖ Source generators discover and wire all handlers\n‚úÖ IDE tools provide navigation and traceability\n‚úÖ Testing framework with scenario generation\n‚úÖ 100% test coverage of public APIs\n‚úÖ < 1ms in-memory operation performance\nWhat's Included\nCore Components\nDispatcher - Message routing and coordination\nReceptors - Command receivers (stateless)\nPerspectives - Event handlers\nLenses - Query interfaces\nPolicy Engine - Cross-cutting concerns\nLedger - Event store interface\nDrivers - Storage abstraction\nTransports - Message broker abstraction\nDeveloper Experience\nSource Generators - Zero-reflection handler discovery\nAnalyzers - Compile-time validation\nIDE Tools - CodeLens-style references\nTraceability - Message flow visualization\nDebugging - Time-travel debugging foundation\nTesting Foundation\nTesting Strategy - Overall testing approach\nTUnit Integration - Modern test framework\nBogus Scenarios - Realistic data generation\nBehavior Specs - BDD-style testing\nTest Doubles - In-memory mocking\nQuick Start\nInstallation\n`bash\ndotnet add package Whizbang Core --version 0 1 0\n`\nBasic Usage\n`csharp\nusing Whizbang;\n// 1 Define a command\npublic record CreateOrder(Guid CustomerId, List<OrderItem> Items);\n// 2 Define a receptor\n[WhizbangHandler]\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async Task<OrderCreated> Receive(CreateOrder cmd) {\n        // Validation and business logic\n        if (cmd Items",
        "startIndex": 0,
        "preview": "Version 0 1 0 - Foundation Release\nOverview\nVersion 0 1 0 is the foundation release of Whizbang, establishing a complete skeleton of all major compone..."
      },
      {
        "id": "v0.1.0/README-chunk-1",
        "text": "Whizbang Core --version 0 1 0 ` Basic Usage `csharp using Whizbang; // 1 Define a command public record CreateOrder(Guid CustomerId, List<OrderItem> Items); // 2 Define a receptor [WhizbangHandler] public class OrderReceptor : IReceptor<CreateOrder, OrderCreated> { public async Task<OrderCreated> Receive(CreateOrder cmd) { // Validation and business logic if (cmd Items Count == 0) {\n            throw new InvalidOperationException(\"Order must have items\");\n        }\n        // Emit event\n        return new OrderCreated(Guid NewGuid(), cmd CustomerId, cmd Items);\n    }\n}\n// 3 Define perspectives\n[WhizbangHandler]\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly Dictionary<Guid, Order> _orders = new();\n    public Task Update(OrderCreated e) {\n        _orders[e OrderId] = new Order {\n            Id = e OrderId,\n            CustomerId = e CustomerId,\n            Items = e Items\n        };\n        return Task CompletedTask;\n    }\n}\n// 4 Define a lens\npublic interface IOrderLens : ILens {\n    Order Focus(Guid orderId);\n    IEnumerable<Order> ViewByCustomer(Guid customerId);\n}\n[WhizbangLens]\npublic class OrderLens : IOrderLens {\n    private readonly Dictionary<Guid, Order> _orders;\n    public Order Focus(Guid orderId) => _orders[orderId];\n    public IEnumerable<Order> ViewByCustomer(Guid customerId) =>\n        _orders Values Where(o => o CustomerId == customerId);\n}\n// 5 Configure and use\nvar builder = WebApplication CreateBuilder(args);\nbuilder Services AddWhizbang(options => {\n    options RegisterGeneratedHandlers();  // Source-generated registration\n    options UseInMemory();                // In-memory implementations\n    options EnableTraceability();         // IDE tools and debugging\n});\nvar app = builder Build();\n// 6 Use via dispatcher\napp MapPost(\"/orders\", async (CreateOrder cmd, IDispatcher dispatcher) => {\n    var result = await dispatcher Send(cmd);\n    return Results Ok(result);\n});\napp MapGet(\"/orders/{id}\", (Guid id, IDispatcher dispatcher) => {\n    var lens = dispatcher GetLens<IOrderLens>();\n    var order = lens Focus(id);\n    return Results",
        "startIndex": 2128,
        "preview": "Whizbang Core --version 0 1 0 ` Basic Usage `csharp using Whizbang; // 1 Define a command public record CreateOrder(Guid CustomerId, List<OrderItem> I..."
      },
      {
        "id": "v0.1.0/README-chunk-2",
        "text": "}); var app = builder Build(); // 6 Use via dispatcher app MapPost(\"/orders\", async (CreateOrder cmd, IDispatcher dispatcher) => { var result = await dispatcher Send(cmd); return Results Ok(result); }); app MapGet(\"/orders/{id}\", (Guid id, IDispatcher dispatcher) => { var lens = dispatcher GetLens<IOrderLens>(); var order = lens Focus(id); return Results Ok(order);\n});\n`\nIDE Features\nCodeLens References\n`csharp\n// IDE shows: \"2 handlers | 1 perspective | Last: 50ms ago\"\npublic record OrderCreated(Guid OrderId, Guid CustomerId);  \n// IDE shows: \"Handles: CreateOrder | Publishes: OrderCreated\"\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> { }\n`\nTraceability Overlay\nSee message flow inline in the editor\nVisualize command ‚Üí receptor ‚Üí event ‚Üí perspective chains\nClick to navigate between components\nView execution timings and counts\nAnalyzer Warnings\n`csharp\n// Warning WB0001: Command 'CancelOrder' has no handler\npublic record CancelOrder(Guid OrderId);  // Squiggly line here\n// Quick Fix: Generate handler for CancelOrder (Ctrl+ )\n`\nTesting Example\n`csharp\n[TestClass]\npublic class OrderTests : WhizbangTestBase {\n    [Test]\n    [MethodDataSource(nameof(OrderScenarios))]\n    public async Task CreateOrder_ShouldEmitOrderCreated(OrderScenario scenario) {\n        // Arrange\n        var dispatcher = CreateDispatcher();\n        // Act\n        var result = await dispatcher Send(scenario Command);\n        // Assert\n        await Verify Event<OrderCreated>() WithCustomerId(scenario CustomerId) WasPublished();\n    }\n    public static IEnumerable<OrderScenario> OrderScenarios() {\n        var faker = new OrderScenarioFaker();\n        yield return faker Generate();  // Happy path\n        yield return faker WithNoItems() Generate();  // Error case\n        yield return faker WithManyItems(100)",
        "startIndex": 3883,
        "preview": "}); var app = builder Build(); // 6 Use via dispatcher app MapPost(\"/orders\", async (CreateOrder cmd, IDispatcher dispatcher) => { var result = await ..."
      },
      {
        "id": "v0.1.0/README-chunk-3",
        "text": "dispatcher = CreateDispatcher(); // Act var result = await dispatcher Send(scenario Command); // Assert await Verify Event<OrderCreated>() WithCustomerId(scenario CustomerId) WasPublished(); } public static IEnumerable<OrderScenario> OrderScenarios() { var faker = new OrderScenarioFaker(); yield return faker Generate(); // Happy path yield return faker WithNoItems() Generate(); // Error case yield return faker WithManyItems(100) Generate();  // Stress case\n    }\n}\n`\nPerformance Characteristics\nIn-Memory Performance\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Message Dispatch | < 1Œºs | TBD |\n| Handler Invocation | < 100ns | TBD |\n| Event Publishing | < 1Œºs | TBD |\n| Lens Query | < 1ms | TBD |\n| Policy Application | < 10Œºs | TBD |\nMemory Allocation\nZero allocations in dispatch hot path\nPooled objects for messages\nMinimal GC pressure\nMigration Path\nTo v0 2 0\nVersion 0 2 0 enhances existing components without breaking changes:\nReceptors gain validation attributes\nPerspectives support batch updates\nLenses add pagination\nPolicies become composable\nSee v0 2 0 Migration Guide\nKnown Limitations\nAs a foundation release, v0 1 0 has intentional limitations:\nIn-Memory Only: No persistent storage yet\nStateless Receptors: No event sourcing support\nBasic Policies: Limited to Retry, Timeout, Cache, CircuitBreaker\nSingle Node: No distributed messaging\nNo Sagas: Long-running processes not supported\nThese limitations are addressed in subsequent versions while maintaining backward compatibility Examples\nComplete Examples\nBasic Receptor - Simple command handling\nPolicy Usage - Applying policies to handlers\nTest Scenario - Testing with Bogus\nComponent Documentation\nCore Components\nDispatcher\nReceptors\nPerspectives\nLenses\nPolicy Engine\nLedger\nDrivers\nTransports\nDeveloper Experience\nSource Generators\nAnalyzers\nIDE Tools\nTraceability\nTesting\nTesting Foundation\nTUnit Integration\nBogus Scenarios\nBehavior Specs\nFeedback\nThis is the foundation release - your feedback shapes the future:\nReport issues: https://github com/whizbang/whizbang/issues\nJoin discussions: https://github com/whizbang/whizbang/discussions\nContribute: See Contributing Guide",
        "startIndex": 5375,
        "preview": "dispatcher = CreateDispatcher(); // Act var result = await dispatcher Send(scenario Command); // Assert await Verify Event<OrderCreated>() WithCustome..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/_folder",
    "title": "Version 0.1.0 - Foundation",
    "category": "General",
    "url": "/docs/v0.1.0/_folder",
    "chunks": [
      {
        "id": "v0.1.0/_folder-chunk-0",
        "text": "",
        "startIndex": 0,
        "preview": ""
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/deployment-strategies",
    "title": "Deployment Strategies",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/deployment-strategies",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-0",
        "text": "Deployment Strategies\nComprehensive guide to deployment strategies for Whizbang applications - blue-green deployments, canary releases, rolling updates, feature flags, and safe rollback patterns ---\nDeployment Strategy Comparison\n| Strategy | Downtime | Risk | Rollback Speed | Cost |\n|----------|----------|------|----------------|------|\n| Recreate | ‚ùå Yes | ‚ö†Ô∏è High | Slow | Low |\n| Rolling Update | ‚úÖ No | ‚ö†Ô∏è Medium | Medium | Low |\n| Blue-Green | ‚úÖ No | ‚úÖ Low | Fast | High |\n| Canary | ‚úÖ No | ‚úÖ Very Low | Fast | Medium |\n---\nStrategy 1: Blue-Green Deployment\nZero downtime - Run two identical environments (blue = production, green = staging), then swap Architecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Blue-Green Deployment                             ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ\n‚îÇ  ‚îÇ Load Balancer‚îÇ                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ\n‚îÇ         ‚îÇ                                           ‚îÇ\n‚îÇ         ‚îÇ Traffic (100%)                            ‚îÇ\n‚îÇ         ‚ñº                                           ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ  ‚îÇ  Blue (v1 0) ‚îÇ          ‚îÇ Green (v1 1) ‚îÇ        ‚îÇ\n‚îÇ  ‚îÇ  - Live      ‚îÇ          ‚îÇ - Staging    ‚îÇ        ‚îÇ\n‚îÇ  ‚îÇ  - 3 pods    ‚îÇ          ‚îÇ - 3 pods     ‚îÇ        ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  After validation:                                 ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ\n‚îÇ  ‚îÇ Load Balancer‚îÇ                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ\n‚îÇ         ‚îÇ                                           ‚îÇ\n‚îÇ         ‚îÇ Traffic (100%)                            ‚îÇ\n‚îÇ         ‚ñº                                           ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ  ‚îÇ  Blue (v1 0) ‚îÇ          ‚îÇ Green (v1 1) ‚îÇ        ‚îÇ\n‚îÇ  ‚îÇ  - Idle      ‚îÇ          ‚îÇ - Live       ‚îÇ        ‚îÇ\n‚îÇ  ‚îÇ  - 3 pods    ‚îÇ          ‚îÇ - 3 pods     ‚îÇ        ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKubernetes Manifests\nblue-deployment yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service-blue\n  labels:\n    app: order-service\n    version: blue\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: order-service\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: order-service\n        version: blue\n    spec:\n      containers:\nname: order-service\n        image: myregistry azurecr io/order-service:1",
        "startIndex": 0,
        "preview": "Deployment Strategies\nComprehensive guide to deployment strategies for Whizbang applications - blue-green deployments, canary releases, rolling update..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-1",
        "text": "pods ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Kubernetes Manifests blue-deployment yaml: `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service-blue labels: app: order-service version: blue spec: replicas: 3 selector: matchLabels: app: order-service version: blue template: metadata: labels: app: order-service version: blue spec: containers: name: order-service image: myregistry azurecr io/order-service:1 0 0\n        ports:\ncontainerPort: 8080\n        env:\nname: ASPNETCORE_ENVIRONMENT\n          value: Production\n`\ngreen-deployment yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service-green\n  labels:\n    app: order-service\n    version: green\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: order-service\n      version: green\n  template:\n    metadata:\n      labels:\n        app: order-service\n        version: green\n    spec:\n      containers:\nname: order-service\n        image: myregistry azurecr io/order-service:1 1 0  New version\n        ports:\ncontainerPort: 8080\n        env:\nname: ASPNETCORE_ENVIRONMENT\n          value: Production\n`\nservice yaml (switch between blue/green):\n`yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: order-service\nspec:\n  selector:\n    app: order-service\n    version: blue  Switch to \"green\" after validation\n  ports:\nprotocol: TCP\n    port: 80\n    targetPort: 8080\n  type: LoadBalancer\n`\nGitHub Actions Workflow github/workflows/blue-green-deploy yml:\n`yaml\nname: Blue-Green Deployment\non:\n  push:\n    branches: [main]\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\nuses: actions/checkout@v4\nname: Build and push Docker image\n        run: |\n          docker build -t myregistry azurecr io/order-service:${{ github sha }} docker push myregistry azurecr io/order-service:${{ github sha }}\nname: Deploy to Green environment\n        run: |\n          kubectl set image deployment/order-service-green \\\n            order-service=myregistry azurecr io/order-service:${{ github sha }}\n          kubectl rollout status deployment/order-service-green\nname: Run smoke tests on Green\n        run: |\n          GREEN_URL=$(kubectl get svc order-service-green -o jsonpath='{ status loadBalancer ingress[0] ip}')\n          curl -f http://$GREEN_URL/health || exit 1\nname: Switch traffic to Green\n        run: |\n          kubectl patch svc order-service -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'\nname: Wait for traffic switch\n        run: sleep 30\nname: Verify production traffic\n        run: |\n          curl -f http://order-service myapp",
        "startIndex": 1087,
        "preview": "pods ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Kubernetes Manifests blue-deployment yaml: `ya..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-2",
        "text": "Green run: | GREEN_URL=$(kubectl get svc order-service-green -o jsonpath='{ status loadBalancer ingress[0] ip}') curl -f http://$GREEN_URL/health || exit 1 name: Switch traffic to Green run: | kubectl patch svc order-service -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}' name: Wait for traffic switch run: sleep 30 name: Verify production traffic run: | curl -f http://order-service myapp com/health || exit 1\nname: Scale down Blue (keep for rollback)\n        run: |\n          kubectl scale deployment/order-service-blue --replicas=1\n`\nRollback\n`bash\nInstant rollback: Switch service back to blue\nkubectl patch svc order-service -p '{\"spec\":{\"selector\":{\"version\":\"blue\"}}}'\nScale blue back up\nkubectl scale deployment/order-service-blue --replicas=3\n`\n---\nStrategy 2: Canary Deployment\nGradual rollout - Deploy new version to small percentage of users, then gradually increase Architecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Canary Deployment                                 ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ\n‚îÇ  ‚îÇ Load Balancer‚îÇ                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ\n‚îÇ         ‚îÇ                                           ‚îÇ\n‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ\n‚îÇ    ‚îÇ         ‚îÇ                                      ‚îÇ\n‚îÇ    ‚ñº 90%     ‚ñº 10% (canary)                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ\n‚îÇ  ‚îÇ v1 0‚îÇ  ‚îÇv1 1 ‚îÇ                                  ‚îÇ\n‚îÇ  ‚îÇ 9pods‚îÇ  ‚îÇ1pod ‚îÇ                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  After validation: 50/50                           ‚îÇ\n‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ\n‚îÇ    ‚îÇ         ‚îÇ                                      ‚îÇ\n‚îÇ    ‚ñº 50%     ‚ñº 50%                                 ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ\n‚îÇ  ‚îÇ v1 0‚îÇ  ‚îÇv1 1 ‚îÇ                                  ‚îÇ\n‚îÇ  ‚îÇ 5pods‚îÇ  ‚îÇ5pods‚îÇ                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKubernetes with Istio\nvirtualservice yaml:\n`yaml\napiVersion: networking istio io/v1beta1\nkind: VirtualService\nmetadata:\n  name: order-service\nspec:\n  hosts:\norder-service myapp com\n  http:\nmatch:\nheaders:\n        canary:\n          exact: \"true\"  Users with canary header get v1 1\n    route:\ndestination:\n        host: order-service\n        subset: v1-1\n      weight: 100\nroute:\ndestination:\n        host: order-service\n        subset: v1-0\n      weight: 90  90% of traffic to v1 0\ndestination:\n        host: order-service\n        subset: v1-1\n      weight: 10  10% of traffic to v1 1 (canary)\n`\ndestinationrule yaml:\n`yaml\napiVersion: networking istio",
        "startIndex": 4807,
        "preview": "Green run: | GREEN_URL=$(kubectl get svc order-service-green -o jsonpath='{ status loadBalancer ingress[0] ip}') curl -f http://$GREEN_URL/health || e..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-3",
        "text": "Users with canary header get v1 1 route: destination: host: order-service subset: v1-1 weight: 100 route: destination: host: order-service subset: v1-0 weight: 90 90% of traffic to v1 0 destination: host: order-service subset: v1-1 weight: 10 10% of traffic to v1 1 (canary) ` destinationrule yaml: `yaml apiVersion: networking istio io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: order-service\nspec:\n  host: order-service\n  subsets:\nname: v1-0\n    labels:\n      version: \"1 0 0\"\nname: v1-1\n    labels:\n      version: \"1 1 0\"\n`\nGradual Rollout Script\ncanary-rollout sh:\n`bash\n# /bin/bash\nWEIGHTS=(\n  \"90:10\"   Stage 1: 10% canary\n  \"75:25\"   Stage 2: 25% canary\n  \"50:50\"   Stage 3: 50% canary\n  \"25:75\"   Stage 4: 75% canary\n  \"0:100\"   Stage 5: 100% canary (full rollout)\n)\nfor WEIGHT in \"${WEIGHTS[@]}\"; do\n  IFS=':' read -r OLD_WEIGHT NEW_WEIGHT <<< \"$WEIGHT\"\n  echo \"Shifting traffic: $OLD_WEIGHT% v1 0, $NEW_WEIGHT% v1 1\"\n  kubectl apply -f - <<EOF\napiVersion: networking istio io/v1beta1\nkind: VirtualService\nmetadata:\n  name: order-service\nspec:\n  hosts:\norder-service myapp com\n  http:\nroute:\ndestination:\n        host: order-service\n        subset: v1-0\n      weight: $OLD_WEIGHT\ndestination:\n        host: order-service\n        subset: v1-1\n      weight: $NEW_WEIGHT\nEOF\n  echo \"Waiting 5 minutes for metrics \"\n  sleep 300\n  Check error rate\n  ERROR_RATE=$(curl -s \"http://prometheus:9090/api/v1/query query=error_rate\" | jq ' data result[0] value[1]')\n  if (( $(echo \"$ERROR_RATE > 5\" | bc -l) )); then\n    echo \"ERROR: Error rate exceeded 5% ($ERROR_RATE%) Rolling back \"\n    kubectl apply -f virtualservice-v1 0 yaml  Rollback to 100% v1 0\n    exit 1\n  fi\n  echo \"Metrics look good Proceeding to next stage \"\ndone\necho \"Canary deployment complete \"\n`\n---\nStrategy 3: Rolling Update\nDefault Kubernetes strategy - Replace pods one-by-one Deployment Manifest\ndeployment",
        "startIndex": 7293,
        "preview": "Users with canary header get v1 1 route: destination: host: order-service subset: v1-1 weight: 100 route: destination: host: order-service subset: v1-..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-4",
        "text": "5% ($ERROR_RATE%) Rolling back \" kubectl apply -f virtualservice-v1 0 yaml Rollback to 100% v1 0 exit 1 fi echo \"Metrics look good Proceeding to next stage \" done echo \"Canary deployment complete \" ` --- Strategy 3: Rolling Update Default Kubernetes strategy - Replace pods one-by-one Deployment Manifest deployment yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service\nspec:\n  replicas: 10\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1  Max 1 pod unavailable during update\n      maxSurge: 2        Max 2 extra pods during update\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\nname: order-service\n        image: myregistry azurecr io/order-service:1 1 0\n        ports:\ncontainerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /health/live\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n`\nRollout\n`bash\nApply new version\nkubectl apply -f deployment yaml\nWatch rollout progress\nkubectl rollout status deployment/order-service\nOutput:\nWaiting for deployment \"order-service\" rollout to finish: 2 out of 10 new replicas have been updated Waiting for deployment \"order-service\" rollout to finish: 5 out of 10 new replicas have been updated Waiting for deployment \"order-service\" rollout to finish: 8 out of 10 new replicas have been updated deployment \"order-service\" successfully rolled out\n`\nRollback\n`bash\nRollback to previous version\nkubectl rollout undo deployment/order-service\nRollback to specific revision\nkubectl rollout undo deployment/order-service --to-revision=3\nView rollout history\nkubectl rollout history deployment/order-service\n`\n---\nStrategy 4: Recreate (Downtime)\nSimple but with downtime - Terminate all old pods, then start new pods deployment yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service\nspec:\n  replicas: 3\n  strategy:\n    type: Recreate  ‚ùå Causes downtime\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\nname: order-service\n        image: myregistry azurecr io/order-service:1 1",
        "startIndex": 8849,
        "preview": "5% ($ERROR_RATE%) Rolling back \" kubectl apply -f virtualservice-v1 0 yaml Rollback to 100% v1 0 exit 1 fi echo \"Metrics look good Proceeding to next ..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-5",
        "text": "Simple but with downtime - Terminate all old pods, then start new pods deployment yaml: `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service spec: replicas: 3 strategy: type: Recreate ‚ùå Causes downtime selector: matchLabels: app: order-service template: metadata: labels: app: order-service spec: containers: name: order-service image: myregistry azurecr io/order-service:1 1 0\n`\nWhen to use:\n‚ö†Ô∏è Only for non-critical services\n‚ö†Ô∏è When database migrations require downtime\n‚ö†Ô∏è Development/staging environments\n---\nFeature Flags\nDecouple deployment from release - Deploy new code with features disabled, then enable via feature flags LaunchDarkly Integration\nProgram cs:\n`csharp\nbuilder Services AddSingleton<ILdClient>(sp => {\n  var config = Configuration Builder(builder Configuration[\"LaunchDarkly:SdkKey\"]) Build();\n  return new LdClient(config);\n});\n`\nUsage:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly ILdClient _featureFlags;\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    var user = Context User(command CustomerId);\n    // Check feature flag\n    var useNewPricingEngine = await _featureFlags BoolVariationAsync(\n      \"new-pricing-engine\",\n      user,\n      defaultValue: false\n    );\n    decimal totalAmount;\n    if (useNewPricingEngine) {\n      totalAmount = CalculateTotalWithNewEngine(command Items);\n    } else {\n      totalAmount = CalculateTotalWithOldEngine(command Items);\n    }\n    // Process order",
        "startIndex": 10960,
        "preview": "Simple but with downtime - Terminate all old pods, then start new pods deployment yaml: `yaml apiVersion: apps/v1 kind: Deployment metadata: name: ord..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-6",
        "text": "HandleAsync( CreateOrder command, CancellationToken ct = default ) { var user = Context User(command CustomerId); // Check feature flag var useNewPricingEngine = await _featureFlags BoolVariationAsync( \"new-pricing-engine\", user, defaultValue: false ); decimal totalAmount; if (useNewPricingEngine) { totalAmount = CalculateTotalWithNewEngine(command Items); } else { totalAmount = CalculateTotalWithOldEngine(command Items); } // Process order return new OrderCreated { OrderId = orderId, TotalAmount = totalAmount };\n  }\n}\n`\nGradual Rollout with Feature Flags\n`csharp\n// LaunchDarkly dashboard:\n// Day 1: Enable for 10% of users\n// Day 2: Enable for 25% of users\n// Day 3: Enable for 50% of users\n// Day 4: Enable for 100% of users\n// Rollback: Disable feature flag instantly (no deployment needed)\n`\n---\nDatabase Migrations\nBackward-Compatible Migrations\nStep 1: Add new column (optional):\n`sql\nALTER TABLE orders ADD COLUMN payment_method TEXT NULL;\n`\nStep 2: Deploy new code (reads from payment_method if present, falls back to old logic)\nStep 3: Backfill data:\n`sql\nUPDATE orders SET payment_method = 'credit_card' WHERE payment_method IS NULL;\n`\nStep 4: Make column required:\n`sql\nALTER TABLE orders ALTER COLUMN payment_method SET NOT NULL;\n`\nExpand-Contract Pattern\nExpand phase:\nAdd new column/table (optional)\nDeploy code that writes to both old and new schema\nBackfill data\nContract phase:\nDeploy code that reads from new schema only\nRemove old column/table\n---\nHealth Check Gates\nPrevent traffic to unhealthy pods:\ndeployment yaml:\n`yaml\nreadinessProbe:\n  httpGet:\n    path: /health/ready\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  failureThreshold: 3\nlivenessProbe:\n  httpGet:\n    path: /health/live\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  failureThreshold: 3\n`\nReadinessProbe: Pod receives traffic only when /health/ready returns 200\nLivenessProbe: Kubernetes restarts pod if /health/live fails\n---\nPre-Deployment Checks\npre-deploy sh:\n`bash\n# /bin/bash\necho \"Running pre-deployment checks \"\nCheck database connectivity\necho \"Checking database",
        "startIndex": 12139,
        "preview": "HandleAsync( CreateOrder command, CancellationToken ct = default ) { var user = Context User(command CustomerId); // Check feature flag var useNewPric..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-7",
        "text": "failureThreshold: 3 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 30 periodSeconds: 10 failureThreshold: 3 ` ReadinessProbe: Pod receives traffic only when /health/ready returns 200 LivenessProbe: Kubernetes restarts pod if /health/live fails --- Pre-Deployment Checks pre-deploy sh: `bash # /bin/bash echo \"Running pre-deployment checks \" Check database connectivity echo \"Checking database \"\npsql $DATABASE_URL -c \"SELECT 1\" > /dev/null || {\n  echo \"ERROR: Database unreachable\"\n  exit 1\n}\nRun database migrations\necho \"Running migrations \"\ndotnet ef database update || {\n  echo \"ERROR: Migrations failed\"\n  exit 1\n}\nRun integration tests\necho \"Running integration tests \"\ndotnet test --filter Category=Integration || {\n  echo \"ERROR: Integration tests failed\"\n  exit 1\n}\nCheck external dependencies\necho \"Checking external dependencies \"\ncurl -f https://api stripe com/v1/health || {\n  echo \"ERROR: Stripe API unreachable\"\n  exit 1\n}\necho \"Pre-deployment checks passed \"\n`\n---\nPost-Deployment Verification\npost-deploy sh:\n`bash\n# /bin/bash\necho \"Running post-deployment verification \"\nHealth check\necho \"Checking health endpoint \"\ncurl -f https://order-service myapp com/health || {\n  echo \"ERROR: Health check failed\"\n  exit 1\n}\nSmoke tests\necho \"Running smoke tests \"\nORDER_ID=$(curl -s -X POST https://order-service myapp com/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"customerId\":\"test-123\",\"items\":[{\"productId\":\"prod-456\",\"quantity\":1,\"unitPrice\":19 99}]}' \\\n  | jq -r ' orderId')\ncurl -f https://order-service myapp com/orders/$ORDER_ID || {\n  echo \"ERROR: Smoke test failed\"\n  exit 1\n}\nCheck metrics\necho \"Checking error rate \"\nERROR_RATE=$(curl -s \"http://prometheus:9090/api/v1/query query=error_rate\" | jq -r ' data result[0] value[1]')\nif (( $(echo \"$ERROR_RATE > 5\" | bc -l) )); then\n  echo \"ERROR: Error rate exceeded 5% ($ERROR_RATE%)\"\n  exit 1\nfi\necho \"Post-deployment verification passed",
        "startIndex": 13799,
        "preview": "failureThreshold: 3 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 30 periodSeconds: 10 failureThreshold: 3 ` ReadinessPro..."
      },
      {
        "id": "v0.1.0/advanced-topics/deployment-strategies-chunk-8",
        "text": "\"ERROR: Smoke test failed\" exit 1 } Check metrics echo \"Checking error rate \" ERROR_RATE=$(curl -s \"http://prometheus:9090/api/v1/query query=error_rate\" | jq -r ' data result[0] value[1]') if (( $(echo \"$ERROR_RATE > 5\" | bc -l) )); then echo \"ERROR: Error rate exceeded 5% ($ERROR_RATE%)\" exit 1 fi echo \"Post-deployment verification passed \"\n`\n---\nKey Takeaways\n‚úÖ Blue-Green - Zero downtime, instant rollback, high cost (2x resources)\n‚úÖ Canary - Gradual rollout, low risk, requires traffic splitting (Istio)\n‚úÖ Rolling Update - Default Kubernetes strategy, medium risk\n‚úÖ Feature Flags - Decouple deployment from release\n‚úÖ Backward-Compatible Migrations - Avoid downtime during schema changes\n‚úÖ Health Checks - Prevent traffic to unhealthy pods\n‚úÖ Pre/Post-Deployment Checks - Automated verification\n---\nDecision Matrix\n| Use Case | Recommended Strategy |\n|----------|---------------------|\n| Critical production services | Blue-Green or Canary |\n| Standard services | Rolling Update |\n| Feature releases | Feature Flags + Rolling Update |\n| Database migrations | Expand-Contract + Blue-Green |\n| Non-critical services | Rolling Update or Recreate |\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15343,
        "preview": "\"ERROR: Smoke test failed\" exit 1 } Check metrics echo \"Checking error rate \" ERROR_RATE=$(curl -s \"http://prometheus:9090/api/v1/query query=error_ra..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/monitoring",
    "title": "Monitoring & Observability",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/monitoring",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-0",
        "text": "Monitoring & Observability\nComprehensive monitoring and observability for Whizbang applications - Application Insights, Prometheus metrics, distributed tracing, health checks, and dashboards ---\nObservability Pillars\n| Pillar | Tool | Purpose |\n|--------|------|---------|\n| Logs | Application Insights | Structured logging and queries |\n| Metrics | Prometheus + Grafana | Time-series metrics and dashboards |\n| Traces | Application Insights | Distributed tracing across services |\n| Health | ASP NET Health Checks | Service health and dependencies |\n---\nApplication Insights\nSetup\nProgram cs:\n`csharp\nbuilder Services AddApplicationInsightsTelemetry(options => {\n  options ConnectionString = builder Configuration[\"ApplicationInsights:ConnectionString\"];\n  options EnableAdaptiveSampling = true;\n  options EnableDependencyTrackingTelemetryModule = true;\n  options EnablePerformanceCounterCollectionModule = true;\n});\nbuilder Services AddApplicationInsightsTelemetryProcessor<FilterHealthChecksTelemetryProcessor>();\n`\nappsettings json:\n`json\n{\n  \"ApplicationInsights\": {\n    \"ConnectionString\": \"InstrumentationKey= ;IngestionEndpoint=https:// \"\n  }\n}\n`\nStructured Logging\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly ILogger<CreateOrderReceptor> _logger;\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    using (_logger BeginScope(new Dictionary<string, object> {\n      [\"OrderId\"] = orderId,\n      [\"CustomerId\"] = command CustomerId\n    })) {\n      _logger LogInformation(\n        \"Creating order for customer {CustomerId} with {ItemCount} items\",\n        command CustomerId,\n        command Items Length\n      );\n      try {\n        // Process order _logger LogInformation(\n          \"Order {OrderId} created successfully with total amount {TotalAmount:C}\",\n          orderId,\n          totalAmount\n        );\n        return new OrderCreated { OrderId = orderId, TotalAmount = totalAmount };\n      } catch (Exception ex) {\n        _logger LogError(\n          ex,\n          \"Failed to create order for customer {CustomerId}\",\n          command CustomerId\n        );\n        throw;\n      }\n    }\n  }\n}\n`\nKusto Queries (Application Insights)\nQuery 1: Error rate by operation:\n`kusto\nrequests\n| where timestamp > ago(1h)\n| summarize\n    Total = count(),\n    Errors = countif(success == false),\n    ErrorRate = 100",
        "startIndex": 0,
        "preview": "Monitoring & Observability\nComprehensive monitoring and observability for Whizbang applications - Application Insights, Prometheus metrics, distribute..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-1",
        "text": "{ _logger LogError( ex, \"Failed to create order for customer {CustomerId}\", command CustomerId ); throw; } } } } ` Kusto Queries (Application Insights) Query 1: Error rate by operation: `kusto requests | where timestamp > ago(1h) | summarize Total = count(), Errors = countif(success == false), ErrorRate = 100 0 * countif(success == false) / count()\n  by name\n| order by ErrorRate desc\n`\nQuery 2: P95 latency by operation:\n`kusto\nrequests\n| where timestamp > ago(1h)\n| summarize\n    p50 = percentile(duration, 50),\n    p95 = percentile(duration, 95),\n    p99 = percentile(duration, 99)\n  by name\n| order by p95 desc\n`\nQuery 3: Failed operations with traces:\n`kusto\nrequests\n| where timestamp > ago(1h) and success == false\n| join kind=inner (\n    traces\n    | where timestamp > ago(1h)\n  ) on operation_Id\n| project\n    timestamp,\n    operation_Name,\n    resultCode,\n    message,\n    customDimensions\n| order by timestamp desc\n`\n---\nPrometheus Metrics\nSetup\nProgram cs:\n`csharp\nbuilder Services AddOpenTelemetry() WithMetrics(metrics => {\n    metrics AddMeter(\"Whizbang *\") AddAspNetCoreInstrumentation() AddHttpClientInstrumentation() AddPrometheusExporter();\n  });\napp MapPrometheusScrapingEndpoint();  // /metrics endpoint\n`\nCustom Metrics\nOrderMetrics cs:\n`csharp\nusing System Diagnostics Metrics;\npublic class OrderMetrics {\n  private static readonly Meter Meter = new(\"Whizbang OrderService\");\n  private static readonly Counter<long> OrdersCreated = Meter CreateCounter<long>(\n    \"orders_created_total\",\n    description: \"Total number of orders created\"\n  );\n  private static readonly Histogram<double> OrderAmount = Meter CreateHistogram<double>(\n    \"order_amount\",\n    unit: \"USD\",\n    description: \"Order amount distribution\"\n  );\n  private static readonly ObservableGauge<int> ActiveOrders = Meter CreateObservableGauge<int>(\n    \"active_orders\",\n    observeValue: () => GetActiveOrderCount(),\n    description: \"Current number of active orders\"\n  );\n  public static void RecordOrderCreated(decimal amount) {\n    OrdersCreated Add(1);\n    OrderAmount Record((double)amount);\n  }\n  private static int GetActiveOrderCount() {\n    // Query database for active orders\n    return 0;  // Placeholder\n  }\n}\n`\nUsage:\n`csharp\npublic async Task<OrderCreated> HandleAsync(\n  CreateOrder command,\n  CancellationToken ct = default\n) {\n  // Process order OrderMetrics",
        "startIndex": 2454,
        "preview": "{ _logger LogError( ex, \"Failed to create order for customer {CustomerId}\", command CustomerId ); throw; } } } } ` Kusto Queries (Application Insights..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-2",
        "text": "active orders\" ); public static void RecordOrderCreated(decimal amount) { OrdersCreated Add(1); OrderAmount Record((double)amount); } private static int GetActiveOrderCount() { // Query database for active orders return 0; // Placeholder } } ` Usage: `csharp public async Task<OrderCreated> HandleAsync( CreateOrder command, CancellationToken ct = default ) { // Process order OrderMetrics RecordOrderCreated(totalAmount);\n  return new OrderCreated { OrderId = orderId, TotalAmount = totalAmount };\n}\n`\nPrometheus Queries (PromQL)\nQuery 1: Request rate (requests/second):\n`promql\nrate(http_requests_total[5m])\n`\nQuery 2: Error rate percentage:\n`promql\n100 * (\n  rate(http_requests_total{status=~\"5 \"}[5m])\n  /\n  rate(http_requests_total[5m])\n)\n`\nQuery 3: P95 latency:\n`promql\nhistogram_quantile(0 95, rate(http_request_duration_seconds_bucket[5m]))\n`\nQuery 4: Orders created per minute:\n`promql\nrate(orders_created_total[1m]) * 60\n`\n---\nDistributed Tracing\nActivity (W3C Trace Context)\nCreateOrderReceptor cs:\n`csharp\npublic async Task<OrderCreated> HandleAsync(\n  CreateOrder command,\n  CancellationToken ct = default\n) {\n  using var activity = Activity Current Source StartActivity(\"CreateOrder\");\n  activity SetTag(\"order customer_id\", command CustomerId);\n  activity SetTag(\"order item_count\", command Items Length);\n  try {\n    // Process order activity SetTag(\"order total_amount\", totalAmount);\n    activity SetStatus(ActivityStatusCode Ok);\n    return new OrderCreated { OrderId = orderId, TotalAmount = totalAmount };\n  } catch (Exception ex) {\n    activity SetStatus(ActivityStatusCode Error, ex Message);\n    throw;\n  }\n}\n`\nPropagate Trace Context\nMessageEnvelope cs:\n`csharp\npublic record MessageEnvelope {\n  public required string MessageId { get; init; }\n  public required string MessageType { get; init; }\n  public required Dictionary<string, string> Headers { get; init; }\n  public static MessageEnvelope CreateFromActivity(string messageId, string messageType) {\n    var headers = new Dictionary<string, string>();\n    // Propagate W3C Trace Context\n    if (Activity Current = null) {\n      headers[\"traceparent\"] = Activity Current Id string Empty;\n      if ( string IsNullOrEmpty(Activity Current TraceStateString)) {\n        headers[\"tracestate\"] = Activity Current TraceStateString;\n      }\n    }\n    return new MessageEnvelope {\n      MessageId = messageId,\n      MessageType = messageType,\n      Headers = headers\n    };\n  }\n}\n`\nServiceBusPublisher",
        "startIndex": 4545,
        "preview": "active orders\" ); public static void RecordOrderCreated(decimal amount) { OrdersCreated Add(1); OrderAmount Record((double)amount); } private static i..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-3",
        "text": "// Propagate W3C Trace Context if (Activity Current = null) { headers[\"traceparent\"] = Activity Current Id string Empty; if ( string IsNullOrEmpty(Activity Current TraceStateString)) { headers[\"tracestate\"] = Activity Current TraceStateString; } } return new MessageEnvelope { MessageId = messageId, MessageType = messageType, Headers = headers }; } } ` ServiceBusPublisher cs:\n`csharp\npublic async Task PublishAsync(object @event, CancellationToken ct = default) {\n  var envelope = MessageEnvelope CreateFromActivity(\n    messageId: Guid NewGuid() ToString(),\n    messageType: @event GetType() Name\n  );\n  var message = new ServiceBusMessage(JsonSerializer SerializeToUtf8Bytes(@event)) {\n    MessageId = envelope MessageId,\n    Subject = envelope MessageType\n  };\n  // Propagate trace context in message properties\n  foreach (var header in envelope Headers) {\n    message ApplicationProperties[header Key] = header Value;\n  }\n  await _sender SendMessageAsync(message, ct);\n}\n`\nServiceBusProcessor cs:\n`csharp\nprivate async Task ProcessMessageAsync(ProcessMessageEventArgs args) {\n  // Extract trace context from message\n  var traceparent = args Message ApplicationProperties GetValueOrDefault(\"traceparent\") as string;\n  Activity activity = null;\n  if ( string IsNullOrEmpty(traceparent)) {\n    activity = Activity Current Source StartActivity(\n      \"ProcessMessage\",\n      ActivityKind Consumer,\n      traceparent\n    );\n  }\n  try {\n    // Process message await args CompleteMessageAsync(args Message);\n  } finally {\n    activity Dispose();\n  }\n}\n`\n---\nHealth Checks\nBasic Health Checks\nProgram cs:\n`csharp\nbuilder Services AddHealthChecks() AddNpgSql(\n    builder Configuration[\"Database:ConnectionString\"],\n    name: \"database\",\n    tags: [\"db\", \"postgres\"]\n  ) AddAzureServiceBusTopic(\n    builder Configuration[\"AzureServiceBus:ConnectionString\"],\n    \"orders\",\n    name: \"servicebus\",\n    tags: [\"messaging\", \"servicebus\"]\n  ) AddUrlGroup(\n    new Uri(\"https://api stripe com/v1/health\"),\n    name: \"stripe\",\n    tags: [\"external\", \"payment\"]\n  );\napp MapHealthChecks(\"/health\", new HealthCheckOptions {\n  ResponseWriter = UIResponseWriter WriteHealthCheckUIResponse\n});\napp MapHealthChecks(\"/health/ready\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"ready\")\n});\napp MapHealthChecks(\"/health/live\", new HealthCheckOptions {\n  Predicate = _ => true\n});\n`\nCustom Health Check\nOrderServiceHealthCheck cs:\n`csharp\npublic class OrderServiceHealthCheck : IHealthCheck {\n  private readonly IDbConnection _db;\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    try {\n      // Check database connectivity\n      var count = await _db",
        "startIndex": 6645,
        "preview": "// Propagate W3C Trace Context if (Activity Current = null) { headers[\"traceparent\"] = Activity Current Id string Empty; if ( string IsNullOrEmpty(Act..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-4",
        "text": "MapHealthChecks(\"/health/live\", new HealthCheckOptions { Predicate = _ => true }); ` Custom Health Check OrderServiceHealthCheck cs: `csharp public class OrderServiceHealthCheck : IHealthCheck { private readonly IDbConnection _db; public async Task<HealthCheckResult> CheckHealthAsync( HealthCheckContext context, CancellationToken ct = default ) { try { // Check database connectivity var count = await _db ExecuteScalarAsync<int>(\"SELECT COUNT(*) FROM orders LIMIT 1\");\n      // Check outbox backlog\n      var outboxBacklog = await _db ExecuteScalarAsync<int>(\n        \"SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL\"\n      );\n      if (outboxBacklog > 10000) {\n        return HealthCheckResult Degraded(\n          $\"Outbox backlog is {outboxBacklog} messages\",\n          data: new Dictionary<string, object> {\n            [\"outbox_backlog\"] = outboxBacklog\n          }\n        );\n      }\n      return HealthCheckResult Healthy(\"Order service is healthy\", data: new Dictionary<string, object> {\n        [\"outbox_backlog\"] = outboxBacklog\n      });\n    } catch (Exception ex) {\n      return HealthCheckResult Unhealthy(\"Order service is unhealthy\", ex);\n    }\n  }\n}\n`\nRegistration:\n`csharp\nbuilder Services AddHealthChecks() AddCheck<OrderServiceHealthCheck>(\"order-service\", tags: [\"ready\"]);\n`\n---\nDashboards\nGrafana Dashboard (JSON)\norders-dashboard json:\n`json\n{\n  \"dashboard\": {\n    \"title\": \"Order Service Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total{service=\\\"order-service\\\"}[5m])\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"100 * (rate(http_requests_total{service=\\\"order-service\\\",status=~\\\"5 \\\"}[5m]) / rate(http_requests_total{service=\\\"order-service\\\"}[5m]))\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"P95 Latency\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0 95, rate(http_request_duration_seconds_bucket{service=\\\"order-service\\\"}[5m]))\"\n          }\n        ],\n        \"type\": \"graph\"\n      },\n      {\n        \"title\": \"Orders Created\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(orders_created_total[1m]) * 60\"\n          }\n        ],\n        \"type\": \"graph\"\n      }\n    ]\n  }\n}\n`\nAzure Dashboard (KQL)\norders-dashboard kql:\n`kusto\n// Request rate\nrequests\n| where timestamp > ago(1h)\n| summarize RequestRate = count() / 60 0 by bin(timestamp, 1m)\n| render timechart\n// Error rate\nrequests\n| where timestamp > ago(1h)\n| summarize\n    Total = count(),\n    Errors = countif(success == false)\n  by bin(timestamp, 1m)\n| extend ErrorRate = 100",
        "startIndex": 9032,
        "preview": "MapHealthChecks(\"/health/live\", new HealthCheckOptions { Predicate = _ => true }); ` Custom Health Check OrderServiceHealthCheck cs: `csharp public cl..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-5",
        "text": "// Request rate requests | where timestamp > ago(1h) | summarize RequestRate = count() / 60 0 by bin(timestamp, 1m) | render timechart // Error rate requests | where timestamp > ago(1h) | summarize Total = count(), Errors = countif(success == false) by bin(timestamp, 1m) | extend ErrorRate = 100 0 * Errors / Total\n| render timechart\n// P95 latency\nrequests\n| where timestamp > ago(1h)\n| summarize p95 = percentile(duration, 95) by bin(timestamp, 1m)\n| render timechart\n// Top slow operations\nrequests\n| where timestamp > ago(1h)\n| summarize p95 = percentile(duration, 95) by name\n| top 10 by p95 desc\n| render barchart\n`\n---\nAlerts\nPrometheus Alerts\nalerts yml:\n`yaml\ngroups:\nname: order-service\n    interval: 30s\n    rules:\nalert: HighErrorRate\n        expr: |\n          100 * (\n            rate(http_requests_total{service=\"order-service\",status=~\"5 \"}[5m])\n            /\n            rate(http_requests_total{service=\"order-service\"}[5m])\n          ) > 5\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate on Order Service\"\n          description: \"Error rate is {{ $value }}% over the last 5 minutes\"\nalert: HighLatency\n        expr: |\n          histogram_quantile(0 95,\n            rate(http_request_duration_seconds_bucket{service=\"order-service\"}[5m])\n          ) > 1 0\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High latency on Order Service\"\n          description: \"P95 latency is {{ $value }}s over the last 5 minutes\"\nalert: OutboxBacklog\n        expr: outbox_backlog > 10000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Outbox backlog is high\"\n          description: \"Outbox has {{ $value }} unprocessed messages\"\n`\nApplication Insights Alerts\nAzure CLI:\n`bash\nCreate alert for error rate\naz monitor metrics alert create \\\n  --name \"High Error Rate\" \\\n  --resource-group whizbang-rg \\\n  --scopes /subscriptions/ /resourceGroups/whizbang-rg/providers/Microsoft Insights/components/whizbang-ai \\\n  --condition \"count requests/failed > 50\" \\\n  --window-size 5m \\\n  --evaluation-frequency 1m \\\n  --severity 2 \\\n  --description \"Error rate exceeded 50 requests/5min\"\nCreate alert for P95 latency\naz monitor metrics alert create \\\n  --name \"High Latency\" \\\n  --resource-group whizbang-rg \\\n  --scopes /subscriptions/ /resourceGroups/whizbang-rg/providers/Microsoft",
        "startIndex": 11385,
        "preview": "// Request rate requests | where timestamp > ago(1h) | summarize RequestRate = count() / 60 0 by bin(timestamp, 1m) | render timechart // Error rate r..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-6",
        "text": "--resource-group whizbang-rg \\ --scopes /subscriptions/ /resourceGroups/whizbang-rg/providers/Microsoft Insights/components/whizbang-ai \\ --condition \"count requests/failed > 50\" \\ --window-size 5m \\ --evaluation-frequency 1m \\ --severity 2 \\ --description \"Error rate exceeded 50 requests/5min\" Create alert for P95 latency az monitor metrics alert create \\ --name \"High Latency\" \\ --resource-group whizbang-rg \\ --scopes /subscriptions/ /resourceGroups/whizbang-rg/providers/Microsoft Insights/components/whizbang-ai \\\n  --condition \"percentile requests/duration > 1000\" \\\n  --window-size 5m \\\n  --evaluation-frequency 1m \\\n  --severity 3 \\\n  --description \"P95 latency exceeded 1 second\"\n`\n---\nLog Aggregation\nSerilog with Sinks\nProgram cs:\n`csharp\nusing Serilog;\nusing Serilog Sinks ApplicationInsights TelemetryConverters;\nLog Logger = new LoggerConfiguration() MinimumLevel Information() MinimumLevel Override(\"Microsoft\", LogEventLevel Warning) Enrich FromLogContext() Enrich WithMachineName() Enrich WithEnvironmentName() WriteTo Console(new JsonFormatter()) WriteTo ApplicationInsights(\n    builder Configuration[\"ApplicationInsights:ConnectionString\"],\n    TelemetryConverter Traces\n  ) CreateLogger();\nbuilder Host UseSerilog();\n`\nappsettings json:\n`json\n{\n  \"Serilog\": {\n    \"MinimumLevel\": {\n      \"Default\": \"Information\",\n      \"Override\": {\n        \"Microsoft\": \"Warning\",\n        \"System\": \"Warning\"\n      }\n    }\n  }\n}\n`\n---\nPerformance Monitoring\nBenchmarkDotNet Integration\nCreateOrderBenchmark cs:\n`csharp\nusing BenchmarkDotNet Attributes;\nusing BenchmarkDotNet Running;\n[MemoryDiagnoser]\n[SimpleJob(warmupCount: 3, iterationCount: 10)]\npublic class CreateOrderBenchmark {\n  private CreateOrderReceptor _receptor = null ;\n  private CreateOrder _command = null ;\n  [GlobalSetup]\n  public void Setup() {\n    _receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n    _command = new CreateOrder {\n      CustomerId = \"cust-123\",\n      Items = [\n        new OrderItem { ProductId = \"prod-456\", Quantity = 2, UnitPrice = 19 99m }\n      ]\n    };\n  }\n  [Benchmark]\n  public async Task<OrderCreated> CreateOrder() {\n    return await _receptor HandleAsync(_command);\n  }\n}\n`\nRun:\n`bash\ndotnet run -c Release --project Benchmarks\nOutput:\n| Method      | Mean     | Error   | StdDev | Allocated |\n|------------ |---------:|--------:|-------:|----------:|\n| CreateOrder | 125 3 Œºs | 2 34 Œºs | 2",
        "startIndex": 13546,
        "preview": "--resource-group whizbang-rg \\ --scopes /subscriptions/ /resourceGroups/whizbang-rg/providers/Microsoft Insights/components/whizbang-ai \\ --condition ..."
      },
      {
        "id": "v0.1.0/advanced-topics/monitoring-chunk-7",
        "text": "] }; } [Benchmark] public async Task<OrderCreated> CreateOrder() { return await _receptor HandleAsync(_command); } } ` Run: `bash dotnet run -c Release --project Benchmarks Output: | Method | Mean | Error | StdDev | Allocated | |------------ |---------:|--------:|-------:|----------:| | CreateOrder | 125 3 Œºs | 2 34 Œºs | 2 19 Œºs |     512 B |\n`\n---\nKey Takeaways\n‚úÖ Application Insights - Logs, metrics, traces in one platform\n‚úÖ Prometheus + Grafana - Time-series metrics and dashboards\n‚úÖ Distributed Tracing - W3C Trace Context propagation\n‚úÖ Health Checks - Readiness and liveness probes\n‚úÖ Custom Metrics - Business-specific KPIs\n‚úÖ Alerts - Proactive incident detection\n‚úÖ Structured Logging - Queryable logs with context\n---\nMonitoring Checklist\n[ ] Application Insights configured with connection string\n[ ] Prometheus metrics exported at /metrics\n[ ] Distributed tracing enabled with W3C Trace Context\n[ ] Health checks at /health, /health/ready, /health/live\n[ ] Custom metrics for business KPIs (orders created, revenue, etc )\n[ ] Alerts configured for error rate, latency, backlog\n[ ] Dashboards created in Grafana and Azure Portal\n[ ] Log aggregation with Serilog\n[ ] Performance benchmarks with BenchmarkDotNet\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15494,
        "preview": "] }; } [Benchmark] public async Task<OrderCreated> CreateOrder() { return await _receptor HandleAsync(_command); } } ` Run: `bash dotnet run -c Releas..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/multi-tenancy",
    "title": "Multi-Tenancy Patterns",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/multi-tenancy",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-0",
        "text": "Multi-Tenancy Patterns\nComprehensive guide to multi-tenancy architectures with Whizbang - database-per-tenant, schema-per-tenant, row-level security, tenant context management, and migration strategies ---\nMulti-Tenancy Comparison\n| Pattern | Isolation | Cost | Complexity | Scale Limit |\n|---------|-----------|------|------------|-------------|\n| Database Per Tenant | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | High | Medium | ~1,000 tenants |\n| Schema Per Tenant | ‚≠ê‚≠ê‚≠ê‚≠ê | Medium | Medium | ~10,000 tenants |\n| Row-Level Security (RLS) | ‚≠ê‚≠ê‚≠ê | Low | Low | ~100,000+ tenants |\n| Discriminator Column | ‚≠ê‚≠ê | Low | Low | ~100,000+ tenants |\n---\nPattern 1: Database Per Tenant\nStrongest isolation - Each tenant has dedicated database Architecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Multi-Tenant SaaS Application                     ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ\n‚îÇ  ‚îÇ  Tenant Resolver ‚îÇ                              ‚îÇ\n‚îÇ  ‚îÇ  - Header/JWT    ‚îÇ                              ‚îÇ\n‚îÇ  ‚îÇ  - Subdomain     ‚îÇ                              ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ\n‚îÇ           ‚îÇ                                         ‚îÇ\n‚îÇ           ‚ñº                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ\n‚îÇ  ‚îÇ Connection Pool  ‚îÇ                              ‚îÇ\n‚îÇ  ‚îÇ  Manager         ‚îÇ                              ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ\n‚îÇ           ‚îÇ                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ  ‚îÇ        ‚îÇ                           ‚îÇ            ‚îÇ\n‚îÇ  ‚ñº        ‚ñº                           ‚ñº            ‚îÇ\n‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ ‚îÇDB-A ‚îÇ ‚îÇDB-B ‚îÇ ‚îÇDB-Z ‚îÇ         ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nTenant Context (AsyncLocal)\nTenantContext cs:\n`csharp\npublic static class TenantContext {\n  private static readonly AsyncLocal<string > _tenantId = new();\n  public static string CurrentTenantId {\n    get => _tenantId Value;\n    set => _tenantId Value = value;\n  }\n  public static string RequireTenantId() {\n    return CurrentTenantId throw new InvalidOperationException(\"No tenant context established\");\n  }\n}\n`\nWhy AsyncLocal :\n‚úÖ Thread-safe\n‚úÖ Async-safe (flows through await calls)\n‚úÖ Request-scoped (automatically cleared after request)\nTenant Identification Middleware\nTenantIdentificationMiddleware",
        "startIndex": 0,
        "preview": "Multi-Tenancy Patterns\nComprehensive guide to multi-tenancy architectures with Whizbang - database-per-tenant, schema-per-tenant, row-level security, ..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-1",
        "text": "CurrentTenantId { get => _tenantId Value; set => _tenantId Value = value; } public static string RequireTenantId() { return CurrentTenantId throw new InvalidOperationException(\"No tenant context established\"); } } ` Why AsyncLocal : ‚úÖ Thread-safe ‚úÖ Async-safe (flows through await calls) ‚úÖ Request-scoped (automatically cleared after request) Tenant Identification Middleware TenantIdentificationMiddleware cs:\n`csharp\npublic class TenantIdentificationMiddleware {\n  private readonly RequestDelegate _next;\n  public TenantIdentificationMiddleware(RequestDelegate next) {\n    _next = next;\n  }\n  public async Task InvokeAsync(HttpContext context) {\n    // Option 1: Custom header\n    var tenantId = context Request Headers[\"X-Tenant-Id\"] FirstOrDefault();\n    // Option 2: Subdomain (e g , acme myapp com -> acme)\n    if (string IsNullOrEmpty(tenantId)) {\n      var host = context Request Host Host;\n      tenantId = host Split(' ') FirstOrDefault();\n    }\n    // Option 3: JWT claim\n    if (string IsNullOrEmpty(tenantId)) {\n      tenantId = context User FindFirst(\"tenant_id\") Value;\n    }\n    if (string IsNullOrEmpty(tenantId)) {\n      context Response StatusCode = 400;\n      await context Response WriteAsync(\"Missing tenant identification\");\n      return;\n    }\n    // Set tenant context\n    TenantContext CurrentTenantId = tenantId;\n    await _next(context);\n  }\n}\n`\nRegistration (Program cs):\n`csharp\napp UseMiddleware<TenantIdentificationMiddleware>();\n`\nTenant-Aware Database Connections\nTenantDbConnectionFactory cs:\n`csharp\npublic interface ITenantDbConnectionFactory {\n  Task<IDbConnection> CreateConnectionAsync(CancellationToken ct = default);\n}\npublic class TenantDbConnectionFactory : ITenantDbConnectionFactory {\n  private readonly IConfiguration _config;\n  private readonly ILogger<TenantDbConnectionFactory> _logger;\n  public async Task<IDbConnection> CreateConnectionAsync(CancellationToken ct = default) {\n    var tenantId = TenantContext RequireTenantId();\n    var connectionString = GetConnectionString(tenantId);\n    var connection = new NpgsqlConnection(connectionString);\n    await connection OpenAsync(ct);\n    _logger LogDebug(\"Opened connection to tenant database: {TenantId}\", tenantId);\n    return connection;\n  }\n  private string GetConnectionString(string tenantId) {\n    // Option 1: Configuration-based\n    var connectionString = _config[$\"Tenants:{tenantId}:ConnectionString\"];\n    if ( string IsNullOrEmpty(connectionString)) {\n      return connectionString;\n    }\n    // Option 2: Template-based (same server, different database)\n    var template = _config[\"Database:TenantTemplate\"] throw new InvalidOperationException(\"Missing tenant template connection string\");\n    return template Replace(\"{TenantId}\", tenantId);\n  }\n}\n`\nappsettings json:\n`json\n{\n  \"Database\": {\n    \"TenantTemplate\": \"Host=db myapp com;Database=tenant_{TenantId};Username=app;Password=*\"\n  }\n}\n`\nTenant-Aware Receptors\nCreateOrderReceptor",
        "startIndex": 2541,
        "preview": "CurrentTenantId { get => _tenantId Value; set => _tenantId Value = value; } public static string RequireTenantId() { return CurrentTenantId throw new ..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-2",
        "text": "if ( string IsNullOrEmpty(connectionString)) { return connectionString; } // Option 2: Template-based (same server, different database) var template = _config[\"Database:TenantTemplate\"] throw new InvalidOperationException(\"Missing tenant template connection string\"); return template Replace(\"{TenantId}\", tenantId); } } ` appsettings json: `json { \"Database\": { \"TenantTemplate\": \"Host=db myapp com;Database=tenant_{TenantId};Username=app;Password=*\" } } ` Tenant-Aware Receptors CreateOrderReceptor cs:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly ITenantDbConnectionFactory _dbFactory;\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    var tenantId = TenantContext RequireTenantId();\n    await using var connection = await _dbFactory CreateConnectionAsync(ct);\n    await using var tx = await connection BeginTransactionAsync(ct);\n    try {\n      // Insert order (tenant-specific database)\n      await connection ExecuteAsync(\n        \"\"\"\n        INSERT INTO orders (order_id, customer_id, total_amount, created_at)\n        VALUES (@OrderId, @CustomerId, @TotalAmount, NOW())\n        \"\"\",\n        new {\n          OrderId = orderId,\n          CustomerId = command CustomerId,\n          TotalAmount = command Items Sum(i => i Quantity * i UnitPrice)\n        },\n        transaction: tx\n      );\n      // Insert outbox message\n      await connection ExecuteAsync(\n        \"\"\"\n        INSERT INTO outbox (message_id, message_type, message_body, created_at)\n        VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW())\n        \"\"\",\n        transaction: tx\n      );\n      await tx CommitAsync(ct);\n      return new OrderCreated {\n        OrderId = orderId,\n        CustomerId = command CustomerId,\n        TenantId = tenantId,  // Include tenant in event\n        CreatedAt = DateTime UtcNow\n      };\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n}\n`\nTenant Onboarding\nTenantOnboardingReceptor cs:\n`csharp\npublic record CreateTenant : ICommand<TenantCreated> {\n  public required string TenantId { get; init; }\n  public required string Name { get; init; }\n  public required string AdminEmail { get; init; }\n}\npublic class TenantOnboardingReceptor : IReceptor<CreateTenant, TenantCreated> {\n  private readonly IConfiguration _config;\n  private readonly IDbConnection _adminDb;\n  public async Task<TenantCreated> HandleAsync(\n    CreateTenant command,\n    CancellationToken ct = default\n  ) {\n    // 1 Create tenant database\n    var adminConnectionString = _config[\"Database:AdminConnectionString\"];\n    await using var adminConn = new NpgsqlConnection(adminConnectionString);\n    await adminConn OpenAsync(ct);\n    await adminConn ExecuteAsync($\"CREATE DATABASE tenant_{command TenantId}\");\n    // 2",
        "startIndex": 5096,
        "preview": "if ( string IsNullOrEmpty(connectionString)) { return connectionString; } // Option 2: Template-based (same server, different database) var template =..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-3",
        "text": "IReceptor<CreateTenant, TenantCreated> { private readonly IConfiguration _config; private readonly IDbConnection _adminDb; public async Task<TenantCreated> HandleAsync( CreateTenant command, CancellationToken ct = default ) { // 1 Create tenant database var adminConnectionString = _config[\"Database:AdminConnectionString\"]; await using var adminConn = new NpgsqlConnection(adminConnectionString); await adminConn OpenAsync(ct); await adminConn ExecuteAsync($\"CREATE DATABASE tenant_{command TenantId}\"); // 2 Run schema migrations\n    var tenantConnectionString = _config[\"Database:TenantTemplate\"] Replace(\"{TenantId}\", command TenantId);\n    await using var tenantConn = new NpgsqlConnection(tenantConnectionString);\n    await tenantConn OpenAsync(ct);\n    await tenantConn ExecuteAsync(File ReadAllText(\"schema sql\"));\n    // 3 Register tenant in admin database\n    await _adminDb ExecuteAsync(\n      \"\"\"\n      INSERT INTO tenants (tenant_id, name, admin_email, created_at, status)\n      VALUES (@TenantId, @Name, @AdminEmail, NOW(), 'active')\n      \"\"\",\n      new {\n        TenantId = command TenantId,\n        Name = command Name,\n        AdminEmail = command AdminEmail\n      }\n    );\n    return new TenantCreated {\n      TenantId = command TenantId,\n      Name = command Name,\n      CreatedAt = DateTime UtcNow\n    };\n  }\n}\n`\n---\nPattern 2: Schema Per Tenant\nMedium isolation - Shared database, separate schemas per tenant Schema Management\nPostgreSQL schemas:\n`sql\n-- Create tenant schemas\nCREATE SCHEMA tenant_acme;\nCREATE SCHEMA tenant_globex;\n-- Create tables in each schema\nCREATE TABLE tenant_acme orders (\n  order_id UUID PRIMARY KEY,\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n);\nCREATE TABLE tenant_globex orders (\n  order_id UUID PRIMARY KEY,\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n);\n`\nTenant-Aware Connection\nSchemaPerTenantDbConnectionFactory cs:\n`csharp\npublic class SchemaPerTenantDbConnectionFactory : ITenantDbConnectionFactory {\n  private readonly IConfiguration _config;\n  public async Task<IDbConnection> CreateConnectionAsync(CancellationToken ct = default) {\n    var tenantId = TenantContext RequireTenantId();\n    var connectionString = _config[\"Database:ConnectionString\"];\n    var connection = new NpgsqlConnection(connectionString);\n    await connection OpenAsync(ct);\n    // Set search_path to tenant schema\n    await connection ExecuteAsync($\"SET search_path TO tenant_{tenantId}\");\n    return connection;\n  }\n}\n`\nTenant Onboarding (Schema)\n`csharp\npublic async Task<TenantCreated> HandleAsync(\n  CreateTenant command,\n  CancellationToken ct = default\n) {\n  await using var connection = new NpgsqlConnection(_config[\"Database:ConnectionString\"]);\n  await connection",
        "startIndex": 7446,
        "preview": "IReceptor<CreateTenant, TenantCreated> { private readonly IConfiguration _config; private readonly IDbConnection _adminDb; public async Task<TenantCre..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-4",
        "text": "var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(ct); // Set search_path to tenant schema await connection ExecuteAsync($\"SET search_path TO tenant_{tenantId}\"); return connection; } } ` Tenant Onboarding (Schema) `csharp public async Task<TenantCreated> HandleAsync( CreateTenant command, CancellationToken ct = default ) { await using var connection = new NpgsqlConnection(_config[\"Database:ConnectionString\"]); await connection OpenAsync(ct);\n  // 1 Create schema\n  await connection ExecuteAsync($\"CREATE SCHEMA tenant_{command TenantId}\");\n  // 2 Create tables in schema\n  await connection ExecuteAsync($\"\"\"\n    CREATE TABLE tenant_{command TenantId} orders (\n      order_id UUID PRIMARY KEY,\n      customer_id TEXT NOT NULL,\n      total_amount DECIMAL(18,2) NOT NULL,\n      created_at TIMESTAMP NOT NULL\n    )\n    \"\"\");\n  // 3 Register tenant\n  await connection ExecuteAsync(\n    \"\"\"\n    INSERT INTO public tenants (tenant_id, name, admin_email, created_at, status)\n    VALUES (@TenantId, @Name, @AdminEmail, NOW(), 'active')\n    \"\"\",\n    new { TenantId = command TenantId, Name = command Name, AdminEmail = command AdminEmail }\n  );\n  return new TenantCreated { TenantId = command TenantId, CreatedAt = DateTime UtcNow };\n}\n`\n---\nPattern 3: Row-Level Security (RLS)\nLower isolation - Shared database and schema, automatic row filtering PostgreSQL RLS Setup\n`sql\n-- Enable RLS on table\nCREATE TABLE orders (\n  order_id UUID PRIMARY KEY,\n  tenant_id TEXT NOT NULL,\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n);\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\n-- Create RLS policy\nCREATE POLICY tenant_isolation_policy ON orders\n  USING (tenant_id = current_setting('app tenant_id')::text);\n-- Grant access\nGRANT SELECT, INSERT, UPDATE, DELETE ON orders TO app_user;\n`\nTenant Context (PostgreSQL)\nRLSDbConnectionFactory cs:\n`csharp\npublic class RLSDbConnectionFactory : ITenantDbConnectionFactory {\n  private readonly IConfiguration _config;\n  public async Task<IDbConnection> CreateConnectionAsync(CancellationToken ct = default) {\n    var tenantId = TenantContext RequireTenantId();\n    var connectionString = _config[\"Database:ConnectionString\"];\n    var connection = new NpgsqlConnection(connectionString);\n    await connection OpenAsync(ct);\n    // Set tenant context for RLS\n    await connection ExecuteAsync(\n      \"SELECT set_config('app",
        "startIndex": 9765,
        "preview": "var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(ct); // Set search_path to tenant schema await connection ExecuteA..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-5",
        "text": "(PostgreSQL) RLSDbConnectionFactory cs: `csharp public class RLSDbConnectionFactory : ITenantDbConnectionFactory { private readonly IConfiguration _config; public async Task<IDbConnection> CreateConnectionAsync(CancellationToken ct = default) { var tenantId = TenantContext RequireTenantId(); var connectionString = _config[\"Database:ConnectionString\"]; var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(ct); // Set tenant context for RLS await connection ExecuteAsync( \"SELECT set_config('app tenant_id', @TenantId, false)\",\n      new { TenantId = tenantId }\n    );\n    return connection;\n  }\n}\n`\nAutomatic Tenant Filtering\nWith RLS enabled, all queries automatically filter by tenant:\n`csharp\n// This query automatically filters to current tenant\nvar orders = await connection QueryAsync<OrderRow>(\n  \"\"\"\n  SELECT * FROM orders\n  WHERE customer_id = @CustomerId\n  \"\"\",\n  new { CustomerId = \"cust-123\" }\n);\n// Equivalent to:\n// SELECT * FROM orders\n// WHERE customer_id = 'cust-123' AND tenant_id = 'current-tenant'\n`\n---\nPattern 4: Discriminator Column\nLowest isolation - Shared database/schema, manual tenant filtering Schema\n`sql\nCREATE TABLE orders (\n  order_id UUID PRIMARY KEY,\n  tenant_id TEXT NOT NULL,  -- Discriminator column\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n);\n-- Index for tenant queries\nCREATE INDEX idx_orders_tenant_id ON orders(tenant_id);\n`\nManual Filtering\nCreateOrderReceptor cs:\n`csharp\npublic async Task<OrderCreated> HandleAsync(\n  CreateOrder command,\n  CancellationToken ct = default\n) {\n  var tenantId = TenantContext RequireTenantId();\n  await using var connection = new NpgsqlConnection(_config[\"Database:ConnectionString\"]);\n  await connection OpenAsync(ct);\n  // ALWAYS include tenant_id in INSERT\n  await connection ExecuteAsync(\n    \"\"\"\n    INSERT INTO orders (order_id, tenant_id, customer_id, total_amount, created_at)\n    VALUES (@OrderId, @TenantId, @CustomerId, @TotalAmount, NOW())\n    \"\"\",\n    new {\n      OrderId = orderId,\n      TenantId = tenantId,  // ‚ö†Ô∏è Critical: Include tenant ID\n      CustomerId = command CustomerId,\n      TotalAmount = totalAmount\n    }\n  );\n  return new OrderCreated { OrderId = orderId, TenantId = tenantId };\n}\n// ALWAYS include tenant_id in WHERE clause\nvar orders = await connection",
        "startIndex": 11742,
        "preview": "(PostgreSQL) RLSDbConnectionFactory cs: `csharp public class RLSDbConnectionFactory : ITenantDbConnectionFactory { private readonly IConfiguration _co..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-6",
        "text": "@TotalAmount, NOW()) \"\"\", new { OrderId = orderId, TenantId = tenantId, // ‚ö†Ô∏è Critical: Include tenant ID CustomerId = command CustomerId, TotalAmount = totalAmount } ); return new OrderCreated { OrderId = orderId, TenantId = tenantId }; } // ALWAYS include tenant_id in WHERE clause var orders = await connection QueryAsync<OrderRow>(\n  \"\"\"\n  SELECT * FROM orders\n  WHERE tenant_id = @TenantId AND customer_id = @CustomerId\n  \"\"\",\n  new { TenantId = tenantId, CustomerId = \"cust-123\" }\n);\n`\n‚ö†Ô∏è Risk: Developers must remember to include tenant_id in every query (easy to forget) ---\nCross-Tenant Analytics\nShared analytics database for reporting across tenants:\nArchitecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Tenant Databases                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ\n‚îÇ  ‚îÇDB-A ‚îÇ  ‚îÇDB-B ‚îÇ ‚îÇDB-Z ‚îÇ                 ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò                 ‚îÇ\n‚îÇ     ‚îÇ        ‚îÇ                   ‚îÇ                     ‚îÇ\n‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ\n‚îÇ              ‚îÇ Events                                  ‚îÇ\n‚îÇ              ‚ñº                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ\n‚îÇ  ‚îÇ Analytics Worker          ‚îÇ                         ‚îÇ\n‚îÇ  ‚îÇ  - CrossTenantPerspective ‚îÇ                         ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ\n‚îÇ             ‚îÇ                                           ‚îÇ\n‚îÇ             ‚ñº                                           ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ\n‚îÇ  ‚îÇ Shared Analytics Database ‚îÇ                         ‚îÇ\n‚îÇ  ‚îÇ  - Aggregated metrics     ‚îÇ                         ‚îÇ\n‚îÇ  ‚îÇ  - All tenants            ‚îÇ                         ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nCross-Tenant Perspective\nCrossTenantAnalyticsPerspective cs:\n`csharp\npublic class CrossTenantAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IDbConnection _analyticsDb;  // Shared analytics database\n  public async Task HandleAsync(OrderCreated @event, CancellationToken ct = default) {\n    // Insert into shared analytics database (includes tenant_id)\n    await _analyticsDb ExecuteAsync(\n      \"\"\"\n      INSERT INTO order_analytics (order_id, tenant_id, customer_id, total_amount, created_at)\n      VALUES (@OrderId, @TenantId, @CustomerId, @TotalAmount, @CreatedAt)\n      \"\"\",\n      new {\n        OrderId = @event OrderId,\n        TenantId = @event TenantId,  // Track which tenant\n        CustomerId = @event CustomerId,\n        TotalAmount = @event TotalAmount,\n        CreatedAt = @event CreatedAt\n      }\n    );\n  }\n}\n`\nAnalytics Queries\n`csharp\n// Query across all tenants\nvar metrics = await _analyticsDb",
        "startIndex": 13570,
        "preview": "@TotalAmount, NOW()) \"\"\", new { OrderId = orderId, TenantId = tenantId, // ‚ö†Ô∏è Critical: Include tenant ID CustomerId = command CustomerId, TotalAmount..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-7",
        "text": "(@OrderId, @TenantId, @CustomerId, @TotalAmount, @CreatedAt) \"\"\", new { OrderId = @event OrderId, TenantId = @event TenantId, // Track which tenant CustomerId = @event CustomerId, TotalAmount = @event TotalAmount, CreatedAt = @event CreatedAt } ); } } ` Analytics Queries `csharp // Query across all tenants var metrics = await _analyticsDb QueryAsync<TenantMetrics>(\n  \"\"\"\n  SELECT\n    tenant_id,\n    COUNT(*) AS total_orders,\n    SUM(total_amount) AS total_revenue,\n    AVG(total_amount) AS avg_order_value\n  FROM order_analytics\n  WHERE created_at >= @StartDate\n  GROUP BY tenant_id\n  ORDER BY total_revenue DESC\n  \"\"\",\n  new { StartDate = DateTime UtcNow AddDays(-30) }\n);\n`\n---\nTenant Isolation Testing\nTenantIsolationTests cs:\n`csharp\npublic class TenantIsolationTests {\n  [Test]\n  public async Task CreateOrder_DifferentTenants_IsolatedData() {\n    // Arrange - Tenant A\n    TenantContext CurrentTenantId = \"tenant-a\";\n    var receptorA = new CreateOrderReceptor(_dbFactory);\n    var commandA = new CreateOrder { CustomerId = \"cust-a\", Items = [ ] };\n    // Act - Tenant A creates order\n    var resultA = await receptorA HandleAsync(commandA);\n    // Arrange - Tenant B\n    TenantContext CurrentTenantId = \"tenant-b\";\n    var receptorB = new CreateOrderReceptor(_dbFactory);\n    var commandB = new CreateOrder { CustomerId = \"cust-b\", Items = [ ] };\n    // Act - Tenant B creates order\n    var resultB = await receptorB HandleAsync(commandB);\n    // Assert - Tenant A cannot see Tenant B's order\n    TenantContext CurrentTenantId = \"tenant-a\";\n    await using var connA = await _dbFactory CreateConnectionAsync();\n    var ordersA = await connA QueryAsync<OrderRow>(\"SELECT * FROM orders\");\n    await Assert That(ordersA) HasCount(1);\n    await Assert That(ordersA Single() OrderId) IsEqualTo(resultA OrderId);\n    // Assert - Tenant B cannot see Tenant A's order\n    TenantContext CurrentTenantId = \"tenant-b\";\n    await using var connB = await _dbFactory CreateConnectionAsync();\n    var ordersB = await connB QueryAsync<OrderRow>(\"SELECT * FROM orders\");\n    await Assert That(ordersB) HasCount(1);\n    await Assert That(ordersB Single() OrderId) IsEqualTo(resultB OrderId);\n  }\n}\n`\n---\nMigration Strategies\nMigrating from Discriminator to Database-Per-Tenant\nStep 1: Export tenant data:\n`csharp\nvar tenantIds = await _db",
        "startIndex": 16113,
        "preview": "(@OrderId, @TenantId, @CustomerId, @TotalAmount, @CreatedAt) \"\"\", new { OrderId = @event OrderId, TenantId = @event TenantId, // Track which tenant Cu..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-8",
        "text": "await using var connB = await _dbFactory CreateConnectionAsync(); var ordersB = await connB QueryAsync<OrderRow>(\"SELECT * FROM orders\"); await Assert That(ordersB) HasCount(1); await Assert That(ordersB Single() OrderId) IsEqualTo(resultB OrderId); } } ` --- Migration Strategies Migrating from Discriminator to Database-Per-Tenant Step 1: Export tenant data: `csharp var tenantIds = await _db QueryAsync<string>(\"SELECT DISTINCT tenant_id FROM orders\");\nforeach (var tenantId in tenantIds) {\n  var orders = await _db QueryAsync<OrderRow>(\n    \"SELECT * FROM orders WHERE tenant_id = @TenantId\",\n    new { TenantId = tenantId }\n  );\n  await File WriteAllTextAsync(\n    $\"export/tenant-{tenantId}-orders json\",\n    JsonSerializer Serialize(orders)\n  );\n}\n`\nStep 2: Create tenant databases:\n`csharp\nforeach (var tenantId in tenantIds) {\n  await _adminDb ExecuteAsync($\"CREATE DATABASE tenant_{tenantId}\");\n  await using var tenantConn = new NpgsqlConnection(\n    $\"Host=localhost;Database=tenant_{tenantId}; \"\n  );\n  await tenantConn OpenAsync();\n  await tenantConn ExecuteAsync(File ReadAllText(\"schema sql\"));\n}\n`\nStep 3: Import data:\n`csharp\nforeach (var tenantId in tenantIds) {\n  var orders = JsonSerializer Deserialize<OrderRow[]>(\n    await File ReadAllTextAsync($\"export/tenant-{tenantId}-orders json\")\n  );\n  await using var tenantConn = new NpgsqlConnection(\n    $\"Host=localhost;Database=tenant_{tenantId}; \"\n  );\n  await tenantConn OpenAsync();\n  await tenantConn ExecuteAsync(\n    \"INSERT INTO orders (order_id, customer_id, total_amount, created_at) VALUES (@OrderId, @CustomerId, @TotalAmount, @CreatedAt)\",\n    orders\n  );\n}\n`\n---\nKey Takeaways\n‚úÖ Database Per Tenant - Strongest isolation, higher cost (~1,000 tenants)\n‚úÖ Schema Per Tenant - Medium isolation, shared database (~10,000 tenants)\n‚úÖ Row-Level Security - Automatic filtering, lower isolation (~100K+ tenants)\n‚úÖ Discriminator Column - Manual filtering, lowest isolation (~100K+ tenants)\n‚úÖ AsyncLocal Context - Thread-safe, async-safe tenant tracking\n‚úÖ Cross-Tenant Analytics - Shared analytics database for reporting\n---\nDecision Matrix\n| Use Case | Recommended Pattern |\n|----------|---------------------|\n| B2B SaaS (< 1K customers) | Database Per Tenant |\n| B2B SaaS (1K-10K customers) | Schema Per Tenant |\n| B2C SaaS (millions of users) | RLS or Discriminator |\n| Strict compliance (HIPAA, etc",
        "startIndex": 18107,
        "preview": "await using var connB = await _dbFactory CreateConnectionAsync(); var ordersB = await connB QueryAsync<OrderRow>(\"SELECT * FROM orders\"); await Assert..."
      },
      {
        "id": "v0.1.0/advanced-topics/multi-tenancy-chunk-9",
        "text": "for reporting --- Decision Matrix | Use Case | Recommended Pattern | |----------|---------------------| | B2B SaaS (< 1K customers) | Database Per Tenant | | B2B SaaS (1K-10K customers) | Schema Per Tenant | | B2C SaaS (millions of users) | RLS or Discriminator | | Strict compliance (HIPAA, etc ) | Database Per Tenant |\n| Cost-sensitive | RLS or Discriminator |\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20090,
        "preview": "for reporting --- Decision Matrix | Use Case | Recommended Pattern | |----------|---------------------| | B2B SaaS (< 1K customers) | Database Per Ten..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/native-aot",
    "title": "Native AOT",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/native-aot",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/native-aot-chunk-0",
        "text": "Native AOT\nDeploy Whizbang applications with Native AOT (Ahead-of-Time compilation) for faster startup, smaller memory footprint, and self-contained executables ---\nWhy Native AOT | Metric | JIT ( NET Runtime) | Native AOT |\n|--------|-------------------|------------|\n| Startup Time | 1-2 seconds | < 100ms |\n| Memory Footprint | 100-200 MB | 20-40 MB |\n| Deployment Size | 80 MB + runtime | 10-15 MB (self-contained) |\n| Reflection | ‚úÖ Fully supported | ‚ùå Limited |\n| Trim-Safe | Optional | ‚úÖ Required |\n---\nEnabling Native AOT\nProject file ( csproj):\n`xml\n<Project Sdk=\"Microsoft NET Sdk Web\">\n  <PropertyGroup>\n    <TargetFramework>net10 0</TargetFramework>\n    <PublishAot>true</PublishAot>\n    <InvariantGlobalization>true</InvariantGlobalization>\n    <IlcOptimizationPreference>Speed</IlcOptimizationPreference>\n    <IlcGenerateStackTraceData>false</IlcGenerateStackTraceData>\n  </PropertyGroup>\n</Project>\n`\nPublish:\n`bash\ndotnet publish -c Release -r linux-x64\n`\nOutput:\n`\nECommerce OrderService API (self-contained executable)\nSize: 12 3 MB\nStartup: 87ms\nMemory: 24 MB\n`\n---\nWhizbang is AOT-Ready\nWhizbang uses source generators instead of reflection, making it AOT-compatible by default:\n`csharp\n// ‚ùå BAD - Reflection (not AOT-compatible)\npublic class ReflectionDispatcher : IDispatcher {\n  public async Task<TResponse> DispatchAsync<TRequest, TResponse>(\n    TRequest request,\n    CancellationToken ct\n  ) {\n    var receptorType = typeof(IReceptor<,>) MakeGenericType(typeof(TRequest), typeof(TResponse));\n    var receptor = (IReceptor<TRequest, TResponse>)_services GetService(receptorType);\n    return await receptor HandleAsync(request, ct);\n  }\n}\n// ‚úÖ GOOD - Source-generated (AOT-compatible)\npublic partial class GeneratedDispatcher : IDispatcher {\n  public async Task<TResponse> DispatchAsync<TRequest, TResponse>(\n    TRequest request,\n    CancellationToken ct\n  ) {\n    return request switch {\n      CreateOrder cmd => (TResponse)(object)await DispatchCreateOrderAsync(cmd, ct),\n      UpdateOrder cmd => (TResponse)(object)await DispatchUpdateOrderAsync(cmd, ct),\n      _ => throw new InvalidOperationException($\"No handler for {typeof(TRequest) Name}\")\n    };\n  }\n  [MethodImpl(MethodImplOptions AggressiveInlining)]\n  private async Task<OrderCreated> DispatchCreateOrderAsync(\n    CreateOrder command,\n    CancellationToken ct\n  ) {\n    var receptor = _services GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n    return await receptor",
        "startIndex": 0,
        "preview": "Native AOT\nDeploy Whizbang applications with Native AOT (Ahead-of-Time compilation) for faster startup, smaller memory footprint, and self-contained e..."
      },
      {
        "id": "v0.1.0/advanced-topics/native-aot-chunk-1",
        "text": ") { return request switch { CreateOrder cmd => (TResponse)(object)await DispatchCreateOrderAsync(cmd, ct), UpdateOrder cmd => (TResponse)(object)await DispatchUpdateOrderAsync(cmd, ct), _ => throw new InvalidOperationException($\"No handler for {typeof(TRequest) Name}\") }; } [MethodImpl(MethodImplOptions AggressiveInlining)] private async Task<OrderCreated> DispatchCreateOrderAsync( CreateOrder command, CancellationToken ct ) { var receptor = _services GetRequiredService<IReceptor<CreateOrder, OrderCreated>>(); return await receptor HandleAsync(command, ct);\n  }\n}\n`\nKey differences:\n‚úÖ No reflection - Direct method calls\n‚úÖ No MakeGenericType - All types known at compile-time\n‚úÖ Inlineable - JIT/AOT can inline small methods\n‚úÖ Trim-safe - No dynamic type loading\n---\nJSON Serialization (AOT-Compatible)\nUse System Text Json source generators for AOT-compatible JSON:\nJsonContextRegistry cs:\n`csharp\nusing System Text Json Serialization;\n[JsonSerializable(typeof(CreateOrder))]\n[JsonSerializable(typeof(OrderCreated))]\n[JsonSerializable(typeof(PaymentProcessed))]\n[JsonSerializable(typeof(ShipmentCreated))]\npublic partial class MessageJsonContext : JsonSerializerContext {\n}\npublic static class JsonContextRegistry {\n  public static JsonSerializerOptions CreateOptions() {\n    return new JsonSerializerOptions {\n      TypeInfoResolver = JsonTypeInfoResolver Combine(\n        MessageJsonContext Default\n      )\n    };\n  }\n}\n`\nUsage:\n`csharp\n// ‚úÖ GOOD - AOT-compatible\nvar options = JsonContextRegistry CreateOptions();\nvar json = JsonSerializer Serialize(order, options);\nvar deserialized = JsonSerializer Deserialize<OrderCreated>(json, options);\n// ‚ùå BAD - NOT AOT-compatible\nvar json = JsonSerializer Serialize(order);  // Uses reflection\nvar deserialized = JsonSerializer Deserialize<OrderCreated>(json);\n`\nWhizbang MessageJsonContextGenerator:\nWhizbang automatically generates JsonSerializerContext for all messages:\n`csharp\n// Generated by Whizbang Generators MessageJsonContextGenerator\n[JsonSerializable(typeof(CreateOrder))]\n[JsonSerializable(typeof(OrderCreated))]\n// all discovered messages\npublic partial class WhizbangJsonContext : JsonSerializerContext {\n}\n`\n---\nTrim Warnings\nEnable trim analysis to detect non-AOT-safe code:\nProject file:\n`xml\n<PropertyGroup>\n  <PublishAot>true</PublishAot>\n  <EnableTrimAnalyzer>true</EnableTrimAnalyzer>\n  <SuppressTrimAnalysisWarnings>false</SuppressTrimAnalysisWarnings>\n</PropertyGroup>\n`\nCommon warnings:\n`\nIL2026: Using member 'System Type GetType(string)' which has 'RequiresUnreferencedCodeAttribute' can break functionality when trimming application code `\nFix:\n`csharp\n// ‚ùå BAD\nvar type = Type GetType(\"MyNamespace MyClass\");\n// ‚úÖ GOOD\nvar type = typeof(MyClass);  // Compile-time reference\n`\n---\nDependency Injection (AOT-Compatible)\nUse constructor injection with explicit registrations:\nProgram",
        "startIndex": 2472,
        "preview": ") { return request switch { CreateOrder cmd => (TResponse)(object)await DispatchCreateOrderAsync(cmd, ct), UpdateOrder cmd => (TResponse)(object)await..."
      },
      {
        "id": "v0.1.0/advanced-topics/native-aot-chunk-2",
        "text": "IL2026: Using member 'System Type GetType(string)' which has 'RequiresUnreferencedCodeAttribute' can break functionality when trimming application code ` Fix: `csharp // ‚ùå BAD var type = Type GetType(\"MyNamespace MyClass\"); // ‚úÖ GOOD var type = typeof(MyClass); // Compile-time reference ` --- Dependency Injection (AOT-Compatible) Use constructor injection with explicit registrations: Program cs:\n`csharp\n// ‚úÖ GOOD - Explicit registration (AOT-compatible)\nbuilder Services AddSingleton<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\nbuilder Services AddSingleton<IReceptor<UpdateOrder, OrderUpdated>, UpdateOrderReceptor>();\n// ‚ùå BAD - Assembly scanning (NOT AOT-compatible)\nbuilder Services Scan(scan => scan FromAssemblyOf<CreateOrderReceptor>() AddClasses(classes => classes AssignableTo(typeof(IReceptor<,>))) AsImplementedInterfaces() WithSingletonLifetime()\n);\n`\nWhizbang ReceptorDiscoveryGenerator:\nWhizbang automatically generates DI registrations:\n`csharp\n// Generated by Whizbang Generators ReceptorDiscoveryGenerator\npublic static class ReceptorServiceCollectionExtensions {\n  public static IServiceCollection AddGeneratedReceptors(this IServiceCollection services) {\n    services AddSingleton<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n    services AddSingleton<IReceptor<UpdateOrder, OrderUpdated>, UpdateOrderReceptor>();\n    // all discovered receptors\n    return services;\n  }\n}\n`\n---\nEntity Framework Core (AOT-Compatible)\nEF Core 10 added AOT support with compiled models:\nGenerate compiled model:\n`bash\ndotnet ef dbcontext optimize -c OrderDbContext -o CompiledModels\n`\nGenerated code:\n`csharp\n// CompiledModels/OrderDbContextModel cs\npublic partial class OrderDbContextModel : RuntimeModel {\n  static OrderDbContextModel() {\n    var model = new OrderDbContextModel();\n    model Initialize();\n    _instance = model;\n  }\n  private static OrderDbContextModel _instance;\n  public static IModel Instance => _instance;\n}\n`\nUsage:\n`csharp\npublic class OrderDbContext : DbContext {\n  protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) {\n    optionsBuilder UseNpgsql(\"Host=localhost;Database=orders; \") UseModel(OrderDbContextModel Instance);  // Use compiled model\n  }\n}\n`\n---\nDapper (AOT-Compatible)\nDapper works with AOT, but avoid dynamic SQL:\n‚úÖ GOOD:\n`csharp\nvar orders = await connection QueryAsync<OrderRow>(\n  \"\"\"\n  SELECT order_id, customer_id, total_amount\n  FROM orders\n  WHERE customer_id = @CustomerId\n  \"\"\",\n  new { CustomerId = \"cust-123\" }\n);\n`\n‚ùå BAD:\n`csharp\nvar orders = await connection",
        "startIndex": 4802,
        "preview": "IL2026: Using member 'System Type GetType(string)' which has 'RequiresUnreferencedCodeAttribute' can break functionality when trimming application cod..."
      },
      {
        "id": "v0.1.0/advanced-topics/native-aot-chunk-3",
        "text": "} ` --- Dapper (AOT-Compatible) Dapper works with AOT, but avoid dynamic SQL: ‚úÖ GOOD: `csharp var orders = await connection QueryAsync<OrderRow>( \"\"\" SELECT order_id, customer_id, total_amount FROM orders WHERE customer_id = @CustomerId \"\"\", new { CustomerId = \"cust-123\" } ); ` ‚ùå BAD: `csharp var orders = await connection QueryAsync(  // Dynamic type\n  \"SELECT * FROM orders WHERE customer_id = @CustomerId\",\n  new { CustomerId = \"cust-123\" }\n);\n`\n---\nAzure Service Bus (AOT-Compatible)\nAzure Service Bus SDK is AOT-compatible in NET 10:\nProgram cs:\n`csharp\nbuilder Services AddSingleton<ServiceBusClient>(sp => {\n  var connectionString = builder Configuration[\"AzureServiceBus:ConnectionString\"];\n  return new ServiceBusClient(connectionString);\n});\nbuilder Services AddSingleton<ServiceBusSender>(sp => {\n  var client = sp GetRequiredService<ServiceBusClient>();\n  return client CreateSender(\"orders\");\n});\n`\n---\nTesting AOT Compatibility\nCompile with AOT\n`bash\ndotnet publish -c Release -r linux-x64\n`\nIf compilation succeeds, your code is AOT-compatible Run Trim Analysis\n`bash\ndotnet publish -c Release -r linux-x64 -p:EnableTrimAnalyzer=true\n`\nReview warnings in build output Validate at Runtime\n`bash /bin/Release/net10 0/linux-x64/publish/ECommerce OrderService API\n`\nIf it starts and handles requests, AOT is working correctly ---\nPerformance Comparison\nBenchmark: Order Creation (1000 requests)\n| Runtime | Startup | Total Time | Memory |\n|---------|---------|------------|--------|\n| JIT | 1 2s | 3 5s | 142 MB |\n| AOT | 0 09s | 2 4s | 28 MB |\nAOT wins:\n‚úÖ 13x faster startup\n‚úÖ 1 5x faster overall (less GC pressure)\n‚úÖ 5x smaller memory\n---\nTroubleshooting AOT Issues\nIssue 1: Reflection Warnings\nError:\n`\nIL2026: Using member 'Type GetType(string)' which has 'RequiresUnreferencedCodeAttribute'\n`\nFix: Replace reflection with compile-time types:\n`csharp\n// ‚ùå BAD\nvar type = Type",
        "startIndex": 7019,
        "preview": "} ` --- Dapper (AOT-Compatible) Dapper works with AOT, but avoid dynamic SQL: ‚úÖ GOOD: `csharp var orders = await connection QueryAsync<OrderRow>( \"\"\" ..."
      },
      {
        "id": "v0.1.0/advanced-topics/native-aot-chunk-4",
        "text": "wins: ‚úÖ 13x faster startup ‚úÖ 1 5x faster overall (less GC pressure) ‚úÖ 5x smaller memory --- Troubleshooting AOT Issues Issue 1: Reflection Warnings Error: ` IL2026: Using member 'Type GetType(string)' which has 'RequiresUnreferencedCodeAttribute' ` Fix: Replace reflection with compile-time types: `csharp // ‚ùå BAD var type = Type GetType(typeName);\n// ‚úÖ GOOD\nvar type = typeName switch {\n  \"CreateOrder\" => typeof(CreateOrder),\n  \"UpdateOrder\" => typeof(UpdateOrder),\n  _ => throw new InvalidOperationException($\"Unknown type: {typeName}\")\n};\n`\nIssue 2: JSON Deserialization Fails\nError:\n`\nSystem InvalidOperationException: Serialization and deserialization of 'CreateOrder' is not supported `\nFix: Add [JsonSerializable(typeof(CreateOrder))] to JsonSerializerContext Issue 3: Missing Dependencies\nError:\n`\nUnhandled exception System DllNotFoundException: Unable to load shared library 'libssl so 3'\n`\nFix: Include native dependencies in publish:\n`xml\n<ItemGroup>\n  <RuntimeHostConfigurationOption Include=\"System Globalization Invariant\" Value=\"true\" />\n  <TrimmerRootAssembly Include=\"System Private CoreLib\" />\n</ItemGroup>\n`\n---\nKey Takeaways\n‚úÖ Whizbang is AOT-Ready - Zero reflection, source-generated code\n‚úÖ 13x Faster Startup - < 100ms vs 1-2 seconds\n‚úÖ 5x Smaller Memory - 28 MB vs 142 MB\n‚úÖ JSON Source Generators - MessageJsonContextGenerator\n‚úÖ Trim Analysis - Detect non-AOT-safe code at build time\n‚úÖ EF Core Compiled Models - dotnet ef dbcontext optimize\n---\nWhen to Use Native AOT\n| Scenario | Use AOT |\n|----------|----------|\n| Serverless (Azure Functions, AWS Lambda) | ‚úÖ Yes (fast cold starts) |\n| Containers (Kubernetes) | ‚úÖ Yes (smaller images) |\n| Edge Computing | ‚úÖ Yes (resource-constrained) |\n| Long-Running Services | ‚ö†Ô∏è Maybe (JIT eventually optimizes better) |\n| Developer Workstations | ‚ùå No (longer build times) |\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 8592,
        "preview": "wins: ‚úÖ 13x faster startup ‚úÖ 1 5x faster overall (less GC pressure) ‚úÖ 5x smaller memory --- Troubleshooting AOT Issues Issue 1: Reflection Warnings Er..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/performance-tuning",
    "title": "Performance Tuning",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/performance-tuning",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-0",
        "text": "Performance Tuning\nOptimize Whizbang performance with zero-allocation patterns, object pooling, batching, database optimizations, and profiling techniques ---\nPerformance Benchmarks\n| Metric | Target | Typical |\n|--------|--------|---------|\n| Dispatcher Latency | < 20ns | 15ns |\n| Message Throughput | > 100K msg/sec | 150K msg/sec |\n| Memory Allocations | Zero | 0 per dispatch |\n| Database Round-Trips | 1 per batch | 1 per 100 messages |\n---\nZero-Allocation Dispatch\nWhizbang achieves zero allocations through direct method invocation:\n`csharp\n// Generated code (ReceptorDiscoveryGenerator)\npublic class GeneratedDispatcher : IDispatcher {\n  private readonly IServiceProvider _services;\n  public async Task<TResponse> DispatchAsync<TRequest, TResponse>(\n    TRequest request,\n    CancellationToken ct = default\n  ) where TRequest : ICommand<TResponse> {\n    // Direct method invocation - zero reflection, zero allocations\n    return request switch {\n      CreateOrder cmd => (TResponse)(object)await DispatchCreateOrderAsync(cmd, ct),\n      UpdateOrder cmd => (TResponse)(object)await DispatchUpdateOrderAsync(cmd, ct),\n      _ => throw new InvalidOperationException($\"No handler for {typeof(TRequest) Name}\")\n    };\n  }\n  private async Task<OrderCreated> DispatchCreateOrderAsync(\n    CreateOrder command,\n    CancellationToken ct\n  ) {\n    var receptor = _services GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n    return await receptor HandleAsync(command, ct);\n  }\n}\n`\nWhy this is fast:\n‚úÖ No reflection - Direct method calls compiled ahead-of-time\n‚úÖ No allocations - No boxing, no temporary objects\n‚úÖ Inlineable - JIT can inline small methods\n‚úÖ Branch prediction - Pattern matching optimized by JIT\n---\nObject Pooling\nPolicy Context Pooling\nReuse PolicyContext objects to avoid allocations:\n`csharp\npublic static class PolicyContextPool {\n  private static readonly ObjectPool<PolicyContext> Pool =\n    ObjectPool Create<PolicyContext>();\n  public static PolicyContext Rent(\n    object message,\n    MessageEnvelope envelope,\n    IServiceProvider services,\n    string environment\n  ) {\n    var context = Pool Get();\n    context Message = message;\n    context Envelope = envelope;\n    context Services = services;\n    context Environment = environment;\n    return context;\n  }\n  public static void Return(PolicyContext context) {\n    context Clear();  // Reset state\n    Pool Return(context);\n  }\n}\n`\nUsage:\n`csharp\nvar context = PolicyContextPool",
        "startIndex": 0,
        "preview": "Performance Tuning\nOptimize Whizbang performance with zero-allocation patterns, object pooling, batching, database optimizations, and profiling techni..."
      },
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-1",
        "text": "string environment ) { var context = Pool Get(); context Message = message; context Envelope = envelope; context Services = services; context Environment = environment; return context; } public static void Return(PolicyContext context) { context Clear(); // Reset state Pool Return(context); } } ` Usage: `csharp var context = PolicyContextPool Rent(message, envelope, services, \"production\");\ntry {\n  var config = await policyEngine MatchAsync(context);\n} finally {\n  PolicyContextPool Return(context);  // ALWAYS return to pool\n}\n`\nBenchmarks:\nWithout pooling: 1000 allocations/sec\nWith pooling: 0 allocations/sec (after warmup)\nBulk Processing Pools\nPool arrays for bulk operations:\n`csharp\npublic static class ArrayPool {\n  public static T[] Rent<T>(int minLength) {\n    return System Buffers ArrayPool<T> Shared Rent(minLength);\n  }\n  public static void Return<T>(T[] array, bool clearArray = false) {\n    System Buffers ArrayPool<T> Shared Return(array, clearArray);\n  }\n}\n`\nUsage:\n`csharp\nvar buffer = ArrayPool Rent<OutboxMessage>(100);\ntry {\n  var count = await ClaimWorkAsync(buffer);\n  await ProcessMessagesAsync(buffer AsSpan(0, count));\n} finally {\n  ArrayPool Return(buffer, clearArray: true);\n}\n`\n---\nBatching\nDatabase Batching\nProcess multiple messages in single database transaction:\n`csharp\npublic async Task<WorkBatch> ProcessWorkBatchAsync(\n  Guid instanceId,\n  string serviceName,\n  MessageCompletion[] outboxCompletions,  // Batch of 100\n  MessageFailure[] outboxFailures,        // Batch of failed\n  OutboxMessage[] newOutboxMessages,      // Batch of new\n  CancellationToken ct = default\n) {\n  await using var tx = await _db BeginTransactionAsync(ct);\n  try {\n    // 1 Delete completed messages (single query)\n    await _db ExecuteAsync(\n      \"\"\"\n      DELETE FROM outbox\n      WHERE message_id = ANY(@MessageIds)\n      \"\"\",\n      new { MessageIds = outboxCompletions Select(c => c MessageId) ToArray() },\n      transaction: tx\n    );\n    // 2 Update failed messages (single query)\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE outbox\n      SET\n        attempts = attempts + 1,\n        next_retry_at = NOW() + INTERVAL '5 minutes',\n        error_message = failures error\n      FROM (SELECT UNNEST(@MessageIds::uuid[]) AS message_id, UNNEST(@Errors::text[]) AS error) failures\n      WHERE outbox message_id = failures message_id\n      \"\"\",\n      new {\n        MessageIds = outboxFailures Select(f => f MessageId)",
        "startIndex": 2469,
        "preview": "string environment ) { var context = Pool Get(); context Message = message; context Envelope = envelope; context Services = services; context Environm..."
      },
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-2",
        "text": "(single query) await _db ExecuteAsync( \"\"\" UPDATE outbox SET attempts = attempts + 1, next_retry_at = NOW() + INTERVAL '5 minutes', error_message = failures error FROM (SELECT UNNEST(@MessageIds::uuid[]) AS message_id, UNNEST(@Errors::text[]) AS error) failures WHERE outbox message_id = failures message_id \"\"\", new { MessageIds = outboxFailures Select(f => f MessageId) ToArray(),\n        Errors = outboxFailures Select(f => f ErrorMessage) ToArray()\n      },\n      transaction: tx\n    );\n    // 3 Insert new messages (single query)\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO outbox (message_id, message_type, message_body, created_at)\n      SELECT UNNEST(@MessageIds::uuid[]), UNNEST(@MessageTypes::text[]), UNNEST(@MessageBodies::jsonb[]), NOW()\n      \"\"\",\n      new {\n        MessageIds = newOutboxMessages Select(m => m MessageId) ToArray(),\n        MessageTypes = newOutboxMessages Select(m => m MessageType) ToArray(),\n        MessageBodies = newOutboxMessages Select(m => m MessageBody) ToArray()\n      },\n      transaction: tx\n    );\n    await tx CommitAsync(ct);\n  } catch {\n    await tx RollbackAsync(ct);\n    throw;\n  }\n}\n`\nPerformance:\nWithout batching: 100 round-trips (100ms @ 1ms each)\nWith batching: 3 round-trips (3ms)\n33x faster\nMessage Publishing Batching\nBatch events before publishing to Service Bus:\n`csharp\npublic class BatchingPublisher {\n  private readonly Channel<OutboxMessage> _channel = Channel CreateUnbounded<OutboxMessage>();\n  private readonly ServiceBusSender _sender;\n  public BatchingPublisher(ServiceBusSender sender) {\n    _sender = sender;\n    _ = Task Run(ProcessBatchesAsync);\n  }\n  public async Task PublishAsync(OutboxMessage message, CancellationToken ct) {\n    await _channel Writer WriteAsync(message, ct);\n  }\n  private async Task ProcessBatchesAsync() {\n    await foreach (var batch in _channel Reader ReadAllAsync() Buffer(TimeSpan FromMilliseconds(100), 100)) {\n      var serviceBusBatch = await _sender CreateMessageBatchAsync();\n      foreach (var message in batch) {\n        serviceBusBatch TryAddMessage(new ServiceBusMessage(message MessageBody));\n      }\n      await _sender SendMessagesAsync(serviceBusBatch);\n    }\n  }\n}\n`\nPerformance:\nWithout batching: 100 Service Bus calls (500ms)\nWith batching: 1 Service Bus call (5ms)\n100x faster\n---\nDatabase Optimizations\nConnection Pooling\nConfigure aggressive connection pooling:\nappsettings json:\n`json\n{\n  \"ConnectionStrings\": {\n    \"OrdersDb\": \"Host=localhost;Database=orders;Username=postgres;Password=postgres;Pooling=true;MinPoolSize=10;MaxPoolSize=100;ConnectionIdleLifetime=300\"\n  }\n}\n`\nPrepared Statements\nUse Dapper with prepared statements:\n`csharp\nvar orders = await _db",
        "startIndex": 4568,
        "preview": "(single query) await _db ExecuteAsync( \"\"\" UPDATE outbox SET attempts = attempts + 1, next_retry_at = NOW() + INTERVAL '5 minutes', error_message = fa..."
      },
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-3",
        "text": "Performance: Without batching: 100 Service Bus calls (500ms) With batching: 1 Service Bus call (5ms) 100x faster --- Database Optimizations Connection Pooling Configure aggressive connection pooling: appsettings json: `json { \"ConnectionStrings\": { \"OrdersDb\": \"Host=localhost;Database=orders;Username=postgres;Password=postgres;Pooling=true;MinPoolSize=10;MaxPoolSize=100;ConnectionIdleLifetime=300\" } } ` Prepared Statements Use Dapper with prepared statements: `csharp var orders = await _db QueryAsync<OrderRow>(\n  \"\"\"\n  SELECT * FROM orders\n  WHERE customer_id = @CustomerId AND created_at >= @StartDate\n  \"\"\",\n  new { CustomerId = \"cust-123\", StartDate = DateTime UtcNow AddDays(-30) },\n  commandType: CommandType Text,\n  commandTimeout: 30\n);\n`\nPostgreSQL caches prepared statements automatically Indexes\nCreate indexes for common queries:\n`sql\n-- Outbox queries (claim work)\nCREATE INDEX idx_outbox_claim ON outbox(created_at, partition_number)\n  WHERE processed_at IS NULL;\n-- Inbox queries (deduplication)\nCREATE INDEX idx_inbox_message_id ON inbox(message_id)\n  WHERE processed_at IS NULL;\n-- Perspective checkpoints\nCREATE INDEX idx_checkpoints_stream ON perspective_checkpoints(stream_id, perspective_name);\n`\nPartitioning\nPartition large tables by date:\n`sql\nCREATE TABLE outbox (\n  message_id UUID NOT NULL,\n  created_at TIMESTAMP NOT NULL,\n  -- other columns\n) PARTITION BY RANGE (created_at);\nCREATE TABLE outbox_2024_12 PARTITION OF outbox\n  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');\nCREATE TABLE outbox_2025_01 PARTITION OF outbox\n  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\n`\nBenefits:\nFaster queries (scan only relevant partitions)\nEasier maintenance (drop old partitions)\n---\nProfiling\nBenchmarkDotNet\nBenchmark critical paths:\nCreateOrderBenchmark cs:\n`csharp\nusing BenchmarkDotNet Attributes;\n[MemoryDiagnoser]\n[SimpleJob(warmupCount: 3, iterationCount: 10)]\npublic class CreateOrderBenchmark {\n  private CreateOrderReceptor _receptor;\n  private CreateOrder _command;\n  [GlobalSetup]\n  public void Setup() {\n    _receptor = new CreateOrderReceptor( );\n    _command = new CreateOrder( );\n  }\n  [Benchmark]\n  public async Task<OrderCreated> CreateOrder() {\n    return await _receptor HandleAsync(_command);\n  }\n}\n`\nRun:\n`bash\ndotnet run -c Release --project Benchmarks\n`\nOutput:\n`\n|      Method |     Mean |   Error |  StdDev | Allocated |\n|------------ |---------:|--------:|--------:|----------:|\n| CreateOrder | 125 3 Œºs | 2 34 Œºs | 2",
        "startIndex": 6896,
        "preview": "Performance: Without batching: 100 Service Bus calls (500ms) With batching: 1 Service Bus call (5ms) 100x faster --- Database Optimizations Connection..."
      },
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-4",
        "text": "} [Benchmark] public async Task<OrderCreated> CreateOrder() { return await _receptor HandleAsync(_command); } } ` Run: `bash dotnet run -c Release --project Benchmarks ` Output: ` | Method | Mean | Error | StdDev | Allocated | |------------ |---------:|--------:|--------:|----------:| | CreateOrder | 125 3 Œºs | 2 34 Œºs | 2 19 Œºs |     512 B |\n`\ndotnet-trace\nProfile production workloads:\n`bash\nStart tracing\ndotnet-trace collect --process-id 1234 --profile cpu-sampling\nStop after 30 seconds\nOpen trace file in PerfView or Visual Studio\n`\nApplication Insights\nMonitor performance in production:\n`csharp\nbuilder Services AddApplicationInsightsTelemetry();\nbuilder Services AddOpenTelemetryMetrics(metrics => {\n  metrics AddMeter(\"Whizbang *\") AddAspNetCoreInstrumentation() AddHttpClientInstrumentation();\n});\n`\nQuery in Azure:\n`kusto\nrequests\n| where timestamp > ago(1h)\n| summarize avg(duration), percentile(duration, 95) by name\n| order by avg_duration desc\n`\n---\nMemory Optimizations\nStruct Value Types\nUse structs for small, immutable data:\n`csharp\n// ‚úÖ GOOD - Struct (stack-allocated)\npublic readonly struct MessageId {\n  private readonly Guid _value;\n  public MessageId(Guid value) => _value = value;\n  public override string ToString() => _value ToString(\"N\");\n}\n// ‚ùå BAD - Class (heap-allocated)\npublic class MessageId {\n  public Guid Value { get; }\n  public MessageId(Guid value) => Value = value;\n}\n`\nSpan<T> for Slicing\nAvoid allocations when slicing arrays:\n`csharp\n// ‚ùå BAD - Allocates new array\nvar subset = array Skip(10) Take(50) ToArray();\n// ‚úÖ GOOD - No allocation\nvar subset = array AsSpan(10, 50);\n`\nValueTask for Hot Paths\nUse ValueTask for frequently called async methods:\n`csharp\n// ‚úÖ GOOD - ValueTask avoids allocation if completed synchronously\npublic ValueTask<OrderCreated> HandleAsync(\n  CreateOrder command,\n  CancellationToken ct = default\n) {\n  // If cached, return synchronously (no allocation)\n  if (_cache TryGetValue(command",
        "startIndex": 8886,
        "preview": "} [Benchmark] public async Task<OrderCreated> CreateOrder() { return await _receptor HandleAsync(_command); } } ` Run: `bash dotnet run -c Release --p..."
      },
      {
        "id": "v0.1.0/advanced-topics/performance-tuning-chunk-5",
        "text": "var subset = array AsSpan(10, 50); ` ValueTask for Hot Paths Use ValueTask for frequently called async methods: `csharp // ‚úÖ GOOD - ValueTask avoids allocation if completed synchronously public ValueTask<OrderCreated> HandleAsync( CreateOrder command, CancellationToken ct = default ) { // If cached, return synchronously (no allocation) if (_cache TryGetValue(command CustomerId, out var cached)) {\n    return new ValueTask<OrderCreated>(cached);\n  }\n  // Otherwise, await async operation\n  return new ValueTask<OrderCreated>(HandleSlowPathAsync(command, ct));\n}\n`\n---\nConcurrency Optimizations\nParallel Processing\nProcess perspectives in parallel:\n`csharp\npublic async Task HandleEventAsync(object @event, CancellationToken ct) {\n  var perspectives = GetPerspectives(@event);\n  await Parallel ForEachAsync(\n    perspectives,\n    new ParallelOptions { MaxDegreeOfParallelism = Environment ProcessorCount, CancellationToken = ct },\n    async (perspective, ct) => {\n      await perspective HandleAsync(@event, ct);\n    }\n  );\n}\n`\nAsync Coordination\nUse SemaphoreSlim for async locking:\n`csharp\n// ‚úÖ GOOD - Async-friendly\nprivate readonly SemaphoreSlim _lock = new(1, 1);\npublic async Task ProcessAsync() {\n  await _lock WaitAsync();\n  try {\n    // Critical section\n  } finally {\n    _lock Release();\n  }\n}\n// ‚ùå BAD - Blocks thread\nprivate readonly object _lock = new();\npublic async Task ProcessAsync() {\n  lock (_lock) {  // Don't use lock() with async\n    await SomeAsyncOperation();  // Deadlock risk\n  }\n}\n`\n---\nKey Takeaways\n‚úÖ Zero Allocations - Direct method invocation, no reflection\n‚úÖ Object Pooling - Reuse PolicyContext, arrays (1000x fewer allocations)\n‚úÖ Batching - Database batching (33x faster), message batching (100x faster)\n‚úÖ Indexes - Optimize common queries\n‚úÖ Profiling - BenchmarkDotNet, dotnet-trace, Application Insights\n‚úÖ Span<T> - Avoid array allocations\n‚úÖ ValueTask - Reduce allocations for hot paths\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 10538,
        "preview": "var subset = array AsSpan(10, 50); ` ValueTask for Hot Paths Use ValueTask for frequently called async methods: `csharp // ‚úÖ GOOD - ValueTask avoids a..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/scaling",
    "title": "Scaling Patterns",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/scaling",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-0",
        "text": "Scaling Patterns\nComprehensive guide to scaling Whizbang applications - horizontal autoscaling, database partitioning, load balancing strategies, and performance optimization under load ---\nScaling Approaches\n| Approach | When to Use | Cost | Complexity |\n|----------|-------------|------|------------|\n| Vertical Scaling | Quick fix, single database | Medium | Low |\n| Horizontal Scaling | Production systems | Low per unit | Medium |\n| Database Partitioning | > 100M rows | Medium | High |\n| Read Replicas | Read-heavy workloads | Medium | Low |\n---\nHorizontal Pod Autoscaling (HPA)\nAutomatically scale pods based on CPU, memory, or custom metrics CPU-Based Autoscaling\nhpa yaml:\n`yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: order-service-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: order-service\n  minReplicas: 3\n  maxReplicas: 100\n  metrics:\ntype: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70  Target 70% CPU\n  behavior:\n    scaleUp:\n      stabilizationWindowSeconds: 60  Wait 60s before scaling up\n      policies:\ntype: Percent\n        value: 50  Scale up by 50% of current pods\n        periodSeconds: 60\ntype: Pods\n        value: 5  Or add 5 pods (whichever is larger)\n        periodSeconds: 60\n    scaleDown:\n      stabilizationWindowSeconds: 300  Wait 5min before scaling down\n      policies:\ntype: Percent\n        value: 10  Scale down by 10% of current pods\n        periodSeconds: 60\n`\ndeployment yaml (with resource limits):\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\nname: order-service\n        image: myregistry azurecr io/order-service:1 0 0\n        resources:\n          requests:\n            cpu: 500m      0 5 CPU cores\n            memory: 512Mi\n          limits:\n            cpu: 1000m     1 CPU core\n            memory: 1Gi\n`\nCustom Metrics Autoscaling\nhpa-custom",
        "startIndex": 0,
        "preview": "Scaling Patterns\nComprehensive guide to scaling Whizbang applications - horizontal autoscaling, database partitioning, load balancing strategies, and ..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-1",
        "text": "deployment yaml (with resource limits): `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service spec: replicas: 3 template: spec: containers: name: order-service image: myregistry azurecr io/order-service:1 0 0 resources: requests: cpu: 500m 0 5 CPU cores memory: 512Mi limits: cpu: 1000m 1 CPU core memory: 1Gi ` Custom Metrics Autoscaling hpa-custom yaml:\n`yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: order-service-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: order-service\n  minReplicas: 3\n  maxReplicas: 100\n  metrics:\ntype: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: \"1000\"  1000 req/sec per pod\ntype: Pods\n    pods:\n      metric:\n        name: outbox_backlog\n      target:\n        type: AverageValue\n        averageValue: \"100\"  100 messages per pod\n`\nExpose custom metrics (Prometheus Adapter):\n`yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: adapter-config\ndata:\n  config",
        "startIndex": 2016,
        "preview": "deployment yaml (with resource limits): `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service spec: replicas: 3 template: spec: con..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-2",
        "text": "3 maxReplicas: 100 metrics: type: Pods pods: metric: name: http_requests_per_second target: type: AverageValue averageValue: \"1000\" 1000 req/sec per pod type: Pods pods: metric: name: outbox_backlog target: type: AverageValue averageValue: \"100\" 100 messages per pod ` Expose custom metrics (Prometheus Adapter): `yaml apiVersion: v1 kind: ConfigMap metadata: name: adapter-config data: config yaml: |\n    rules:\nseriesQuery: 'http_requests_total{namespace=\"production\"}'\n      resources:\n        overrides:\n          namespace: {resource: \"namespace\"}\n          pod: {resource: \"pod\"}\n      name:\n        matches: \"^http_requests_total$\"\n        as: \"http_requests_per_second\"\n      metricsQuery: 'rate(http_requests_total[1m])'\n`\n---\nDatabase Scaling\nRead Replicas\nPostgreSQL with read replicas:\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Database Scaling - Read Replicas                 ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                 ‚îÇ\n‚îÇ  ‚îÇ Order Service ‚îÇ                                 ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                 ‚îÇ\n‚îÇ          ‚îÇ                                          ‚îÇ\n‚îÇ          ‚îÇ Writes                                   ‚îÇ\n‚îÇ          ‚ñº                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ\n‚îÇ  ‚îÇ Primary (Write)‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ Replication             ‚îÇ\n‚îÇ                          ‚îÇ                          ‚îÇ\n‚îÇ                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ\n‚îÇ                     ‚îÇ         ‚îÇ                     ‚îÇ\n‚îÇ                     ‚ñº         ‚ñº                     ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ              ‚îÇReplica-1‚îÇ ‚îÇReplica-2‚îÇ               ‚îÇ\n‚îÇ              ‚îÇ (Read)  ‚îÇ ‚îÇ (Read)  ‚îÇ               ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îÇ                     ‚ñ≤         ‚ñ≤                     ‚îÇ\n‚îÇ                     ‚îÇ Reads   ‚îÇ                     ‚îÇ\n‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ\n‚îÇ                          ‚îÇ                          ‚îÇ\n‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ                  ‚îÇ  Order Service ‚îÇ                ‚îÇ\n‚îÇ                  ‚îÇ  (Read Queries)‚îÇ                ‚îÇ\n‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nConnection factory:\n`csharp\npublic interface IDbConnectionFactory {\n  Task<IDbConnection> CreateWriteConnectionAsync(CancellationToken ct = default);\n  Task<IDbConnection> CreateReadConnectionAsync(CancellationToken ct = default);\n}\npublic class PostgresConnectionFactory : IDbConnectionFactory {\n  private readonly IConfiguration _config;\n  private readonly Random _random = new();\n  public async Task<IDbConnection> CreateWriteConnectionAsync(CancellationToken ct) {\n    var connectionString = _config[\"Database:Primary:ConnectionString\"];\n    var connection = new NpgsqlConnection(connectionString);\n    await connection OpenAsync(ct);\n    return connection;\n  }\n  public async Task<IDbConnection> CreateReadConnectionAsync(CancellationToken ct) {\n    // Load balance across read replicas\n    var replicas = _config GetSection(\"Database:ReadReplicas\") Get<string[]>();\n    var connectionString = replicas[_random Next(replicas Length)];\n    var connection = new NpgsqlConnection(connectionString);\n    await connection OpenAsync(ct);\n    return connection;\n  }\n}\n`\nappsettings json:\n`json\n{\n  \"Database\": {\n    \"Primary\": {\n      \"ConnectionString\": \"Host=primary postgres;Database=orders;",
        "startIndex": 2713,
        "preview": "3 maxReplicas: 100 metrics: type: Pods pods: metric: name: http_requests_per_second target: type: AverageValue averageValue: \"1000\" 1000 req/sec per p..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-3",
        "text": "connection; } public async Task<IDbConnection> CreateReadConnectionAsync(CancellationToken ct) { // Load balance across read replicas var replicas = _config GetSection(\"Database:ReadReplicas\") Get<string[]>(); var connectionString = replicas[_random Next(replicas Length)]; var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(ct); return connection; } } ` appsettings json: `json { \"Database\": { \"Primary\": { \"ConnectionString\": \"Host=primary postgres;Database=orders; \"\n    },\n    \"ReadReplicas\": [\n      \"Host=replica1 postgres;Database=orders; \",\n      \"Host=replica2 postgres;Database=orders; \"\n    ]\n  }\n}\n`\nUsage:\n`csharp\n// Write operations use primary\npublic async Task<OrderCreated> HandleAsync(CreateOrder command, CancellationToken ct) {\n  await using var connection = await _dbFactory CreateWriteConnectionAsync(ct);\n  // Insert order }\n// Read operations use replicas\npublic async Task<OrderRow > GetOrderAsync(string orderId, CancellationToken ct) {\n  await using var connection = await _dbFactory CreateReadConnectionAsync(ct);\n  return await connection QuerySingleOrDefaultAsync<OrderRow>(\n    \"SELECT * FROM orders WHERE order_id = @OrderId\",\n    new { OrderId = orderId }\n  );\n}\n`\nTable Partitioning\nPartition by date (e g , monthly partitions):\n`sql\n-- Create partitioned table\nCREATE TABLE orders (\n  order_id UUID NOT NULL,\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n) PARTITION BY RANGE (created_at);\n-- Create partitions\nCREATE TABLE orders_2024_12 PARTITION OF orders\n  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');\nCREATE TABLE orders_2025_01 PARTITION OF orders\n  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\nCREATE TABLE orders_2025_02 PARTITION OF orders\n  FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');\n-- Create indexes on each partition\nCREATE INDEX idx_orders_2024_12_customer ON orders_2024_12(customer_id);\nCREATE INDEX idx_orders_2025_01_customer ON orders_2025_01(customer_id);\nCREATE INDEX idx_orders_2025_02_customer ON orders_2025_02(customer_id);\n`\nAutomated partition management:\n`csharp\npublic class PartitionManagementService : BackgroundService {\n  private readonly IDbConnection _db;\n  private readonly ILogger<PartitionManagementService> _logger;\n  protected override async Task ExecuteAsync(CancellationToken ct) {\n    while ( ct IsCancellationRequested) {\n      try {\n        await CreateNextMonthPartitionAsync(ct);\n        await DropOldPartitionsAsync(ct);\n      } catch (Exception ex) {\n        _logger LogError(ex, \"Failed to manage partitions\");\n      }\n      // Run daily\n      await Task Delay(TimeSpan",
        "startIndex": 5921,
        "preview": "connection; } public async Task<IDbConnection> CreateReadConnectionAsync(CancellationToken ct) { // Load balance across read replicas var replicas = _..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-4",
        "text": "public class PartitionManagementService : BackgroundService { private readonly IDbConnection _db; private readonly ILogger<PartitionManagementService> _logger; protected override async Task ExecuteAsync(CancellationToken ct) { while ( ct IsCancellationRequested) { try { await CreateNextMonthPartitionAsync(ct); await DropOldPartitionsAsync(ct); } catch (Exception ex) { _logger LogError(ex, \"Failed to manage partitions\"); } // Run daily await Task Delay(TimeSpan FromDays(1), ct);\n    }\n  }\n  private async Task CreateNextMonthPartitionAsync(CancellationToken ct) {\n    var nextMonth = DateTime UtcNow AddMonths(2) ToString(\"yyyy-MM\");\n    var startDate = $\"{nextMonth}-01\";\n    var endDate = DateTime Parse(startDate) AddMonths(1) ToString(\"yyyy-MM-dd\");\n    _logger LogInformation(\"Creating partition for {NextMonth}\", nextMonth);\n    await _db ExecuteAsync($\"\"\"\n      CREATE TABLE IF NOT EXISTS orders_{nextMonth Replace(\"-\", \"_\")} PARTITION OF orders\n        FOR VALUES FROM ('{startDate}') TO ('{endDate}')\n      \"\"\");\n    await _db ExecuteAsync($\"\"\"\n      CREATE INDEX IF NOT EXISTS idx_orders_{nextMonth Replace(\"-\", \"_\")}_customer\n        ON orders_{nextMonth Replace(\"-\", \"_\")}(customer_id)\n      \"\"\");\n  }\n  private async Task DropOldPartitionsAsync(CancellationToken ct) {\n    // Drop partitions older than 2 years\n    var cutoffDate = DateTime UtcNow AddYears(-2);\n    var cutoffMonth = cutoffDate ToString(\"yyyy_MM\");\n    _logger LogInformation(\"Dropping partitions older than {CutoffMonth}\", cutoffMonth);\n    await _db",
        "startIndex": 8086,
        "preview": "public class PartitionManagementService : BackgroundService { private readonly IDbConnection _db; private readonly ILogger<PartitionManagementService>..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-5",
        "text": "await _db ExecuteAsync($\"\"\" CREATE INDEX IF NOT EXISTS idx_orders_{nextMonth Replace(\"-\", \"_\")}_customer ON orders_{nextMonth Replace(\"-\", \"_\")}(customer_id) \"\"\"); } private async Task DropOldPartitionsAsync(CancellationToken ct) { // Drop partitions older than 2 years var cutoffDate = DateTime UtcNow AddYears(-2); var cutoffMonth = cutoffDate ToString(\"yyyy_MM\"); _logger LogInformation(\"Dropping partitions older than {CutoffMonth}\", cutoffMonth); await _db ExecuteAsync($\"DROP TABLE IF EXISTS orders_{cutoffMonth}\");\n  }\n}\n`\nPartition by Hash (Customer ID)\n`sql\n-- Partition by hash (distribute evenly across partitions)\nCREATE TABLE orders (\n  order_id UUID NOT NULL,\n  customer_id TEXT NOT NULL,\n  total_amount DECIMAL(18,2) NOT NULL,\n  created_at TIMESTAMP NOT NULL\n) PARTITION BY HASH (customer_id);\n-- Create 8 partitions\nCREATE TABLE orders_0 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 0);\nCREATE TABLE orders_1 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 1);\nCREATE TABLE orders_2 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 2);\nCREATE TABLE orders_3 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 3);\nCREATE TABLE orders_4 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 4);\nCREATE TABLE orders_5 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 5);\nCREATE TABLE orders_6 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 6);\nCREATE TABLE orders_7 PARTITION OF orders FOR VALUES WITH (MODULUS 8, REMAINDER 7);\n`\nBenefits:\n‚úÖ Queries scan only relevant partition(s)\n‚úÖ Easier maintenance (drop old partitions)\n‚úÖ Better index performance (smaller indexes)\n---\nOutbox/Inbox Partitioning\nPartition by Instance\nMultiple instances claim work from different partitions:\n`sql\nCREATE TABLE outbox (\n  message_id UUID PRIMARY KEY,\n  partition_number INT NOT NULL,  -- 0-9 (10 partitions)\n  message_type TEXT NOT NULL,\n  message_body JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL,\n  processed_at TIMESTAMP NULL\n);\nCREATE INDEX idx_outbox_partition ON outbox(partition_number, created_at)\n  WHERE processed_at IS NULL;\n`\nClaim work from specific partition:\n`csharp\npublic async Task<OutboxMessage[]> ClaimWorkAsync(\n  Guid instanceId,\n  int partitionNumber,\n  int batchSize,\n  CancellationToken ct = default\n) {\n  return await _db",
        "startIndex": 9157,
        "preview": "await _db ExecuteAsync($\"\"\" CREATE INDEX IF NOT EXISTS idx_orders_{nextMonth Replace(\"-\", \"_\")}_customer ON orders_{nextMonth Replace(\"-\", \"_\")}(custo..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-6",
        "text": "NOT NULL, message_body JSONB NOT NULL, created_at TIMESTAMP NOT NULL, processed_at TIMESTAMP NULL ); CREATE INDEX idx_outbox_partition ON outbox(partition_number, created_at) WHERE processed_at IS NULL; ` Claim work from specific partition: `csharp public async Task<OutboxMessage[]> ClaimWorkAsync( Guid instanceId, int partitionNumber, int batchSize, CancellationToken ct = default ) { return await _db QueryAsync<OutboxMessage>(\n    \"\"\"\n    UPDATE outbox\n    SET processed_at = NOW(), processed_by = @InstanceId\n    WHERE message_id IN (\n      SELECT message_id\n      FROM outbox\n      WHERE partition_number = @PartitionNumber\n        AND processed_at IS NULL\n      ORDER BY created_at\n      LIMIT @BatchSize\n      FOR UPDATE SKIP LOCKED\n    )\n    RETURNING *\n    \"\"\",\n    new { InstanceId = instanceId, PartitionNumber = partitionNumber, BatchSize = batchSize }\n  ) ToArray();\n}\n`\nAssign partition to instance:\n`csharp\npublic class OutboxWorker : BackgroundService {\n  private readonly int _partitionNumber;\n  public OutboxWorker(IConfiguration config) {\n    // Assign partition based on instance index (K8s pod ordinal)\n    var podName = Environment GetEnvironmentVariable(\"POD_NAME\") \"pod-0\";\n    _partitionNumber = int Parse(podName Split('-') Last()) % 10;\n  }\n  protected override async Task ExecuteAsync(CancellationToken ct) {\n    while ( ct IsCancellationRequested) {\n      var messages = await _outbox ClaimWorkAsync(\n        _instanceId,\n        _partitionNumber,  // Only claim from assigned partition\n        batchSize: 100,\n        ct\n      );\n      await ProcessMessagesAsync(messages, ct);\n      await Task Delay(TimeSpan FromSeconds(1), ct);\n    }\n  }\n}\n`\n---\nLoad Balancing\nService Mesh (Istio)\ndestinationrule yaml (connection pool settings):\n`yaml\napiVersion: networking istio io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: order-service\nspec:\n  host: order-service\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 50\n        http2MaxRequests: 100\n        maxRequestsPerConnection: 2\n    loadBalancer:\n      simple: LEAST_REQUEST  Route to pod with fewest active requests\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n`\nSticky Sessions (Session Affinity)\nservice yaml:\n`yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: order-service\nspec:\n  selector:\n    app: order-service\n  sessionAffinity: ClientIP  Route same client to same pod\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 3600  1 hour\n  ports:\nprotocol: TCP\n    port: 80\n    targetPort: 8080\n`\n---\nCaching\nDistributed Cache (Redis)\nProgram cs:\n`csharp\nbuilder Services",
        "startIndex": 11008,
        "preview": "NOT NULL, message_body JSONB NOT NULL, created_at TIMESTAMP NOT NULL, processed_at TIMESTAMP NULL ); CREATE INDEX idx_outbox_partition ON outbox(parti..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-7",
        "text": "Sticky Sessions (Session Affinity) service yaml: `yaml apiVersion: v1 kind: Service metadata: name: order-service spec: selector: app: order-service sessionAffinity: ClientIP Route same client to same pod sessionAffinityConfig: clientIP: timeoutSeconds: 3600 1 hour ports: protocol: TCP port: 80 targetPort: 8080 ` --- Caching Distributed Cache (Redis) Program cs: `csharp builder Services AddStackExchangeRedisCache(options => {\n  options Configuration = builder Configuration[\"Redis:ConnectionString\"];\n  options InstanceName = \"whizbang:\";\n});\n`\nUsage:\n`csharp\npublic class GetOrderReceptor : IReceptor<GetOrder, OrderRow > {\n  private readonly IDistributedCache _cache;\n  private readonly IDbConnection _db;\n  public async Task<OrderRow > HandleAsync(GetOrder query, CancellationToken ct) {\n    var cacheKey = $\"order:{query OrderId}\";\n    // Try cache first\n    var cached = await _cache GetStringAsync(cacheKey, ct);\n    if (cached = null) {\n      return JsonSerializer Deserialize<OrderRow>(cached);\n    }\n    // Cache miss - query database\n    var order = await _db QuerySingleOrDefaultAsync<OrderRow>(\n      \"SELECT * FROM orders WHERE order_id = @OrderId\",\n      new { OrderId = query OrderId }\n    );\n    if (order = null) {\n      // Cache for 5 minutes\n      await _cache SetStringAsync(\n        cacheKey,\n        JsonSerializer Serialize(order),\n        new DistributedCacheEntryOptions {\n          AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(5)\n        },\n        ct\n      );\n    }\n    return order;\n  }\n}\n`\nCache Invalidation\nOrderSummaryPerspective cs:\n`csharp\npublic async Task HandleAsync(OrderCreated @event, CancellationToken ct) {\n  // Update read model\n  await _db ExecuteAsync(\n    \"INSERT INTO order_summary ( ) VALUES ( )\"\n  );\n  // Invalidate cache\n  await _cache RemoveAsync($\"order:{@event OrderId}\", ct);\n}\n`\n---\nConnection Pooling\nNpgsql Connection Pool\nappsettings json:\n`json\n{\n  \"Database\": {\n    \"ConnectionString\": \"Host=postgres;Database=orders;Username=app;Password=*;Pooling=true;MinPoolSize=10;MaxPoolSize=100;ConnectionIdleLifetime=300\"\n  }\n}\n`\nConnection pool metrics:\n`csharp\npublic class ConnectionPoolMetrics {\n  private static readonly Gauge ActiveConnections = Metrics CreateGauge(\n    \"npgsql_active_connections\",\n    \"Number of active PostgreSQL connections\"\n  );\n  public static void RecordMetrics() {\n    var poolingDataSource = (NpgsqlDataSource)_dataSource;\n    ActiveConnections Set(poolingDataSource Statistics Idle + poolingDataSource Statistics Busy);\n  }\n}\n`\n---\nRate Limiting\nDistributed Rate Limiting (Redis)\nRateLimitingMiddleware",
        "startIndex": 13330,
        "preview": "Sticky Sessions (Session Affinity) service yaml: `yaml apiVersion: v1 kind: Service metadata: name: order-service spec: selector: app: order-service s..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-8",
        "text": "pool metrics: `csharp public class ConnectionPoolMetrics { private static readonly Gauge ActiveConnections = Metrics CreateGauge( \"npgsql_active_connections\", \"Number of active PostgreSQL connections\" ); public static void RecordMetrics() { var poolingDataSource = (NpgsqlDataSource)_dataSource; ActiveConnections Set(poolingDataSource Statistics Idle + poolingDataSource Statistics Busy); } } ` --- Rate Limiting Distributed Rate Limiting (Redis) RateLimitingMiddleware cs:\n`csharp\npublic class RateLimitingMiddleware {\n  private readonly RequestDelegate _next;\n  private readonly IDistributedCache _cache;\n  public async Task InvokeAsync(HttpContext context) {\n    var userId = context User FindFirst(ClaimTypes NameIdentifier) Value \"anonymous\";\n    var key = $\"rate-limit:{userId}:{DateTime UtcNow:yyyyMMddHHmm}\";\n    var countStr = await _cache GetStringAsync(key);\n    var count = int Parse(countStr \"0\");\n    if (count >= 100) {\n      context Response StatusCode = 429;\n      await context Response WriteAsync(\"Rate limit exceeded\");\n      return;\n    }\n    await _cache SetStringAsync(\n      key,\n      (count + 1) ToString(),\n      new DistributedCacheEntryOptions {\n        AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(1)\n      }\n    );\n    await _next(context);\n  }\n}\n`\n---\nLoad Testing\nk6 Load Test\nload-test js:\n`javascript\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nexport const options = {\n  stages: [\n    { duration: '2m', target: 100 },   // Ramp up to 100 users\n    { duration: '5m', target: 100 },   // Stay at 100 users\n    { duration: '2m', target: 200 },   // Ramp up to 200 users\n    { duration: '5m', target: 200 },   // Stay at 200 users\n    { duration: '2m', target: 0 },     // Ramp down to 0\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<500'],  // 95% of requests < 500ms\n    http_req_failed: ['rate<0 01'],    // Error rate < 1%\n  },\n};\nexport default function () {\n  const payload = JSON stringify({\n    customerId: 'cust-123',\n    items: [\n      { productId: 'prod-456', quantity: 2, unitPrice: 19 99 }\n    ]\n  });\n  const params = {\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': 'Bearer '\n    },\n  };\n  const res = http post('https://order-service myapp com/orders', payload, params);\n  check(res, {\n    'status is 201': (r) => r",
        "startIndex": 15548,
        "preview": "pool metrics: `csharp public class ConnectionPoolMetrics { private static readonly Gauge ActiveConnections = Metrics CreateGauge( \"npgsql_active_conne..."
      },
      {
        "id": "v0.1.0/advanced-topics/scaling-chunk-9",
        "text": "const payload = JSON stringify({ customerId: 'cust-123', items: [ { productId: 'prod-456', quantity: 2, unitPrice: 19 99 } ] }); const params = { headers: { 'Content-Type': 'application/json', 'Authorization': 'Bearer ' }, }; const res = http post('https://order-service myapp com/orders', payload, params); check(res, { 'status is 201': (r) => r status === 201,\n    'response time < 500ms': (r) => r timings duration < 500,\n  });\n  sleep(1);\n}\n`\nRun:\n`bash\nk6 run load-test js\n`\n---\nKey Takeaways\n‚úÖ HPA - Autoscale pods based on CPU, memory, or custom metrics\n‚úÖ Read Replicas - Offload read traffic from primary database\n‚úÖ Partitioning - Improve query performance and maintenance\n‚úÖ Load Balancing - Distribute traffic evenly (LEAST_REQUEST)\n‚úÖ Caching - Reduce database load with Redis\n‚úÖ Connection Pooling - Reuse database connections\n‚úÖ Rate Limiting - Prevent abuse with distributed rate limiting\n---\nScaling Checklist\n[ ] HPA configured with appropriate min/max replicas\n[ ] Resource requests/limits set on all pods\n[ ] Read replicas configured for read-heavy workloads\n[ ] Tables partitioned for > 100M rows\n[ ] Indexes created for common queries\n[ ] Redis cache configured with TTL\n[ ] Connection pooling enabled (MinPoolSize=10, MaxPoolSize=100)\n[ ] Load testing performed with k6\n[ ] Metrics monitored (CPU, memory, request rate, error rate)\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 17420,
        "preview": "const payload = JSON stringify({ customerId: 'cust-123', items: [ { productId: 'prod-456', quantity: 2, unitPrice: 19 99 } ] }); const params = { head..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/security",
    "title": "Security Best Practices",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/security",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/security-chunk-0",
        "text": "Security Best Practices\nComprehensive security guide for Whizbang applications - authentication, authorization, data encryption, secrets management, and OWASP Top 10 mitigations ---\nSecurity Checklist\n| Category | Requirement | Status |\n|----------|-------------|--------|\n| Authentication | JWT with RS256 signing | ‚úÖ |\n| Authorization | Policy-based RBAC | ‚úÖ |\n| Encryption | TLS 1 3 in transit | ‚úÖ |\n| Encryption | AES-256 at rest | ‚úÖ |\n| Secrets | Azure Key Vault | ‚úÖ |\n| Input Validation | Command validation | ‚úÖ |\n| SQL Injection | Parameterized queries | ‚úÖ |\n| CSRF | SameSite cookies | ‚úÖ |\n---\nAuthentication\nJWT with RS256\nWhy RS256 (asymmetric) :\n‚úÖ Public key verification (no shared secret)\n‚úÖ Harder to compromise (private key stays on auth server)\n‚úÖ Standard for microservices\nappsettings json:\n`json\n{\n  \"Authentication\": {\n    \"Authority\": \"https://login microsoftonline com/{tenant-id}/v2 0\",\n    \"Audience\": \"api://order-service\",\n    \"ValidIssuer\": \"https://login microsoftonline com/{tenant-id}/v2 0\"\n  }\n}\n`\nProgram cs:\n`csharp\nbuilder Services AddAuthentication(JwtBearerDefaults AuthenticationScheme) AddJwtBearer(options => {\n    options Authority = builder Configuration[\"Authentication:Authority\"];\n    options Audience = builder Configuration[\"Authentication:Audience\"];\n    options TokenValidationParameters = new TokenValidationParameters {\n      ValidateIssuer = true,\n      ValidateAudience = true,\n      ValidateLifetime = true,\n      ValidateIssuerSigningKey = true,\n      ValidIssuer = builder Configuration[\"Authentication:ValidIssuer\"],\n      ClockSkew = TimeSpan Zero  // No grace period for expired tokens\n    };\n  });\napp UseAuthentication();\napp UseAuthorization();\n`\nRequire Authentication on Endpoints\n`csharp\napp MapPost(\"/orders\", async (\n  CreateOrder command,\n  IDispatcher dispatcher,\n  CancellationToken ct\n) => {\n  var result = await dispatcher DispatchAsync<CreateOrder, OrderCreated>(command, ct);\n  return Results Created($\"/orders/{result OrderId}\", result);\n}) RequireAuthorization();  // ‚úÖ Require authentication\n`\n---\nAuthorization\nPolicy-Based Authorization\nProgram cs:\n`csharp\nbuilder Services AddAuthorizationBuilder() AddPolicy(\"CreateOrder\", policy => policy RequireAuthenticatedUser() RequireClaim(\"scope\", \"orders write\")) AddPolicy(\"ViewOrders\", policy => policy RequireAuthenticatedUser() RequireClaim(\"scope\", \"orders read\")) AddPolicy(\"AdminOnly\", policy => policy RequireAuthenticatedUser() RequireRole(\"Admin\"));\n`\nUsage:\n`csharp\napp",
        "startIndex": 0,
        "preview": "Security Best Practices\nComprehensive security guide for Whizbang applications - authentication, authorization, data encryption, secrets management, a..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-1",
        "text": "OrderCreated>(command, ct); return Results Created($\"/orders/{result OrderId}\", result); }) RequireAuthorization(); // ‚úÖ Require authentication ` --- Authorization Policy-Based Authorization Program cs: `csharp builder Services AddAuthorizationBuilder() AddPolicy(\"CreateOrder\", policy => policy RequireAuthenticatedUser() RequireClaim(\"scope\", \"orders write\")) AddPolicy(\"ViewOrders\", policy => policy RequireAuthenticatedUser() RequireClaim(\"scope\", \"orders read\")) AddPolicy(\"AdminOnly\", policy => policy RequireAuthenticatedUser() RequireRole(\"Admin\")); ` Usage: `csharp app MapPost(\"/orders\", async (\n  CreateOrder command,\n  IDispatcher dispatcher,\n  CancellationToken ct\n) => {\n  var result = await dispatcher DispatchAsync<CreateOrder, OrderCreated>(command, ct);\n  return Results Created($\"/orders/{result OrderId}\", result);\n}) RequireAuthorization(\"CreateOrder\");  // ‚úÖ Require specific policy\napp MapGet(\"/orders/{orderId}\", async (\n  string orderId,\n  IDbConnection db\n) => {\n  var order = await db QuerySingleOrDefaultAsync<OrderRow>(\n    \"SELECT * FROM orders WHERE order_id = @OrderId\",\n    new { OrderId = orderId }\n  );\n  return order is not null Results Ok(order) : Results NotFound();\n}) RequireAuthorization(\"ViewOrders\");\n`\nResource-Based Authorization\nOrderAuthorizationHandler cs:\n`csharp\npublic class OrderAuthorizationHandler : AuthorizationHandler<OperationAuthorizationRequirement, OrderRow> {\n  protected override Task HandleRequirementAsync(\n    AuthorizationHandlerContext context,\n    OperationAuthorizationRequirement requirement,\n    OrderRow order\n  ) {\n    var userId = context User FindFirst(ClaimTypes NameIdentifier) Value;\n    // Users can only view their own orders (unless admin)\n    if (requirement Name == \"View\") {\n      if (context User IsInRole(\"Admin\") || order CustomerId == userId) {\n        context Succeed(requirement);\n      }\n    }\n    // Only admins can delete orders\n    if (requirement Name == \"Delete\") {\n      if (context User IsInRole(\"Admin\")) {\n        context Succeed(requirement);\n      }\n    }\n    return Task CompletedTask;\n  }\n}\n`\nRegistration:\n`csharp\nbuilder Services AddSingleton<IAuthorizationHandler, OrderAuthorizationHandler>();\n`\nUsage:\n`csharp\napp MapDelete(\"/orders/{orderId}\", async (\n  string orderId,\n  IDbConnection db,\n  IAuthorizationService authz,\n  HttpContext context\n) => {\n  var order = await db QuerySingleOrDefaultAsync<OrderRow>(\n    \"SELECT * FROM orders WHERE order_id = @OrderId\",\n    new { OrderId = orderId }\n  );\n  if (order is null) {\n    return Results NotFound();\n  }\n  // Check authorization\n  var authResult = await authz AuthorizeAsync(\n    context User,\n    order,\n    new OperationAuthorizationRequirement { Name = \"Delete\" }\n  );\n  if ( authResult Succeeded) {\n    return Results",
        "startIndex": 1761,
        "preview": "OrderCreated>(command, ct); return Results Created($\"/orders/{result OrderId}\", result); }) RequireAuthorization(); // ‚úÖ Require authentication ` --- ..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-2",
        "text": "* FROM orders WHERE order_id = @OrderId\", new { OrderId = orderId } ); if (order is null) { return Results NotFound(); } // Check authorization var authResult = await authz AuthorizeAsync( context User, order, new OperationAuthorizationRequirement { Name = \"Delete\" } ); if ( authResult Succeeded) { return Results Forbid();\n  }\n  await db ExecuteAsync(\n    \"DELETE FROM orders WHERE order_id = @OrderId\",\n    new { OrderId = orderId }\n  );\n  return Results NoContent();\n}) RequireAuthorization();\n`\n---\nEncryption\nTLS 1 3 (In Transit)\nappsettings json:\n`json\n{\n  \"Kestrel\": {\n    \"Endpoints\": {\n      \"Https\": {\n        \"Url\": \"https://0 0 0 0:443\",\n        \"Certificate\": {\n          \"Path\": \"/app/certs/certificate pfx\",\n          \"Password\": \"*\"\n        },\n        \"Protocols\": \"Http1AndHttp2AndHttp3\",\n        \"SslProtocols\": [\"Tls13\"]\n      }\n    }\n  }\n}\n`\nAES-256 Encryption (At Rest)\nDataEncryptionService cs:\n`csharp\npublic interface IDataEncryptionService {\n  byte[] Encrypt(byte[] plaintext);\n  byte[] Decrypt(byte[] ciphertext);\n}\npublic class AesDataEncryptionService : IDataEncryptionService {\n  private readonly byte[] _key;\n  public AesDataEncryptionService(IConfiguration config) {\n    // Get encryption key from Azure Key Vault\n    _key = Convert FromBase64String(config[\"Encryption:Key\"]);\n    if (_key Length = 32) {\n      throw new InvalidOperationException(\"Encryption key must be 256 bits (32 bytes)\");\n    }\n  }\n  public byte[] Encrypt(byte[] plaintext) {\n    using var aes = Aes Create();\n    aes Key = _key;\n    aes GenerateIV();  // Random IV for each encryption\n    using var encryptor = aes CreateEncryptor();\n    using var ms = new MemoryStream();\n    // Write IV first (needed for decryption)\n    ms Write(aes IV, 0, aes IV Length);\n    using (var cs = new CryptoStream(ms, encryptor, CryptoStreamMode Write)) {\n      cs Write(plaintext, 0, plaintext Length);\n    }\n    return ms ToArray();\n  }\n  public byte[] Decrypt(byte[] ciphertext) {\n    using var aes = Aes Create();\n    aes Key = _key;\n    // Read IV from ciphertext\n    var iv = new byte[16];\n    Array Copy(ciphertext, 0, iv, 0, 16);\n    aes IV = iv;\n    using var decryptor = aes CreateDecryptor();\n    using var ms = new MemoryStream(ciphertext, 16, ciphertext",
        "startIndex": 4760,
        "preview": "* FROM orders WHERE order_id = @OrderId\", new { OrderId = orderId } ); if (order is null) { return Results NotFound(); } // Check authorization var au..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-3",
        "text": "} public byte[] Decrypt(byte[] ciphertext) { using var aes = Aes Create(); aes Key = _key; // Read IV from ciphertext var iv = new byte[16]; Array Copy(ciphertext, 0, iv, 0, 16); aes IV = iv; using var decryptor = aes CreateDecryptor(); using var ms = new MemoryStream(ciphertext, 16, ciphertext Length - 16);\n    using var cs = new CryptoStream(ms, decryptor, CryptoStreamMode Read);\n    using var result = new MemoryStream();\n    cs CopyTo(result);\n    return result ToArray();\n  }\n}\n`\nUsage:\n`csharp\npublic async Task<PaymentProcessed> HandleAsync(\n  ProcessPayment command,\n  CancellationToken ct = default\n) {\n  // Encrypt sensitive data before storing\n  var encryptedCardNumber = _encryption Encrypt(\n    Encoding UTF8 GetBytes(command CardNumber)\n  );\n  await _db ExecuteAsync(\n    \"\"\"\n    INSERT INTO payments (payment_id, order_id, encrypted_card_number, created_at)\n    VALUES (@PaymentId, @OrderId, @EncryptedCardNumber, NOW())\n    \"\"\",\n    new {\n      PaymentId = paymentId,\n      OrderId = command OrderId,\n      EncryptedCardNumber = encryptedCardNumber\n    }\n  );\n  return new PaymentProcessed { PaymentId = paymentId };\n}\n`\n---\nSecrets Management\nAzure Key Vault\nProgram cs:\n`csharp\nvar keyVaultUri = new Uri(builder Configuration[\"KeyVault:VaultUri\"]);\nbuilder Configuration AddAzureKeyVault(\n  keyVaultUri,\n  new DefaultAzureCredential()\n);\n`\nAzure Key Vault Secrets:\n`bash\nCreate secrets in Key Vault\naz keyvault secret set \\\n  --vault-name whizbang-kv \\\n  --name \"Database--ConnectionString\" \\\n  --value \"Host= ;Database=orders;Username=app;Password=*\"\naz keyvault secret set \\\n  --vault-name whizbang-kv \\\n  --name \"AzureServiceBus--ConnectionString\" \\\n  --value \"Endpoint=sb:// ;SharedAccessKeyName= ;SharedAccessKey=*\"\naz keyvault secret set \\\n  --vault-name whizbang-kv \\\n  --name \"Encryption--Key\" \\\n  --value \"base64-encoded-256-bit-key\"\n`\nUsage:\n`csharp\n// Automatically resolved from Key Vault\nvar connectionString = builder Configuration[\"Database:ConnectionString\"];\nvar serviceBusConnectionString = builder Configuration[\"AzureServiceBus:ConnectionString\"];\nvar encryptionKey = builder Configuration[\"Encryption:Key\"];\n`\nManaged Identity (Avoid Credentials)\nappsettings json:\n`json\n{\n  \"KeyVault\": {\n    \"VaultUri\": \"https://whizbang-kv vault azure",
        "startIndex": 6701,
        "preview": "} public byte[] Decrypt(byte[] ciphertext) { using var aes = Aes Create(); aes Key = _key; // Read IV from ciphertext var iv = new byte[16]; Array Cop..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-4",
        "text": "secret set \\ --vault-name whizbang-kv \\ --name \"Encryption--Key\" \\ --value \"base64-encoded-256-bit-key\" ` Usage: `csharp // Automatically resolved from Key Vault var connectionString = builder Configuration[\"Database:ConnectionString\"]; var serviceBusConnectionString = builder Configuration[\"AzureServiceBus:ConnectionString\"]; var encryptionKey = builder Configuration[\"Encryption:Key\"]; ` Managed Identity (Avoid Credentials) appsettings json: `json { \"KeyVault\": { \"VaultUri\": \"https://whizbang-kv vault azure net/\"\n  }\n}\n`\nNo credentials needed - Azure Managed Identity provides access:\n`bash\nAssign Managed Identity to App Service\naz webapp identity assign --name whizbang-api --resource-group whizbang-rg\nGrant Key Vault access to Managed Identity\naz keyvault set-policy \\\n  --name whizbang-kv \\\n  --object-id <managed-identity-object-id> \\\n  --secret-permissions get list\n`\n---\nInput Validation\nCommand Validation\nCreateOrderValidator cs:\n`csharp\npublic static class CreateOrderValidator {\n  public static ValidationResult Validate(CreateOrder command) {\n    var errors = new List<string>();\n    if (string IsNullOrWhiteSpace(command CustomerId)) {\n      errors Add(\"Customer ID is required\");\n    }\n    if (command Items Length == 0) {\n      errors Add(\"Order must contain at least one item\");\n    }\n    foreach (var item in command Items) {\n      if (item Quantity <= 0) {\n        errors Add($\"Item {item ProductId}: Quantity must be greater than zero\");\n      }\n      if (item UnitPrice <= 0) {\n        errors Add($\"Item {item ProductId}: Unit price must be greater than zero\");\n      }\n    }\n    return errors Count == 0 ValidationResult Success()\n      : ValidationResult Failure(errors);\n  }\n}\n`\nValidationPolicy cs:\n`csharp\npublic class ValidationPolicy : IPolicy {\n  public async Task ApplyAsync(PolicyContext context, CancellationToken ct = default) {\n    var result = context Message switch {\n      CreateOrder cmd => CreateOrderValidator Validate(cmd),\n      UpdateOrder cmd => UpdateOrderValidator Validate(cmd),\n      _ => ValidationResult Success()\n    };\n    if ( result IsSuccess) {\n      throw new ValidationException(string Join(\"; \", result Errors));\n    }\n  }\n}\n`\nSQL Injection Prevention\n‚úÖ ALWAYS use parameterized queries:\n`csharp\n// ‚úÖ GOOD - Parameterized query (safe)\nvar orders = await _db",
        "startIndex": 8691,
        "preview": "secret set \\ --vault-name whizbang-kv \\ --name \"Encryption--Key\" \\ --value \"base64-encoded-256-bit-key\" ` Usage: `csharp // Automatically resolved fro..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-5",
        "text": "=> CreateOrderValidator Validate(cmd), UpdateOrder cmd => UpdateOrderValidator Validate(cmd), _ => ValidationResult Success() }; if ( result IsSuccess) { throw new ValidationException(string Join(\"; \", result Errors)); } } } ` SQL Injection Prevention ‚úÖ ALWAYS use parameterized queries: `csharp // ‚úÖ GOOD - Parameterized query (safe) var orders = await _db QueryAsync<OrderRow>(\n  \"\"\"\n  SELECT * FROM orders\n  WHERE customer_id = @CustomerId AND created_at >= @StartDate\n  \"\"\",\n  new { CustomerId = customerId, StartDate = startDate }\n);\n// ‚ùå BAD - String interpolation (SQL injection risk)\nvar orders = await _db QueryAsync<OrderRow>(\n  $\"SELECT * FROM orders WHERE customer_id = '{customerId}'\"\n);\n`\n---\nOWASP Top 10 Mitigations\nBroken Access Control\n‚úÖ Mitigation: Policy-based authorization + resource-based authorization\n`csharp\n// Check user can access resource\nvar authResult = await _authz AuthorizeAsync(user, order, \"View\");\nif ( authResult Succeeded) {\n  return Results Forbid();\n}\n`\nCryptographic Failures\n‚úÖ Mitigation: TLS 1 3 + AES-256 encryption + Azure Key Vault\n`csharp\n// Encrypt sensitive data\nvar encryptedData = _encryption Encrypt(sensitiveData);\n`\nInjection\n‚úÖ Mitigation: Parameterized queries + input validation\n`csharp\n// Always use parameters\nawait _db ExecuteAsync(\n  \"INSERT INTO orders ( ) VALUES (@Value)\",\n  new { Value = userInput }\n);\n`\nInsecure Design\n‚úÖ Mitigation: Principle of least privilege + defense in depth\n`csharp\n// Multiple layers of security RequireAuthorization(\"CreateOrder\")  // Layer 1: Policy AddPolicy(new ValidationPolicy())    // Layer 2: Validation AddPolicy(new TenantIsolationPolicy())  // Layer 3: Tenant isolation\n`\nSecurity Misconfiguration\n‚úÖ Mitigation: Secure defaults + configuration validation\n`csharp\n// Validate configuration on startup\nvar requiredSettings = new[] {\n  \"Database:ConnectionString\",\n  \"AzureServiceBus:ConnectionString\",\n  \"Encryption:Key\"\n};\nforeach (var setting in requiredSettings) {\n  if (string IsNullOrEmpty(builder Configuration[setting])) {\n    throw new InvalidOperationException($\"Missing required setting: {setting}\");\n  }\n}\n`\nVulnerable and Outdated Components\n‚úÖ Mitigation: Automated dependency scanning\n`yaml github/workflows/security-scan",
        "startIndex": 10508,
        "preview": "=> CreateOrderValidator Validate(cmd), UpdateOrder cmd => UpdateOrderValidator Validate(cmd), _ => ValidationResult Success() }; if ( result IsSuccess..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-6",
        "text": "defaults + configuration validation `csharp // Validate configuration on startup var requiredSettings = new[] { \"Database:ConnectionString\", \"AzureServiceBus:ConnectionString\", \"Encryption:Key\" }; foreach (var setting in requiredSettings) { if (string IsNullOrEmpty(builder Configuration[setting])) { throw new InvalidOperationException($\"Missing required setting: {setting}\"); } } ` Vulnerable and Outdated Components ‚úÖ Mitigation: Automated dependency scanning `yaml github/workflows/security-scan yml\nname: Security Scan\non:\n  push:\n    branches: [main]\n  schedule:\ncron: '0 0   0'  Weekly\njobs:\n  scan:\n    runs-on: ubuntu-latest\n    steps:\nuses: actions/checkout@v4\nname: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          scan-type: 'fs'\n          scan-ref: ' '\n          format: 'sarif'\n          output: 'trivy-results sarif'\nname: Upload results to GitHub Security\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: 'trivy-results sarif'\n`\nIdentification and Authentication Failures\n‚úÖ Mitigation: JWT with short expiry + refresh tokens\n`csharp\noptions TokenValidationParameters = new TokenValidationParameters {\n  ValidateLifetime = true,\n  ClockSkew = TimeSpan Zero  // No grace period\n};\n`\nSoftware and Data Integrity Failures\n‚úÖ Mitigation: Message signing + envelope validation\n`csharp\npublic class MessageIntegrityPolicy : IPolicy {\n  public async Task ApplyAsync(PolicyContext context, CancellationToken ct = default) {\n    var signature = context Envelope Headers GetValueOrDefault(\"signature\");\n    if (string IsNullOrEmpty(signature)) {\n      throw new SecurityException(\"Missing message signature\");\n    }\n    var expectedSignature = ComputeSignature(context Message);\n    if (signature = expectedSignature) {\n      throw new SecurityException(\"Invalid message signature\");\n    }\n  }\n  private string ComputeSignature(object message) {\n    var json = JsonSerializer Serialize(message);\n    var hash = SHA256 HashData(Encoding UTF8 GetBytes(json));\n    return Convert ToBase64String(hash);\n  }\n}\n`\nSecurity Logging and Monitoring Failures\n‚úÖ Mitigation: Structured logging + Application Insights\n`csharp\n_logger LogWarning(\n  \"Unauthorized access attempt: User {UserId} attempted to access Order {OrderId}\",\n  userId,\n  orderId\n);\n`\nServer-Side Request Forgery (SSRF)\n‚úÖ Mitigation: Whitelist allowed hosts + URL validation\n`csharp\npublic class UrlValidationPolicy : IPolicy {\n  private static readonly string[] AllowedHosts = [\n    \"api stripe com\",\n    \"api twilio com\"\n  ];\n  public async Task ApplyAsync(PolicyContext context, CancellationToken ct = default) {\n    if (context",
        "startIndex": 12391,
        "preview": "defaults + configuration validation `csharp // Validate configuration on startup var requiredSettings = new[] { \"Database:ConnectionString\", \"AzureSer..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-7",
        "text": "{OrderId}\", userId, orderId ); ` Server-Side Request Forgery (SSRF) ‚úÖ Mitigation: Whitelist allowed hosts + URL validation `csharp public class UrlValidationPolicy : IPolicy { private static readonly string[] AllowedHosts = [ \"api stripe com\", \"api twilio com\" ]; public async Task ApplyAsync(PolicyContext context, CancellationToken ct = default) { if (context Message is IExternalApiCall apiCall) {\n      var uri = new Uri(apiCall Url);\n      if ( AllowedHosts Contains(uri Host)) {\n        throw new SecurityException($\"Host not allowed: {uri Host}\");\n      }\n    }\n  }\n}\n`\n---\nSecurity Headers\nSecurityHeadersMiddleware cs:\n`csharp\napp Use(async (context, next) => {\n  // Prevent clickjacking\n  context Response Headers Append(\"X-Frame-Options\", \"DENY\");\n  // Prevent MIME sniffing\n  context Response Headers Append(\"X-Content-Type-Options\", \"nosniff\");\n  // Enable XSS protection\n  context Response Headers Append(\"X-XSS-Protection\", \"1; mode=block\");\n  // Content Security Policy\n  context Response Headers Append(\n    \"Content-Security-Policy\",\n    \"default-src 'self'; script-src 'self'; style-src 'self'\"\n  );\n  // Strict Transport Security (HSTS)\n  context Response Headers Append(\n    \"Strict-Transport-Security\",\n    \"max-age=31536000; includeSubDomains\"\n  );\n  await next();\n});\n`\n---\nRate Limiting\nProgram cs:\n`csharp\nbuilder Services AddRateLimiter(options => {\n  options AddFixedWindowLimiter(\"api\", limiter => {\n    limiter PermitLimit = 100;\n    limiter Window = TimeSpan FromMinutes(1);\n    limiter QueueProcessingOrder = QueueProcessingOrder OldestFirst;\n    limiter QueueLimit = 10;\n  });\n});\napp UseRateLimiter();\n`\nUsage:\n`csharp\napp MapPost(\"/orders\", async (\n  CreateOrder command,\n  IDispatcher dispatcher,\n  CancellationToken ct\n) => {\n  var result = await dispatcher DispatchAsync<CreateOrder, OrderCreated>(command, ct);\n  return Results Created($\"/orders/{result OrderId}\", result);\n}) RequireAuthorization() RequireRateLimiting(\"api\");\n`\n---\nKey Takeaways\n‚úÖ JWT with RS256 - Asymmetric signing for microservices\n‚úÖ Policy-Based Authorization - Fine-grained access control\n‚úÖ TLS 1 3 + AES-256 - Encryption in transit and at rest\n‚úÖ Azure Key Vault - Centralized secrets management\n‚úÖ Input Validation - Validate all commands\n‚úÖ Parameterized Queries - Prevent SQL injection\n‚úÖ OWASP Top 10 - Comprehensive mitigations\n‚úÖ Rate Limiting - Prevent abuse\n---\nVersion 0 1",
        "startIndex": 14576,
        "preview": "{OrderId}\", userId, orderId ); ` Server-Side Request Forgery (SSRF) ‚úÖ Mitigation: Whitelist allowed hosts + URL validation `csharp public class UrlVal..."
      },
      {
        "id": "v0.1.0/advanced-topics/security-chunk-8",
        "text": "1 3 + AES-256 - Encryption in transit and at rest ‚úÖ Azure Key Vault - Centralized secrets management ‚úÖ Input Validation - Validate all commands ‚úÖ Parameterized Queries - Prevent SQL injection ‚úÖ OWASP Top 10 - Comprehensive mitigations ‚úÖ Rate Limiting - Prevent abuse --- Version 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 16607,
        "preview": "1 3 + AES-256 - Encryption in transit and at rest ‚úÖ Azure Key Vault - Centralized secrets management ‚úÖ Input Validation - Validate all commands ‚úÖ Para..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/testing-receptors",
    "title": "Testing Receptors & Perspectives",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/testing-receptors",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-0",
        "text": "Testing Receptors & Perspectives\nComprehensive testing strategies for receptors and perspectives using TUnit, mocking patterns, test fixtures, and integration testing techniques ---\nTesting Philosophy\n| Layer | Test Type | Coverage Target | Speed |\n|-------|-----------|----------------|-------|\n| Receptors | Unit Tests | 100% | < 10ms |\n| Perspectives | Unit Tests | 100% | < 10ms |\n| Integration | Integration Tests | Happy paths + error cases | < 500ms |\n| End-to-End | E2E Tests | Critical user journeys | < 5s |\n---\nTesting Stack\nWhizbang uses modern NET testing tools:\n`xml\n<ItemGroup>\n  <PackageReference Include=\"TUnit\" Version=\"1 0 0\" />\n  <PackageReference Include=\"TUnit Assertions\" Version=\"1 0 0\" />\n  <PackageReference Include=\"Rocks\" Version=\"8 0 0\" />\n  <PackageReference Include=\"Bogus\" Version=\"35 0 0\" />\n  <PackageReference Include=\"Testcontainers\" Version=\"4 0 0\" />\n</ItemGroup>\n`\nWhy these tools :\nTUnit - Modern source-generation test framework (faster than xUnit)\nTUnit Assertions - Fluent assertions native to TUnit\nRocks - Source-generation mocking (AOT-compatible, faster than Moq)\nBogus - Test data generation\nTestcontainers - Docker-based integration tests\n---\nUnit Testing Receptors\nBasic Receptor Test\nCreateOrderReceptorTests cs:\n`csharp\nusing TUnit Assertions;\nusing TUnit Core;\npublic class CreateOrderReceptorTests {\n  [Test]\n  public async Task HandleAsync_ValidOrder_ReturnsOrderCreated() {\n    // Arrange\n    var command = new CreateOrder {\n      CustomerId = \"cust-123\",\n      Items = [\n        new OrderItem { ProductId = \"prod-456\", Quantity = 2, UnitPrice = 19 99m }\n      ]\n    };\n    var mockDb = Rock Create<IDbConnection>();\n    mockDb Methods(m => m ExecuteAsync(Arg Any<string>(), Arg Any<object>(), Arg Any<IDbTransaction>())) Returns(Task FromResult(1));\n    var receptor = new CreateOrderReceptor(mockDb Instance(), Mock Of<ILogger<CreateOrderReceptor>>());\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    await Assert That(result) IsNotNull();\n    await Assert That(result OrderId) IsNotNull();\n    await Assert That(result CustomerId) IsEqualTo(\"cust-123\");\n    await Assert That(result TotalAmount) IsEqualTo(39",
        "startIndex": 0,
        "preview": "Testing Receptors & Perspectives\nComprehensive testing strategies for receptors and perspectives using TUnit, mocking patterns, test fixtures, and int..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-1",
        "text": "Create<IDbConnection>(); mockDb Methods(m => m ExecuteAsync(Arg Any<string>(), Arg Any<object>(), Arg Any<IDbTransaction>())) Returns(Task FromResult(1)); var receptor = new CreateOrderReceptor(mockDb Instance(), Mock Of<ILogger<CreateOrderReceptor>>()); // Act var result = await receptor HandleAsync(command); // Assert await Assert That(result) IsNotNull(); await Assert That(result OrderId) IsNotNull(); await Assert That(result CustomerId) IsEqualTo(\"cust-123\"); await Assert That(result TotalAmount) IsEqualTo(39 98m);\n  }\n  [Test]\n  public async Task HandleAsync_EmptyOrder_ThrowsValidationException() {\n    // Arrange\n    var command = new CreateOrder {\n      CustomerId = \"cust-123\",\n      Items = []  // Empty items\n    };\n    var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>(), Mock Of<ILogger<CreateOrderReceptor>>());\n    // Act & Assert\n    await Assert That(() => receptor HandleAsync(command)) ThrowsExactly<ValidationException>() WithMessage(\"Order must contain at least one item\");\n  }\n}\n`\n---\nMocking with Rocks\nRocks generates mocks at compile-time using source generators (AOT-compatible):\nDatabase Mocking\n`csharp\n[Test]\npublic async Task HandleAsync_DatabaseFailure_ThrowsException() {\n  // Arrange\n  var mockDb = Rock Create<IDbConnection>();\n  mockDb Methods(m => m BeginTransactionAsync(Arg Any<CancellationToken>())) Throws<InvalidOperationException>();\n  var receptor = new CreateOrderReceptor(mockDb Instance(), Mock Of<ILogger<CreateOrderReceptor>>());\n  var command = CreateValidOrder();\n  // Act & Assert\n  await Assert That(() => receptor HandleAsync(command)) ThrowsExactly<InvalidOperationException>();\n}\n`\nService Bus Mocking\n`csharp\n[Test]\npublic async Task HandleAsync_PublishesToServiceBus() {\n  // Arrange\n  var mockSender = Rock Create<ServiceBusSender>();\n  var capturedMessage = default(ServiceBusMessage);\n  mockSender Methods(m => m SendMessageAsync(Arg Any<ServiceBusMessage>(), Arg Any<CancellationToken>())) Callback<ServiceBusMessage, CancellationToken>((msg, ct) => {\n      capturedMessage = msg;\n      return Task CompletedTask;\n    });\n  var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>(), mockSender Instance());\n  var command = CreateValidOrder();\n  // Act\n  await receptor HandleAsync(command);\n  // Assert\n  await Assert That(capturedMessage) IsNotNull();\n  await Assert That(capturedMessage Subject) IsEqualTo(\"OrderCreated\");\n}\n`\n---\nTest Data Generation with Bogus\nOrderTestData cs:\n`csharp\nusing Bogus;\npublic static class OrderTestData {\n  private static readonly Faker<CreateOrder> OrderFaker = new Faker<CreateOrder>() RuleFor(o => o CustomerId, f => $\"cust-{f Random Guid()}\") RuleFor(o => o Items, f => new[] {\n      new OrderItem {\n        ProductId = $\"prod-{f Random Guid()}\",\n        Quantity = f Random Int(1, 10),\n        UnitPrice = f Finance",
        "startIndex": 2212,
        "preview": "Create<IDbConnection>(); mockDb Methods(m => m ExecuteAsync(Arg Any<string>(), Arg Any<object>(), Arg Any<IDbTransaction>())) Returns(Task FromResult(..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-2",
        "text": "using Bogus; public static class OrderTestData { private static readonly Faker<CreateOrder> OrderFaker = new Faker<CreateOrder>() RuleFor(o => o CustomerId, f => $\"cust-{f Random Guid()}\") RuleFor(o => o Items, f => new[] { new OrderItem { ProductId = $\"prod-{f Random Guid()}\", Quantity = f Random Int(1, 10), UnitPrice = f Finance Amount(10, 100)\n      }\n    });\n  public static CreateOrder CreateValidOrder() => OrderFaker Generate();\n  public static CreateOrder CreateOrderWithItems(int itemCount) {\n    var order = OrderFaker Generate();\n    order Items = Enumerable Range(0, itemCount) Select(_ => new OrderItem {\n        ProductId = $\"prod-{Guid NewGuid()}\",\n        Quantity = Random Shared Next(1, 10),\n        UnitPrice = Random Shared Next(10, 100)\n      }) ToArray();\n    return order;\n  }\n}\n`\nUsage:\n`csharp\n[Test]\npublic async Task HandleAsync_MultipleItems_CalculatesTotalCorrectly() {\n  // Arrange\n  var order = OrderTestData CreateOrderWithItems(5);\n  var expectedTotal = order Items Sum(i => i Quantity * i UnitPrice);\n  var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n  // Act\n  var result = await receptor HandleAsync(order);\n  // Assert\n  await Assert That(result TotalAmount) IsEqualTo(expectedTotal);\n}\n`\n---\nUnit Testing Perspectives\nBasic Perspective Test\nOrderSummaryPerspectiveTests cs:\n`csharp\npublic class OrderSummaryPerspectiveTests {\n  [Test]\n  public async Task HandleAsync_OrderCreated_InsertsOrderSummary() {\n    // Arrange\n    var @event = new OrderCreated {\n      OrderId = \"order-123\",\n      CustomerId = \"cust-456\",\n      TotalAmount = 99 99m,\n      CreatedAt = DateTime UtcNow\n    };\n    var mockDb = Rock Create<IDbConnection>();\n    var capturedSql = default(string);\n    var capturedParams = default(object);\n    mockDb Methods(m => m ExecuteAsync(Arg Any<string>(), Arg Any<object>(), Arg Any<IDbTransaction>())) Callback<string, object, IDbTransaction>((sql, param, tx) => {\n        capturedSql = sql;\n        capturedParams = param;\n        return Task FromResult(1);\n      });\n    var perspective = new OrderSummaryPerspective(mockDb Instance());\n    // Act\n    await perspective HandleAsync(@event);\n    // Assert\n    await Assert That(capturedSql) Contains(\"INSERT INTO order_summary\");\n    await Assert That(capturedParams) IsNotNull();\n  }\n  [Test]\n  public async Task HandleAsync_PaymentProcessed_UpdatesOrderSummary() {\n    // Arrange\n    var @event = new PaymentProcessed {\n      OrderId = \"order-123\",\n      PaymentId = \"pay-789\",\n      Amount = 99 99m,\n      ProcessedAt = DateTime UtcNow\n    };\n    var mockDb = Rock",
        "startIndex": 4573,
        "preview": "using Bogus; public static class OrderTestData { private static readonly Faker<CreateOrder> OrderFaker = new Faker<CreateOrder>() RuleFor(o => o Custo..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-3",
        "text": "Act await perspective HandleAsync(@event); // Assert await Assert That(capturedSql) Contains(\"INSERT INTO order_summary\"); await Assert That(capturedParams) IsNotNull(); } [Test] public async Task HandleAsync_PaymentProcessed_UpdatesOrderSummary() { // Arrange var @event = new PaymentProcessed { OrderId = \"order-123\", PaymentId = \"pay-789\", Amount = 99 99m, ProcessedAt = DateTime UtcNow }; var mockDb = Rock Create<IDbConnection>();\n    var capturedSql = default(string);\n    mockDb Methods(m => m ExecuteAsync(Arg Any<string>(), Arg Any<object>(), Arg Any<IDbTransaction>())) Callback<string, object, IDbTransaction>((sql, param, tx) => {\n        capturedSql = sql;\n        return Task FromResult(1);\n      });\n    var perspective = new OrderSummaryPerspective(mockDb Instance());\n    // Act\n    await perspective HandleAsync(@event);\n    // Assert\n    await Assert That(capturedSql) Contains(\"UPDATE order_summary\");\n    await Assert That(capturedSql) Contains(\"payment_id = @PaymentId\");\n  }\n}\n`\n---\nTest Fixtures\nShared test infrastructure:\nDatabaseFixture cs:\n`csharp\npublic class DatabaseFixture : IAsyncLifetime {\n  public IDbConnection Connection { get; private set; } = null ;\n  public async Task InitializeAsync() {\n    Connection = new NpgsqlConnection(\"Host=localhost;Database=test_db;\");\n    await Connection OpenAsync();\n    // Create schema\n    await Connection ExecuteAsync(\"\"\"\n      CREATE TABLE IF NOT EXISTS orders (\n        order_id TEXT PRIMARY KEY,\n        customer_id TEXT NOT NULL,\n        total_amount DECIMAL(18,2) NOT NULL,\n        created_at TIMESTAMP NOT NULL\n      )\n      \"\"\");\n  }\n  public async Task DisposeAsync() {\n    // Clean up\n    await Connection ExecuteAsync(\"DROP TABLE IF EXISTS orders\");\n    await Connection DisposeAsync();\n  }\n}\n`\nUsage:\n`csharp\npublic class CreateOrderReceptorIntegrationTests : IClassFixture<DatabaseFixture> {\n  private readonly DatabaseFixture _fixture;\n  public CreateOrderReceptorIntegrationTests(DatabaseFixture fixture) {\n    _fixture = fixture;\n  }\n  [Test]\n  public async Task HandleAsync_WithRealDatabase_InsertsOrder() {\n    // Arrange\n    var receptor = new CreateOrderReceptor(_fixture Connection);\n    var command = OrderTestData CreateValidOrder();\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    var inserted = await _fixture Connection QuerySingleOrDefaultAsync<OrderRow>(\n      \"SELECT * FROM orders WHERE order_id = @OrderId\",\n      new { OrderId = result OrderId }\n    );\n    await Assert That(inserted) IsNotNull();\n    await Assert That(inserted CustomerId) IsEqualTo(command CustomerId);\n  }\n}\n`\n---\nIntegration Testing with Testcontainers\nPostgreSQL Container:\n`csharp\nusing Testcontainers",
        "startIndex": 6853,
        "preview": "Act await perspective HandleAsync(@event); // Assert await Assert That(capturedSql) Contains(\"INSERT INTO order_summary\"); await Assert That(capturedP..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-4",
        "text": "receptor HandleAsync(command); // Assert var inserted = await _fixture Connection QuerySingleOrDefaultAsync<OrderRow>( \"SELECT * FROM orders WHERE order_id = @OrderId\", new { OrderId = result OrderId } ); await Assert That(inserted) IsNotNull(); await Assert That(inserted CustomerId) IsEqualTo(command CustomerId); } } ` --- Integration Testing with Testcontainers PostgreSQL Container: `csharp using Testcontainers PostgreSql;\npublic class PostgresIntegrationTests : IAsyncLifetime {\n  private PostgreSqlContainer _postgres = null ;\n  private IDbConnection _connection = null ;\n  public async Task InitializeAsync() {\n    _postgres = new PostgreSqlBuilder() WithImage(\"postgres:16\") WithDatabase(\"test_db\") WithUsername(\"postgres\") WithPassword(\"postgres\") Build();\n    await _postgres StartAsync();\n    _connection = new NpgsqlConnection(_postgres GetConnectionString());\n    await _connection OpenAsync();\n    // Run migrations\n    await _connection ExecuteAsync(File ReadAllText(\"schema sql\"));\n  }\n  [Test]\n  public async Task HandleAsync_WithPostgres_FullIntegration() {\n    // Arrange\n    var receptor = new CreateOrderReceptor(_connection);\n    var command = OrderTestData CreateValidOrder();\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    var order = await _connection QuerySingleAsync<OrderRow>(\n      \"SELECT * FROM orders WHERE order_id = @OrderId\",\n      new { OrderId = result OrderId }\n    );\n    await Assert That(order TotalAmount) IsEqualTo(result TotalAmount);\n  }\n  public async Task DisposeAsync() {\n    await _connection DisposeAsync();\n    await _postgres DisposeAsync();\n  }\n}\n`\nAzure Service Bus Container:\n`csharp\nusing Testcontainers Azurite;\npublic class ServiceBusIntegrationTests : IAsyncLifetime {\n  private AzuriteContainer _azurite = null ;\n  private ServiceBusClient _client = null ;\n  public async Task InitializeAsync() {\n    _azurite = new AzuriteBuilder() WithImage(\"mcr microsoft com/azure-storage/azurite:latest\") Build();\n    await _azurite StartAsync();\n    _client = new ServiceBusClient(_azurite GetConnectionString());\n  }\n  [Test]\n  public async Task HandleAsync_PublishesToServiceBus_MessageReceived() {\n    // Arrange\n    var sender = _client CreateSender(\"orders\");\n    var receiver = _client CreateReceiver(\"orders\");\n    var @event = new OrderCreated {\n      OrderId = \"order-123\",\n      CustomerId = \"cust-456\",\n      TotalAmount = 99 99m\n    };\n    // Act\n    await sender SendMessageAsync(new ServiceBusMessage(\n      JsonSerializer SerializeToUtf8Bytes(@event)\n    ));\n    // Assert\n    var message = await receiver ReceiveMessageAsync(TimeSpan FromSeconds(5));\n    await Assert That(message) IsNotNull();\n    var received = JsonSerializer Deserialize<OrderCreated>(message Body ToArray());\n    await Assert That(received OrderId) IsEqualTo(\"order-123\");\n  }\n  public async Task DisposeAsync() {\n    await _client",
        "startIndex": 9165,
        "preview": "receptor HandleAsync(command); // Assert var inserted = await _fixture Connection QuerySingleOrDefaultAsync<OrderRow>( \"SELECT * FROM orders WHERE ord..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-5",
        "text": "CustomerId = \"cust-456\", TotalAmount = 99 99m }; // Act await sender SendMessageAsync(new ServiceBusMessage( JsonSerializer SerializeToUtf8Bytes(@event) )); // Assert var message = await receiver ReceiveMessageAsync(TimeSpan FromSeconds(5)); await Assert That(message) IsNotNull(); var received = JsonSerializer Deserialize<OrderCreated>(message Body ToArray()); await Assert That(received OrderId) IsEqualTo(\"order-123\"); } public async Task DisposeAsync() { await _client DisposeAsync();\n    await _azurite DisposeAsync();\n  }\n}\n`\n---\nParameterized Tests\nTUnit supports parameterized tests:\n`csharp\npublic class OrderValidationTests {\n  [Test]\n  [Arguments(0, \"Quantity must be greater than zero\")]\n  [Arguments(-1, \"Quantity must be greater than zero\")]\n  [Arguments(-100, \"Quantity must be greater than zero\")]\n  public async Task HandleAsync_InvalidQuantity_ThrowsValidationException(\n    int quantity,\n    string expectedMessage\n  ) {\n    // Arrange\n    var command = new CreateOrder {\n      CustomerId = \"cust-123\",\n      Items = [\n        new OrderItem { ProductId = \"prod-456\", Quantity = quantity, UnitPrice = 19 99m }\n      ]\n    };\n    var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n    // Act & Assert\n    await Assert That(() => receptor HandleAsync(command)) ThrowsExactly<ValidationException>() WithMessage(expectedMessage);\n  }\n  [Test]\n  [Arguments(\"\")]\n  [Arguments(\" \")]\n  [Arguments(null)]\n  public async Task HandleAsync_InvalidCustomerId_ThrowsValidationException(string customerId) {\n    // Arrange\n    var command = new CreateOrder {\n      CustomerId = customerId,\n      Items = [\n        new OrderItem { ProductId = \"prod-456\", Quantity = 1, UnitPrice = 19 99m }\n      ]\n    };\n    var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n    // Act & Assert\n    await Assert That(() => receptor HandleAsync(command)) ThrowsExactly<ValidationException>() WithMessage(\"Customer ID is required\");\n  }\n}\n`\n---\nAsync Testing Best Practices\nUse await in Assertions\n`csharp\n// ‚úÖ GOOD - Await TUnit assertions\nawait Assert That(result) IsNotNull();\nawait Assert That(result OrderId) IsEqualTo(\"order-123\");\n// ‚ùå BAD - Don't forget await\nAssert That(result) IsNotNull();  // Won't work in TUnit\n`\nTest Cancellation\n`csharp\n[Test]\npublic async Task HandleAsync_CancellationRequested_ThrowsOperationCanceledException() {\n  // Arrange\n  var cts = new CancellationTokenSource();\n  cts Cancel();\n  var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n  var command = OrderTestData CreateValidOrder();\n  // Act & Assert\n  await Assert That(() => receptor HandleAsync(command, cts Token))",
        "startIndex": 11703,
        "preview": "CustomerId = \"cust-456\", TotalAmount = 99 99m }; // Act await sender SendMessageAsync(new ServiceBusMessage( JsonSerializer SerializeToUtf8Bytes(@even..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-6",
        "text": "Assert That(result) IsNotNull(); // Won't work in TUnit ` Test Cancellation `csharp [Test] public async Task HandleAsync_CancellationRequested_ThrowsOperationCanceledException() { // Arrange var cts = new CancellationTokenSource(); cts Cancel(); var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>()); var command = OrderTestData CreateValidOrder(); // Act & Assert await Assert That(() => receptor HandleAsync(command, cts Token)) ThrowsExactly<OperationCanceledException>();\n}\n`\nTest Timeout\n`csharp\n[Test]\n[Timeout(5000)]  // 5 seconds max\npublic async Task HandleAsync_SlowOperation_CompletesWithinTimeout() {\n  // Arrange\n  var receptor = new CreateOrderReceptor(Mock Of<IDbConnection>());\n  var command = OrderTestData CreateValidOrder();\n  // Act\n  var result = await receptor HandleAsync(command);\n  // Assert\n  await Assert That(result) IsNotNull();\n}\n`\n---\nTesting Policies\nTesting custom policies:\nPolicyTests cs:\n`csharp\npublic class TenantIsolationPolicyTests {\n  [Test]\n  public async Task ApplyAsync_DifferentTenant_ThrowsUnauthorizedException() {\n    // Arrange\n    var context = new PolicyContext {\n      Message = new CreateOrder { CustomerId = \"cust-123\" },\n      Envelope = new MessageEnvelope {\n        Headers = new Dictionary<string, string> {\n          [\"tenant-id\"] = \"tenant-A\"\n        }\n      }\n    };\n    var policy = new TenantIsolationPolicy();\n    // Assume current tenant is \"tenant-B\"\n    TenantContext CurrentTenantId = \"tenant-B\";\n    // Act & Assert\n    await Assert That(() => policy ApplyAsync(context)) ThrowsExactly<UnauthorizedException>() WithMessage(\"Tenant mismatch\");\n  }\n  [Test]\n  public async Task ApplyAsync_SameTenant_Succeeds() {\n    // Arrange\n    var context = new PolicyContext {\n      Message = new CreateOrder { CustomerId = \"cust-123\" },\n      Envelope = new MessageEnvelope {\n        Headers = new Dictionary<string, string> {\n          [\"tenant-id\"] = \"tenant-A\"\n        }\n      }\n    };\n    var policy = new TenantIsolationPolicy();\n    TenantContext CurrentTenantId = \"tenant-A\";\n    // Act\n    await policy ApplyAsync(context);\n    // Assert - No exception thrown\n  }\n}\n`\n---\nCode Coverage\nMeasure code coverage:\n`bash\ndotnet test --collect:\"XPlat Code Coverage\"\n`\nGenerate HTML report:\n`bash\ndotnet tool install -g dotnet-reportgenerator-globaltool\nreportgenerator \\\n  -reports:\"/coverage cobertura xml\" \\\n  -targetdir:\"coverage-report\" \\\n  -reporttypes:Html\nopen coverage-report/index",
        "startIndex": 13903,
        "preview": "Assert That(result) IsNotNull(); // Won't work in TUnit ` Test Cancellation `csharp [Test] public async Task HandleAsync_CancellationRequested_ThrowsO..."
      },
      {
        "id": "v0.1.0/advanced-topics/testing-receptors-chunk-7",
        "text": "CurrentTenantId = \"tenant-A\"; // Act await policy ApplyAsync(context); // Assert - No exception thrown } } ` --- Code Coverage Measure code coverage: `bash dotnet test --collect:\"XPlat Code Coverage\" ` Generate HTML report: `bash dotnet tool install -g dotnet-reportgenerator-globaltool reportgenerator \\ -reports:\"/coverage cobertura xml\" \\ -targetdir:\"coverage-report\" \\ -reporttypes:Html open coverage-report/index html\n`\nTarget coverage:\nReceptors: 100% (critical business logic)\nPerspectives: 100% (data consistency)\nPolicies: 100% (security/validation)\nInfrastructure: 80%+ (lower priority)\n---\nKey Takeaways\n‚úÖ TUnit - Modern source-generation test framework\n‚úÖ Rocks - AOT-compatible mocking with source generators\n‚úÖ Bogus - Generate realistic test data\n‚úÖ Testcontainers - Docker-based integration tests\n‚úÖ 100% Coverage - All receptors, perspectives, policies\n‚úÖ Parameterized Tests - Test multiple scenarios efficiently\n‚úÖ Async Testing - Proper async/await patterns\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15934,
        "preview": "CurrentTenantId = \"tenant-A\"; // Act await policy ApplyAsync(context); // Assert - No exception thrown } } ` --- Code Coverage Measure code coverage: ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/advanced-topics/troubleshooting",
    "title": "Troubleshooting Guide",
    "category": "Advanced Topics",
    "url": "/docs/v0.1.0/advanced-topics/troubleshooting",
    "chunks": [
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-0",
        "text": "Troubleshooting Guide\nComprehensive troubleshooting guide for Whizbang applications - common issues, debugging techniques, diagnostic tools, and step-by-step solutions ---\nCommon Issues\n| Issue | Symptom | Root Cause | Solution |\n|-------|---------|------------|----------|\n| No Handler Found | InvalidOperationException | Missing receptor registration | Check DI registration |\n| Message Not Published | Events not reaching subscribers | Outbox stuck | Check outbox worker |\n| Duplicate Processing | Message handled twice | Inbox not working | Check inbox deduplication |\n| High Latency | Slow responses | Database query | Add indexes |\n| Memory Leak | Memory grows indefinitely | Unclosed connections | Use await using |\n---\nIssue 1: No Handler Found\nSymptom\n`\nSystem InvalidOperationException: No handler registered for CreateOrder\n`\nDiagnosis\n`csharp\n// Check DI container\nvar dispatcher = serviceProvider GetService<IDispatcher>();\nvar receptor = serviceProvider GetService<IReceptor<CreateOrder, OrderCreated>>();\nif (receptor is null) {\n  Console WriteLine(\"ERROR: Receptor not registered \");\n}\n`\nSolution 1: Missing DI Registration\nProblem:\n`csharp\n// ‚ùå Receptor not registered\nbuilder Services AddSingleton<IDispatcher, GeneratedDispatcher>();\n`\nFix:\n`csharp\n// ‚úÖ Register receptor\nbuilder Services AddSingleton<IDispatcher, GeneratedDispatcher>();\nbuilder Services AddSingleton<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n`\nSolution 2: Use Source-Generated Registration\nWhizbang ReceptorDiscoveryGenerator automatically generates DI registrations:\n`csharp\n// Generated by Whizbang Generators ReceptorDiscoveryGenerator\nbuilder Services AddGeneratedReceptors();  // Registers all receptors\n`\n---\nIssue 2: Message Not Published\nSymptom\nEvents not reaching subscribers (no errors in logs) Diagnosis\n`sql\n-- Check outbox backlog\nSELECT COUNT(*) FROM outbox WHERE processed_at IS NULL;\n-- If count > 0, outbox worker is stuck\n`\nSolution 1: Outbox Worker Not Running\nProblem: Outbox worker background service not registered Fix:\n`csharp\nbuilder Services AddHostedService<OutboxWorker>();\n`\nSolution 2: Database Transaction Not Committed\nProblem:\n`csharp\n// ‚ùå Transaction never committed\nawait using var tx = await _db BeginTransactionAsync(ct);\nawait _db ExecuteAsync(\"INSERT INTO orders (",
        "startIndex": 0,
        "preview": "Troubleshooting Guide\nComprehensive troubleshooting guide for Whizbang applications - common issues, debugging techniques, diagnostic tools, and step-..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-1",
        "text": "worker is stuck ` Solution 1: Outbox Worker Not Running Problem: Outbox worker background service not registered Fix: `csharp builder Services AddHostedService<OutboxWorker>(); ` Solution 2: Database Transaction Not Committed Problem: `csharp // ‚ùå Transaction never committed await using var tx = await _db BeginTransactionAsync(ct); await _db ExecuteAsync(\"INSERT INTO orders ( )\", transaction: tx);\nawait _db ExecuteAsync(\"INSERT INTO outbox ( )\", transaction: tx);\n// Missing: await tx CommitAsync(ct);\n`\nFix:\n`csharp\n// ‚úÖ Always commit transaction\nawait using var tx = await _db BeginTransactionAsync(ct);\ntry {\n  await _db ExecuteAsync(\"INSERT INTO orders ( )\", transaction: tx);\n  await _db ExecuteAsync(\"INSERT INTO outbox ( )\", transaction: tx);\n  await tx CommitAsync(ct);  // ‚úÖ Commit\n} catch {\n  await tx RollbackAsync(ct);\n  throw;\n}\n`\nSolution 3: Service Bus Connection String Wrong\nProblem: Wrong connection string or permissions Diagnosis:\n`bash\nTest Service Bus connection\ncurl -X POST https://myservicebus servicebus windows net/orders/messages \\\n  -H \"Authorization: SharedAccessSignature \" \\\n  -d '{\"test\": true}'\n`\nFix:\n`json\n{\n  \"AzureServiceBus\": {\n    \"ConnectionString\": \"Endpoint=sb://myservicebus servicebus windows net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=*\"\n  }\n}\n`\n---\nIssue 3: Duplicate Processing\nSymptom\nMessage handled twice (duplicate database inserts) Diagnosis\n`sql\n-- Check inbox for duplicate messages\nSELECT message_id, COUNT(*) AS count\nFROM inbox\nGROUP BY message_id\nHAVING COUNT(*) > 1;\n`\nSolution 1: Inbox Not Implemented\nProblem: No inbox deduplication Fix: Implement inbox pattern:\n`csharp\npublic async Task HandleAsync(OrderCreated @event, CancellationToken ct) {\n  await using var tx = await _db BeginTransactionAsync(ct);\n  try {\n    // 1 Check inbox (deduplication)\n    var exists = await _db ExecuteScalarAsync<bool>(\n      \"SELECT EXISTS(SELECT 1 FROM inbox WHERE message_id = @MessageId)\",\n      new { MessageId = @event MessageId },\n      transaction: tx\n    );\n    if (exists) {\n      _logger LogWarning(\"Message {MessageId} already processed (duplicate)\", @event MessageId);\n      await tx CommitAsync(ct);\n      return;  // ‚úÖ Skip duplicate\n    }\n    // 2 Process message\n    await _db ExecuteAsync(\"UPDATE order_summary SET \", transaction: tx);\n    // 3",
        "startIndex": 2317,
        "preview": "worker is stuck ` Solution 1: Outbox Worker Not Running Problem: Outbox worker background service not registered Fix: `csharp builder Services AddHost..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-2",
        "text": "FROM inbox WHERE message_id = @MessageId)\", new { MessageId = @event MessageId }, transaction: tx ); if (exists) { _logger LogWarning(\"Message {MessageId} already processed (duplicate)\", @event MessageId); await tx CommitAsync(ct); return; // ‚úÖ Skip duplicate } // 2 Process message await _db ExecuteAsync(\"UPDATE order_summary SET \", transaction: tx); // 3 Record in inbox\n    await _db ExecuteAsync(\n      \"INSERT INTO inbox (message_id, processed_at) VALUES (@MessageId, NOW())\",\n      new { MessageId = @event MessageId },\n      transaction: tx\n    );\n    await tx CommitAsync(ct);\n  } catch {\n    await tx RollbackAsync(ct);\n    throw;\n  }\n}\n`\nSolution 2: Service Bus PeekLock Not Used\nProblem: Using ReceiveAndDelete mode (at-most-once delivery) Fix: Use PeekLock mode (at-least-once delivery):\n`csharp\nvar processor = client CreateProcessor(\"orders\", new ServiceBusProcessorOptions {\n  ReceiveMode = ServiceBusReceiveMode PeekLock,  // ‚úÖ Use PeekLock\n  MaxConcurrentCalls = 10\n});\n`\n---\nIssue 4: High Latency\nSymptom\nAPI responses taking > 1 second Diagnosis\nApplication Insights query:\n`kusto\nrequests\n| where timestamp > ago(1h)\n| summarize p95 = percentile(duration, 95) by name\n| where p95 > 1000  // > 1 second\n| order by p95 desc\n`\nPostgreSQL slow query log:\n`sql\n-- Enable slow query log\nALTER DATABASE orders SET log_min_duration_statement = 1000;  -- Log queries > 1s\n-- View slow queries\nSELECT query, mean_exec_time, calls\nFROM pg_stat_statements\nWHERE mean_exec_time > 1000\nORDER BY mean_exec_time DESC\nLIMIT 10;\n`\nSolution 1: Missing Index\nProblem: Full table scan on large table Diagnosis:\n`sql\nEXPLAIN ANALYZE\nSELECT * FROM orders WHERE customer_id = 'cust-123';\n-- Output:\n-- Seq Scan on orders (cost=0 00 100000 00 rows=1 width=100)\n-- Planning Time: 0 5 ms\n-- Execution Time: 1234 5 ms\n`\nFix: Add index:\n`sql\nCREATE INDEX idx_orders_customer_id ON orders(customer_id);\n-- After index:\n-- Index Scan using idx_orders_customer_id (cost=0 29 8 31 rows=1 width=100)\n-- Planning Time: 0 5 ms\n-- Execution Time: 1",
        "startIndex": 4293,
        "preview": "FROM inbox WHERE message_id = @MessageId)\", new { MessageId = @event MessageId }, transaction: tx ); if (exists) { _logger LogWarning(\"Message {Messag..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-3",
        "text": "100000 00 rows=1 width=100) -- Planning Time: 0 5 ms -- Execution Time: 1234 5 ms ` Fix: Add index: `sql CREATE INDEX idx_orders_customer_id ON orders(customer_id); -- After index: -- Index Scan using idx_orders_customer_id (cost=0 29 8 31 rows=1 width=100) -- Planning Time: 0 5 ms -- Execution Time: 1 2 ms\n`\nSolution 2: N+1 Query Problem\nProblem:\n`csharp\n// ‚ùå N+1 queries (1 for orders, N for items)\nvar orders = await _db QueryAsync<OrderRow>(\"SELECT * FROM orders WHERE customer_id = @CustomerId\");\nforeach (var order in orders) {\n  order Items = await _db QueryAsync<OrderItemRow>(\n    \"SELECT * FROM order_items WHERE order_id = @OrderId\",\n    new { OrderId = order OrderId }\n  );\n}\n`\nFix: Use JOIN or batch query:\n`csharp\n// ‚úÖ Single query with JOIN\nvar orders = await _db QueryAsync<OrderRow, OrderItemRow, OrderRow>(\n  \"\"\"\n  SELECT o , i FROM orders o\n  LEFT JOIN order_items i ON o order_id = i order_id\n  WHERE o customer_id = @CustomerId\n  \"\"\",\n  (order, item) => {\n    order Items Add(item);\n    return order;\n  },\n  new { CustomerId = customerId }\n);\n`\n---\nIssue 5: Memory Leak\nSymptom\nMemory usage grows indefinitely, eventually causing OOM Diagnosis\ndotnet-counters:\n`bash\ndotnet-counters monitor --process-id 1234 System Runtime\nOutput:\n[System Runtime]\nGC Heap Size (MB)                      500 -> 1000 -> 1500 -> 2000 (growing)\nGen 0 GC Count                         1000\nGen 1 GC Count                         100\nGen 2 GC Count                         10\n`\ndotnet-gcdump:\n`bash\ndotnet-gcdump collect --process-id 1234\ndotnet-gcdump report gcdump_20250101_123456\n`\nSolution 1: Unclosed Connections\nProblem:\n`csharp\n// ‚ùå Connection not disposed\nvar connection = new NpgsqlConnection(connectionString);\nawait connection OpenAsync();\n// Process data // Missing: await connection DisposeAsync();\n`\nFix:\n`csharp\n// ‚úÖ Use await using\nawait using var connection = new NpgsqlConnection(connectionString);\nawait connection OpenAsync();\n// Process data",
        "startIndex": 5973,
        "preview": "100000 00 rows=1 width=100) -- Planning Time: 0 5 ms -- Execution Time: 1234 5 ms ` Fix: Add index: `sql CREATE INDEX idx_orders_customer_id ON orders..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-4",
        "text": "gcdump_20250101_123456 ` Solution 1: Unclosed Connections Problem: `csharp // ‚ùå Connection not disposed var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(); // Process data // Missing: await connection DisposeAsync(); ` Fix: `csharp // ‚úÖ Use await using await using var connection = new NpgsqlConnection(connectionString); await connection OpenAsync(); // Process data // Automatically disposed\n`\nSolution 2: Event Handler Not Unsubscribed\nProblem:\n`csharp\n// ‚ùå Event handler keeps object alive\npublic class OrderProcessor {\n  public OrderProcessor(IEventBus eventBus) {\n    eventBus OrderCreated += HandleOrderCreated;  // Never unsubscribed\n  }\n  private void HandleOrderCreated(OrderCreated @event) {\n    // Process order }\n}\n`\nFix:\n`csharp\n// ‚úÖ Unsubscribe when disposed\npublic class OrderProcessor : IDisposable {\n  private readonly IEventBus _eventBus;\n  public OrderProcessor(IEventBus eventBus) {\n    _eventBus = eventBus;\n    _eventBus OrderCreated += HandleOrderCreated;\n  }\n  public void Dispose() {\n    _eventBus OrderCreated -= HandleOrderCreated;  // ‚úÖ Unsubscribe\n  }\n}\n`\n---\nDebugging Techniques\nEnable Detailed Logging\nappsettings Development json:\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Debug\",\n      \"Microsoft\": \"Information\",\n      \"Whizbang\": \"Trace\"\n    }\n  }\n}\n`\nUse Correlation IDs\n`csharp\npublic class CorrelationIdMiddleware {\n  private readonly RequestDelegate _next;\n  public async Task InvokeAsync(HttpContext context) {\n    var correlationId = context Request Headers[\"X-Correlation-ID\"] FirstOrDefault() Guid NewGuid() ToString();\n    context Response Headers Add(\"X-Correlation-ID\", correlationId);\n    using (_logger BeginScope(new Dictionary<string, object> {\n      [\"CorrelationId\"] = correlationId\n    })) {\n      await _next(context);\n    }\n  }\n}\n`\nApplication Insights query:\n`kusto\ntraces\n| where customDimensions CorrelationId == \"abc-123\"\n| order by timestamp asc\n`\nSQL Query Logging\nProgram cs:\n`csharp\nbuilder Logging AddFilter(\"Microsoft EntityFrameworkCore Database Command\", LogLevel Information);\n`\nOutput:\n`\nExecuted DbCommand (123ms) [Parameters=[@CustomerId='cust-123'], CommandType='Text', CommandTimeout='30']\nSELECT * FROM orders WHERE customer_id = @CustomerId\n`\nDistributed Tracing\nView trace in Application Insights:\n`kusto\ndependencies\n| where operation_Id == \"abc-123\"\n| project timestamp, target, name, duration\n| order by timestamp asc\n// Output:\n// timestamp                 target                    name                  duration\n// 2025-01-01 12:00:00 000   postgres",
        "startIndex": 7644,
        "preview": "gcdump_20250101_123456 ` Solution 1: Unclosed Connections Problem: `csharp // ‚ùå Connection not disposed var connection = new NpgsqlConnection(connecti..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-5",
        "text": "(123ms) [Parameters=[@CustomerId='cust-123'], CommandType='Text', CommandTimeout='30'] SELECT * FROM orders WHERE customer_id = @CustomerId ` Distributed Tracing View trace in Application Insights: `kusto dependencies | where operation_Id == \"abc-123\" | project timestamp, target, name, duration | order by timestamp asc // Output: // timestamp target name duration // 2025-01-01 12:00:00 000 postgres myapp com        SELECT * FROM orders  123ms\n// 2025-01-01 12:00:00 150   servicebus windows net    Send message          45ms\n`\n---\nDiagnostic Tools\ndotnet-counters (Live Metrics)\n`bash\nMonitor live counters\ndotnet-counters monitor --process-id 1234\nOutput:\n[System Runtime]\nCPU Usage (%)                          45\nGC Heap Size (MB)                      256\nGen 0 GC Count                         100\nGen 1 GC Count                         10\nGen 2 GC Count                         1\nException Count                        5\nThreadPool Thread Count                25\n`\ndotnet-trace (Performance Profiling)\n`bash\nCollect trace\ndotnet-trace collect --process-id 1234 --profile cpu-sampling\nConvert to speedscope format\ndotnet-trace convert trace nettrace --format speedscope\nOpen in speedscope app\n`\ndotnet-dump (Memory Analysis)\n`bash\nCapture memory dump\ndotnet-dump collect --process-id 1234\nAnalyze dump\ndotnet-dump analyze dump_20250101_123456\nCommands:\n> dumpheap -stat        Object statistics\n> gcroot <address>      GC root analysis\n> dumpheap -mt <type>   Objects of specific type\n`\nkubectl logs (Kubernetes)\n`bash\nView logs\nkubectl logs order-service-abc123\nFollow logs\nkubectl logs -f order-service-abc123\nView logs from all pods\nkubectl logs -l app=order-service --tail=100\nView logs from previous pod (after crash)\nkubectl logs order-service-abc123 --previous\n`\nkubectl exec (Shell Access)\n`bash\nExecute command in pod\nkubectl exec order-service-abc123 -- ps aux\nInteractive shell\nkubectl exec -it order-service-abc123 -- /bin/bash\nTest database connectivity\nkubectl exec order-service-abc123 -- psql $DATABASE_URL -c \"SELECT 1\"\n`\n---\nPerformance Profiling\nBenchmarkDotNet\nCreateOrderBenchmark cs:\n`csharp\nusing BenchmarkDotNet Attributes;\nusing BenchmarkDotNet Running;\n[MemoryDiagnoser]\n[SimpleJob(warmupCount: 3, iterationCount: 10)]\npublic class CreateOrderBenchmark {\n  [Benchmark]\n  public async Task<OrderCreated> CreateOrder() {\n    return await _receptor",
        "startIndex": 9841,
        "preview": "(123ms) [Parameters=[@CustomerId='cust-123'], CommandType='Text', CommandTimeout='30'] SELECT * FROM orders WHERE customer_id = @CustomerId ` Distribu..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-6",
        "text": "kubectl exec -it order-service-abc123 -- /bin/bash Test database connectivity kubectl exec order-service-abc123 -- psql $DATABASE_URL -c \"SELECT 1\" ` --- Performance Profiling BenchmarkDotNet CreateOrderBenchmark cs: `csharp using BenchmarkDotNet Attributes; using BenchmarkDotNet Running; [MemoryDiagnoser] [SimpleJob(warmupCount: 3, iterationCount: 10)] public class CreateOrderBenchmark { [Benchmark] public async Task<OrderCreated> CreateOrder() { return await _receptor HandleAsync(_command);\n  }\n}\n`\nRun:\n`bash\ndotnet run -c Release --project Benchmarks\nOutput:\n| Method      | Mean     | Error   | StdDev | Allocated |\n|------------ |---------:|--------:|-------:|----------:|\n| CreateOrder | 125 3 Œºs | 2 34 Œºs | 2 19 Œºs |     512 B |\n`\nPerfView (Windows)\n`bash\nCollect CPU samples\nPerfView exe collect /MaxCollectSec:30 /Zip:true\nAnalyze trace\nPerfView exe trace etl\n`\n---\nHealth Check Diagnostics\nCheck Health Endpoint\n`bash\ncurl https://order-service myapp com/health\nOutput:\n{\n\"status\": \"Unhealthy\",\n\"results\": {\n\"database\": { \"status\": \"Healthy\" },\n\"servicebus\": { \"status\": \"Unhealthy\", \"description\": \"Connection failed\" }\n}\n}\n`\nCustom Health Check\n`csharp\npublic class OutboxHealthCheck : IHealthCheck {\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    var backlog = await _db ExecuteScalarAsync<int>(\n      \"SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL\"\n    );\n    if (backlog > 10000) {\n      return HealthCheckResult Degraded(\n        $\"Outbox backlog is {backlog} messages\",\n        data: new Dictionary<string, object> { [\"backlog\"] = backlog }\n      );\n    }\n    return HealthCheckResult",
        "startIndex": 11819,
        "preview": "kubectl exec -it order-service-abc123 -- /bin/bash Test database connectivity kubectl exec order-service-abc123 -- psql $DATABASE_URL -c \"SELECT 1\" ` ..."
      },
      {
        "id": "v0.1.0/advanced-topics/troubleshooting-chunk-7",
        "text": "CheckHealthAsync( HealthCheckContext context, CancellationToken ct = default ) { var backlog = await _db ExecuteScalarAsync<int>( \"SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL\" ); if (backlog > 10000) { return HealthCheckResult Degraded( $\"Outbox backlog is {backlog} messages\", data: new Dictionary<string, object> { [\"backlog\"] = backlog } ); } return HealthCheckResult Healthy();\n  }\n}\n`\n---\nKey Takeaways\n‚úÖ No Handler Found - Check DI registration or use source-generated AddGeneratedReceptors()\n‚úÖ Message Not Published - Check outbox worker, transaction commit, Service Bus connection\n‚úÖ Duplicate Processing - Implement inbox pattern for idempotency\n‚úÖ High Latency - Add database indexes, avoid N+1 queries\n‚úÖ Memory Leak - Use await using for connections, unsubscribe event handlers\n‚úÖ Diagnostic Tools - dotnet-counters, dotnet-trace, dotnet-dump, kubectl logs\n---\nTroubleshooting Checklist\n[ ] Check logs in Application Insights or Kubernetes\n[ ] Verify DI registrations (receptors, perspectives, policies)\n[ ] Check database connectivity and connection string\n[ ] Verify Service Bus connection and permissions\n[ ] Check outbox/inbox tables for backlog\n[ ] Review slow query log in PostgreSQL\n[ ] Monitor metrics (CPU, memory, request rate, error rate)\n[ ] Use correlation IDs to trace requests across services\n[ ] Profile with dotnet-trace or BenchmarkDotNet\n[ ] Check health endpoints for service status\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 13049,
        "preview": "CheckHealthAsync( HealthCheckContext context, CancellationToken ct = default ) { var backlog = await _db ExecuteScalarAsync<int>( \"SELECT COUNT(*) FRO..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/README",
    "title": "Core Components Overview",
    "category": "Components",
    "url": "/docs/v0.1.0/components/README",
    "chunks": [
      {
        "id": "v0.1.0/components/README-chunk-0",
        "text": "Core Components Overview\nComponent Architecture\nAll components in Whizbang v0 1 0 work together to provide a complete message-driven architecture Each component has a specific responsibility and clean interface `mermaid\ngraph LR\n    CMD[Command] --> D[Dispatcher]\n    D --> R[Receptor]\n    R --> E[Event]\n    E --> D\n    D --> P[Perspectives]\n    P --> S[(Storage)]\n    Q[Query] --> L[Lens]\n    L --> S\n    POL[Policies] - ->|Wrap| R\n    POL - ->|Wrap| P\n    style CMD fill:#e3f2fd\n    style E fill:#fff3e0\n    style Q fill:#f3e5f5\n`\nComponent Responsibilities\nMessage Flow Components\n| Component | Responsibility | Interface |\n|-----------|---------------|-----------|\n| Dispatcher | Routes all messages | IDispatcher |\n| Receptors | Receive messages, make decisions | IReceptor<T, R> |\n| Perspectives | React to events, update state | IPerspectiveOf<T> |\n| Lenses | Provide read-only queries | ILens |\nInfrastructure Components\n| Component | Responsibility | Interface |\n|-----------|---------------|-----------|\n| Policy Engine | Cross-cutting concerns | IPolicyOf<T> |\n| Ledger | Event storage abstraction | ILedger |\n| Drivers | Database abstraction | IDriver |\n| Transports | Message broker abstraction | ITransport |\nIn-Memory Implementations\nIn v0 1 0, all components have in-memory implementations:\n`csharp\nservices AddWhizbang(options => {\n    options",
        "startIndex": 0,
        "preview": "Core Components Overview\nComponent Architecture\nAll components in Whizbang v0 1 0 work together to provide a complete message-driven architecture Each..."
      },
      {
        "id": "v0.1.0/components/README-chunk-1",
        "text": "Engine | Cross-cutting concerns | IPolicyOf<T> | | Ledger | Event storage abstraction | ILedger | | Drivers | Database abstraction | IDriver | | Transports | Message broker abstraction | ITransport | In-Memory Implementations In v0 1 0, all components have in-memory implementations: `csharp services AddWhizbang(options => { options UseInMemory();  // Configures all in-memory implementations\n});\n`\nThis configures:\nInMemoryDispatcher - Routes messages via dictionary\nInMemoryLedger - Stores events in lists\nInMemoryDriver - Stores data in dictionaries\nInMemoryTransport - Pub/sub via event handlers\nComponent Interaction\nCommand Processing Flow\nCommand submitted to Dispatcher\nDispatcher routes to appropriate Receptor\nReceptor validates and makes decision\nReceptor returns Event(s)\nDispatcher publishes events to Perspectives\nPerspectives update their state\nQuery Processing Flow\nQuery request made\nDispatcher provides appropriate Lens\nLens queries underlying storage\nResults returned to caller\nPolicy Application\nPolicies wrap component execution:\n`csharp\n[Retry(3)]\n[Timeout(5000)]\npublic class PaymentReceptor : IReceptor<ProcessPayment> {\n    // Policies applied automatically via source generation\n}\n`\nComponent Discovery\nAll components are discovered at compile time:\n`csharp\n[WhizbangHandler]  // Source generator finds this\npublic class OrderReceptor : IReceptor<CreateOrder> { }\n[WhizbangHandler]  // And this\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> { }\n[WhizbangLens]  // And this\npublic class OrderLens : IOrderLens { }\n`\nComponent Registration\nSource generators create registration code:\n`csharp\n// Generated code\npublic static class WhizbangGenerated {\n    public static void RegisterHandlers(IServiceCollection services) {\n        services AddScoped<IReceptor<CreateOrder>, OrderReceptor>();\n        services AddScoped<IPerspectiveOf<OrderCreated>, OrderPerspective>();\n        services AddScoped<IOrderLens, OrderLens>();\n        // all discovered components\n    }\n}\n`\nComponent Testing\nAll components are testable via in-memory implementations:\n`csharp\n[Test]\npublic async Task TestOrderFlow() {\n    var dispatcher = new InMemoryDispatcher();\n    var ledger = new InMemoryLedger();\n    // Register components\n    dispatcher Register(new OrderReceptor());\n    dispatcher Register(new OrderPerspective());\n    // Test command flow\n    var result = await dispatcher Send(new CreateOrder( ));\n    // Verify\n    Assert",
        "startIndex": 1364,
        "preview": "Engine | Cross-cutting concerns | IPolicyOf<T> | | Ledger | Event storage abstraction | ILedger | | Drivers | Database abstraction | IDriver | | Trans..."
      },
      {
        "id": "v0.1.0/components/README-chunk-2",
        "text": "Component Testing All components are testable via in-memory implementations: `csharp [Test] public async Task TestOrderFlow() { var dispatcher = new InMemoryDispatcher(); var ledger = new InMemoryLedger(); // Register components dispatcher Register(new OrderReceptor()); dispatcher Register(new OrderPerspective()); // Test command flow var result = await dispatcher Send(new CreateOrder( )); // Verify Assert IsType<OrderCreated>(result);\n}\n`\nComponent Guidelines\nInterface Segregation\nEach component has a focused interface with single responsibility Dependency Injection\nAll components are registered in DI container and resolved automatically Testability\nEvery component can be tested in isolation using in-memory implementations Extensibility\nNew components can be added by implementing the appropriate interface Navigation\nDetailed Documentation\nDispatcher - Message routing\nReceptors - Command handling\nPerspectives - Event handling\nLenses - Queries\nPolicy Engine - Cross-cutting concerns\nLedger - Event storage\nDrivers - Database abstraction\nTransports - Messaging abstraction",
        "startIndex": 3490,
        "preview": "Component Testing All components are testable via in-memory implementations: `csharp [Test] public async Task TestOrderFlow() { var dispatcher = new I..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/dispatcher",
    "title": "Dispatcher Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/dispatcher",
    "chunks": [
      {
        "id": "v0.1.0/components/dispatcher-chunk-0",
        "text": "Dispatcher Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic message dispatcher with handler discovery and in-process routing\n:::\n:::planned\nComing in v0 2 0: \nPipeline middleware support\nHandler prioritization\nParallel execution\nSee pipeline features ‚Üí\n:::\n:::planned\nComing in v0 3 0: \nSaga orchestration\nWorkflow support\nCompensation patterns\nSee orchestration features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>Basic<br/>Routing] --> v020[v0 2 0<br/>Pipeline<br/>Middleware]\n    v020 --> v030[v0 3 0<br/>Saga<br/>Workflows]\n    v030 --> v040[v0 4 0<br/>Streaming<br/>Reactive]\n    v040 --> v050[v0 5 0<br/>Distributed<br/>Orchestration]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nThe Dispatcher is the heart of Whizbang - it routes messages to handlers, orchestrates component interactions, and ensures proper execution flow In v0 1 0, it provides basic handler discovery and routing with support for commands, events, and queries What is a Dispatcher A Dispatcher:\nRoutes messages to appropriate handlers\nOrchestrates component interactions\nManages execution flow and dependencies\nCoordinates between receptors, perspectives, and lenses\nThink of the dispatcher as the conductor of an orchestra - it ensures each component plays its part at the right time Core Interface (v0 1",
        "startIndex": 0,
        "preview": "Dispatcher Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic message dispatcher with handler discovery and in-process r..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-1",
        "text": "is a Dispatcher A Dispatcher: Routes messages to appropriate handlers Orchestrates component interactions Manages execution flow and dependencies Coordinates between receptors, perspectives, and lenses Think of the dispatcher as the conductor of an orchestra - it ensures each component plays its part at the right time Core Interface (v0 1 0)\n:::new\nThe fundamental dispatcher interface with three distinct patterns:\n:::\n`csharp\npublic interface IDispatcher {\n    // Send command - returns delivery receipt (can work over wire)\n    Task<IDeliveryReceipt> SendAsync(object message);\n    Task<IDeliveryReceipt> SendAsync(object message, IMessageContext context);\n    // Local invocation - returns typed result (in-process only, zero allocation)\n    Task<TResult> LocalInvokeAsync<TResult>(object message);\n    Task<TResult> LocalInvokeAsync<TResult>(object message, IMessageContext context);\n    // Publish event to all interested perspectives (fire-and-forget)\n    Task PublishAsync<TEvent>(TEvent @event);\n    // Batch operations\n    Task<IEnumerable<IDeliveryReceipt>> SendManyAsync(IEnumerable<object> messages);\n    Task<IEnumerable<TResult>> LocalInvokeManyAsync<TResult>(IEnumerable<object> messages);\n}\n`\nThree Dispatch Patterns\nSendAsync - Command Dispatch with Acknowledgment\nUse when: Sending commands that may execute remotely or asynchronously\n`csharp\n// Returns delivery receipt, not business result\nvar receipt = await dispatcher SendAsync(new ProcessOrder(orderId));\n// Receipt contains delivery metadata\nConsole WriteLine($\"Message {receipt MessageId} delivered at {receipt Timestamp}\");\nConsole WriteLine($\"Status: {receipt Status}\"); // Accepted, Queued, Delivered\n`\nCharacteristics:\nReturns IDeliveryReceipt with correlation info\nCan work over network transports (future versions)\nSupports inbox pattern and async workflows\nIncludes full observability envelope\nLocalInvokeAsync - In-Process RPC\nUse when: Calling handlers within the same process and need the business result immediately\n`csharp\n// Returns typed business result\nvar result = await dispatcher LocalInvokeAsync<OrderCreated>(new CreateOrder(items));\n// Access business data directly\nConsole WriteLine($\"Order created: {result",
        "startIndex": 1503,
        "preview": "is a Dispatcher A Dispatcher: Routes messages to appropriate handlers Orchestrates component interactions Manages execution flow and dependencies Coor..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-2",
        "text": "Supports inbox pattern and async workflows Includes full observability envelope LocalInvokeAsync - In-Process RPC Use when: Calling handlers within the same process and need the business result immediately `csharp // Returns typed business result var result = await dispatcher LocalInvokeAsync<OrderCreated>(new CreateOrder(items)); // Access business data directly Console WriteLine($\"Order created: {result OrderId}\");\n`\nCharacteristics:\nReturns strongly-typed business result\nIn-process only - throws if used with remote transport\nZero allocation - skips envelope creation for maximum performance\nTarget: < 20ns per invocation, 0 bytes allocated\nIdeal for high-throughput local workflows\nPublishAsync - Event Broadcasting\nUse when: Notifying multiple handlers about an event\n`csharp\n// Fire-and-forget to all subscribers\nawait dispatcher",
        "startIndex": 3371,
        "preview": "Supports inbox pattern and async workflows Includes full observability envelope LocalInvokeAsync - In-Process RPC Use when: Calling handlers within th..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-3",
        "text": "only - throws if used with remote transport Zero allocation - skips envelope creation for maximum performance Target: < 20ns per invocation, 0 bytes allocated Ideal for high-throughput local workflows PublishAsync - Event Broadcasting Use when: Notifying multiple handlers about an event `csharp // Fire-and-forget to all subscribers await dispatcher PublishAsync(new OrderPlaced(orderId));\n// All perspectives receive the event\n// - OrderPerspective updates order view\n// - InventoryPerspective reserves items\n// - NotificationPerspective sends email\n`\nCharacteristics:\nFire-and-forget semantics\nNo return value\nFans out to all registered handlers\nHandlers execute independently\nWhen To Use Which Pattern\n| Pattern | Use Case | Returns | Can Go Over Wire | Performance Target |\n|---------|----------|---------|------------------|-------------------|\n| SendAsync | Async workflows, remote execution, inbox pattern | Delivery receipt | ‚úÖ Yes (future) | Normal |\n| LocalInvokeAsync | High-throughput local calls, immediate results | Business result | ‚ùå No | < 20ns, 0B |\n| PublishAsync | Event notification, fan-out | void | ‚úÖ Yes (future) | Normal |\nDelivery Receipt\nThe IDeliveryReceipt provides correlation and tracking information:\n`csharp\npublic interface IDeliveryReceipt {\n    MessageId MessageId { get; }         // Unique message identifier\n    DateTimeOffset Timestamp { get; }     // When message was accepted\n    string Destination { get; }           // Where message was routed\n    DeliveryStatus Status { get; }        // Accepted, Queued, Delivered\n    IReadOnlyDictionary<string, object> Metadata { get; } // Extensible data\n}\npublic enum DeliveryStatus {\n    Accepted,   // Message accepted by dispatcher\n    Queued,     // Message queued for async processing\n    Delivered   // Message delivered to handler\n}\n`\nPipeline Behaviors\n:::new\nv0 1 0 introduces pipeline behavior support for cross-cutting concerns:\n:::\nPipeline behaviors allow you to inject middleware-style logic into the dispatch flow",
        "startIndex": 3803,
        "preview": "only - throws if used with remote transport Zero allocation - skips envelope creation for maximum performance Target: < 20ns per invocation, 0 bytes a..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-4",
        "text": "enum DeliveryStatus { Accepted, // Message accepted by dispatcher Queued, // Message queued for async processing Delivered // Message delivered to handler } ` Pipeline Behaviors :::new v0 1 0 introduces pipeline behavior support for cross-cutting concerns: ::: Pipeline behaviors allow you to inject middleware-style logic into the dispatch flow Common use cases include:\nInbox Pattern - De-duplicate messages, ensure idempotency\nValidation - Validate commands before execution\nLogging - Log all messages and results\nRetry Logic - Automatically retry failed operations\nPerformance Monitoring - Track execution times\nTransaction Management - Wrap execution in transactions\nIPipelineBehavior Interface\n`csharp\npublic interface IPipelineBehavior<TRequest, TResponse> {\n    /// <summary>\n    /// Execute behavior and optionally call next in pipeline\n    /// </summary>\n    /// <param name=\"request\">The message being dispatched</param>\n    /// <param name=\"next\">Delegate to invoke next behavior or handler</param>\n    /// <param name=\"cancellationToken\">Cancellation token</param>\n    /// <returns>The response (potentially modified)</returns>\n    Task<TResponse> Handle(\n        TRequest request,\n        Func<Task<TResponse>> next,\n        CancellationToken cancellationToken = default\n    );\n}\n`\nExample: Inbox Pattern Behavior\n`csharp\npublic class InboxBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> {\n    private readonly IInboxStore _inbox;\n    public async Task<TResponse> Handle(\n        TRequest request,\n        Func<Task<TResponse>> next,\n        CancellationToken cancellationToken\n    ) {\n        var messageId = GetMessageId(request);\n        // Check if already processed\n        if (await _inbox HasProcessedAsync(messageId)) {\n            return await _inbox GetResultAsync<TResponse>(messageId);\n        }\n        // Mark as processing\n        await _inbox MarkProcessingAsync(messageId);\n        try {\n            // Execute handler\n            var response = await next();\n            // Store result\n            await _inbox StoreResultAsync(messageId, response);\n            return response;\n        } catch (Exception ex) {\n            await _inbox MarkFailedAsync(messageId, ex);\n            throw;\n        }\n    }\n}\n`\nExample: Validation Behavior\n`csharp\npublic class ValidationBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> {\n    private readonly IValidator<TRequest> _validator;\n    public async Task<TResponse> Handle(\n        TRequest request,\n        Func<Task<TResponse>> next,\n        CancellationToken cancellationToken\n    ) {\n        // Validate request\n        var validationResult = await _validator ValidateAsync(request);\n        if ( validationResult IsValid) {\n            throw new ValidationException(validationResult",
        "startIndex": 5467,
        "preview": "enum DeliveryStatus { Accepted, // Message accepted by dispatcher Queued, // Message queued for async processing Delivered // Message delivered to han..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-5",
        "text": "throw; } } } ` Example: Validation Behavior `csharp public class ValidationBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> { private readonly IValidator<TRequest> _validator; public async Task<TResponse> Handle( TRequest request, Func<Task<TResponse>> next, CancellationToken cancellationToken ) { // Validate request var validationResult = await _validator ValidateAsync(request); if ( validationResult IsValid) { throw new ValidationException(validationResult Errors);\n        }\n        // Continue pipeline\n        return await next();\n    }\n}\n`\nExample: Logging Behavior\n`csharp\npublic class LoggingBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> {\n    private readonly ILogger _logger;\n    public async Task<TResponse> Handle(\n        TRequest request,\n        Func<Task<TResponse>> next,\n        CancellationToken cancellationToken\n    ) {\n        var requestName = typeof(TRequest) Name;\n        _logger LogInformation(\"Handling {Request}\", requestName);\n        var stopwatch = Stopwatch StartNew();\n        try {\n            var response = await next();\n            stopwatch Stop();\n            _logger LogInformation(\n                \"Handled {Request} in {Elapsed}ms\",\n                requestName,\n                stopwatch ElapsedMilliseconds\n            );\n            return response;\n        } catch (Exception ex) {\n            stopwatch Stop();\n            _logger LogError(\n                ex,\n                \"Error handling {Request} after {Elapsed}ms\",\n                requestName,\n                stopwatch ElapsedMilliseconds\n            );\n            throw;\n        }\n    }\n}\n`\nRegistering Behaviors\n`csharp\nservices AddWhizbangDispatcher(dispatcher => {\n    // Behaviors execute in registration order\n    dispatcher AddPipelineBehavior<InboxBehavior<,>>();\n    dispatcher AddPipelineBehavior<ValidationBehavior<,>>();\n    dispatcher AddPipelineBehavior<LoggingBehavior<,>>();\n});\n`\nPerformance Considerations\nPipeline behaviors add overhead to each dispatch:\nTarget: < 5% overhead per behavior\nRecommendation: Keep behaviors lightweight\nOptimization: Use struct-based behaviors where possible\nMonitoring: Track behavior execution times\nIn-Memory Implementation\n`csharp\npublic class InMemoryDispatcher : IDispatcher {\n    private readonly Dictionary<Type, Delegate> _handlers;\n    private readonly Dictionary<Type, List<Delegate>> _eventHandlers;\n    private readonly IServiceProvider _serviceProvider;\n    public InMemoryDispatcher(IServiceProvider serviceProvider) {\n        _serviceProvider = serviceProvider;\n        _handlers = WhizbangGenerated GetCommandHandlers();  // Source-generated\n        _eventHandlers = WhizbangGenerated GetEventHandlers();  // Source-generated\n    }\n    public async Task<TResult> Send<TResult>(ICommand<TResult> command) {\n        var commandType = command GetType();\n        if ( _handlers TryGetValue(commandType, out var handler)) {\n            throw new HandlerNotFoundException(commandType);\n        }\n        // Apply policies (generated code handles this)\n        var receptor = _serviceProvider GetRequiredService(handler Method DeclaringType);\n        var result = await handler",
        "startIndex": 7927,
        "preview": "throw; } } } ` Example: Validation Behavior `csharp public class ValidationBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> { pr..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-6",
        "text": "Source-generated _eventHandlers = WhizbangGenerated GetEventHandlers(); // Source-generated } public async Task<TResult> Send<TResult>(ICommand<TResult> command) { var commandType = command GetType(); if ( _handlers TryGetValue(commandType, out var handler)) { throw new HandlerNotFoundException(commandType); } // Apply policies (generated code handles this) var receptor = _serviceProvider GetRequiredService(handler Method DeclaringType); var result = await handler DynamicInvoke(receptor, command);\n        // If result is an event, publish it\n        if (result is IEvent @event) {\n            await Publish(@event);\n        }\n        return (TResult)result;\n    }\n    public async Task Publish<TEvent>(TEvent @event) {\n        var eventType = @event GetType();\n        if (_eventHandlers TryGetValue(eventType, out var handlers)) {\n            var tasks = handlers Select(async handler => {\n                var perspective = _serviceProvider GetRequiredService(handler Method DeclaringType);\n                await handler DynamicInvoke(perspective, @event);\n            });\n            await Task WhenAll(tasks);\n        }\n    }\n    public TLens GetLens<TLens>() where TLens : ILens {\n        return _serviceProvider GetRequiredService<TLens>();\n    }\n}\n`\nSource-Generated Routing\nThe source generator creates efficient routing tables:\n`csharp\n// Generated by Whizbang Generators\npublic static partial class WhizbangGenerated {\n    public static Dictionary<Type, Delegate> GetCommandHandlers() {\n        return new Dictionary<Type, Delegate> {\n            [typeof(CreateOrder)] = (Func<OrderReceptor, CreateOrder, Task<OrderCreated>>)\n                ((receptor, cmd) => receptor Receive(cmd)),\n            [typeof(CancelOrder)] = (Func<OrderReceptor, CancelOrder, Task<OrderCancelled>>)\n                ((receptor, cmd) => receptor Cancel(cmd)),\n            // all discovered handlers\n        };\n    }\n    public static Dictionary<Type, List<Delegate>> GetEventHandlers() {\n        return new Dictionary<Type, List<Delegate>> {\n            [typeof(OrderCreated)] = new List<Delegate> {\n                (Func<OrderPerspective, OrderCreated, Task>)\n                    ((perspective, e) => perspective Update(e)),\n                (Func<InventoryPerspective, OrderCreated, Task>)\n                    ((perspective, e) => perspective Update(e)),\n            },\n            // all discovered event handlers\n        };\n    }\n}\n`\nMessage Context\nEvery message carries context for traceability:\n`csharp\npublic class MessageContext : IMessageContext {\n    public Guid MessageId { get; init; } = Guid NewGuid();\n    public Guid CorrelationId { get; init; }\n    public Guid CausationId { get; init; }\n    public DateTimeOffset Timestamp { get; init; } = DateTimeOffset UtcNow();\n    public string UserId { get; init; }\n    public Dictionary<string, object> Metadata { get; init; } = new();\n    public ISpan",
        "startIndex": 10637,
        "preview": "Source-generated _eventHandlers = WhizbangGenerated GetEventHandlers(); // Source-generated } public async Task<TResult> Send<TResult>(ICommand<TResul..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-7",
        "text": "{ get; init; } = Guid NewGuid(); public Guid CorrelationId { get; init; } public Guid CausationId { get; init; } public DateTimeOffset Timestamp { get; init; } = DateTimeOffset UtcNow(); public string UserId { get; init; } public Dictionary<string, object> Metadata { get; init; } = new(); public ISpan Span { get; init; }  // OpenTelemetry span\n}\n`\nPolicy Application\nThe dispatcher applies policies through generated decorators:\n`csharp\n// Source-generated decorator for policies\npublic class PolicyAwareDispatcher : IDispatcher {\n    private readonly IDispatcher _inner;\n    private readonly IPolicyEngine _policies;\n    public async Task<TResult> Send<TResult>(ICommand<TResult> command) {\n        // Get policies for this command type (compile-time determined)\n        var policies = WhizbangGenerated GetPoliciesFor(command GetType());\n        // Apply policies in order\n        return await _policies Execute(policies, async () => {\n            return await _inner Send(command);\n        });\n    }\n}\n`\nTraceability Integration\nThe dispatcher provides hooks for traceability:\n`csharp\npublic class TraceableDispatcher : IDispatcher {\n    private readonly IDispatcher _inner;\n    private readonly ITraceabilityService _traceability;\n    public async Task<TResult> Send<TResult>(ICommand<TResult> command) {\n        var span = _traceability StartSpan($\"Send {command GetType() Name}\");\n        try {\n            var result = await _inner Send(command);\n            _traceability RecordSuccess(span, command, result);\n            // Update IDE overlay\n            _traceability UpdateOverlay(command GetType(), result GetType());\n            return result;\n        }\n        catch (Exception ex) {\n            _traceability RecordError(span, command, ex);\n            throw;\n        }\n        finally {\n            span End();\n        }\n    }\n}\n`\nError Handling\nThe dispatcher provides comprehensive error information:\n`csharp\npublic class HandlerNotFoundException : Exception {\n    public Type CommandType { get; }\n    public HandlerNotFoundException(Type commandType) \n        : base(FormatMessage(commandType)) {\n        CommandType = commandType;\n    }\n    private static string FormatMessage(Type commandType) {\n        return $@\"\nNo handler found for command '{commandType Name}' To fix this:\nCreate a receptor that implements IReceptor<{commandType Name}>\nAdd the [WhizbangHandler] attribute to the receptor\nEnsure the receptor is in a scanned assembly\nExample:\n[WhizbangHandler]\npublic class {commandType Name Replace(\"Command\", \"\")}Receptor : IReceptor<{commandType Name}, {commandType Name Replace(\"Command\", \"\")}Result> {{\n    public async Task<{commandType",
        "startIndex": 13080,
        "preview": "{ get; init; } = Guid NewGuid(); public Guid CorrelationId { get; init; } public Guid CausationId { get; init; } public DateTimeOffset Timestamp { get..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-8",
        "text": "handler found for command '{commandType Name}' To fix this: Create a receptor that implements IReceptor<{commandType Name}> Add the [WhizbangHandler] attribute to the receptor Ensure the receptor is in a scanned assembly Example: [WhizbangHandler] public class {commandType Name Replace(\"Command\", \"\")}Receptor : IReceptor<{commandType Name}, {commandType Name Replace(\"Command\", \"\")}Result> {{ public async Task<{commandType Name Replace(\"Command\", \"\")}Result> Receive({commandType Name} command) {{\n        // Handle command\n    }}\n}}\nQuick Fix: Press Ctrl+ to generate the handler automatically \";\n    }\n}\n`\nConfiguration\n`csharp\npublic class DispatcherOptions {\n    /// <summary>\n    /// Maximum time to wait for a handler (milliseconds)\n    /// </summary>\n    public int DefaultTimeout { get; set; } = 30000;\n    /// <summary>\n    /// Enable parallel event publishing\n    /// </summary>\n    public bool ParallelEventPublishing { get; set; } = true;\n    /// <summary>\n    /// Maximum degree of parallelism for events\n    /// </summary>\n    public int MaxEventParallelism { get; set; } = 10;\n    /// <summary>\n    /// Enable traceability hooks\n    /// </summary>\n    public bool EnableTraceability { get; set; } = true;\n    /// <summary>\n    /// Record performance metrics\n    /// </summary>\n    public bool EnableMetrics { get; set; } = true;\n}\n`\nTesting\n`csharp\n[Test]\npublic class DispatcherTests {\n    private IDispatcher _dispatcher;\n    [SetUp]\n    public void Setup() {\n        var services = new ServiceCollection();\n        services AddWhizbang(o => o UseInMemory());\n        var provider = services BuildServiceProvider();\n        _dispatcher = provider GetRequiredService<IDispatcher>();\n    }\n    [Test]\n    public async Task Send_Command_Should_Return_Result() {\n        // Arrange\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            Items: new[] { new OrderItem(\"SKU-001\", 2, 29 99m) }\n        );\n        // Act\n        var result = await _dispatcher Send(command);\n        // Assert\n        Assert IsType<OrderCreated>(result);\n        Assert NotEqual(Guid Empty, result OrderId);\n    }\n    [Test]\n    public async Task Publish_Event_Should_Notify_All_Perspectives() {\n        // Arrange\n        var @event = new OrderCreated(Guid NewGuid(), Guid NewGuid());\n        var notificationCount = 0;\n        // Subscribe to notifications\n        _dispatcher Subscribe<OrderCreated>(e => {\n            notificationCount++;\n            return Task CompletedTask;\n        });\n        // Act\n        await _dispatcher Publish(@event);\n        // Assert\n        Assert",
        "startIndex": 8353,
        "preview": "handler found for command '{commandType Name}' To fix this: Create a receptor that implements IReceptor<{commandType Name}> Add the [WhizbangHandler] ..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-9",
        "text": "Assert Assert IsType<OrderCreated>(result); Assert NotEqual(Guid Empty, result OrderId); } [Test] public async Task Publish_Event_Should_Notify_All_Perspectives() { // Arrange var @event = new OrderCreated(Guid NewGuid(), Guid NewGuid()); var notificationCount = 0; // Subscribe to notifications _dispatcher Subscribe<OrderCreated>(e => { notificationCount++; return Task CompletedTask; }); // Act await _dispatcher Publish(@event); // Assert Assert Greater(notificationCount, 0);\n    }\n}\n`\nPerformance Characteristics\n| Operation | Target | Actual (v0 1 0) |\n|-----------|--------|-----------------|\n| Command Routing | < 100ns | TBD |\n| Event Publishing (1 handler) | < 1Œºs | TBD |\n| Event Publishing (10 handlers) | < 10Œºs | TBD |\n| Context Creation | < 50ns | TBD |\n| Policy Application | < 1Œºs per policy | TBD |\nIDE Integration\nThe dispatcher provides real-time information to the IDE:\n`csharp\n// IDE shows: \"5 commands routed | 23 events published | Last: 2ms ago\"\npublic interface IDispatcher { }\n// IDE shows: \"Routed 15 times | Avg: 1 2ms | Last: CreateOrder\"\npublic async Task<TResult> Send<TResult>(ICommand<TResult> command);\n`\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo middleware - Cannot inject cross-cutting concerns\nSequential execution - Perspectives run one at a time\nNo saga support - Cannot coordinate multi-step workflows\nNo retry logic - Failed operations aren't retried\nSingle instance - No distributed coordination\nMigration Path\nTo v0 2 0 (Pipeline & Middleware)\n:::planned\nv0 2 0 adds pipeline processing:\n:::\n`csharp\n// v0 2 0 - Middleware pipeline\nservices AddWhizbangDispatcher(dispatcher => {\n    dispatcher AddMiddleware<LoggingMiddleware>();\n    dispatcher AddMiddleware<ValidationMiddleware>();\n    dispatcher AddMiddleware<MetricsMiddleware>();\n});\n`\nTo v0 3 0 (Saga Orchestration)\n:::planned\nv0 3 0 adds workflow support:\n:::\n`csharp\n// v0 3",
        "startIndex": 17641,
        "preview": "Assert Assert IsType<OrderCreated>(result); Assert NotEqual(Guid Empty, result OrderId); } [Test] public async Task Publish_Event_Should_Notify_All_Pe..."
      },
      {
        "id": "v0.1.0/components/dispatcher-chunk-10",
        "text": "0 (Pipeline & Middleware) :::planned v0 2 0 adds pipeline processing: ::: `csharp // v0 2 0 - Middleware pipeline services AddWhizbangDispatcher(dispatcher => { dispatcher AddMiddleware<LoggingMiddleware>(); dispatcher AddMiddleware<ValidationMiddleware>(); dispatcher AddMiddleware<MetricsMiddleware>(); }); ` To v0 3 0 (Saga Orchestration) :::planned v0 3 0 adds workflow support: ::: `csharp // v0 3 0 - Saga orchestration\npublic class OrderSaga : ISaga<CreateOrder> {\n    public async Task<SagaResult> Execute(CreateOrder command) {\n        // Multi-step workflow with compensation\n    }\n}\n`\nBest Practices\nKeep dispatcher thin - Logic belongs in handlers, not dispatcher\nHandle errors gracefully - Don't let one perspective failure break all\nUse dependency injection - Let DI container manage lifetimes\nMonitor performance - Track dispatch times and success rates\nTest handler discovery - Ensure all handlers are registered\nDesign for async - All operations should be async\nRelated Documentation\nReceptors - Command handlers\nPerspectives - Event handlers\nLenses - Query handlers\nLedger - Event storage\nFeature Evolution - How dispatcher evolves\nNext Steps\nSee v0 2 0 Pipeline for middleware support\nSee v0 3 0 Orchestration for saga patterns\nReview Examples for usage patterns",
        "startIndex": 19116,
        "preview": "0 (Pipeline & Middleware) :::planned v0 2 0 adds pipeline processing: ::: `csharp // v0 2 0 - Middleware pipeline services AddWhizbangDispatcher(dispa..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/drivers",
    "title": "Drivers Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/drivers",
    "chunks": [
      {
        "id": "v0.1.0/components/drivers-chunk-0",
        "text": "Drivers Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-memory driver with simple key-value storage abstraction\n:::\n:::planned\nComing in v0 2 0: \nFile-based driver for persistence\nJSON serialization support\nBasic indexing capabilities\nSee file storage features ‚Üí\n:::\n:::planned\nComing in v0 4 0: \nSQL database drivers (PostgreSQL, SQL Server)\nNoSQL drivers (MongoDB, Redis)\nJSONB support for flexible schemas\nSee database features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>In-Memory<br/>Key-Value] --> v020[v0 2 0<br/>File<br/>JSON]\n    v020 --> v030[v0 3 0<br/>Embedded<br/>SQLite]\n    v030 --> v040[v0 4 0<br/>Database<br/>SQL/NoSQL]\n    v040 --> v050[v0 5 0<br/>Distributed<br/>Multi-Model]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nDrivers provide the storage abstraction layer in Whizbang, allowing the framework to work with different storage backends without changing application code In v0 1 0, we provide a simple in-memory driver perfect for development, testing, and prototyping What is a Driver A Driver:\nAbstracts storage implementation details\nProvides a consistent interface for data operations\nHandles serialization and deserialization\nManages connections and resources\nThink of drivers as adapters that allow Whizbang to speak different storage \"languages\" while maintaining a consistent programming model Core Interface (v0 1 0)\n:::new\nThe basic driver interface for storage operations:\n:::\n`csharp\npublic interface IDriver {\n    // Basic CRUD operations\n    Task<T",
        "startIndex": 0,
        "preview": "Drivers Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-memory driver with simple key-value storage abstraction\n::..."
      },
      {
        "id": "v0.1.0/components/drivers-chunk-1",
        "text": "serialization and deserialization Manages connections and resources Think of drivers as adapters that allow Whizbang to speak different storage \"languages\" while maintaining a consistent programming model Core Interface (v0 1 0) :::new The basic driver interface for storage operations: ::: `csharp public interface IDriver { // Basic CRUD operations Task<T > Get<T>(string key) where T : class;\n    Task Set<T>(string key, T value) where T : class;\n    Task<bool> Delete(string key);\n    Task<bool> Exists(string key);\n    // Collection operations\n    Task<IEnumerable<T>> GetAll<T>(string prefix = \"\") where T : class;\n    Task Clear(string prefix = \"\");\n    // Driver metadata\n    string Name { get; }\n    DriverCapabilities Capabilities { get; }\n}\npublic enum DriverCapabilities {\n    None = 0,\n    Persistence = 1,\n    Transactions = 2,\n    Queries = 4,\n    Indexing = 8,\n    Streaming = 16\n}\n`\nIn-Memory Driver\n:::new\nThe default in-memory driver for v0 1 0:\n:::\n`csharp\n[WhizbangDriver(\"InMemory\")]\npublic class InMemoryDriver : IDriver {\n    private readonly ConcurrentDictionary<string, object> _store = new();\n    private readonly ReaderWriterLockSlim _lock = new();\n    public string Name => \"InMemory\";\n    public DriverCapabilities Capabilities => DriverCapabilities None;\n    public Task<T > Get<T>(string key) where T : class {\n        _lock EnterReadLock();\n        try {\n            if (_store TryGetValue(key, out var value)) {\n                return Task FromResult(value as T);\n            }\n            return Task FromResult<T >(null);\n        }\n        finally {\n            _lock ExitReadLock();\n        }\n    }\n    public Task Set<T>(string key, T value) where T : class {\n        _lock EnterWriteLock();\n        try {\n            _store[key] = value;\n            return Task CompletedTask;\n        }\n        finally {\n            _lock ExitWriteLock();\n        }\n    }\n    public Task<bool> Delete(string key) {\n        _lock EnterWriteLock();\n        try {\n            return Task FromResult(_store TryRemove(key, out _));\n        }\n        finally {\n            _lock ExitWriteLock();\n        }\n    }\n    public Task<bool> Exists(string key) {\n        _lock EnterReadLock();\n        try {\n            return Task FromResult(_store ContainsKey(key));\n        }\n        finally {\n            _lock ExitReadLock();\n        }\n    }\n    public Task<IEnumerable<T>> GetAll<T>(string prefix = \"\") where T : class {\n        _lock EnterReadLock();\n        try {\n            var results = _store",
        "startIndex": 1712,
        "preview": "serialization and deserialization Manages connections and resources Think of drivers as adapters that allow Whizbang to speak different storage \"langu..."
      },
      {
        "id": "v0.1.0/components/drivers-chunk-2",
        "text": "FromResult(_store TryRemove(key, out _)); } finally { _lock ExitWriteLock(); } } public Task<bool> Exists(string key) { _lock EnterReadLock(); try { return Task FromResult(_store ContainsKey(key)); } finally { _lock ExitReadLock(); } } public Task<IEnumerable<T>> GetAll<T>(string prefix = \"\") where T : class { _lock EnterReadLock(); try { var results = _store Where(kvp => string IsNullOrEmpty(prefix) || kvp Key StartsWith(prefix)) Select(kvp => kvp Value) OfType<T>();\n            return Task FromResult<IEnumerable<T>>(results ToList());\n        }\n        finally {\n            _lock ExitReadLock();\n        }\n    }\n    public Task Clear(string prefix = \"\") {\n        _lock EnterWriteLock();\n        try {\n            if (string IsNullOrEmpty(prefix)) {\n                _store Clear();\n            } else {\n                var keysToRemove = _store Keys Where(k => k StartsWith(prefix)) ToList();\n                foreach (var key in keysToRemove) {\n                    _store TryRemove(key, out _);\n                }\n            }\n            return Task CompletedTask;\n        }\n        finally {\n            _lock ExitWriteLock();\n        }\n    }\n}\n`\nDriver Registration\nDrivers are registered at startup and discovered by source generators:\n`csharp\n// Manual registration\nservices AddWhizbangDrivers(options => {\n    options UseInMemory();\n});\n// Or with configuration\nservices AddWhizbangDrivers(options => {\n    options UseDriver<InMemoryDriver>(\"default\");\n    options UseDriver<InMemoryDriver>(\"cache\");\n});\n// Source generated registration\npublic static partial class WhizbangGenerated {\n    public static void RegisterDrivers(IServiceCollection services) {\n        services AddSingleton<IDriver, InMemoryDriver>();\n    }\n}\n`\nStore Abstraction\n:::new\nHigher-level store abstraction built on drivers:\n:::\n`csharp\npublic interface IStore<T> where T : class {\n    Task<T > GetById(string id);\n    Task Save(string id, T entity);\n    Task Delete(string id);\n    Task<IEnumerable<T>> GetAll();\n}\npublic class DriverStore<T> : IStore<T> where T : class {\n    private readonly IDriver _driver;\n    private readonly string _prefix;\n    public DriverStore(IDriver driver) {\n        _driver = driver;\n        _prefix = $\"{typeof(T) Name}:\";\n    }\n    public Task<T > GetById(string id) {\n        return _driver Get<T>($\"{_prefix}{id}\");\n    }\n    public Task Save(string id, T entity) {\n        return _driver Set($\"{_prefix}{id}\", entity);\n    }\n    public Task Delete(string id) {\n        return _driver Delete($\"{_prefix}{id}\");\n    }\n    public Task<IEnumerable<T>> GetAll() {\n        return _driver",
        "startIndex": 3885,
        "preview": "FromResult(_store TryRemove(key, out _)); } finally { _lock ExitWriteLock(); } } public Task<bool> Exists(string key) { _lock EnterReadLock(); try { r..."
      },
      {
        "id": "v0.1.0/components/drivers-chunk-3",
        "text": "_prefix; public DriverStore(IDriver driver) { _driver = driver; _prefix = $\"{typeof(T) Name}:\"; } public Task<T > GetById(string id) { return _driver Get<T>($\"{_prefix}{id}\"); } public Task Save(string id, T entity) { return _driver Set($\"{_prefix}{id}\", entity); } public Task Delete(string id) { return _driver Delete($\"{_prefix}{id}\"); } public Task<IEnumerable<T>> GetAll() { return _driver GetAll<T>(_prefix);\n    }\n}\n`\nUsing Drivers in Components\nIn Perspectives\n`csharp\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IStore<Order> _orderStore;\n    public OrderPerspective(IDriver driver) {\n        _orderStore = new DriverStore<Order>(driver);\n    }\n    public async Task Update(OrderCreated @event) {\n        var order = new Order {\n            Id = @event OrderId,\n            CustomerId = @event CustomerId,\n            Items = @event Items,\n            Total = @event Total,\n            Status = OrderStatus Created\n        };\n        await _orderStore Save(@event OrderId ToString(), order);\n    }\n}\n`\nIn Lenses\n`csharp\npublic class OrderLens : IOrderLens {\n    private readonly IStore<Order> _orderStore;\n    public OrderLens(IDriver driver) {\n        _orderStore = new DriverStore<Order>(driver);\n    }\n    public async Task<Order> Focus(Guid orderId) {\n        return await _orderStore GetById(orderId ToString());\n    }\n    public async Task<IEnumerable<Order>> ViewAll() {\n        return await _orderStore GetAll();\n    }\n}\n`\nTesting with Drivers\n`csharp\n[Test]\npublic class DriverTests {\n    private InMemoryDriver _driver;\n    [SetUp]\n    public void Setup() {\n        _driver = new InMemoryDriver();\n    }\n    [Test]\n    public async Task SetAndGet_ShouldStoreAndRetrieve() {\n        // Arrange\n        var testObject = new TestEntity { \n            Id = \"test-1\", \n            Name = \"Test Entity\" \n        };\n        // Act\n        await _driver Set(\"test-1\", testObject);\n        var retrieved = await _driver Get<TestEntity>(\"test-1\");\n        // Assert\n        Assert NotNull(retrieved);\n        Assert Equal(\"Test Entity\", retrieved Name);\n    }\n    [Test]\n    public async Task GetAll_WithPrefix_ShouldFilterResults() {\n        // Arrange\n        await _driver Set(\"order:1\", new Order { Id = Guid NewGuid() });\n        await _driver Set(\"order:2\", new Order { Id = Guid NewGuid() });\n        await _driver Set(\"customer:1\", new Customer { Id = Guid NewGuid() });\n        // Act\n        var orders = await _driver GetAll<Order>(\"order:\");\n        // Assert\n        Assert Equal(2, orders Count());\n    }\n    [Test]\n    public async Task Clear_WithPrefix_ShouldOnlyRemoveMatching() {\n        // Arrange\n        await _driver",
        "startIndex": 6206,
        "preview": "_prefix; public DriverStore(IDriver driver) { _driver = driver; _prefix = $\"{typeof(T) Name}:\"; } public Task<T > GetById(string id) { return _driver ..."
      },
      {
        "id": "v0.1.0/components/drivers-chunk-4",
        "text": "Guid NewGuid() }); await _driver Set(\"order:2\", new Order { Id = Guid NewGuid() }); await _driver Set(\"customer:1\", new Customer { Id = Guid NewGuid() }); // Act var orders = await _driver GetAll<Order>(\"order:\"); // Assert Assert Equal(2, orders Count()); } [Test] public async Task Clear_WithPrefix_ShouldOnlyRemoveMatching() { // Arrange await _driver Set(\"temp:1\", new object());\n        await _driver Set(\"temp:2\", new object());\n        await _driver Set(\"keep:1\", new object());\n        // Act\n        await _driver Clear(\"temp:\");\n        // Assert\n        Assert False(await _driver Exists(\"temp:1\"));\n        Assert False(await _driver Exists(\"temp:2\"));\n        Assert True(await _driver Exists(\"keep:1\"));\n    }\n}\n`\nDriver Selection Strategy\n`csharp\npublic interface IDriverSelector {\n    IDriver GetDriver(string name);\n    IDriver GetDriverForType<T>();\n}\npublic class DriverSelector : IDriverSelector {\n    private readonly Dictionary<string, IDriver> _drivers;\n    public IDriver GetDriver(string name) {\n        return _drivers TryGetValue(name, out var driver) driver \n            : _drivers[\"default\"];\n    }\n    public IDriver GetDriverForType<T>() {\n        // Can implement type-based routing\n        var typeName = typeof(T) Name;\n        return typeName switch {\n            \"Order\" or \"Customer\" => GetDriver(\"primary\"),\n            \"Cache\" or \"Session\" => GetDriver(\"cache\"),\n            _ => GetDriver(\"default\")\n        };\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Driver: InMemory | Objects: 234 | Memory: 5 2MB\"\npublic interface IDriver { }\n// IDE shows: \"Called 45 times | Avg: 0 1ms | Hit rate: 92%\"\npublic Task<T > Get<T>(string key) { }\n// IDE shows: \"Warning: No persistence - data lost on restart\"\npublic class InMemoryDriver : IDriver { }\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Get | < 100ns | TBD |\n| Set | < 500ns | TBD |\n| Delete | < 200ns | TBD |\n| GetAll (1000 items) | < 1ms | TBD |\n| Clear | < 100Œºs | TBD |\nLimitations in v0 1",
        "startIndex": 8499,
        "preview": "Guid NewGuid() }); await _driver Set(\"order:2\", new Order { Id = Guid NewGuid() }); await _driver Set(\"customer:1\", new Customer { Id = Guid NewGuid()..."
      },
      {
        "id": "v0.1.0/components/drivers-chunk-5",
        "text": "| Actual | |-----------|--------|--------| | Get | < 100ns | TBD | | Set | < 500ns | TBD | | Delete | < 200ns | TBD | | GetAll (1000 items) | < 1ms | TBD | | Clear | < 100Œºs | TBD | Limitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo persistence - Data lost on restart\nNo queries - Only key-based lookups\nNo transactions - No atomicity guarantees\nNo indexing - Linear scans for GetAll\nMemory only - Limited by available RAM\nMigration Path\nTo v0 2 0 (File Storage)\n:::planned\nv0 2 0 adds persistent file storage:\n:::\n`csharp\n// v0 2 0 - File-based driver\nservices AddWhizbangDrivers(options => {\n    options UseFileDriver(file => {\n        file DataDirectory = \" /data\";\n        file Format = SerializationFormat Json;\n        file Compression = true;\n    });\n});\n`\nTo v0 4 0 (Database Drivers)\n:::planned\nv0 4 0 adds real database support:\n:::\n`csharp\n// v0 4 0 - SQL and NoSQL drivers\nservices AddWhizbangDrivers(options => {\n    options UsePostgreSQL(\"Host=localhost;Database=whizbang\");\n    options UseMongoDB(\"mongodb://localhost:27017/whizbang\");\n    options UseRedis(\"localhost:6379\");\n});\n`\nBest Practices\nUse abstractions - Depend on IDriver, not concrete implementations\nPlan for persistence - Design assuming data will persist\nUse prefixes - Organize keys with consistent prefixes\nHandle nulls - Always check for null returns from Get\nTest with different drivers - Ensure code works with any driver\nConsider capabilities - Check driver capabilities before using features\nRelated Documentation\nPerspectives - Using drivers for write models\nLenses - Using drivers for read models\nTesting - Testing with in-memory driver\nFeature Evolution - How drivers evolve\nNext Steps\nSee v0 2 0 File Storage for persistence\nSee v0 4 0 Databases for SQL/NoSQL support\nReview Examples for driver patterns",
        "startIndex": 10192,
        "preview": "| Actual | |-----------|--------|--------| | Get | < 100ns | TBD | | Set | < 500ns | TBD | | Delete | < 200ns | TBD | | GetAll (1000 items) | < 1ms | ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/ledger",
    "title": "Ledger Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/ledger",
    "chunks": [
      {
        "id": "v0.1.0/components/ledger-chunk-0",
        "text": "Ledger Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-memory event store with append-only semantics\n:::\n:::planned\nComing in v0 2 0: \nPersistent file-based storage\nEvent streams and versioning\nBasic snapshots\nSee persistence features ‚Üí\n:::\n:::planned\nComing in v0 3 0: \nFull event sourcing with projections\nTime-travel queries\nEvent replay\nSee event sourcing features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>In-Memory<br/>Append-Only] --> v020[v0 2 0<br/>File<br/>Persistent]\n    v020 --> v030[v0 3 0<br/>Event<br/>Sourcing]\n    v030 --> v040[v0 4 0<br/>SQL<br/>JSONB]\n    v040 --> v050[v0 5 0<br/>Distributed<br/>Multi-Region]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nThe Ledger is Whizbang's append-only event store, providing an immutable audit trail of all events in your system In v0 1 0, it's a simple in-memory store that captures events and allows basic retrieval This foundation will evolve into a full event sourcing system What is a Ledger A Ledger:\nStores events in append-only fashion\nPreserves the complete history of state changes\nProvides an immutable audit trail\nEnables event replay and debugging\nThink of the ledger as your system's permanent memory - every significant action is recorded and can never be altered or deleted Core Interface (v0 1 0)\n:::new\nThe basic ledger interface for event storage:\n:::\n`csharp\npublic interface ILedger {\n    // Append an event to the ledger\n    Task<long> Append(IEvent @event);\n    // Read events from the ledger\n    IEnumerable<IEvent> Read(long fromPosition = 0);\n    // Read events of a specific type\n    IEnumerable<T> Read<T>(long fromPosition = 0) where T : IEvent;\n    // Get the current position (last event number)\n    long GetPosition();\n}\n`\nBasic Implementation\n:::new\nIn v0 1",
        "startIndex": 0,
        "preview": "Ledger Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-memory event store with append-only semantics\n:::\n:::planne..."
      },
      {
        "id": "v0.1.0/components/ledger-chunk-1",
        "text": "the ledger Task<long> Append(IEvent @event); // Read events from the ledger IEnumerable<IEvent> Read(long fromPosition = 0); // Read events of a specific type IEnumerable<T> Read<T>(long fromPosition = 0) where T : IEvent; // Get the current position (last event number) long GetPosition(); } ` Basic Implementation :::new In v0 1 0, the ledger uses in-memory storage:\n:::\n`csharp\n[WhizbangLedger]\npublic class InMemoryLedger : ILedger {\n    private readonly List<StoredEvent> _events = new();\n    private readonly object _lock = new();\n    private long _position = 0;\n    public Task<long> Append(IEvent @event) {\n        lock (_lock) {\n            var position = ++_position;\n            _events Add(new StoredEvent {\n                Position = position,\n                EventType = @event GetType() Name,\n                Event = @event,\n                Timestamp = DateTimeOffset UtcNow\n            });\n            return Task FromResult(position);\n        }\n    }\n    public IEnumerable<IEvent> Read(long fromPosition = 0) {\n        lock (_lock) {\n            return _events Where(e => e Position > fromPosition) Select(e => e Event);\n        }\n    }\n    public IEnumerable<T> Read<T>(long fromPosition = 0) where T : IEvent {\n        return Read(fromPosition) OfType<T>();\n    }\n    public long GetPosition() {\n        lock (_lock) {\n            return _position;\n        }\n    }\n}\n`\nEvent Storage\nEvent Structure\n`csharp\npublic interface IEvent {\n    Guid Id { get; }\n    DateTimeOffset Timestamp { get; }\n    string AggregateId { get; }\n    int Version { get; }\n}\n// Stored event wrapper\ninternal class StoredEvent {\n    public long Position { get; set; }\n    public string EventType { get; set; }\n    public IEvent Event { get; set; }\n    public DateTimeOffset Timestamp { get; set; }\n}\n`\nAppending Events\n:::new\nEvents are automatically appended by the dispatcher:\n:::\n`csharp\n// Events flow from receptors through dispatcher to ledger\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    public OrderCreated Receive(CreateOrder cmd) {\n        return new OrderCreated {\n            Id = Guid NewGuid(),\n            Timestamp = DateTimeOffset UtcNow,\n            AggregateId = cmd OrderId ToString(),\n            Version = 1,\n            CustomerId = cmd CustomerId,\n            Items = cmd",
        "startIndex": 1978,
        "preview": "the ledger Task<long> Append(IEvent @event); // Read events from the ledger IEnumerable<IEvent> Read(long fromPosition = 0); // Read events of a speci..."
      },
      {
        "id": "v0.1.0/components/ledger-chunk-2",
        "text": "dispatcher: ::: `csharp // Events flow from receptors through dispatcher to ledger public class OrderReceptor : IReceptor<CreateOrder> { public OrderCreated Receive(CreateOrder cmd) { return new OrderCreated { Id = Guid NewGuid(), Timestamp = DateTimeOffset UtcNow, AggregateId = cmd OrderId ToString(), Version = 1, CustomerId = cmd CustomerId, Items = cmd Items,\n            Total = cmd Total\n        };\n        // Event automatically appended to ledger by dispatcher\n    }\n}\n`\nReading Events\n:::new\nBasic event retrieval in v0 1 0:\n:::\n`csharp\npublic class EventReader {\n    private readonly ILedger _ledger;\n    // Read all events\n    public void ReadAllEvents() {\n        var events = _ledger Read();\n        foreach (var @event in events) {\n            Console WriteLine($\"{@event Timestamp}: {@event GetType() Name}\");\n        }\n    }\n    // Read specific event types\n    public void ReadOrderEvents() {\n        var orderEvents = _ledger Read<OrderCreated>();\n        foreach (var order in orderEvents) {\n            Console WriteLine($\"Order {order AggregateId}: {order Total}\");\n        }\n    }\n    // Read from checkpoint\n    public void ReadNewEvents(long lastPosition) {\n        var newEvents = _ledger Read(fromPosition: lastPosition);\n        foreach (var @event in newEvents) {\n            ProcessEvent(@event);\n        }\n    }\n}\n`\nIntegration with Dispatcher\nThe ledger is automatically integrated with the dispatcher:\n`csharp\n// Source generated registration\npublic static partial class WhizbangGenerated {\n    public static void RegisterLedger(IServiceCollection services) {\n        services AddSingleton<ILedger, InMemoryLedger>();\n    }\n}\n// Dispatcher automatically appends events\npublic class Dispatcher : IDispatcher {\n    private readonly ILedger _ledger;\n    public async Task<TResult> Dispatch<TCommand, TResult>(TCommand command) \n        where TResult : IEvent {\n        // Execute receptor\n        var result = await ExecuteReceptor(command);\n        // Append to ledger\n        await _ledger Append(result);\n        // Update perspectives\n        await UpdatePerspectives(result);\n        return result;\n    }\n}\n`\nDebugging with the Ledger\n:::new\nThe ledger enables powerful debugging capabilities:\n:::\n`csharp\npublic class LedgerDebugger {\n    private readonly ILedger _ledger;\n    // Show event timeline\n    public void ShowTimeline(DateTime from, DateTime to) {\n        var events = _ledger Read() Where(e => e Timestamp >= from && e Timestamp <= to)",
        "startIndex": 3985,
        "preview": "dispatcher: ::: `csharp // Events flow from receptors through dispatcher to ledger public class OrderReceptor : IReceptor<CreateOrder> { public OrderC..."
      },
      {
        "id": "v0.1.0/components/ledger-chunk-3",
        "text": "} ` Debugging with the Ledger :::new The ledger enables powerful debugging capabilities: ::: `csharp public class LedgerDebugger { private readonly ILedger _ledger; // Show event timeline public void ShowTimeline(DateTime from, DateTime to) { var events = _ledger Read() Where(e => e Timestamp >= from && e Timestamp <= to) OrderBy(e => e Timestamp);\n        foreach (var @event in events) {\n            Console WriteLine($\"{@event Timestamp:HH:mm:ss fff} \" +\n                            $\"[{@event GetType() Name}] \" +\n                            $\"Aggregate: {@event AggregateId}\");\n        }\n    }\n    // Analyze event patterns\n    public void AnalyzePatterns() {\n        var events = _ledger Read();\n        var stats = events GroupBy(e => e GetType() Name) Select(g => new {\n                EventType = g Key,\n                Count = g Count(),\n                FirstOccurred = g Min(e => e Timestamp),\n                LastOccurred = g Max(e => e Timestamp)\n            });\n        foreach (var stat in stats) {\n            Console WriteLine($\"{stat EventType}: {stat Count} events\");\n        }\n    }\n}\n`\nTesting with the Ledger\n`csharp\n[Test]\npublic class LedgerTests {\n    private InMemoryLedger _ledger;\n    [SetUp]\n    public void Setup() {\n        _ledger = new InMemoryLedger();\n    }\n    [Test]\n    public async Task Append_ShouldReturnIncrementingPosition() {\n        // Arrange\n        var event1 = new TestEvent { Id = Guid NewGuid() };\n        var event2 = new TestEvent { Id = Guid NewGuid() };\n        // Act\n        var pos1 = await _ledger Append(event1);\n        var pos2 = await _ledger Append(event2);\n        // Assert\n        Assert Equal(1, pos1);\n        Assert Equal(2, pos2);\n    }\n    [Test]\n    public async Task Read_ShouldReturnEventsInOrder() {\n        // Arrange\n        var events = new[] {\n            new TestEvent { Id = Guid NewGuid() },\n            new TestEvent { Id = Guid NewGuid() },\n            new TestEvent { Id = Guid NewGuid() }\n        };\n        foreach (var @event in events) {\n            await _ledger Append(@event);\n        }\n        // Act\n        var readEvents = _ledger Read() ToList();\n        // Assert\n        Assert Equal(3, readEvents Count);\n        Assert Equal(events[0] Id, readEvents[0] Id);\n        Assert Equal(events[2] Id, readEvents[2]",
        "startIndex": 6137,
        "preview": "} ` Debugging with the Ledger :::new The ledger enables powerful debugging capabilities: ::: `csharp public class LedgerDebugger { private readonly IL..."
      },
      {
        "id": "v0.1.0/components/ledger-chunk-4",
        "text": "new TestEvent { Id = Guid NewGuid() }, new TestEvent { Id = Guid NewGuid() } }; foreach (var @event in events) { await _ledger Append(@event); } // Act var readEvents = _ledger Read() ToList(); // Assert Assert Equal(3, readEvents Count); Assert Equal(events[0] Id, readEvents[0] Id); Assert Equal(events[2] Id, readEvents[2] Id);\n    }\n    [Test]\n    public async Task Read_FromPosition_ShouldSkipEarlierEvents() {\n        // Arrange\n        for (int i = 0; i < 5; i++) {\n            await _ledger Append(new TestEvent());\n        }\n        // Act\n        var events = _ledger Read(fromPosition: 3) ToList();\n        // Assert\n        Assert Equal(2, events Count); // Only events 4 and 5\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Events stored: 1,234 | Size: 5 2MB | Last: 2s ago\"\npublic interface ILedger { }\n// IDE shows: \"Appended 45 times | Avg: 0 1ms\"\npublic Task<long> Append(IEvent @event) { }\n// IDE shows: \"Warning: Reading all events can be expensive\"\npublic IEnumerable<IEvent> Read(long fromPosition = 0) { }\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Append | < 1Œºs | TBD |\n| Read (1000 events) | < 1ms | TBD |\n| Read by type | < 2ms | TBD |\n| Get position | < 100ns | TBD |\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nIn-memory only - Events lost on restart\nNo streaming - Must load all events at once\nNo snapshots - Can't optimize long event streams\nSingle stream - No concept of aggregate streams\nNo queries - Basic sequential read only\nMigration Path\nTo v0 2 0 (Persistence)\n:::planned\nv0 2 0 adds persistent storage:\n:::\n`csharp\n// v0 2 0 - File-based persistence\npublic interface ILedger {\n    Task<long> Append(string streamId, IEvent @event);\n    IAsyncEnumerable<IEvent> ReadStream(string streamId);\n    Task<Snapshot> CreateSnapshot(string streamId);\n}\n`\nTo v0 3",
        "startIndex": 8150,
        "preview": "new TestEvent { Id = Guid NewGuid() }, new TestEvent { Id = Guid NewGuid() } }; foreach (var @event in events) { await _ledger Append(@event); } // Ac..."
      },
      {
        "id": "v0.1.0/components/ledger-chunk-5",
        "text": "No queries - Basic sequential read only Migration Path To v0 2 0 (Persistence) :::planned v0 2 0 adds persistent storage: ::: `csharp // v0 2 0 - File-based persistence public interface ILedger { Task<long> Append(string streamId, IEvent @event); IAsyncEnumerable<IEvent> ReadStream(string streamId); Task<Snapshot> CreateSnapshot(string streamId); } ` To v0 3 0 (Event Sourcing)\n:::planned\nv0 3 0 adds full event sourcing:\n:::\n`csharp\n// v0 3 0 - Event sourcing with projections\npublic interface IEventStore : ILedger {\n    Task<T> LoadAggregate<T>(string aggregateId) where T : IAggregate;\n    Task SaveAggregate<T>(T aggregate) where T : IAggregate;\n    Task<ProjectionState> GetProjection(string projectionName);\n    Task RebuildProjection(string projectionName, DateTime from = null);\n}\n`\nBest Practices\nEvents are immutable - Never modify events after creation\nUse meaningful event names - OrderCreated not Event1\nInclude all relevant data - Events should be self-contained\nKeep events small - Large payloads impact performance\nVersion your events - Plan for schema evolution\nTest with the ledger - Verify event flow in tests\nRelated Documentation\nReceptors - Where events come from\nDispatcher - How events reach the ledger\nPerspectives - How events update views\nTesting - Testing with the ledger\nFeature Evolution - How the ledger evolves\nNext Steps\nSee v0 2 0 Persistence for file-based storage\nSee v0 3 0 Event Sourcing for full ES/CQRS\nReview Examples for event design patterns",
        "startIndex": 9711,
        "preview": "No queries - Basic sequential read only Migration Path To v0 2 0 (Persistence) :::planned v0 2 0 adds persistent storage: ::: `csharp // v0 2 0 - File..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/lenses",
    "title": "Lenses Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/lenses",
    "chunks": [
      {
        "id": "v0.1.0/components/lenses-chunk-0",
        "text": "Lenses Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic query interface with Focus, View, Glimpse, Exists, and Scan methods\n:::\n:::planned\nComing in v0 2 0: \nPagination support for large result sets\nAsync enumeration with IAsyncEnumerable\nQuery optimization hints\nSee planned enhancements ‚Üí\n:::\n:::planned\nComing in v0 4 0: \nSQL generation for database queries\nIndex usage optimization\nQuery result caching\nSee database features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>Basic<br/>In-Memory] --> v020[v0 2 0<br/>Pagination<br/>Async]\n    v020 --> v030[v0 3 0<br/>Time-Travel<br/>Queries]\n    v030 --> v040[v0 4 0<br/>SQL<br/>Optimized]\n    v040 --> v050[v0 5 0<br/>Distributed<br/>Federated]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nLenses provide focused, read-only views into your data They are the query side of Whizbang's CQRS implementation, offering a clean separation between reads and writes In v0 1 0, lenses work with in-memory data and establish the foundation for more advanced query capabilities What is a Lens A Lens:\nProvides read-only access to data\nFocuses on specific query needs\nNever modifies state\nAbstracts the underlying storage mechanism\nThink of a lens as a window into your data - you can look through it from different angles to see different views, but you can't reach through it to change what you see Core Interface (v0 1",
        "startIndex": 0,
        "preview": "Lenses Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic query interface with Focus, View, Glimpse, Exists, and Scan me..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-1",
        "text": "on specific query needs Never modifies state Abstracts the underlying storage mechanism Think of a lens as a window into your data - you can look through it from different angles to see different views, but you can't reach through it to change what you see Core Interface (v0 1 0)\n:::new\nThe basic lens interface pattern with five core methods:\n:::\n`csharp\npublic interface ILens {\n    // Focus on a single item\n    T Focus<T>(object id);\n    // View a filtered collection\n    IEnumerable<T> View<T>(Expression<Func<T, bool>> filter);\n    // Glimpse a summary or partial view\n    TSummary Glimpse<TSummary>(object id);\n    // Check existence\n    bool Exists(object id);\n    // Scan all items (use sparingly)\n    IEnumerable<T> Scan<T>();\n}\n`\nDomain-Specific Lenses\n:::new\nCreate specific lens interfaces for your domain:\n:::\n`csharp\n[WhizbangLens]  // Source generator discovers this\npublic interface IOrderLens : ILens {\n    // Strongly-typed methods\n    Order Focus(Guid orderId);\n    IEnumerable<Order> ViewByCustomer(Guid customerId);\n    IEnumerable<Order> ViewByStatus(OrderStatus status);\n    OrderSummary Glimpse(Guid orderId);\n    bool Exists(Guid orderId);\n    IEnumerable<Order> Scan();\n}\n// Implementation for v0 1 0 (in-memory)\npublic class OrderLens : IOrderLens {\n    private readonly Dictionary<Guid, Order> _orders;\n    public OrderLens(IInMemoryStore<Order> store) {\n        _orders = store Collection;\n    }\n    public Order Focus(Guid orderId) {\n        return _orders TryGetValue(orderId, out var order) order \n            : null;\n    }\n    public IEnumerable<Order> ViewByCustomer(Guid customerId) {\n        return _orders Values Where(o => o CustomerId == customerId);\n    }\n    public IEnumerable<Order> ViewByStatus(OrderStatus status) {\n        return _orders Values Where(o => o Status == status);\n    }\n    public OrderSummary Glimpse(Guid orderId) {\n        var order = Focus(orderId);\n        return order == null null : new OrderSummary {\n            Id = order Id,\n            CustomerName = GetCustomerName(order CustomerId),\n            Total = order Total,\n            ItemCount = order Items Count,\n            Status = order Status ToString()\n        };\n    }\n    public bool Exists(Guid orderId) {\n        return _orders ContainsKey(orderId);\n    }\n    public IEnumerable<Order> Scan() {\n        return _orders",
        "startIndex": 1578,
        "preview": "on specific query needs Never modifies state Abstracts the underlying storage mechanism Think of a lens as a window into your data - you can look thro..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-2",
        "text": "= Focus(orderId); return order == null null : new OrderSummary { Id = order Id, CustomerName = GetCustomerName(order CustomerId), Total = order Total, ItemCount = order Items Count, Status = order Status ToString() }; } public bool Exists(Guid orderId) { return _orders ContainsKey(orderId); } public IEnumerable<Order> Scan() { return _orders Values;\n    }\n}\n`\nCore Lens Methods Explained\nFocus - Single Item Retrieval\n:::new\nRetrieve a single item by its identifier:\n:::\n`csharp\npublic interface ICustomerLens : ILens {\n    Customer Focus(Guid customerId);\n}\n// Usage in receptor\npublic class OrderReceptor : IReceptor<UpdateOrder> {\n    public OrderUpdated Receive(UpdateOrder cmd, ICustomerLens lens) {\n        var customer = lens Focus(cmd CustomerId);\n        if (customer == null) {\n            throw new CustomerNotFoundException(cmd CustomerId);\n        }\n        if ( customer IsActive) {\n            throw new InactiveCustomerException();\n        }\n        return new OrderUpdated(cmd OrderId, cmd Changes);\n    }\n}\n`\nView - Filtered Collections\n:::new\nQuery multiple items with filters:\n:::\n`csharp\npublic interface IProductLens : ILens {\n    IEnumerable<Product> View(Expression<Func<Product, bool>> filter);\n    IEnumerable<Product> ViewByCategory(string category);\n    IEnumerable<Product> ViewInPriceRange(decimal min, decimal max);\n}\n// Implementation\npublic class ProductLens : IProductLens {\n    public IEnumerable<Product> ViewByCategory(string category) {\n        return _products Values Where(p => p Category == category);\n    }\n    public IEnumerable<Product> ViewInPriceRange(decimal min, decimal max) {\n        return _products Values Where(p => p Price >= min && p Price <= max);\n    }\n}\n`\nGlimpse - Summaries and Projections\n:::new\nGet lightweight summaries without full entity data:\n:::\n`csharp\npublic interface IInventoryLens : ILens {\n    InventorySummary Glimpse(Guid productId);\n    StockLevel GlimpseStock(Guid productId);\n    IEnumerable<LowStockItem> GlimpseLowStock();\n}\n// Returns just what's needed\npublic InventorySummary Glimpse(Guid productId) {\n    var product = _products[productId];\n    return new InventorySummary {\n        ProductId = product Id,\n        Name = product Name,\n        Available = product Quantity - product Reserved,\n        Status = product Quantity > 10",
        "startIndex": 3666,
        "preview": "= Focus(orderId); return order == null null : new OrderSummary { Id = order Id, CustomerName = GetCustomerName(order CustomerId), Total = order Total,..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-3",
        "text": "ILens { InventorySummary Glimpse(Guid productId); StockLevel GlimpseStock(Guid productId); IEnumerable<LowStockItem> GlimpseLowStock(); } // Returns just what's needed public InventorySummary Glimpse(Guid productId) { var product = _products[productId]; return new InventorySummary { ProductId = product Id, Name = product Name, Available = product Quantity - product Reserved, Status = product Quantity > 10 \"In Stock\" : \"Low Stock\"\n    };\n}\n`\nExists - Efficient Existence Checks\n:::new\nCheck if an item exists without loading it:\n:::\n`csharp\npublic class OrderReceptor : IReceptor<AddItemToOrder> {\n    public ItemAdded Receive(AddItemToOrder cmd, IOrderLens orderLens, IProductLens productLens) {\n        if ( orderLens Exists(cmd OrderId)) {\n            throw new OrderNotFoundException(cmd OrderId);\n        }\n        if ( productLens Exists(cmd ProductId)) {\n            throw new ProductNotFoundException(cmd ProductId);\n        }\n        return new ItemAdded(cmd OrderId, cmd ProductId, cmd Quantity);\n    }\n}\n`\nScan - Full Collection Access\n:::new\nRetrieve all items (use sparingly):\n:::\n`csharp\npublic interface IReportLens : ILens {\n    IEnumerable<Order> ScanOrders();\n    IEnumerable<Customer> ScanCustomers();\n}\n// Use with caution - can be expensive\npublic DailyReport GenerateReport(IReportLens lens) {\n    var allOrders = lens ScanOrders();\n    return new DailyReport {\n        TotalOrders = allOrders Count(),\n        TotalRevenue = allOrders Sum(o => o Total),\n        AverageOrderValue = allOrders Average(o => o Total)\n    };\n}\n`\nComposition Pattern\n:::new\nLenses can be composed for complex queries:\n:::\n`csharp\npublic class OrderSearchLens : IOrderSearchLens {\n    private readonly IOrderLens _orderLens;\n    private readonly ICustomerLens _customerLens;\n    private readonly IProductLens _productLens;\n    public IEnumerable<OrderSearchResult> Search(OrderSearchCriteria criteria) {\n        var orders = _orderLens Scan();\n        if (criteria CustomerId HasValue) {\n            var customer = _customerLens Focus(criteria CustomerId Value);\n            orders = orders Where(o => o CustomerId == customer Id);\n        }\n        if ( string IsNullOrEmpty(criteria ProductSku)) {\n            var product = _productLens ViewBySku(criteria ProductSku) FirstOrDefault();\n            orders = orders Where(o => o Items Any(i => i ProductId == product Id));\n        }\n        return orders",
        "startIndex": 5642,
        "preview": "ILens { InventorySummary Glimpse(Guid productId); StockLevel GlimpseStock(Guid productId); IEnumerable<LowStockItem> GlimpseLowStock(); } // Returns j..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-4",
        "text": "HasValue) { var customer = _customerLens Focus(criteria CustomerId Value); orders = orders Where(o => o CustomerId == customer Id); } if ( string IsNullOrEmpty(criteria ProductSku)) { var product = _productLens ViewBySku(criteria ProductSku) FirstOrDefault(); orders = orders Where(o => o Items Any(i => i ProductId == product Id)); } return orders Select(o => MapToSearchResult(o));\n    }\n}\n`\nSource Generation\n:::new\nLenses are discovered and registered at compile time:\n:::\n`csharp\n// Generated by Whizbang Generators\npublic static partial class WhizbangGenerated {\n    public static void RegisterLenses(IServiceCollection services) {\n        services AddScoped<IOrderLens, OrderLens>();\n        services AddScoped<ICustomerLens, CustomerLens>();\n        services AddScoped<IProductLens, ProductLens>();\n        services AddScoped<IInventoryLens, InventoryLens>();\n    }\n}\n`\nTesting Lenses\n`csharp\n[Test]\npublic class OrderLensTests {\n    private OrderLens _lens;\n    private InMemoryStore<Order> _store;\n    [SetUp]\n    public void Setup() {\n        _store = new InMemoryStore<Order>();\n        _lens = new OrderLens(_store);\n        // Add test data\n        _store Collection[Guid Parse(\"123 \")] = new Order {\n            Id = Guid Parse(\"123 \"),\n            CustomerId = Guid Parse(\"456 \"),\n            Status = OrderStatus Pending,\n            Total = 99 99m\n        };\n    }\n    [Test]\n    public void Focus_ExistingOrder_ShouldReturnOrder() {\n        var order = _lens Focus(Guid Parse(\"123 \"));\n        Assert NotNull(order);\n        Assert Equal(99 99m, order Total);\n    }\n    [Test]\n    public void ViewByStatus_ShouldFilterCorrectly() {\n        var pendingOrders = _lens ViewByStatus(OrderStatus Pending);\n        Assert Equal(1, pendingOrders Count());\n    }\n    [Test]\n    public void Exists_ExistingOrder_ShouldReturnTrue() {\n        Assert True(_lens Exists(Guid Parse(\"123 \")));\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Used by: 5 receptors | Queries: 234 | Avg: 0 5ms\"\npublic interface IOrderLens : ILens { }\n// IDE shows: \"Called 45 times | Last: 2s ago | Avg: 0",
        "startIndex": 7642,
        "preview": "HasValue) { var customer = _customerLens Focus(criteria CustomerId Value); orders = orders Where(o => o CustomerId == customer Id); } if ( string IsNu..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-5",
        "text": "[Test] public void Exists_ExistingOrder_ShouldReturnTrue() { Assert True(_lens Exists(Guid Parse(\"123 \"))); } } ` IDE Features `csharp // IDE shows: \"Used by: 5 receptors | Queries: 234 | Avg: 0 5ms\" public interface IOrderLens : ILens { } // IDE shows: \"Called 45 times | Last: 2s ago | Avg: 0 3ms\"\npublic Order Focus(Guid orderId) { }\n// IDE shows: \"Warning: Scan can be expensive - consider using View with filters\"\npublic IEnumerable<Order> Scan() { }\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Focus (in-memory) | < 100ns | TBD |\n| View (filtered) | < 1Œºs per item | TBD |\n| Glimpse | < 500ns | TBD |\n| Exists | < 50ns | TBD |\n| Scan (1000 items) | < 1ms | TBD |\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo pagination - All results returned at once\nSynchronous only - No async/await support\nIn-memory only - No database queries\nNo caching - Queries execute every time\nMigration Path\nTo v0 2 0 (Enhanced Queries)\n:::planned\nv0 2 0 adds pagination and async support:\n:::\n`csharp\n// v0 2 0 - Pagination\npublic interface IOrderLens : ILens {\n    PagedResult<Order> ViewByCustomer(Guid customerId, int page, int pageSize);\n}\n// v0 2 0 - Async enumeration\npublic interface IOrderLens : ILens {\n    IAsyncEnumerable<Order> ScanAsync();\n}\n`\nTo v0 4 0 (Database Queries)\n:::planned\nv0 4 0 adds real database support with SQL generation:\n:::\n`csharp\n// v0 4 0 - SQL generation\n[SqlOptimized]\npublic class OrderLens : IOrderLens {\n    public Order Focus(Guid orderId) {\n        // Generated SQL: SELECT * FROM Orders WHERE Id = @orderId\n        return _db QuerySingle<Order>(\"",
        "startIndex": 9392,
        "preview": "[Test] public void Exists_ExistingOrder_ShouldReturnTrue() { Assert True(_lens Exists(Guid Parse(\"123 \"))); } } ` IDE Features `csharp // IDE shows: \"..."
      },
      {
        "id": "v0.1.0/components/lenses-chunk-6",
        "text": "4 0 (Database Queries) :::planned v0 4 0 adds real database support with SQL generation: ::: `csharp // v0 4 0 - SQL generation [SqlOptimized] public class OrderLens : IOrderLens { public Order Focus(Guid orderId) { // Generated SQL: SELECT * FROM Orders WHERE Id = @orderId return _db QuerySingle<Order>(\" \", new { orderId });\n    }\n}\n`\nBest Practices\nKeep lenses read-only - Never modify state through a lens\nUse specific methods - ViewByCustomer over generic View\nAvoid Scan - Use filtered queries when possible\nReturn summaries - Use Glimpse for lightweight results\nCheck existence - Use Exists before Focus\nCompose lenses - Combine for complex queries\nRelated Documentation\nReceptors - Using lenses in receptors\nPerspectives - Data that lenses query\nDispatcher - How lenses are provided\nTesting - Testing lenses\nFeature Evolution - How lenses evolve\nNext Steps\nSee v0 2 0 Enhancements for pagination and async features\nSee v0 4 0 Database Support for SQL optimization\nReview Examples for query patterns",
        "startIndex": 10768,
        "preview": "4 0 (Database Queries) :::planned v0 4 0 adds real database support with SQL generation: ::: `csharp // v0 4 0 - SQL generation [SqlOptimized] public ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/perspectives",
    "title": "Perspectives Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/perspectives",
    "chunks": [
      {
        "id": "v0.1.0/components/perspectives-chunk-0",
        "text": "Perspectives Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic event handling with in-memory updates for multiple views\n:::\n:::planned\nComing in v0 2 0: \nBatch update support for performance\nParallel perspective execution\nEnhanced error handling with dead letter queues\nSee planned enhancements ‚Üí\n:::\n:::planned\nComing in v0 3 0: \nFull projection support with rebuild capability\nCheckpoint management for event replay\nSubscription management\nSee projection features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>Basic<br/>In-Memory] --> v020[v0 2 0<br/>Batch<br/>Parallel]\n    v020 --> v030[v0 3 0<br/>Projections<br/>Rebuild]\n    v030 --> v040[v0 4 0<br/>Database<br/>Optimized]\n    v040 --> v050[v0 5 0<br/>Distributed<br/>Partitioned]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nPerspectives are the components that react to events and update various views of your data They handle all write operations in Whizbang, ensuring that state changes flow consistently from events to storage In v0 1 0, perspectives work with in-memory storage and provide the foundation for more advanced features What is a Perspective A Perspective:\nReacts to events emitted by receptors\nUpdates data stores (in-memory in v0 1 0)\nMaintains different views of the same data\nExecutes all write operations in the system\nThink of perspectives as event handlers that maintain materialized views Each perspective provides a different \"perspective\" on the events flowing through your system Core Interface (v0 1 0)\n:::new\nThe fundamental perspective interface for handling events:\n:::\n`csharp\npublic interface IPerspectiveOf<TEvent> {\n    Task Update(TEvent @event);\n}\n`\nSimple, yet powerful - perspectives react to specific events and update their views accordingly Basic Implementation\n:::new\nIn v0 1 0, perspectives work with in-memory storage:\n:::\n`csharp\n[WhizbangHandler]  // Source generator discovers this\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly Dictionary<Guid, Order> _orders;\n    public OrderPerspective(IInMemoryStore<Order> store) {\n        _orders = store",
        "startIndex": 0,
        "preview": "Perspectives Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic event handling with in-memory updates for multiple views..."
      },
      {
        "id": "v0.1.0/components/perspectives-chunk-1",
        "text": "powerful - perspectives react to specific events and update their views accordingly Basic Implementation :::new In v0 1 0, perspectives work with in-memory storage: ::: `csharp [WhizbangHandler] // Source generator discovers this public class OrderPerspective : IPerspectiveOf<OrderCreated> { private readonly Dictionary<Guid, Order> _orders; public OrderPerspective(IInMemoryStore<Order> store) { _orders = store Collection;\n    }\n    public Task Update(OrderCreated @event) {\n        _orders[@event OrderId] = new Order {\n            Id = @event OrderId,\n            CustomerId = @event CustomerId,\n            Items = @event Items,\n            Total = @event Total,\n            Status = OrderStatus Created,\n            CreatedAt = @event Timestamp\n        };\n        return Task CompletedTask;\n    }\n}\n`\nMultiple Perspectives Pattern\n:::new\nDifferent perspectives can handle the same event to create different views:\n:::\n`csharp\n// Order list for display\n[WhizbangHandler]\npublic class OrderListPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly List<OrderListItem> _orderList;\n    public async Task Update(OrderCreated @event) {\n        _orderList Add(new OrderListItem {\n            Id = @event OrderId,\n            CustomerName = await GetCustomerName(@event CustomerId),\n            Total = @event Total,\n            Status = \"New\",\n            CreatedAt = @event Timestamp\n        });\n    }\n}\n// Customer statistics\n[WhizbangHandler]\npublic class CustomerStatsPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly Dictionary<Guid, CustomerStats> _stats;\n    public Task Update(OrderCreated @event) {\n        if ( _stats TryGetValue(@event CustomerId, out var stats)) {\n            stats = _stats[@event CustomerId] = new CustomerStats();\n        }\n        stats OrderCount++;\n        stats TotalSpent += @event Total;\n        stats LastOrderDate = @event Timestamp;\n        return Task CompletedTask;\n    }\n}\n// Analytics perspective\n[WhizbangHandler]\npublic class AnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IAnalyticsStore _analytics;\n    public Task Update(OrderCreated @event) {\n        _analytics RecordMetric(\"orders created\", 1);\n        _analytics RecordMetric(\"orders value\", @event Total);\n        return Task",
        "startIndex": 2308,
        "preview": "powerful - perspectives react to specific events and update their views accordingly Basic Implementation :::new In v0 1 0, perspectives work with in-m..."
      },
      {
        "id": "v0.1.0/components/perspectives-chunk-2",
        "text": "new CustomerStats(); } stats OrderCount++; stats TotalSpent += @event Total; stats LastOrderDate = @event Timestamp; return Task CompletedTask; } } // Analytics perspective [WhizbangHandler] public class AnalyticsPerspective : IPerspectiveOf<OrderCreated> { private readonly IAnalyticsStore _analytics; public Task Update(OrderCreated @event) { _analytics RecordMetric(\"orders created\", 1); _analytics RecordMetric(\"orders value\", @event Total); return Task CompletedTask;\n    }\n}\n`\nEvent Flow\nHow Events Reach Perspectives\n`mermaid\nsequenceDiagram\n    participant R as Receptor\n    participant D as Dispatcher\n    participant P1 as OrderPerspective\n    participant P2 as StatsPerspective\n    participant P3 as AnalyticsPerspective\n    R->>D: OrderCreated event\n    D->>P1: Update(event)\n    D->>P2: Update(event)\n    D->>P3: Update(event)\n    Note over P1,P3: All perspectives update\n`\nHandling Multiple Event Types\nA perspective can handle multiple event types:\n`csharp\n[WhizbangHandler]\npublic class OrderPerspective : \n    IPerspectiveOf<OrderCreated>,\n    IPerspectiveOf<OrderUpdated>,\n    IPerspectiveOf<OrderShipped>,\n    IPerspectiveOf<OrderCancelled> {\n    private readonly Dictionary<Guid, Order> _orders;\n    public Task Update(OrderCreated @event) {\n        _orders[@event OrderId] = new Order { \n            Status = OrderStatus Created \n        };\n        return Task CompletedTask;\n    }\n    public Task Update(OrderUpdated @event) {\n        _orders[@event OrderId] UpdatedAt = @event Timestamp;\n        return Task CompletedTask;\n    }\n    public Task Update(OrderShipped @event) {\n        _orders[@event OrderId] Status = OrderStatus Shipped;\n        _orders[@event OrderId] ShippedAt = @event Timestamp;\n        return Task CompletedTask;\n    }\n    public Task Update(OrderCancelled @event) {\n        _orders[@event OrderId] Status = OrderStatus Cancelled;\n        return Task CompletedTask;\n    }\n}\n`\nError Handling\n:::new\nBasic error handling in v0 1 0:\n:::\n`csharp\npublic class ResilientPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly ILogger<ResilientPerspective> _logger;\n    public async Task Update(OrderCreated @event) {\n        try {\n            // Update logic\n            await UpdateDatabase(@event);\n        }\n        catch (Exception ex) {\n            _logger LogError(ex, \"Failed to update perspective for order {OrderId}\", \n                @event OrderId);\n            // In v0 1 0, errors are logged but not retried\n            // v0 2",
        "startIndex": 4181,
        "preview": "new CustomerStats(); } stats OrderCount++; stats TotalSpent += @event Total; stats LastOrderDate = @event Timestamp; return Task CompletedTask; } } //..."
      },
      {
        "id": "v0.1.0/components/perspectives-chunk-3",
        "text": ": IPerspectiveOf<OrderCreated> { private readonly ILogger<ResilientPerspective> _logger; public async Task Update(OrderCreated @event) { try { // Update logic await UpdateDatabase(@event); } catch (Exception ex) { _logger LogError(ex, \"Failed to update perspective for order {OrderId}\", @event OrderId); // In v0 1 0, errors are logged but not retried // v0 2 0 adds retry policies and dead letter queues\n            throw;\n        }\n    }\n}\n`\nPolicy Application\n:::new\nPolicies can be applied to perspectives:\n:::\n`csharp\n[Retry(3)]\n[Timeout(5000)]\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task Update(OrderCreated @event) {\n        // Policies are applied automatically by the dispatcher\n        await UpdateDatabase(@event);\n    }\n}\n`\nSource Generation\n:::new\nPerspectives are discovered at compile time:\n:::\n`csharp\n// Generated by Whizbang Generators\npublic static partial class WhizbangGenerated {\n    public static void RegisterPerspectives(IServiceCollection services) {\n        services AddScoped<IPerspectiveOf<OrderCreated>, OrderPerspective>();\n        services AddScoped<IPerspectiveOf<OrderCreated>, CustomerStatsPerspective>();\n        services AddScoped<IPerspectiveOf<OrderCreated>, AnalyticsPerspective>();\n    }\n    public static Dictionary<Type, List<Type>> GetEventPerspectives() {\n        return new() {\n            [typeof(OrderCreated)] = new() {\n                typeof(OrderPerspective),\n                typeof(CustomerStatsPerspective),\n                typeof(AnalyticsPerspective)\n            }\n        };\n    }\n}\n`\nTesting Perspectives\n`csharp\n[Test]\npublic class OrderPerspectiveTests {\n    private OrderPerspective _perspective;\n    private InMemoryStore<Order> _store;\n    [SetUp]\n    public void Setup() {\n        _store = new InMemoryStore<Order>();\n        _perspective = new OrderPerspective(_store);\n    }\n    [Test]\n    public async Task Update_OrderCreated_ShouldStoreOrder() {\n        // Arrange\n        var @event = new OrderCreated(\n            OrderId: Guid NewGuid(),\n            CustomerId: Guid NewGuid(),\n            Items: new[] { new OrderItem(\"SKU-001\", 2, 29 99m) },\n            Total: 59 98m,\n            Timestamp: DateTimeOffset UtcNow\n        );\n        // Act\n        await _perspective Update(@event);\n        // Assert\n        Assert True(_store Collection ContainsKey(@event OrderId));\n        var order = _store Collection[@event OrderId];\n        Assert Equal(@event CustomerId, order CustomerId);\n        Assert Equal(@event Total, order Total);\n        Assert Equal(OrderStatus Created, order",
        "startIndex": 6212,
        "preview": ": IPerspectiveOf<OrderCreated> { private readonly ILogger<ResilientPerspective> _logger; public async Task Update(OrderCreated @event) { try { // Upda..."
      },
      {
        "id": "v0.1.0/components/perspectives-chunk-4",
        "text": "Guid NewGuid(), Items: new[] { new OrderItem(\"SKU-001\", 2, 29 99m) }, Total: 59 98m, Timestamp: DateTimeOffset UtcNow ); // Act await _perspective Update(@event); // Assert Assert True(_store Collection ContainsKey(@event OrderId)); var order = _store Collection[@event OrderId]; Assert Equal(@event CustomerId, order CustomerId); Assert Equal(@event Total, order Total); Assert Equal(OrderStatus Created, order Status);\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Handles: OrderCreated, OrderUpdated, OrderShipped | Updated by: 3 dispatchers\"\npublic class OrderPerspective : IPerspectiveOf<OrderCreated> { }\n// IDE shows: \"Published to: 3 perspectives\"\npublic record OrderCreated(Guid OrderId);\n// IDE shows: \"Updates triggered: 127 times | Avg: 2 3ms | Last: 5s ago\"\npublic async Task Update(OrderCreated @event) { }\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Update invocation | < 1Œºs | TBD |\n| In-memory write | < 100ns | TBD |\n| Multiple perspectives | < 10Œºs | TBD |\n| Error handling | < 1ms | TBD |\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo batch updates - Each event processed individually\nSequential execution - Perspectives run one at a time\nBasic error handling - No retry or dead letter queues\nIn-memory only - No database persistence\nMigration Path\nTo v0 2 0 (Enhanced Features)\n:::planned\nv0 2 0 adds performance and reliability features:\n:::\n`csharp\n// v0 2 0 - Batch updates\npublic class OrderPerspective : IBatchPerspective<OrderCreated> {\n    public async Task UpdateBatch(IEnumerable<OrderCreated> events) {\n        // Process multiple events efficiently\n        await BulkInsert(events);\n    }\n}\n// v0 2 0 - Parallel execution\n[ParallelExecution(MaxDegree = 4)]\npublic class AnalyticsPerspective : IPerspectiveOf<OrderCreated> { }\n`\nTo v0 3 0 (Projections)\n:::planned\nv0 3 0 transforms perspectives into full projections:\n:::\n`csharp\n// v0 3",
        "startIndex": 8446,
        "preview": "Guid NewGuid(), Items: new[] { new OrderItem(\"SKU-001\", 2, 29 99m) }, Total: 59 98m, Timestamp: DateTimeOffset UtcNow ); // Act await _perspective Upd..."
      },
      {
        "id": "v0.1.0/components/perspectives-chunk-5",
        "text": "Task UpdateBatch(IEnumerable<OrderCreated> events) { // Process multiple events efficiently await BulkInsert(events); } } // v0 2 0 - Parallel execution [ParallelExecution(MaxDegree = 4)] public class AnalyticsPerspective : IPerspectiveOf<OrderCreated> { } ` To v0 3 0 (Projections) :::planned v0 3 0 transforms perspectives into full projections: ::: `csharp // v0 3 0 - Projection with rebuild\n[Projection(\"OrderSummary\")]\npublic class OrderProjection : IProjection {\n    public async Task Handle(OrderCreated @event) {\n        // Same as perspective but with checkpoint tracking\n    }\n    [Rebuild]\n    public async Task RebuildFrom(DateTime from) {\n        // Rebuild projection from event history\n    }\n}\n`\nBest Practices\nKeep perspectives focused - One concern per perspective\nAvoid complex logic - Perspectives should be simple updates\nHandle errors gracefully - Log and continue when possible\nDesign for idempotency - Same event twice = same result\nUse multiple perspectives - Different views for different needs\nTest with events - Test perspectives with real event data\nRelated Documentation\nReceptors - Where events come from\nDispatcher - How events reach perspectives\nLenses - Reading the data perspectives write\nTesting - Testing perspectives\nFeature Evolution - How perspectives evolve\nNext Steps\nSee v0 2 0 Enhancements for batch and parallel features\nSee v0 3 0 Projections for full projection support\nReview Examples for practical patterns",
        "startIndex": 9998,
        "preview": "Task UpdateBatch(IEnumerable<OrderCreated> events) { // Process multiple events efficiently await BulkInsert(events); } } // v0 2 0 - Parallel executi..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/policy-engine",
    "title": "Policy Engine Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/policy-engine",
    "chunks": [
      {
        "id": "v0.1.0/components/policy-engine-chunk-0",
        "text": "Policy Engine Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic policies - Retry, Timeout, Cache, and CircuitBreaker\n:::\n:::planned\nComing in v0 2 0: \nPolicy composition for combining multiple policies\nBulkhead isolation for resource protection\nRate limiting with token buckets\nSee planned enhancements ‚Üí\n:::\n:::planned\nComing in v0 6 0: \nAuthorization policies\nAudit logging policies\nCompliance and security policies\nSee production features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>Basic<br/>4 Policies] --> v020[v0 2 0<br/>Composition<br/>Rate Limit]\n    v020 --> v030[v0 3 0<br/>Stateful<br/>Persistence]\n    v030 --> v050[v0 5 0<br/>Distributed<br/>Coordination]\n    v050 --> v060[v0 6 0<br/>Security<br/>Audit]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n    style v060 fill:#F44336,color:#fff\n`\nOverview\nThe Policy Engine provides cross-cutting concerns as composable, declarative policies Instead of cluttering your business logic with retry loops, timeout handling, and caching code, you declare policies that the framework applies automatically In v0 1 0, we provide four essential policies to handle the most common scenarios What is a Policy A Policy:\nWraps component execution with additional behavior\nHandles cross-cutting concerns declaratively\nComposes with other policies\nApplies automatically via source generation\nThink of policies as aspects that modify how your components execute without changing their core logic Core Interface (v0 1 0)\n:::new\nThe basic policy interface for wrapping execution:\n:::\n`csharp\npublic interface IPolicyOf<T> {\n    Task<TResult> Execute<TResult>(\n        Func<Task<TResult>> operation,\n        IMessageContext context\n    );\n}\n`\nAvailable Policies in v0 1 0\nRetry Policy\n:::new\nAutomatically retry failed operations with configurable backoff strategies:\n:::\n`csharp\n// Basic retry with fixed delay\n[Retry(3)]\npublic class PaymentReceptor : IReceptor<ProcessPayment, PaymentProcessed> {\n    public async Task<PaymentProcessed> Receive(ProcessPayment cmd) {\n        // If this throws, it will retry up to 3 times\n        return ProcessPayment(cmd);\n    }\n}\n// Exponential backoff\n[Retry(3, BackoffStrategy",
        "startIndex": 0,
        "preview": "Policy Engine Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic policies - Retry, Timeout, Cache, and CircuitBreaker\n::..."
      },
      {
        "id": "v0.1.0/components/policy-engine-chunk-1",
        "text": "Automatically retry failed operations with configurable backoff strategies: ::: `csharp // Basic retry with fixed delay [Retry(3)] public class PaymentReceptor : IReceptor<ProcessPayment, PaymentProcessed> { public async Task<PaymentProcessed> Receive(ProcessPayment cmd) { // If this throws, it will retry up to 3 times return ProcessPayment(cmd); } } // Exponential backoff [Retry(3, BackoffStrategy Exponential)]\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    // Retries with delays: 1s, 2s, 4s\n}\n// Custom delays\n[Retry(Delays = new[] { 100, 500, 2000 })]\npublic class InventoryReceptor : IReceptor<ReserveStock> {\n    // Retries with specific delays: 100ms, 500ms, 2s\n}\n`\nConfiguration Options\n`csharp\n[Retry(\n    MaxAttempts = 3,\n    BackoffStrategy = BackoffStrategy Exponential,\n    InitialDelayMs = 100,\n    MaxDelayMs = 30000,\n    RetryOn = typeof(TransientException),\n    ExcludeOn = typeof(ValidationException)\n)]\n`\nTimeout Policy\n:::new\nPrevent operations from running indefinitely:\n:::\n`csharp\n// Simple timeout\n[Timeout(5000)]  // 5 seconds\npublic class DatabaseReceptor : IReceptor<QueryData> {\n    public QueryResult Receive(QueryData cmd) {\n        // Cancelled if takes longer than 5 seconds\n        return ExecuteQuery(cmd);\n    }\n}\n// Timeout with custom exception\n[Timeout(3000, ThrowOnTimeout = true)]\npublic class CriticalReceptor : IReceptor<CriticalCommand> {\n    // Throws TimeoutException instead of returning default\n}\n`\nCache Policy\n:::new\nCache results to avoid redundant processing:\n:::\n`csharp\n// Cache for 5 minutes\n[Cache(Duration = 300)]  // seconds\npublic class ProductLens : IProductLens {\n    public Product Focus(Guid productId) {\n        // Result cached for 5 minutes\n        return LoadProduct(productId);\n    }\n}\n// Cache with sliding expiration\n[Cache(Duration = 600, Sliding = true)]\npublic class CustomerLens : ICustomerLens {\n    // Cache extends on each access\n}\n// Cache with custom key\n[Cache(Duration = 300, KeyProperty = \"CustomerId\")]\npublic class OrderHistoryReceptor : IReceptor<GetOrderHistory> {\n    // Cached by CustomerId property\n}\n`\nCircuit Breaker Policy\n:::new\nPrevent cascading failures by breaking the circuit after repeated failures:\n:::\n`csharp\n// Basic circuit breaker\n[CircuitBreaker(\n    FailureThreshold = 0",
        "startIndex": 2327,
        "preview": "Automatically retry failed operations with configurable backoff strategies: ::: `csharp // Basic retry with fixed delay [Retry(3)] public class Paymen..."
      },
      {
        "id": "v0.1.0/components/policy-engine-chunk-2",
        "text": "access } // Cache with custom key [Cache(Duration = 300, KeyProperty = \"CustomerId\")] public class OrderHistoryReceptor : IReceptor<GetOrderHistory> { // Cached by CustomerId property } ` Circuit Breaker Policy :::new Prevent cascading failures by breaking the circuit after repeated failures: ::: `csharp // Basic circuit breaker [CircuitBreaker( FailureThreshold = 0 5,  // 50% failure rate\n    SamplingDuration = 10,   // Over 10 seconds\n    MinimumThroughput = 5,   // At least 5 calls\n    BreakDuration = 30       // Break for 30 seconds\n)]\npublic class ExternalServiceReceptor : IReceptor<CallExternalService> {\n    public ServiceResult Receive(CallExternalService cmd) {\n        // Circuit opens after 50% failures\n        // Stays open for 30 seconds\n        // Then half-open to test recovery\n    }\n}\n`\nCircuit States\n`mermaid\nstateDiagram-v2\n    [*] --> Closed: Initial\n    Closed --> Open: Threshold<br/>Exceeded\n    Open --> HalfOpen: After<br/>BreakDuration\n    HalfOpen --> Closed: Success\n    HalfOpen --> Open: Failure\n`\nApplying Policies\nVia Attributes\n:::new\nThe simplest way to apply policies is via attributes:\n:::\n`csharp\n[Retry(3)]\n[Timeout(5000)]\n[Cache(300)]\n[CircuitBreaker(0 5, 10)]\npublic class ResilientReceptor : IReceptor<ImportantCommand> {\n    public CommandResult Receive(ImportantCommand cmd) {\n        // All policies applied in order:\n        // 1 Check cache\n        // 2 Check circuit breaker\n        // 3 Apply timeout\n        // 4 Retry on failure\n        return ProcessCommand(cmd);\n    }\n}\n`\nPolicy Execution Order\nPolicies execute in a specific order (innermost to outermost):\nCache - Check cache first\nCircuitBreaker - Check if circuit is open\nTimeout - Apply timeout to operation\nRetry - Retry if operation fails\nCustom Policies\n:::new\nCreate custom policies for specific needs:\n:::\n`csharp\n[WhizbangPolicy]\npublic class LoggingPolicy : IPolicyOf<IReceptor> {\n    private readonly ILogger _logger;\n    public async Task<TResult> Execute<TResult>(\n        Func<Task<TResult>> operation,\n        IMessageContext context\n    ) {\n        var stopwatch = Stopwatch StartNew();\n        try {\n            _logger LogInformation(\"Executing {Operation}\", context MessageType);\n            var result = await operation();\n            _logger LogInformation(\"Completed in {ElapsedMs}ms\", stopwatch ElapsedMilliseconds);\n            return result;\n        }\n        catch (Exception ex) {\n            _logger",
        "startIndex": 4230,
        "preview": "access } // Cache with custom key [Cache(Duration = 300, KeyProperty = \"CustomerId\")] public class OrderHistoryReceptor : IReceptor<GetOrderHistory> {..."
      },
      {
        "id": "v0.1.0/components/policy-engine-chunk-3",
        "text": "class LoggingPolicy : IPolicyOf<IReceptor> { private readonly ILogger _logger; public async Task<TResult> Execute<TResult>( Func<Task<TResult>> operation, IMessageContext context ) { var stopwatch = Stopwatch StartNew(); try { _logger LogInformation(\"Executing {Operation}\", context MessageType); var result = await operation(); _logger LogInformation(\"Completed in {ElapsedMs}ms\", stopwatch ElapsedMilliseconds); return result; } catch (Exception ex) { _logger LogError(ex, \"Failed after {ElapsedMs}ms\", stopwatch ElapsedMilliseconds);\n            throw;\n        }\n    }\n}\n// Usage\n[LoggingPolicy]\n[Retry(3)]\npublic class AuditedReceptor : IReceptor<AuditedCommand> { }\n`\nSource Generation\n:::new\nPolicies are woven at compile time for zero overhead:\n:::\n`csharp\n// Generated by Whizbang Generators\npublic static class PolicyWeaver {\n    public static OrderReceptor WrapWithPolicies(OrderReceptor receptor) {\n        return new RetryPolicyWrapper(\n            new TimeoutPolicyWrapper(\n                new CachePolicyWrapper(\n                    new CircuitBreakerPolicyWrapper(receptor)\n                )\n            )\n        );\n    }\n}\n`\nTesting with Policies\n`csharp\n[Test]\npublic class PolicyTests {\n    [Test]\n    public async Task Retry_ShouldRetryThreeTimes() {\n        // Arrange\n        var attempts = 0;\n        var receptor = new TestReceptor(() => {\n            attempts++;\n            if (attempts < 3) throw new TransientException();\n            return new TestResult();\n        });\n        var retryPolicy = new RetryPolicy(3);\n        // Act\n        var result = await retryPolicy Execute(\n            () => receptor Receive(new TestCommand()),\n            new MessageContext()\n        );\n        // Assert\n        Assert Equal(3, attempts);\n        Assert NotNull(result);\n    }\n    [Test]\n    public async Task CircuitBreaker_ShouldOpenAfterFailures() {\n        // Arrange\n        var breaker = new CircuitBreakerPolicy(0 5, 10, 5, 30);\n        var failingOperation = () => throw new Exception();\n        // Act - cause failures\n        for (int i = 0; i < 5; i++) {\n            try {\n                await breaker Execute(failingOperation, new MessageContext());\n            }\n            catch { }\n        }\n        // Assert - circuit should be open\n        Assert Throws<CircuitBreakerOpenException>(\n            () => breaker Execute(failingOperation, new MessageContext())\n        );\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Policies: Retry(3), Timeout(5s), Cache(5m)\"\n[Retry(3)][Timeout(5000)][Cache(300)]\npublic class PolicyReceptor : IReceptor<Command> { }\n// IDE shows: \"Circuit breaker state: Closed | Success: 95% | Calls: 1,234\"\n[CircuitBreaker(0",
        "startIndex": 6307,
        "preview": "class LoggingPolicy : IPolicyOf<IReceptor> { private readonly ILogger _logger; public async Task<TResult> Execute<TResult>( Func<Task<TResult>> operat..."
      },
      {
        "id": "v0.1.0/components/policy-engine-chunk-4",
        "text": "Assert - circuit should be open Assert Throws<CircuitBreakerOpenException>( () => breaker Execute(failingOperation, new MessageContext()) ); } } ` IDE Features `csharp // IDE shows: \"Policies: Retry(3), Timeout(5s), Cache(5m)\" [Retry(3)][Timeout(5000)][Cache(300)] public class PolicyReceptor : IReceptor<Command> { } // IDE shows: \"Circuit breaker state: Closed | Success: 95% | Calls: 1,234\" [CircuitBreaker(0 5, 10)]\npublic class ServiceReceptor { }\n// IDE shows: \"Cache hit rate: 78% | Entries: 234 | Memory: 5 2MB\"\n[Cache(300)]\npublic class CachedLens { }\n`\nPerformance Characteristics\n| Policy | Overhead | Memory Impact |\n|--------|----------|---------------|\n| Retry | < 10ns per attempt | Minimal |\n| Timeout | < 100ns | Timer allocation |\n| Cache | < 50ns lookup | Depends on cache size |\n| CircuitBreaker | < 20ns check | State tracking |\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo policy composition - Cannot combine policies dynamically\nBasic configuration - Limited to attribute parameters\nIn-memory state - Policy state not persisted\nNo distributed coordination - Policies are instance-local\nMigration Path\nTo v0 2 0 (Enhanced Policies)\n:::planned\nv0 2 0 adds composition and new policy types:\n:::\n`csharp\n// v0 2 0 - Policy composition\n[PolicySet(\"Resilient\")]\npublic class OrderReceptor { }\n// Define policy sets\nservices AddPolicySet(\"Resilient\", policies => {\n    policies AddRetry(3);\n    policies AddTimeout(5000);\n    policies AddBulkhead(10);  // New in v0 2 0\n    policies AddRateLimit(100, TimeSpan FromMinute(1));  // New in v0 2 0\n});\n`\nTo v0 6 0 (Security Policies)\n:::planned\nv0 6 0 adds security and compliance policies:\n:::\n`csharp\n// v0 6 0 - Security policies\n[Authorize(Roles = \"Admin\")]\n[Audit(Level = AuditLevel",
        "startIndex": 8530,
        "preview": "Assert - circuit should be open Assert Throws<CircuitBreakerOpenException>( () => breaker Execute(failingOperation, new MessageContext()) ); } } ` IDE..."
      },
      {
        "id": "v0.1.0/components/policy-engine-chunk-5",
        "text": "policies AddBulkhead(10); // New in v0 2 0 policies AddRateLimit(100, TimeSpan FromMinute(1)); // New in v0 2 0 }); ` To v0 6 0 (Security Policies) :::planned v0 6 0 adds security and compliance policies: ::: `csharp // v0 6 0 - Security policies [Authorize(Roles = \"Admin\")] [Audit(Level = AuditLevel Full)]\n[EncryptPII]\npublic class SecureReceptor { }\n`\nBest Practices\nOrder matters - Apply policies in the right order\nConfigure appropriately - Don't retry non-transient errors\nMonitor policy metrics - Track success rates and performance\nTest with policies - Include policies in your tests\nUse circuit breakers - Protect external dependencies\nCache judiciously - Consider memory and staleness\nRelated Documentation\nReceptors - Applying policies to receptors\nPerspectives - Applying policies to perspectives\nDispatcher - How policies are executed\nTesting - Testing with policies\nFeature Evolution - How policies evolve\nNext Steps\nSee v0 2 0 Enhancements for composition and new policies\nSee v0 6 0 Production for security policies\nReview Examples for policy patterns",
        "startIndex": 9912,
        "preview": "policies AddBulkhead(10); // New in v0 2 0 policies AddRateLimit(100, TimeSpan FromMinute(1)); // New in v0 2 0 }); ` To v0 6 0 (Security Policies) ::..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/receptors",
    "title": "Receptors Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/receptors",
    "chunks": [
      {
        "id": "v0.1.0/components/receptors-chunk-0",
        "text": "Receptors Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Type-safe receptors with async support and automatic multi-destination routing\n:::\n:::planned\nComing in v0 2 0: \nSource-generated automatic registration\nPolicy integration through attributes\nZero-reflection performance\nSee planned enhancements ‚Üí\n:::\n:::planned\nComing in v0 3 0: \nAutomatic causality tracking\nComplete time-travel debugging\nReplay capability from any point\nSee temporal features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>Type-Safe<br/>Multi-Destination] --> v020[v0 2 0<br/>Source Generation<br/>Policy Integration]\n    v020 --> v030[v0 3 0<br/>Temporal Awareness<br/>Time-Travel Debug]\n    v030 --> v040[v0 4 0<br/>Distributed<br/>Production Ready]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#9C27B0,color:#fff\n`\nOverview\nReceptors are the decision-making components in Whizbang They receive commands, apply business rules, and emit events representing the decisions made In v0 1 0, receptors are stateless and focus on simple command-to-event transformation What is a Receptor A Receptor:\nReceives commands from the dispatcher\nValidates business rules\nDecides what should happen\nEmits events representing decisions\nNever performs side effects directly\nThink of a receptor as a pure decision function: given a command, what event(s) should occur Core Interface (v0 1",
        "startIndex": 0,
        "preview": "Receptors Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Type-safe receptors with async support and automatic multi-destin..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-1",
        "text": "simple command-to-event transformation What is a Receptor A Receptor: Receives commands from the dispatcher Validates business rules Decides what should happen Emits events representing decisions Never performs side effects directly Think of a receptor as a pure decision function: given a command, what event(s) should occur Core Interface (v0 1 0)\n:::new\nThe type-safe receptor interface with generic message and response types:\n:::\n`csharp\npublic interface IReceptor<TMessage, TResponse> {\n    Task<TResponse> Receive(TMessage message);\n}\n`\nKey Features\nType Safety: Compile-time checking for message and response types\nAsync Support: All operations return Task<TResponse> for async handling\nMulti-Destination: Multiple receptors can handle the same message type\nZero Reflection: Source generation provides maximum performance\nResponse Type Flexibility\nReceptors support flexible response types:\n| Response Type | Behavior | Example |\n|---------------|----------|---------|\n| Single Response | Return typed response | Task<OrderCreated> |\n| Tuple Response | Return multiple related responses | Task<(PaymentProcessed, AuditEvent)> |\n| Array Response | Return dynamic number of responses | Task<NotificationEvent[]> |\n| Result Type | Success/failure handling | Task<Result<OrderCreated>> |\nStateless Implementation\n:::new\nIn v0 1 0, all receptors are stateless and get any needed state from parameters:\n:::\n`csharp\n[WhizbangHandler]  // Source generator discovers this\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async Task<OrderCreated> Receive(CreateOrder cmd) {\n        // Simple validation\n        if (cmd Items Count == 0) {\n            throw new InvalidOperationException(\"Order must have items\");\n        }\n        // Make decision and return response\n        return new OrderCreated(\n            OrderId: Guid NewGuid(),\n            CustomerId: cmd CustomerId,\n            Items: cmd Items,\n            Total: cmd Items Sum(i => i Quantity * i Price),\n            CreatedAt: DateTimeOffset",
        "startIndex": 1492,
        "preview": "simple command-to-event transformation What is a Receptor A Receptor: Receives commands from the dispatcher Validates business rules Decides what shou..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-2",
        "text": "Receive(CreateOrder cmd) { // Simple validation if (cmd Items Count == 0) { throw new InvalidOperationException(\"Order must have items\"); } // Make decision and return response return new OrderCreated( OrderId: Guid NewGuid(), CustomerId: cmd CustomerId, Items: cmd Items, Total: cmd Items Sum(i => i Quantity * i Price), CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nMulti-Destination Routing\n:::new\nKey Feature: Multiple receptors can handle the same message type, running automatically in parallel:\n:::\n`csharp\n// Multiple receptors can handle the same message type\npublic class OrderBusinessReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async Task<OrderCreated> Receive(CreateOrder cmd) {\n        // Main business logic\n        var order = await ProcessOrder(cmd);\n        return new OrderCreated(order Id, order Items);\n    }\n}\npublic class OrderAuditReceptor : IReceptor<CreateOrder, AuditEvent> {\n    public async Task<AuditEvent> Receive(CreateOrder cmd) {\n        // Compliance logging runs in parallel\n        await _auditLog Record(\"OrderCreationAttempt\", cmd);\n        return new AuditEvent(\"OrderCreationAttempt\", cmd OrderId);\n    }\n}\npublic class OrderFraudReceptor : IReceptor<CreateOrder, FraudCheckResult> {\n    public async Task<FraudCheckResult> Receive(CreateOrder cmd) {\n        // Fraud detection runs in parallel\n        var riskScore = await _fraudEngine Analyze(cmd);\n        return new FraudCheckResult(cmd OrderId, riskScore);\n    }\n}\n// Framework automatically routes CreateOrder to all three receptors\n// All run in parallel, each returning their specific response type\n`\nWorking with Lenses\nFor queries, receptors can receive lens parameters:\n`csharp\npublic class OrderUpdateReceptor : IReceptor<UpdateOrder, OrderUpdated> {\n    public async Task<OrderUpdated> Receive(UpdateOrder cmd, IOrderLens lens) {\n        // Use lens to query current state (read-only)\n        var currentOrder = await lens Focus(cmd OrderId);\n        if (currentOrder == null) {\n            throw new OrderNotFoundException(cmd OrderId);\n        }\n        if (currentOrder Status == OrderStatus Shipped) {\n            throw new InvalidOperationException(\"Cannot update shipped order\");\n        }\n        // Return response based on decision\n        return new OrderUpdated(\n            OrderId: cmd OrderId,\n            Changes: cmd Changes,\n            UpdatedAt: DateTimeOffset",
        "startIndex": 3180,
        "preview": "Receive(CreateOrder cmd) { // Simple validation if (cmd Items Count == 0) { throw new InvalidOperationException(\"Order must have items\"); } // Make de..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-3",
        "text": "state (read-only) var currentOrder = await lens Focus(cmd OrderId); if (currentOrder == null) { throw new OrderNotFoundException(cmd OrderId); } if (currentOrder Status == OrderStatus Shipped) { throw new InvalidOperationException(\"Cannot update shipped order\"); } // Return response based on decision return new OrderUpdated( OrderId: cmd OrderId, Changes: cmd Changes, UpdatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nFlexible Response Types\nReceptors can return single responses, tuples, or arrays:\n`csharp\n// Single response\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async Task<OrderCreated> Receive(CreateOrder cmd) {\n        return new OrderCreated(cmd OrderId);\n    }\n}\n// Multiple responses via tuple\npublic class PaymentReceptor : IReceptor<ProcessPayment, (PaymentProcessed, AuditEvent)> {\n    public async Task<(PaymentProcessed, AuditEvent)> Receive(ProcessPayment cmd) {\n        var payment = await ProcessPayment(cmd);\n        return (\n            new PaymentProcessed(payment Id),\n            new AuditEvent(\"PaymentProcessed\", payment Id)\n        );\n    }\n}\n// Array for dynamic responses\npublic class NotificationReceptor : IReceptor<OrderCreated, NotificationEvent[]> {\n    public async Task<NotificationEvent[]> Receive(OrderCreated evt) {\n        var notifications = new List<NotificationEvent>();\n        notifications Add(new EmailSent(evt CustomerId));\n        if (evt Total > 1000) {\n            notifications Add(new HighValueAlert(evt OrderId));\n        }\n        return notifications ToArray();\n    }\n}\n`\nError Handling\nUse Result<T> for explicit success/failure:\n`csharp\npublic class OrderCancelReceptor : IReceptor<CancelOrder, Result<OrderCancelled>> {\n    public async Task<Result<OrderCancelled>> Receive(CancelOrder cmd, IOrderLens lens) {\n        var order = await lens Focus(cmd OrderId);\n        if (order == null) {\n            return Result Failure<OrderCancelled>(\"Order not found\");\n        }\n        if (order Status == OrderStatus Shipped) {\n            return Result Failure<OrderCancelled>(\"Cannot cancel shipped order\");\n        }\n        return Result Success(new OrderCancelled(cmd OrderId));\n    }\n}\n`\nSource Generation\n:::new\nReceptors are discovered at compile time via source generators:\n:::\n`csharp\n// Generated by Whizbang Generators\npublic static partial class WhizbangGenerated {\n    public static void RegisterReceptors(IServiceCollection services) {\n        services AddScoped<IReceptor<CreateOrder, OrderCreated>, OrderReceptor>();\n        services AddScoped<IReceptor<CreateOrder, AuditEvent>, OrderAuditReceptor>();\n        services AddScoped<IReceptor<CreateOrder, FraudCheckResult>, OrderFraudReceptor>();\n        services AddScoped<IReceptor<UpdateOrder, OrderUpdated>, OrderUpdateReceptor>();\n        services",
        "startIndex": 5241,
        "preview": "state (read-only) var currentOrder = await lens Focus(cmd OrderId); if (currentOrder == null) { throw new OrderNotFoundException(cmd OrderId); } if (c..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-4",
        "text": "} ` Source Generation :::new Receptors are discovered at compile time via source generators: ::: `csharp // Generated by Whizbang Generators public static partial class WhizbangGenerated { public static void RegisterReceptors(IServiceCollection services) { services AddScoped<IReceptor<CreateOrder, OrderCreated>, OrderReceptor>(); services AddScoped<IReceptor<CreateOrder, AuditEvent>, OrderAuditReceptor>(); services AddScoped<IReceptor<CreateOrder, FraudCheckResult>, OrderFraudReceptor>(); services AddScoped<IReceptor<UpdateOrder, OrderUpdated>, OrderUpdateReceptor>(); services AddScoped<IReceptor<CancelOrder, Result<OrderCancelled>>, OrderCancelReceptor>();\n    }\n}\n`\nPolicy Application\n:::new\nPolicies can be applied to receptors via attributes:\n:::\n`csharp\n[Retry(3, BackoffStrategy Exponential)]\n[Timeout(5000)]\n[CircuitBreaker(0 5, TimeoutSeconds = 30)]\npublic class PaymentReceptor : IReceptor<ProcessPayment, PaymentProcessed> {\n    public async Task<PaymentProcessed> Receive(ProcessPayment cmd) {\n        // Policies are applied automatically by the dispatcher\n        var result = await ProcessPaymentAsync(cmd);\n        return new PaymentProcessed(cmd PaymentId, result Amount);\n    }\n}\n`\nTesting Receptors\n`csharp\n[Test]\npublic class OrderReceptorTests {\n    private OrderReceptor _receptor;\n    [SetUp]\n    public void Setup() {\n        _receptor = new OrderReceptor();\n    }\n    [Test]\n    public async Task CreateOrder_WithItems_ShouldReturnOrderCreated() {\n        // Arrange\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            Items: new[] { new OrderItem(\"SKU-001\", 2, 29 99m) }\n        );\n        // Act\n        var result = await _receptor Receive(command);\n        // Assert\n        Assert IsType<OrderCreated>(result);\n        Assert NotEqual(Guid Empty, result OrderId);\n        Assert Equal(59 98m, result Total);\n    }\n    [Test]\n    public async Task CreateOrder_WithNoItems_ShouldThrow() {\n        // Arrange\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            Items: Array Empty<OrderItem>()\n        );\n        // Act & Assert\n        await Assert ThrowsAsync<InvalidOperationException>(\n            () => _receptor Receive(command)\n        );\n    }\n}\n`\nIDE Features\nThe IDE provides rich support for receptors:\n`csharp\n// IDE shows: \"Handles: CreateOrder ‚Üí OrderCreated | Type-safe async receptor\"\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> { }\n// IDE shows: \"3 receptors handle this message type\"\npublic record CreateOrder(Guid CustomerId, OrderItem[] Items);\n// IDE shows: \"Returned by: OrderReceptor Receive, OrderBusinessReceptor",
        "startIndex": 7660,
        "preview": "} ` Source Generation :::new Receptors are discovered at compile time via source generators: ::: `csharp // Generated by Whizbang Generators public st..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-5",
        "text": "The IDE provides rich support for receptors: `csharp // IDE shows: \"Handles: CreateOrder ‚Üí OrderCreated | Type-safe async receptor\" public class OrderReceptor : IReceptor<CreateOrder, OrderCreated> { } // IDE shows: \"3 receptors handle this message type\" public record CreateOrder(Guid CustomerId, OrderItem[] Items); // IDE shows: \"Returned by: OrderReceptor Receive, OrderBusinessReceptor Receive\"\npublic record OrderCreated(Guid OrderId, Guid CustomerId);\n`\nDispatcher Integration\nThe Dispatcher provides different ways to invoke receptors:\n`csharp\npublic interface IDispatcher {\n    // Inline async - wait for single response\n    Task<TResponse> Send<TResponse>(object message);\n    // Fire and forget - no response needed\n    Task Fire(object message);\n    // Callback - handle response asynchronously\n    Task SendWithCallback<TResponse>(object message, Func<TResponse, Task> callback);\n    // Multiple responses (from multiple receptors)\n    Task<IEnumerable<object>> SendAll(object message);\n}\n`\nUsage Examples\n`csharp\npublic class OrderController {\n    private readonly IDispatcher _dispatcher;\n    // Inline async - wait for result\n    public async Task<IActionResult> CreateOrder(CreateOrderRequest request) {\n        var command = new CreateOrder(request CustomerId, request Items);\n        var result = await _dispatcher Send<OrderCreated>(command);\n        return Ok(result);\n    }\n    // Fire and forget - audit logging\n    public async Task LogAction(string action) {\n        var auditCommand = new LogAuditEvent(action, GetUserId());\n        await _dispatcher Fire(auditCommand); // Don't wait for completion\n    }\n    // Multiple responses - get all results\n    public async Task<IActionResult> ProcessOrderWithAudit(CreateOrder command) {\n        var results = await _dispatcher SendAll(command);\n        var orderCreated = results OfType<OrderCreated>() Single();\n        var auditEvent = results OfType<AuditEvent>() Single();\n        var fraudResult = results OfType<FraudCheckResult>() Single();\n        return Ok(new { orderCreated, auditEvent, fraudResult });\n    }\n}\n`\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nNo state management - Receptors cannot maintain state between calls\nBasic validation - Manual validation in code  \nLimited dependency injection - Cannot inject services directly into Receive method\nSingle message handling - Each receptor handles one message type\nMigration Path\nTo v0 2 0 (Non-Breaking)\n:::planned\nv0 2",
        "startIndex": 9747,
        "preview": "The IDE provides rich support for receptors: `csharp // IDE shows: \"Handles: CreateOrder ‚Üí OrderCreated | Type-safe async receptor\" public class Order..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-6",
        "text": "versions: ::: No state management - Receptors cannot maintain state between calls Basic validation - Manual validation in code Limited dependency injection - Cannot inject services directly into Receive method Single message handling - Each receptor handles one message type Migration Path To v0 2 0 (Non-Breaking) :::planned v0 2 0 adds these enhancements without breaking existing code:\n:::\n`csharp\n// v0 1 0 - Current async interface\npublic async Task<OrderCreated> Receive(CreateOrder cmd) { }\n// v0 2 0 - Enhanced capabilities\npublic async Task<OrderCreated> Receive(\n    [Valid] CreateOrder cmd,      // Automatic validation\n    IOrderService service,        // Service injection\n    IMessageContext context       // Context injection\n) { }\n`\nTo v0 3 0 (Stateful Receptors)\n:::planned\nv0 3 0 introduces stateful receptors for event sourcing:\n:::\n`csharp\n// v0 3 0 - Stateful receptor\n[EventSourced]\npublic class OrderReceptor : IStatefulReceptor<Order> {\n    private Order state;  // Maintained from events\n    public OrderUpdated Receive(UpdateOrder cmd) {\n        // Can access state directly\n        if (state Status == OrderStatus Shipped) {\n            throw new InvalidOperationException();\n        }\n        return new OrderUpdated(state Id, cmd",
        "startIndex": 11856,
        "preview": "versions: ::: No state management - Receptors cannot maintain state between calls Basic validation - Manual validation in code Limited dependency inje..."
      },
      {
        "id": "v0.1.0/components/receptors-chunk-7",
        "text": "sourcing: ::: `csharp // v0 3 0 - Stateful receptor [EventSourced] public class OrderReceptor : IStatefulReceptor<Order> { private Order state; // Maintained from events public OrderUpdated Receive(UpdateOrder cmd) { // Can access state directly if (state Status == OrderStatus Shipped) { throw new InvalidOperationException(); } return new OrderUpdated(state Id, cmd Changes);\n    }\n}\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Receive invocation | < 100ns | TBD |\n| Event creation | < 50ns | TBD |\n| Validation | < 1Œºs | TBD |\n| Policy application | < 10Œºs | TBD |\nBest Practices\nKeep receptors pure - No side effects, only decisions\nReturn events - Always return events, not void\nValidate early - Check preconditions first\nUse meaningful names - OrderReceptor, not OrderHandler\nOne command type - Each receptor handles one command\nTest thoroughly - Unit test all paths\nRelated Documentation\nDispatcher - How commands reach receptors\nPerspectives - What happens to emitted events\nLenses - Querying state in receptors\nPolicy Engine - Applying policies to receptors\nTesting - Testing receptors\nNext Steps\nSee v0 2 0 Enhancements for validation and injection features\nSee v0 3 0 Stateful Receptors for event sourcing\nReview Examples for practical usage",
        "startIndex": 12784,
        "preview": "sourcing: ::: `csharp // v0 3 0 - Stateful receptor [EventSourced] public class OrderReceptor : IStatefulReceptor<Order> { private Order state; // Mai..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/components/transports",
    "title": "Transports Component",
    "category": "Components",
    "url": "/docs/v0.1.0/components/transports",
    "chunks": [
      {
        "id": "v0.1.0/components/transports-chunk-0",
        "text": "Transports Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-process transport with synchronous message passing\n:::\n:::planned\nComing in v0 2 0: \nHTTP transport for REST APIs\nWebSocket support for real-time\nBasic message serialization\nSee HTTP features ‚Üí\n:::\n:::planned\nComing in v0 3 0: \nMessage queue transports (RabbitMQ, Redis)\nPub/sub patterns\nMessage routing and topics\nSee messaging features ‚Üí\n:::\nEvolution Timeline\n`mermaid\ngraph LR\n    v010[v0 1 0<br/>In-Process<br/>Sync] --> v020[v0 2 0<br/>HTTP<br/>WebSocket]\n    v020 --> v030[v0 3 0<br/>Queues<br/>Pub/Sub]\n    v030 --> v040[v0 4 0<br/>gRPC<br/>Streaming]\n    v040 --> v050[v0 5 0<br/>Cloud<br/>Federation]\n    style v010 fill:#4CAF50,color:#fff\n    style v020 fill:#2196F3,color:#fff\n    style v030 fill:#FF9800,color:#fff\n    style v040 fill:#795548,color:#fff\n    style v050 fill:#9C27B0,color:#fff\n`\nOverview\nTransports provide the communication layer in Whizbang, enabling message exchange between components In v0 1 0, we provide a simple in-process transport that passes messages directly in memory - perfect for monolithic applications and testing What is a Transport A Transport:\nCarries messages between components\nHandles serialization and deserialization\nManages connections and channels\nProvides delivery guarantees\nThink of transports as the postal service of your application - they ensure messages get from sender to receiver reliably Core Interface (v0 1 0)\n:::new\nThe basic transport interface for message passing:\n:::\n`csharp\npublic interface ITransport {\n    // Send a message\n    Task<TResponse> Send<TRequest, TResponse>(TRequest request, string destination)\n        where TRequest : IMessage\n        where TResponse : IMessage;\n    // Send without response\n    Task Publish<TMessage>(TMessage message, string topic)\n        where TMessage : IMessage;\n    // Subscribe to messages\n    Task Subscribe<TMessage>(string topic, Func<TMessage, Task> handler)\n        where TMessage : IMessage;\n    // Transport metadata\n    string Name { get; }\n    TransportCapabilities Capabilities { get; }\n}\npublic enum TransportCapabilities {\n    None = 0,\n    RequestResponse = 1,\n    PublishSubscribe = 2,\n    Streaming = 4,\n    Reliable = 8,\n    Ordered = 16\n}\n`\nIn-Process Transport\n:::new\nThe default in-process transport for v0 1",
        "startIndex": 0,
        "preview": "Transports Component Version Status Next Update\nVersion History\n:::new\nNew in v0 1 0: Basic in-process transport with synchronous message passing\n:::\n..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-1",
        "text": ": IMessage; // Transport metadata string Name { get; } TransportCapabilities Capabilities { get; } } public enum TransportCapabilities { None = 0, RequestResponse = 1, PublishSubscribe = 2, Streaming = 4, Reliable = 8, Ordered = 16 } ` In-Process Transport :::new The default in-process transport for v0 1 0:\n:::\n`csharp\n[WhizbangTransport(\"InProcess\")]\npublic class InProcessTransport : ITransport {\n    private readonly Dictionary<string, object> _handlers = new();\n    private readonly Dictionary<string, List<Func<object, Task>>> _subscribers = new();\n    private readonly object _lock = new();\n    public string Name => \"InProcess\";\n    public TransportCapabilities Capabilities => \n        TransportCapabilities RequestResponse | \n        TransportCapabilities PublishSubscribe |\n        TransportCapabilities Ordered;\n    // Register a handler for request/response\n    public void RegisterHandler<TRequest, TResponse>(\n        string destination, \n        Func<TRequest, Task<TResponse>> handler)\n        where TRequest : IMessage\n        where TResponse : IMessage {\n        lock (_lock) {\n            _handlers[destination] = handler;\n        }\n    }\n    public async Task<TResponse> Send<TRequest, TResponse>(\n        TRequest request, \n        string destination)\n        where TRequest : IMessage\n        where TResponse : IMessage {\n        object handler;\n        lock (_lock) {\n            if ( _handlers TryGetValue(destination, out handler )) {\n                throw new TransportException($\"No handler registered for {destination}\");\n            }\n        }\n        var typedHandler = (Func<TRequest, Task<TResponse>>)handler;\n        return await typedHandler(request);\n    }\n    public async Task Publish<TMessage>(TMessage message, string topic)\n        where TMessage : IMessage {\n        List<Func<object, Task>> subscribers;\n        lock (_lock) {\n            if ( _subscribers TryGetValue(topic, out subscribers )) {\n                return; // No subscribers\n            }\n            subscribers = subscribers ToList(); // Copy to avoid lock during execution\n        }\n        // Execute all subscribers\n        var tasks = subscribers Select(sub => sub(message ));\n        await Task WhenAll(tasks);\n    }\n    public Task Subscribe<TMessage>(string topic, Func<TMessage, Task> handler)\n        where TMessage : IMessage {\n        lock (_lock) {\n            if ( _subscribers ContainsKey(topic)) {\n                _subscribers[topic] = new List<Func<object, Task>>();\n            }\n            _subscribers[topic] Add(async obj => await handler((TMessage)obj));\n        }\n        return Task",
        "startIndex": 2347,
        "preview": ": IMessage; // Transport metadata string Name { get; } TransportCapabilities Capabilities { get; } } public enum TransportCapabilities { None = 0, Req..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-2",
        "text": "Execute all subscribers var tasks = subscribers Select(sub => sub(message )); await Task WhenAll(tasks); } public Task Subscribe<TMessage>(string topic, Func<TMessage, Task> handler) where TMessage : IMessage { lock (_lock) { if ( _subscribers ContainsKey(topic)) { _subscribers[topic] = new List<Func<object, Task>>(); } _subscribers[topic] Add(async obj => await handler((TMessage)obj)); } return Task CompletedTask;\n    }\n}\n`\nMessage Contracts\n:::new\nDefine messages for transport:\n:::\n`csharp\npublic interface IMessage {\n    Guid Id { get; }\n    DateTimeOffset Timestamp { get; }\n    Dictionary<string, string> Headers { get; }\n}\npublic abstract record Message : IMessage {\n    public Guid Id { get; init; } = Guid NewGuid();\n    public DateTimeOffset Timestamp { get; init; } = DateTimeOffset UtcNow;\n    public Dictionary<string, string> Headers { get; init; } = new();\n}\n// Command message\npublic record CreateOrderCommand : Message {\n    public Guid CustomerId { get; init; }\n    public List<OrderItem> Items { get; init; }\n    public decimal Total { get; init; }\n}\n// Event message\npublic record OrderCreatedEvent : Message {\n    public Guid OrderId { get; init; }\n    public Guid CustomerId { get; init; }\n    public OrderStatus Status { get; init; }\n}\n// Query message\npublic record GetOrderQuery : Message {\n    public Guid OrderId { get; init; }\n}\n// Response message\npublic record OrderResponse : Message {\n    public Order Order { get; init; }\n    public bool Success { get; init; }\n    public string Error { get; init; }\n}\n`\nTransport Registration\nTransports are registered and configured at startup:\n`csharp\n// Manual registration\nservices AddWhizbangTransports(options => {\n    options UseInProcess();\n});\n// Register handlers\nservices AddTransportHandlers(handlers => {\n    handlers Handle<CreateOrderCommand, OrderCreatedEvent>(\"orders\", \n        async cmd => {\n            // Process command\n            return new OrderCreatedEvent { \n                OrderId = Guid NewGuid(),\n                CustomerId = cmd",
        "startIndex": 4659,
        "preview": "Execute all subscribers var tasks = subscribers Select(sub => sub(message )); await Task WhenAll(tasks); } public Task Subscribe<TMessage>(string topi..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-3",
        "text": "} ` Transport Registration Transports are registered and configured at startup: `csharp // Manual registration services AddWhizbangTransports(options => { options UseInProcess(); }); // Register handlers services AddTransportHandlers(handlers => { handlers Handle<CreateOrderCommand, OrderCreatedEvent>(\"orders\", async cmd => { // Process command return new OrderCreatedEvent { OrderId = Guid NewGuid(), CustomerId = cmd CustomerId \n            };\n        });\n});\n// Source generated registration\npublic static partial class WhizbangGenerated {\n    public static void RegisterTransports(IServiceCollection services) {\n        services AddSingleton<ITransport, InProcessTransport>();\n        // Auto-discover and register handlers\n        services AddScoped<IHandler<CreateOrderCommand>, CreateOrderHandler>();\n    }\n}\n`\nUsing Transports\nIn Receptors\n`csharp\npublic class OrderReceptor : IReceptor<CreateOrder> {\n    private readonly ITransport _transport;\n    public OrderReceptor(ITransport transport) {\n        _transport = transport;\n    }\n    public async Task<OrderCreated> Receive(CreateOrder cmd) {\n        // Validate locally\n        if ( IsValid(cmd)) {\n            throw new ValidationException(\"Invalid order\");\n        }\n        // Send to inventory service (in-process for now)\n        var inventoryCommand = new CheckInventoryCommand {\n            Items = cmd Items\n        };\n        var inventoryResponse = await _transport Send<CheckInventoryCommand, InventoryResponse>(\n            inventoryCommand, \n            \"inventory\"\n        );\n        if ( inventoryResponse Available) {\n            throw new InsufficientInventoryException();\n        }\n        // Create order\n        var orderCreated = new OrderCreated {\n            OrderId = Guid NewGuid(),\n            CustomerId = cmd CustomerId,\n            Items = cmd Items\n        };\n        // Publish event\n        await _transport Publish(orderCreated, \"orders created\");\n        return orderCreated;\n    }\n}\n`\nEvent Subscriptions\n`csharp\npublic class NotificationService {\n    private readonly ITransport _transport;\n    public async Task Start() {\n        // Subscribe to order events\n        await _transport Subscribe<OrderCreatedEvent>(\n            \"orders created\",\n            HandleOrderCreated\n        );\n        await _transport Subscribe<OrderShippedEvent>(\n            \"orders shipped\",\n            HandleOrderShipped\n        );\n    }\n    private async Task HandleOrderCreated(OrderCreatedEvent evt) {\n        // Send confirmation email\n        await SendEmail(evt CustomerId, \"Order Confirmed\", \n            $\"Your order {evt OrderId} has been confirmed \");\n    }\n    private async Task HandleOrderShipped(OrderShippedEvent evt) {\n        // Send shipping notification\n        await SendEmail(evt CustomerId, \"Order Shipped\",\n            $\"Your order {evt OrderId} has been shipped \");\n    }\n}\n`\nMessage Pipeline\n:::new\nSimple message pipeline for v0 1",
        "startIndex": 6288,
        "preview": "} ` Transport Registration Transports are registered and configured at startup: `csharp // Manual registration services AddWhizbangTransports(options ..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-4",
        "text": "email await SendEmail(evt CustomerId, \"Order Confirmed\", $\"Your order {evt OrderId} has been confirmed \"); } private async Task HandleOrderShipped(OrderShippedEvent evt) { // Send shipping notification await SendEmail(evt CustomerId, \"Order Shipped\", $\"Your order {evt OrderId} has been shipped \"); } } ` Message Pipeline :::new Simple message pipeline for v0 1 0:\n:::\n`csharp\npublic interface IMessagePipeline {\n    Task<TResponse> Process<TRequest, TResponse>(\n        TRequest request,\n        Func<TRequest, Task<TResponse>> next);\n}\npublic class MessagePipeline : IMessagePipeline {\n    private readonly List<IMessageMiddleware> _middleware = new();\n    public void Use(IMessageMiddleware middleware) {\n        _middleware Add(middleware);\n    }\n    public async Task<TResponse> Process<TRequest, TResponse>(\n        TRequest request,\n        Func<TRequest, Task<TResponse>> handler) {\n        // Build pipeline\n        Func<TRequest, Task<TResponse>> pipeline = handler;\n        foreach (var middleware in _middleware Reverse<IMessageMiddleware>()) {\n            var next = pipeline;\n            pipeline = async req => await middleware Process(req, () => next(req));\n        }\n        return await pipeline(request);\n    }\n}\n// Example middleware\npublic class LoggingMiddleware : IMessageMiddleware {\n    private readonly ILogger _logger;\n    public async Task<object> Process(object message, Func<Task<object>> next) {\n        _logger LogInformation(\"Processing {MessageType}\", message GetType() Name);\n        var start = Stopwatch StartNew();\n        try {\n            var result = await next();\n            _logger LogInformation(\"Processed in {ElapsedMs}ms\", start ElapsedMilliseconds);\n            return result;\n        }\n        catch (Exception ex) {\n            _logger LogError(ex, \"Failed after {ElapsedMs}ms\", start ElapsedMilliseconds);\n            throw;\n        }\n    }\n}\n`\nTesting with Transports\n`csharp\n[Test]\npublic class TransportTests {\n    private InProcessTransport _transport;\n    [SetUp]\n    public void Setup() {\n        _transport = new InProcessTransport();\n    }\n    [Test]\n    public async Task Send_ShouldInvokeHandler() {\n        // Arrange\n        var handlerCalled = false;\n        _transport RegisterHandler<TestCommand, TestResponse>(\n            \"test\",\n            async cmd => {\n                handlerCalled = true;\n                return new TestResponse { Success = true };\n            }\n        );\n        // Act\n        var response = await _transport Send<TestCommand, TestResponse>(\n            new TestCommand(),\n            \"test\"\n        );\n        // Assert\n        Assert True(handlerCalled);\n        Assert True(response Success);\n    }\n    [Test]\n    public async Task Publish_ShouldNotifyAllSubscribers() {\n        // Arrange\n        var received1 = false;\n        var received2 = false;\n        await _transport Subscribe<TestEvent>(\"test",
        "startIndex": 8806,
        "preview": "email await SendEmail(evt CustomerId, \"Order Confirmed\", $\"Your order {evt OrderId} has been confirmed \"); } private async Task HandleOrderShipped(Ord..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-5",
        "text": "return new TestResponse { Success = true }; } ); // Act var response = await _transport Send<TestCommand, TestResponse>( new TestCommand(), \"test\" ); // Assert Assert True(handlerCalled); Assert True(response Success); } [Test] public async Task Publish_ShouldNotifyAllSubscribers() { // Arrange var received1 = false; var received2 = false; await _transport Subscribe<TestEvent>(\"test topic\", evt => {\n            received1 = true;\n            return Task CompletedTask;\n        });\n        await _transport Subscribe<TestEvent>(\"test topic\", evt => {\n            received2 = true;\n            return Task CompletedTask;\n        });\n        // Act\n        await _transport Publish(new TestEvent(), \"test topic\");\n        // Assert\n        Assert True(received1);\n        Assert True(received2);\n    }\n}\n`\nIDE Features\n`csharp\n// IDE shows: \"Transport: InProcess | Handlers: 12 | Subscribers: 34\"\npublic interface ITransport { }\n// IDE shows: \"Called 234 times | Avg: 0 5ms | Success: 99 8%\"\npublic Task<TResponse> Send<TRequest, TResponse>( ) { }\n// IDE shows: \"Topic: orders created | Subscribers: 3\"\npublic Task Publish<TMessage>(TMessage message, string topic) { }\n`\nPerformance Characteristics\n| Operation | Target | Actual |\n|-----------|--------|--------|\n| Send (in-process) | < 100ns | TBD |\n| Publish (10 subscribers) | < 1Œºs | TBD |\n| Subscribe | < 50ns | TBD |\n| Message serialization | N/A | N/A |\nLimitations in v0 1 0\n:::info\nThese limitations are addressed in future versions:\n:::\nIn-process only - No network communication\nNo persistence - Messages lost on crash\nNo serialization - Direct object passing\nNo retry - Failed messages are lost\nSingle instance - No distributed messaging\nMigration Path\nTo v0 2 0 (HTTP/WebSocket)\n:::planned\nv0 2 0 adds network transports:\n:::\n`csharp\n// v0 2 0 - HTTP transport\nservices AddWhizbangTransports(options => {\n    options UseHttp(http => {\n        http BaseUrl = \"https://api example com\";\n        http Timeout = TimeSpan FromSeconds(30);\n    });\n});\n`\nTo v0 3 0 (Message Queues)\n:::planned\nv0 3",
        "startIndex": 11346,
        "preview": "return new TestResponse { Success = true }; } ); // Act var response = await _transport Send<TestCommand, TestResponse>( new TestCommand(), \"test\" ); ..."
      },
      {
        "id": "v0.1.0/components/transports-chunk-6",
        "text": "2 0 (HTTP/WebSocket) :::planned v0 2 0 adds network transports: ::: `csharp // v0 2 0 - HTTP transport services AddWhizbangTransports(options => { options UseHttp(http => { http BaseUrl = \"https://api example com\"; http Timeout = TimeSpan FromSeconds(30); }); }); ` To v0 3 0 (Message Queues) :::planned v0 3 0 adds message queue support:\n:::\n`csharp\n// v0 3 0 - RabbitMQ transport\nservices AddWhizbangTransports(options => {\n    options UseRabbitMQ(rabbit => {\n        rabbit ConnectionString = \"amqp://localhost\";\n        rabbit ExchangeName = \"whizbang\";\n    });\n});\n`\nBest Practices\nDesign for distribution - Even with in-process, assume network\nUse message contracts - Define clear message schemas\nHandle failures - Plan for transport failures\nVersion messages - Plan for message evolution\nKeep messages small - Large messages impact performance\nTest with different transports - Ensure transport agnostic code\nRelated Documentation\nDispatcher - How messages are routed\nReceptors - Message handlers\nTesting - Testing with transports\nFeature Evolution - How transports evolve\nNext Steps\nSee v0 2 0 HTTP Transport for REST APIs\nSee v0 3 0 Message Queues for async messaging\nReview Examples for transport patterns",
        "startIndex": 13016,
        "preview": "2 0 (HTTP/WebSocket) :::planned v0 2 0 adds network transports: ::: `csharp // v0 2 0 - HTTP transport services AddWhizbangTransports(options => { opt..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/dispatcher",
    "title": "Dispatcher Deep Dive",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/dispatcher",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-0",
        "text": "Dispatcher Deep Dive\nThe Dispatcher is Whizbang's central message router It provides three distinct dispatch patterns for different messaging scenarios: commands, queries, and events Quick Reference\n| Pattern | Use Case | Return Type | Performance | Distribution |\n|---------|----------|-------------|-------------|--------------|\n| SendAsync | Commands with delivery tracking | DeliveryReceipt | ~100Œºs | Local or Remote |\n| LocalInvokeAsync | In-process queries/commands | TResponse | < 20ns | Local only |\n| PublishAsync | Event broadcasting | void | ~50Œºs | Local or Remote |\nIDispatcher Interface\n`csharp\nnamespace Whizbang Core;\npublic interface IDispatcher {\n    // Pattern 1: Command dispatch with delivery receipt\n    Task<DeliveryReceipt> SendAsync<TMessage>(\n        TMessage message,\n        CancellationToken cancellationToken = default\n    ) where TMessage : notnull;\n    // Pattern 2: In-process RPC with typed response\n    Task<TResponse> LocalInvokeAsync<TMessage, TResponse>(\n        TMessage message,\n        CancellationToken cancellationToken = default\n    ) where TMessage : notnull;\n    // Pattern 3: Event broadcasting (fire-and-forget)\n    Task PublishAsync<TMessage>(\n        TMessage message,\n        CancellationToken cancellationToken = default\n    ) where TMessage : notnull;\n}\n`\n---\nPattern 1: SendAsync - Command Dispatch\nUse Case: Send commands with delivery tracking, supports both local and remote dispatch Signature:\n`csharp\nTask<DeliveryReceipt> SendAsync<TMessage>(\n    TMessage message,\n    CancellationToken cancellationToken = default\n) where TMessage : notnull;\n`\nReturns: DeliveryReceipt containing message ID, correlation ID, and timestamp Basic Usage\n`csharp\npublic class OrdersController : ControllerBase {\n    private readonly IDispatcher _dispatcher;\n    public OrdersController(IDispatcher dispatcher) {\n        _dispatcher = dispatcher;\n    }\n    [HttpPost]\n    public async Task<ActionResult> CreateOrder(\n        [FromBody] CreateOrderRequest request,\n        CancellationToken ct) {\n        var command = new CreateOrder(\n            CustomerId: request CustomerId,\n            Items: request Items\n        );\n        // Send command, get delivery receipt\n        var receipt = await _dispatcher SendAsync(command, ct);\n        return Accepted(new {\n            messageId = receipt MessageId,\n            correlationId = receipt CorrelationId,\n            timestamp = receipt",
        "startIndex": 0,
        "preview": "Dispatcher Deep Dive\nThe Dispatcher is Whizbang's central message router It provides three distinct dispatch patterns for different messaging scenario..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-1",
        "text": "[HttpPost] public async Task<ActionResult> CreateOrder( [FromBody] CreateOrderRequest request, CancellationToken ct) { var command = new CreateOrder( CustomerId: request CustomerId, Items: request Items ); // Send command, get delivery receipt var receipt = await _dispatcher SendAsync(command, ct); return Accepted(new { messageId = receipt MessageId, correlationId = receipt CorrelationId, timestamp = receipt Timestamp\n        });\n    }\n}\n`\nDeliveryReceipt Structure\n`csharp\npublic record DeliveryReceipt(\n    Guid MessageId,        // Unique ID for this message\n    Guid CorrelationId,    // ID for tracking related messages\n    DateTimeOffset Timestamp\n);\n`\nUse cases:\nLong-running operations where you track completion separately\nCommands that may be processed asynchronously\nRemote command dispatch via transport (Azure Service Bus, etc )\nIdempotency tracking (store receipt, check for duplicates)\nSendAsync Flow\n`\nClient\n  ‚îú‚îÄ> dispatcher SendAsync(command)\n  ‚îú‚îÄ> Envelope created (MessageId, CorrelationId)\n  ‚îú‚îÄ> Receptor invoked locally\n  ‚îú‚îÄ> Event stored in Outbox\n  ‚îî‚îÄ> DeliveryReceipt returned\nBackground Worker\n  ‚îú‚îÄ> Polls Outbox\n  ‚îú‚îÄ> Publishes event to transport (Azure Service Bus)\n  ‚îî‚îÄ> Marks message as Published\n`\nKey Points:\nAsynchronous semantics: Receipt doesn't mean message is processed, just accepted\nOutbox integration: Event stored for reliable delivery\nIdempotency: Use MessageId to detect duplicates\nExample: Long-Running Order Processing\n`csharp\n[HttpPost(\"orders\")]\npublic async Task<ActionResult> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    var command = new CreateOrder(\n        CustomerId: request CustomerId,\n        Items: request Items\n    );\n    // Send command - returns immediately with receipt\n    var receipt = await _dispatcher SendAsync(command, ct);\n    // Store receipt for later tracking\n    await _trackingService StoreReceiptAsync(\n        receipt MessageId,\n        receipt CorrelationId,\n        \"Order creation initiated\"\n    );\n    // Return 202 Accepted with tracking URL\n    return Accepted(new {\n        trackingUrl = $\"/api/orders/status/{receipt CorrelationId}\",\n        messageId = receipt MessageId\n    });\n}\n[HttpGet(\"orders/status/{correlationId:guid}\")]\npublic async Task<ActionResult> GetOrderStatus(Guid correlationId) {\n    var status = await _trackingService GetStatusAsync(correlationId);\n    return Ok(status);\n}\n`\n---\nPattern 2: LocalInvokeAsync - In-Process RPC\nUse Case: Fast, synchronous-style command/query execution with typed response",
        "startIndex": 2433,
        "preview": "[HttpPost] public async Task<ActionResult> CreateOrder( [FromBody] CreateOrderRequest request, CancellationToken ct) { var command = new CreateOrder( ..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-2",
        "text": "Accepted with tracking URL return Accepted(new { trackingUrl = $\"/api/orders/status/{receipt CorrelationId}\", messageId = receipt MessageId }); } [HttpGet(\"orders/status/{correlationId:guid}\")] public async Task<ActionResult> GetOrderStatus(Guid correlationId) { var status = await _trackingService GetStatusAsync(correlationId); return Ok(status); } ` --- Pattern 2: LocalInvokeAsync - In-Process RPC Use Case: Fast, synchronous-style command/query execution with typed response Signature:\n`csharp\nTask<TResponse> LocalInvokeAsync<TMessage, TResponse>(\n    TMessage message,\n    CancellationToken cancellationToken = default\n) where TMessage : notnull;\n`\nReturns: Typed response from receptor (TResponse) Performance: < 20ns dispatch overhead, zero allocations (with object pooling) Basic Usage\n`csharp\n[HttpPost(\"orders\")]\npublic async Task<ActionResult<OrderCreated>> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    var command = new CreateOrder(\n        CustomerId: request CustomerId,\n        Items: request Items\n    );\n    // Invoke receptor, get typed response\n    var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n        command,\n        ct\n    );\n    // Publish event to perspectives\n    await _dispatcher PublishAsync(result, ct);\n    return CreatedAtAction(\n        nameof(GetOrder),\n        new { orderId = result OrderId },\n        result\n    );\n}\n`\nLocalInvokeAsync Flow\n`\nClient\n  ‚îú‚îÄ> dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command)\n  ‚îú‚îÄ> Lookup receptor in registry (compile-time, zero reflection)\n  ‚îú‚îÄ> Invoke receptor HandleAsync(command)\n  ‚îú‚îÄ> Return typed response\n  ‚îî‚îÄ> < 20ns overhead (zero allocations)\n`\nKey Points:\nCompile-time safety: Type mismatch = compiler error\nZero reflection: Routing generated at compile time\nSynchronous semantics: Waits for receptor to complete\nLocal only: Cannot cross process boundaries\nPerformance: Optimal for in-process commands/queries\nExample: Query with Typed Response\n`csharp\npublic record GetOrderQuery(Guid OrderId);\npublic record OrderDetails(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    string Status\n);\npublic class GetOrderReceptor : IReceptor<GetOrderQuery, OrderDetails> {\n    private readonly IOrderLens _lens;\n    public GetOrderReceptor(IOrderLens lens) {\n        _lens = lens;\n    }\n    public async ValueTask<OrderDetails> HandleAsync(\n        GetOrderQuery query,\n        CancellationToken ct = default) {\n        var order = await _lens GetOrderAsync(query OrderId, ct);\n        if (order is null) {\n            throw new NotFoundException($\"Order {query OrderId} not found\");\n        }\n        return new OrderDetails(\n            OrderId: order OrderId,\n            CustomerId: order CustomerId,\n            Items: order",
        "startIndex": 4577,
        "preview": "Accepted with tracking URL return Accepted(new { trackingUrl = $\"/api/orders/status/{receipt CorrelationId}\", messageId = receipt MessageId }); } [Htt..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-3",
        "text": "GetOrderReceptor(IOrderLens lens) { _lens = lens; } public async ValueTask<OrderDetails> HandleAsync( GetOrderQuery query, CancellationToken ct = default) { var order = await _lens GetOrderAsync(query OrderId, ct); if (order is null) { throw new NotFoundException($\"Order {query OrderId} not found\"); } return new OrderDetails( OrderId: order OrderId, CustomerId: order CustomerId, Items: order Items,\n            Total: order Total,\n            Status: order Status\n        );\n    }\n}\n// Controller usage\n[HttpGet(\"orders/{orderId:guid}\")]\npublic async Task<ActionResult<OrderDetails>> GetOrder(\n    Guid orderId,\n    CancellationToken ct) {\n    var query = new GetOrderQuery(orderId);\n    try {\n        var details = await _dispatcher LocalInvokeAsync<GetOrderQuery, OrderDetails>(\n            query,\n            ct\n        );\n        return Ok(details);\n    } catch (NotFoundException ex) {\n        return NotFound(new { error = ex Message });\n    }\n}\n`\nType Safety Enforcement\n`csharp\n// ‚úÖ CORRECT - Type mismatch caught at compile time\nvar result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n// ‚ùå COMPILER ERROR - Type mismatch\nvar wrong = await _dispatcher LocalInvokeAsync<CreateOrder, PaymentProcessed>(command);\n// Error: No receptor registered for CreateOrder ‚Üí PaymentProcessed\n`\nPerformance Optimization\nLocalInvokeAsync achieves < 20ns overhead through:\nCompile-time routing: Source generators create direct method calls\nValue types: Envelope and hops use structs where possible\nObject pooling: Reuse envelope instances\nZero reflection: No runtime type discovery\nGenerated code example:\n`csharp\n// Generated by Whizbang Generators\nprotected override ReceptorInvoker<TResult> GetReceptorInvoker<TResult>(\n    object message,\n    Type messageType) {\n    // Direct type check, no reflection\n    if (messageType == typeof(CreateOrder)) {\n        var receptor = _serviceProvider GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n        return async msg => (TResult)(object)await receptor HandleAsync((CreateOrder)msg);\n    }\n    // other message types\n    return null;\n}\n`\n---\nPattern 3: PublishAsync - Event Broadcasting\nUse Case: Broadcast events to multiple listeners (perspectives) Signature:\n`csharp\nTask PublishAsync<TMessage>(\n    TMessage message,\n    CancellationToken cancellationToken = default\n) where TMessage : notnull;\n`\nReturns: Task (no return value, fire-and-forget) Basic Usage\n`csharp\n[HttpPost(\"orders\")]\npublic async Task<ActionResult<OrderCreated>> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    var command = new CreateOrder(\n        CustomerId: request",
        "startIndex": 6927,
        "preview": "GetOrderReceptor(IOrderLens lens) { _lens = lens; } public async ValueTask<OrderDetails> HandleAsync( GetOrderQuery query, CancellationToken ct = defa..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-4",
        "text": "Case: Broadcast events to multiple listeners (perspectives) Signature: `csharp Task PublishAsync<TMessage>( TMessage message, CancellationToken cancellationToken = default ) where TMessage : notnull; ` Returns: Task (no return value, fire-and-forget) Basic Usage `csharp [HttpPost(\"orders\")] public async Task<ActionResult<OrderCreated>> CreateOrder( [FromBody] CreateOrderRequest request, CancellationToken ct) { var command = new CreateOrder( CustomerId: request CustomerId,\n        Items: request Items\n    );\n    // 1 Execute command\n    var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n        command,\n        ct\n    );\n    // 2 Publish event to all perspectives\n    await _dispatcher PublishAsync(result, ct);\n    return CreatedAtAction(nameof(GetOrder), new { orderId = result OrderId }, result);\n}\n`\nPublishAsync Flow\n`\nClient\n  ‚îú‚îÄ> dispatcher PublishAsync(event)\n  ‚îú‚îÄ> Find all perspectives for event type\n  ‚îú‚îÄ> Invoke each perspective UpdateAsync(event)\n  ‚îÇ   ‚îú‚îÄ> OrderSummaryPerspective UpdateAsync(OrderCreated)\n  ‚îÇ   ‚îú‚îÄ> InventoryPerspective UpdateAsync(OrderCreated)\n  ‚îÇ   ‚îî‚îÄ> AnalyticsPerspective UpdateAsync(OrderCreated)\n  ‚îî‚îÄ> All perspectives updated (parallel execution)\n`\nKey Points:\nMultiple listeners: One event triggers multiple perspectives\nFire-and-forget: Doesn't wait for perspectives to complete (async)\nLocal broadcast: All perspectives in current process\nOutbox integration: Event can be stored for remote publishing\nExample: Multiple Perspectives\n`csharp\n// Event\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\n// Perspective 1: Order summary for UI\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO order_summaries (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            }\n        );\n    }\n}\n// Perspective 2: Analytics/reporting\npublic class OrderAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO order_analytics (order_id, customer_id, total, created_at) VALUES (@OrderId, @CustomerId, @Total, @CreatedAt)\",\n            new {\n                @event",
        "startIndex": 3697,
        "preview": "Case: Broadcast events to multiple listeners (perspectives) Signature: `csharp Task PublishAsync<TMessage>( TMessage message, CancellationToken cancel..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-5",
        "text": "} // Perspective 2: Analytics/reporting public class OrderAnalyticsPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory _db; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"INSERT INTO order_analytics (order_id, customer_id, total, created_at) VALUES (@OrderId, @CustomerId, @Total, @CreatedAt)\", new { @event OrderId,\n                @event CustomerId,\n                @event Total,\n                @event CreatedAt\n            }\n        );\n    }\n}\n// Perspective 3: Notification system\npublic class NotificationPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IEmailService _email;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await _email SendAsync(\n            to: await GetCustomerEmailAsync(@event CustomerId),\n            subject: \"Order Confirmed\",\n            body: $\"Your order {@event OrderId} has been created Total: {@event Total:C}\"\n        );\n    }\n}\n`\nWhen you call PublishAsync(orderCreated), all three perspectives are invoked automatically Remote Publishing with Outbox\n`csharp\n// In receptor - store event in outbox for remote publishing\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IWorkCoordinator _coordinator;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Business logic var @event = new OrderCreated(/ /);\n        // Store in outbox for reliable publishing\n        await _coordinator ProcessWorkBatchAsync(\n            instanceId: Guid NewGuid(),\n            serviceName: \"OrderService\",\n            hostName: Environment MachineName,\n            processId: Environment ProcessId,\n            metadata: null,\n            outboxCompletions: [],\n            outboxFailures: [],\n            inboxCompletions: [],\n            inboxFailures: [],\n            receptorCompletions: [],\n            receptorFailures: [],\n            perspectiveCompletions: [],\n            perspectiveFailures: [],\n            newOutboxMessages: [\n                new OutboxMessage(\n                    MessageId: Guid CreateVersion7(),\n                    MessageType: typeof(OrderCreated) FullName ,\n                    Payload: JsonSerializer Serialize(@event),\n                    CorrelationId: GetCorrelationId(),\n                    Topic: \"orders\",\n                    PartitionKey: @event CustomerId ToString()\n                )\n            ],\n            newInboxMessages: [],\n            renewOutboxLeaseIds: [],\n            renewInboxLeaseIds: [],\n            flags: WorkBatchFlags",
        "startIndex": 10939,
        "preview": "} // Perspective 2: Analytics/reporting public class OrderAnalyticsPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory ..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-6",
        "text": "metadata: null, outboxCompletions: [], outboxFailures: [], inboxCompletions: [], inboxFailures: [], receptorCompletions: [], receptorFailures: [], perspectiveCompletions: [], perspectiveFailures: [], newOutboxMessages: [ new OutboxMessage( MessageId: Guid CreateVersion7(), MessageType: typeof(OrderCreated) FullName , Payload: JsonSerializer Serialize(@event), CorrelationId: GetCorrelationId(), Topic: \"orders\", PartitionKey: @event CustomerId ToString() ) ], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], flags: WorkBatchFlags None,\n            ct: ct\n        );\n        return @event;\n    }\n}\n`\n---\nDecision Matrix\nWhen to Use Each Pattern\n| Scenario | Pattern | Reason |\n|----------|---------|--------|\n| Create order (synchronous response needed) | LocalInvokeAsync | Need typed OrderCreated response immediately |\n| Create order (async processing) | SendAsync | Return receipt, process in background |\n| Query order details | LocalInvokeAsync | Need typed OrderDetails response |\n| Update read models after command | PublishAsync | Broadcast event to perspectives |\n| Send email notification | PublishAsync | Fire-and-forget to notification perspective |\n| Remote command (cross-service) | SendAsync | Delivery tracking, supports transport |\n| In-process RPC-style call | LocalInvokeAsync | Fastest, type-safe |\nPattern Comparison\n`csharp\n// Scenario: Create an order\n// Option 1: SendAsync (async semantics, delivery tracking)\nvar receipt = await _dispatcher SendAsync(command);\n// Returns: DeliveryReceipt { MessageId, CorrelationId, Timestamp }\n// Use: When you need to track delivery or process asynchronously\n// Option 2: LocalInvokeAsync (sync semantics, typed response)\nvar result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n// Returns: OrderCreated { OrderId, CustomerId, Total, }\n// Use: When you need the result immediately (< 20ns overhead)\n// Option 3: PublishAsync (broadcast to listeners)\nawait _dispatcher PublishAsync(orderCreated);\n// Returns: void\n// Use: After command completes, update all perspectives\n`\n---\nError Handling\nLocalInvokeAsync Error Handling\n`csharp\n[HttpPost(\"orders\")]\npublic async Task<ActionResult> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    try {\n        var command = new CreateOrder(request CustomerId, request Items);\n        var result = await _dispatcher",
        "startIndex": 13936,
        "preview": "metadata: null, outboxCompletions: [], outboxFailures: [], inboxCompletions: [], inboxFailures: [], receptorCompletions: [], receptorFailures: [], per..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-7",
        "text": "to listeners) await _dispatcher PublishAsync(orderCreated); // Returns: void // Use: After command completes, update all perspectives ` --- Error Handling LocalInvokeAsync Error Handling `csharp [HttpPost(\"orders\")] public async Task<ActionResult> CreateOrder( [FromBody] CreateOrderRequest request, CancellationToken ct) { try { var command = new CreateOrder(request CustomerId, request Items); var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n            command,\n            ct\n        );\n        await _dispatcher PublishAsync(result, ct);\n        return CreatedAtAction(nameof(GetOrder), new { orderId = result OrderId }, result);\n    } catch (ValidationException ex) {\n        // Business rule violation (e g , invalid quantity)\n        return BadRequest(new { error = ex Message, errors = ex ValidationErrors });\n    } catch (NotFoundException ex) {\n        // Entity not found (e g , customer doesn't exist)\n        return NotFound(new { error = ex Message });\n    } catch (InvalidOperationException ex) {\n        // Business logic error (e g , insufficient inventory)\n        return Conflict(new { error = ex Message });\n    } catch (OperationCanceledException) {\n        // Client cancelled request\n        return StatusCode(499, new { error = \"Request cancelled\" });\n    } catch (Exception ex) {\n        // Unexpected error\n        _logger LogError(ex, \"Failed to create order\");\n        return StatusCode(500, new { error: \"An unexpected error occurred\" });\n    }\n}\n`\nSendAsync Error Handling\n`csharp\ntry {\n    var receipt = await _dispatcher SendAsync(command, ct);\n    // Store receipt for tracking\n    await _trackingService StoreAsync(receipt);\n    return Accepted(new { trackingId = receipt CorrelationId });\n} catch (Exception ex) {\n    // SendAsync errors typically indicate infrastructure issues\n    _logger LogError(ex, \"Failed to dispatch command\");\n    return StatusCode(503, new { error = \"Service temporarily unavailable\" });\n}\n`\nPublishAsync Error Handling\n`csharp\ntry {\n    await _dispatcher PublishAsync(orderCreated, ct);\n} catch (AggregateException ex) {\n    // One or more perspectives failed\n    foreach (var inner in ex InnerExceptions) {\n        _logger LogError(inner, \"Perspective update failed\");\n    }\n    // Decide: fail request or continue",
        "startIndex": 15791,
        "preview": "to listeners) await _dispatcher PublishAsync(orderCreated); // Returns: void // Use: After command completes, update all perspectives ` --- Error Hand..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-8",
        "text": "new { error = \"Service temporarily unavailable\" }); } ` PublishAsync Error Handling `csharp try { await _dispatcher PublishAsync(orderCreated, ct); } catch (AggregateException ex) { // One or more perspectives failed foreach (var inner in ex InnerExceptions) { _logger LogError(inner, \"Perspective update failed\"); } // Decide: fail request or continue // Option 1: Fail entire request\n    throw;\n    // Option 2: Log and continue (eventual consistency)\n    // Perspectives will catch up via event replay\n}\n`\n---\nAdvanced Patterns\nPattern: Command + Event in Single Transaction\n`csharp\n[HttpPost(\"orders\")]\npublic async Task<ActionResult<OrderCreated>> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    var command = new CreateOrder(request CustomerId, request Items);\n    // Execute command\n    var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n        command,\n        ct\n    );\n    // Publish event to local perspectives\n    await _dispatcher PublishAsync(result, ct);\n    // Also send via SendAsync for outbox (remote publishing)\n    await _dispatcher SendAsync(result, ct);\n    return CreatedAtAction(nameof(GetOrder), new { orderId = result OrderId }, result);\n}\n`\nResult:\nLocal perspectives updated immediately\nEvent stored in outbox for remote publishing\nBackground worker publishes to Azure Service Bus\nPattern: Conditional Publishing\n`csharp\npublic async Task<ActionResult> ProcessPayment(\n    [FromBody] ProcessPaymentRequest request,\n    CancellationToken ct) {\n    var command = new ProcessPayment(request OrderId, request Amount);\n    var result = await _dispatcher LocalInvokeAsync<ProcessPayment, PaymentResult>(\n        command,\n        ct\n    );\n    // Publish different events based on result\n    if (result IsSuccess) {\n        await _dispatcher PublishAsync(\n            new PaymentProcessed(result OrderId, result Amount, result TransactionId),\n            ct\n        );\n    } else {\n        await _dispatcher PublishAsync(\n            new PaymentFailed(result OrderId, result Amount, result ErrorCode),\n            ct\n        );\n    }\n    return Ok(result);\n}\n`\nPattern: Batch Processing\n`csharp\npublic async Task<ActionResult> ProcessOrders(\n    [FromBody] ProcessOrdersRequest request,\n    CancellationToken ct) {\n    var results = new List<OrderCreated>();\n    foreach (var item in request Orders) {\n        var command = new CreateOrder(item CustomerId, item Items);\n        var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n            command,\n            ct\n        );\n        results",
        "startIndex": 17676,
        "preview": "new { error = \"Service temporarily unavailable\" }); } ` PublishAsync Error Handling `csharp try { await _dispatcher PublishAsync(orderCreated, ct); } ..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-9",
        "text": "} return Ok(result); } ` Pattern: Batch Processing `csharp public async Task<ActionResult> ProcessOrders( [FromBody] ProcessOrdersRequest request, CancellationToken ct) { var results = new List<OrderCreated>(); foreach (var item in request Orders) { var command = new CreateOrder(item CustomerId, item Items); var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>( command, ct ); results Add(result);\n    }\n    // Publish all events in batch\n    foreach (var result in results) {\n        await _dispatcher PublishAsync(result, ct);\n    }\n    return Ok(new { ordersCreated = results Count, orders = results });\n}\n`\n---\nPerformance Considerations\nLocalInvokeAsync Benchmarks\n| Scenario | Overhead | Allocations |\n|----------|----------|-------------|\n| Direct method call | 0ns | 0 bytes |\n| LocalInvokeAsync (cold) | 15-20ns | 0 bytes (pooled) |\n| LocalInvokeAsync (warm) | < 10ns | 0 bytes |\n| SendAsync | ~100Œºs | Minimal (envelope) |\n| PublishAsync | ~50Œºs | Minimal |\nTips:\nUse LocalInvokeAsync for hot paths (< 20ns)\nUse SendAsync for asynchronous commands (acceptable ~100Œºs)\nUse PublishAsync for events (fire-and-forget)\nObject Pooling\nWhizbang uses object pooling for message envelopes:\n`csharp\n// Automatically pooled\nvar envelope = MessageEnvelope Create(message, correlationId, causationId);\n// After dispatch, envelope is returned to pool\n// Next dispatch reuses pooled instance (zero allocation)\n`\nResult: Zero allocations in steady state (after warmup) ---\nIntegration with Patterns\nOutbox Pattern\nSendAsync integrates with the Outbox pattern:\n`csharp\n// Receptor stores event in outbox\nvar @event = new OrderCreated(/ /);\nawait _coordinator ProcessWorkBatchAsync(\n    / /,\n    newOutboxMessages: [\n        new OutboxMessage(/ event data /)\n    ],\n    / /\n);\n// Background worker publishes from outbox\nvar batch = await _coordinator ProcessWorkBatchAsync(/ /);\nforeach (var msg in batch ClaimedOutboxMessages) {\n    await _transport PublishAsync(msg);\n}\n`\nSee Outbox Pattern for details Inbox Pattern\nSendAsync integrates with the Inbox pattern for exactly-once processing:\n`csharp\n// Check inbox for duplicate\nvar existing = await _coordinator",
        "startIndex": 19928,
        "preview": "} return Ok(result); } ` Pattern: Batch Processing `csharp public async Task<ActionResult> ProcessOrders( [FromBody] ProcessOrdersRequest request, Can..."
      },
      {
        "id": "v0.1.0/core-concepts/dispatcher-chunk-10",
        "text": "worker publishes from outbox var batch = await _coordinator ProcessWorkBatchAsync(/ /); foreach (var msg in batch ClaimedOutboxMessages) { await _transport PublishAsync(msg); } ` See Outbox Pattern for details Inbox Pattern SendAsync integrates with the Inbox pattern for exactly-once processing: `csharp // Check inbox for duplicate var existing = await _coordinator FindInboxMessageAsync(messageId);\nif (existing is not null) {\n    // Duplicate detected - return cached result\n    return existing Result;\n}\n// Process message\nvar result = await _dispatcher LocalInvokeAsync<TMessage, TResponse>(message);\n// Store in inbox\nawait _coordinator ProcessWorkBatchAsync(\n    / /,\n    newInboxMessages: [\n        new InboxMessage(messageId, result)\n    ],\n    / /\n);\n`\nSee Inbox Pattern for details ---\nTesting\nTesting with Dispatcher\n`csharp\npublic class OrderEndpointsTests {\n    private IDispatcher _dispatcher;\n    private OrdersController _controller;\n    [Before(Test)]\n    public void Setup() {\n        var services = new ServiceCollection();\n        services AddWhizbangCore();\n        services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n        var provider = services BuildServiceProvider();\n        _dispatcher = provider GetRequiredService<IDispatcher>();\n        _controller = new OrdersController(_dispatcher);\n    }\n    [Test]\n    public async Task CreateOrder_ValidRequest_ReturnsCreatedAsync() {\n        // Arrange\n        var request = new CreateOrderRequest(\n            CustomerId: Guid NewGuid(),\n            Items: [new OrderLineItem(Guid NewGuid(), 5, 19 99m)]\n        );\n        // Act\n        var result = await _controller CreateOrder(request, CancellationToken None);\n        // Assert\n        await Assert That(result Result) IsTypeOf<CreatedAtActionResult>();\n        var createdResult = (CreatedAtActionResult)result Result ;\n        await Assert That(createdResult Value) IsTypeOf<OrderCreated>();\n    }\n}\n`\n---\nFurther Reading\nCore Concepts:\nReceptors - Message handlers that dispatcher invokes\nPerspectives - Event listeners for read models\nMessage Context - Correlation and causation tracking\nMessaging Patterns:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nWork Coordination - Distributed work coordination\nExamples:\nECommerce: Order Service - Real-world dispatcher usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 21716,
        "preview": "worker publishes from outbox var batch = await _coordinator ProcessWorkBatchAsync(/ /); foreach (var msg in batch ClaimedOutboxMessages) { await _tran..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/lenses",
    "title": "Lenses Guide",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/lenses",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-0",
        "text": "Lenses Guide\nLenses are query-optimized repositories for reading data from read models (maintained by Perspectives) They complete the \"Q\" in CQRS - providing fast, efficient queries over denormalized data Core Concept\nA Lens is a focused view for querying specific read models:\nReads from denormalized tables (updated by Perspectives)\nFast, simple queries (no joins, no complexity)\nOptimized for specific use cases (customer orders, inventory levels, analytics)\nRead-only (no write operations)\nILensQuery Interface\n`csharp\nnamespace Whizbang Core;\npublic interface ILensQuery {\n    // Marker interface - no required methods\n    // Implement query methods specific to your read model\n}\n`\nKey Characteristics:\nMarker interface: Identifies lens implementations\nNo prescribed methods: Define queries specific to your use case\nRead-only: Never mutates data\nAsync: All methods return Task<T> or ValueTask<T>\n---\nRelationship to Perspectives\nPerspectives and Lenses work together to implement CQRS:\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ WRITE SIDE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                                      ‚îÇ\n‚îÇ  Command ‚Üí Receptor ‚Üí Event          ‚îÇ\n‚îÇ                                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n             ‚îÇ\n             ‚îÇ dispatcher PublishAsync()\n             ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ READ SIDE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                                      ‚îÇ\n‚îÇ  Event ‚Üí Perspective ‚Üí Read Model    ‚îÇ  ‚Üê Perspectives WRITE\n‚îÇ             ‚Üì                        ‚îÇ\n‚îÇ  Read Model Table (denormalized)    ‚îÇ\n‚îÇ             ‚Üì                        ‚îÇ\n‚îÇ  Lens ‚Üí Query Read Model             ‚îÇ  ‚Üê Lenses READ\n‚îÇ             ‚Üì                        ‚îÇ\n‚îÇ  Return DTO to Client                ‚îÇ\n‚îÇ                                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nDivision of Labor:\nPerspectives: Update read models (write-only)\nLenses: Query read models (read-only)\n---\nBasic Example\n`csharp\nusing Whizbang Core;\nusing Dapper;\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public OrderLens(IDbConnectionFactory db) {\n        _db = db;\n    }\n    public async Task<OrderSummary > GetOrderAsync(\n        Guid orderId,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        return await conn",
        "startIndex": 0,
        "preview": "Lenses Guide\nLenses are query-optimized repositories for reading data from read models (maintained by Perspectives) They complete the \"Q\" in CQRS - pr..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-1",
        "text": "(read-only) --- Basic Example `csharp using Whizbang Core; using Dapper; public class OrderLens : ILensQuery { private readonly IDbConnectionFactory _db; public OrderLens(IDbConnectionFactory db) { _db = db; } public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"\"\"\n            SELECT\n                order_id AS OrderId,\n                customer_id AS CustomerId,\n                customer_email AS CustomerEmail,\n                customer_name AS CustomerName,\n                item_count AS ItemCount,\n                total AS Total,\n                status AS Status,\n                created_at AS CreatedAt,\n                shipped_at AS ShippedAt,\n                cancelled_at AS CancelledAt\n            FROM order_summaries\n            WHERE order_id = @OrderId\n            \"\"\",\n            new { OrderId = orderId },\n            commandTimeout: 30,\n            cancellationToken: ct\n        );\n    }\n    public async Task<OrderSummary[]> GetOrdersByCustomerAsync(\n        Guid customerId,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        var orders = await conn QueryAsync<OrderSummary>(\n            \"\"\"\n            SELECT\n                order_id AS OrderId,\n                customer_id AS CustomerId,\n                customer_email AS CustomerEmail,\n                customer_name AS CustomerName,\n                item_count AS ItemCount,\n                total AS Total,\n                status AS Status,\n                created_at AS CreatedAt,\n                shipped_at AS ShippedAt,\n                cancelled_at AS CancelledAt\n            FROM order_summaries\n            WHERE customer_id = @CustomerId\n            ORDER BY created_at DESC\n            \"\"\",\n            new { CustomerId = customerId },\n            commandTimeout: 30,\n            cancellationToken: ct\n        );\n        return orders ToArray();\n    }\n}\n// DTO returned by lens\npublic record OrderSummary(\n    Guid OrderId,\n    Guid CustomerId,\n    string CustomerEmail,\n    string CustomerName,\n    int ItemCount,\n    decimal Total,\n    string Status,\n    DateTimeOffset CreatedAt,\n    DateTimeOffset ShippedAt,\n    DateTimeOffset CancelledAt\n);\n`\nKey Points:\nSimple SQL (single table, no joins)\nReturns DTOs optimized for client\nAsync methods with CancellationToken\nNullable return for \"not found\" cases\n---\nQuery Patterns\nPattern 1: Get by ID\n`csharp\npublic async Task<OrderSummary > GetOrderAsync(\n    Guid orderId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n        \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n        new { OrderId = orderId },\n        cancellationToken: ct\n    );\n}\n`\nUse Case: Retrieve single entity by primary key",
        "startIndex": 2277,
        "preview": "(read-only) --- Basic Example `csharp using Whizbang Core; using Dapper; public class OrderLens : ILensQuery { private readonly IDbConnectionFactory _..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-2",
        "text": "public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleOrDefaultAsync<OrderSummary>( \"SELECT * FROM order_summaries WHERE order_id = @OrderId\", new { OrderId = orderId }, cancellationToken: ct ); } ` Use Case: Retrieve single entity by primary key Pattern 2: List with Filtering\n`csharp\npublic async Task<OrderSummary[]> GetOrdersByStatusAsync(\n    string status,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var orders = await conn QueryAsync<OrderSummary>(\n        \"\"\"\n        SELECT * FROM order_summaries\n        WHERE status = @Status\n        ORDER BY created_at DESC\n        \"\"\",\n        new { Status = status },\n        cancellationToken: ct\n    );\n    return orders ToArray();\n}\n`\nUse Case: Filter and sort lists Pattern 3: Pagination\n`csharp\npublic async Task<PagedResult<OrderSummary>> GetOrdersPagedAsync(\n    int pageNumber,\n    int pageSize,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var offset = (pageNumber - 1) * pageSize;\n    // Get total count\n    var totalCount = await conn ExecuteScalarAsync<int>(\n        \"SELECT COUNT(*) FROM order_summaries\",\n        cancellationToken: ct\n    );\n    // Get page of results\n    var orders = await conn QueryAsync<OrderSummary>(\n        \"\"\"\n        SELECT * FROM order_summaries\n        ORDER BY created_at DESC\n        LIMIT @PageSize OFFSET @Offset\n        \"\"\",\n        new { PageSize = pageSize, Offset = offset },\n        cancellationToken: ct\n    );\n    return new PagedResult<OrderSummary>(\n        Items: orders ToArray(),\n        TotalCount: totalCount,\n        PageNumber: pageNumber,\n        PageSize: pageSize\n    );\n}\npublic record PagedResult<T>(\n    T[] Items,\n    int TotalCount,\n    int PageNumber,\n    int PageSize\n) {\n    public int TotalPages => (int)Math Ceiling(TotalCount / (double)PageSize);\n    public bool HasPreviousPage => PageNumber > 1;\n    public bool HasNextPage => PageNumber < TotalPages;\n}\n`\nUse Case: Large result sets with pagination Pattern 4: Aggregations\n`csharp\npublic async Task<OrderStatistics> GetOrderStatisticsAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    return await conn",
        "startIndex": 4866,
        "preview": "public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return ..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-3",
        "text": "/ (double)PageSize); public bool HasPreviousPage => PageNumber > 1; public bool HasNextPage => PageNumber < TotalPages; } ` Use Case: Large result sets with pagination Pattern 4: Aggregations `csharp public async Task<OrderStatistics> GetOrderStatisticsAsync( Guid customerId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleAsync<OrderStatistics>(\n        \"\"\"\n        SELECT\n            COUNT(*) AS TotalOrders,\n            SUM(total) AS TotalSpent,\n            AVG(total) AS AverageOrderValue,\n            MAX(created_at) AS LastOrderDate\n        FROM order_summaries\n        WHERE customer_id = @CustomerId\n        \"\"\",\n        new { CustomerId = customerId },\n        cancellationToken: ct\n    );\n}\npublic record OrderStatistics(\n    int TotalOrders,\n    decimal TotalSpent,\n    decimal AverageOrderValue,\n    DateTimeOffset LastOrderDate\n);\n`\nUse Case: Analytics and dashboard widgets Pattern 5: Search\n`csharp\npublic async Task<OrderSummary[]> SearchOrdersAsync(\n    string searchTerm,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var orders = await conn QueryAsync<OrderSummary>(\n        \"\"\"\n        SELECT * FROM order_summaries\n        WHERE\n            customer_email ILIKE @SearchPattern\n            OR customer_name ILIKE @SearchPattern\n            OR status ILIKE @SearchPattern\n        ORDER BY created_at DESC\n        LIMIT 100\n        \"\"\",\n        new { SearchPattern = $\"%{searchTerm}%\" },\n        cancellationToken: ct\n    );\n    return orders ToArray();\n}\n`\nUse Case: Free-text search across multiple columns",
        "startIndex": 6869,
        "preview": "/ (double)PageSize); public bool HasPreviousPage => PageNumber > 1; public bool HasNextPage => PageNumber < TotalPages; } ` Use Case: Large result set..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-4",
        "text": "orders = await conn QueryAsync<OrderSummary>( \"\"\" SELECT * FROM order_summaries WHERE customer_email ILIKE @SearchPattern OR customer_name ILIKE @SearchPattern OR status ILIKE @SearchPattern ORDER BY created_at DESC LIMIT 100 \"\"\", new { SearchPattern = $\"%{searchTerm}%\" }, cancellationToken: ct ); return orders ToArray(); } ` Use Case: Free-text search across multiple columns ---\nMultiple Lenses for Same Read Model\nDifferent lenses can query the same read model with different methods:\n`csharp\n// Lens 1: Customer-focused queries\npublic class CustomerOrderLens : ILensQuery {\n    public async Task<OrderSummary[]> GetOrdersByCustomerAsync(Guid customerId, CancellationToken ct = default) {\n        // Query order_summaries filtered by customer_id\n    }\n    public async Task<OrderStatistics> GetCustomerOrderStatisticsAsync(Guid customerId, CancellationToken ct = default) {\n        // Aggregate stats for customer\n    }\n}\n// Lens 2: Admin-focused queries\npublic class AdminOrderLens : ILensQuery {\n    public async Task<OrderSummary[]> GetAllOrdersAsync(int pageNumber, int pageSize, CancellationToken ct = default) {\n        // Query all orders with pagination\n    }\n    public async Task<OrderSummary[]> GetOrdersByDateRangeAsync(DateOnly startDate, DateOnly endDate, CancellationToken ct = default) {\n        // Query by date range\n    }\n    public async Task<decimal> GetTotalRevenueAsync(DateOnly date, CancellationToken ct = default) {\n        // Sum total revenue for date\n    }\n}\n`\nPattern: Organize lenses by use case (customer, admin, analytics) ---\nComplex Queries\nWhile lenses prefer simple queries, you can handle complexity when needed:\nJoining Denormalized Tables\n`csharp\npublic async Task<CustomerOrderHistory> GetCustomerOrderHistoryAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Join two denormalized read models\n    var result = await conn QueryAsync<CustomerOrderHistoryItem>(\n        \"\"\"\n        SELECT\n            os order_id,\n            os total,\n            os status,\n            os created_at,\n            ca total_orders,\n            ca lifetime_value\n        FROM order_summaries os\n        JOIN customer_activity ca ON os customer_id = ca customer_id\n        WHERE os customer_id = @CustomerId\n        ORDER BY os created_at DESC\n        \"\"\",\n        new { CustomerId = customerId },\n        cancellationToken: ct\n    );\n    return new CustomerOrderHistory(\n        CustomerId: customerId,\n        Orders: result",
        "startIndex": 8133,
        "preview": "orders = await conn QueryAsync<OrderSummary>( \"\"\" SELECT * FROM order_summaries WHERE customer_email ILIKE @SearchPattern OR customer_name ILIKE @Sear..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-5",
        "text": "order_id, os total, os status, os created_at, ca total_orders, ca lifetime_value FROM order_summaries os JOIN customer_activity ca ON os customer_id = ca customer_id WHERE os customer_id = @CustomerId ORDER BY os created_at DESC \"\"\", new { CustomerId = customerId }, cancellationToken: ct ); return new CustomerOrderHistory( CustomerId: customerId, Orders: result ToArray()\n    );\n}\n`\nNote: Even when joining, you're joining denormalized read models, not normalized write models Still fast JSON Querying (PostgreSQL)\n`csharp\npublic async Task<Product[]> GetProductsByCategoryAsync(\n    string category,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Query JSON column\n    var products = await conn QueryAsync<Product>(\n        \"\"\"\n        SELECT * FROM product_catalog\n        WHERE metadata->>'category' = @Category\n        ORDER BY name\n        \"\"\",\n        new { Category = category },\n        cancellationToken: ct\n    );\n    return products ToArray();\n}\n`\n---\nDependency Injection\nRegistration\nManual:\n`csharp\nbuilder Services AddTransient<ILensQuery, OrderLens>();\nbuilder Services AddTransient<ILensQuery, InventoryLens>();\n// Or register by interface name\nbuilder Services AddTransient<IOrderLens, OrderLens>();\nbuilder Services AddTransient<IInventoryLens, InventoryLens>();\n`\nAuto-Discovery (with Whizbang Generators):\n`csharp\nbuilder Services AddDiscoveredLenses();  // Finds all ILensQuery implementations\n`\nLifetime\nRecommended: Transient (new instance per request)\nWhy May inject scoped services (e g , DbContext)\nStateless (no benefit to reusing instances)\nLightweight (minimal allocation cost)\n`csharp\nbuilder Services AddTransient<IOrderLens, OrderLens>();\n`\n---\nCaching Strategies\nIn-Memory Caching\n`csharp\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    private readonly IMemoryCache _cache;\n    public OrderLens(IDbConnectionFactory db, IMemoryCache cache) {\n        _db = db;\n        _cache = cache;\n    }\n    public async Task<OrderSummary > GetOrderAsync(\n        Guid orderId,\n        CancellationToken ct = default) {\n        // Try cache first\n        if (_cache TryGetValue(orderId, out OrderSummary cached)) {\n            return cached;\n        }\n        // Query database\n        await using var conn = _db CreateConnection();\n        var order = await conn",
        "startIndex": 10280,
        "preview": "order_id, os total, os status, os created_at, ca total_orders, ca lifetime_value FROM order_summaries os JOIN customer_activity ca ON os customer_id =..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-6",
        "text": "cache) { _db = db; _cache = cache; } public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { // Try cache first if (_cache TryGetValue(orderId, out OrderSummary cached)) { return cached; } // Query database await using var conn = _db CreateConnection(); var order = await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            cancellationToken: ct\n        );\n        if (order is not null) {\n            // Cache for 5 minutes\n            _cache Set(orderId, order, TimeSpan FromMinutes(5));\n        }\n        return order;\n    }\n}\n`\nDistributed Caching (Redis)\n`csharp\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    private readonly IDistributedCache _cache;\n    public async Task<OrderSummary > GetOrderAsync(\n        Guid orderId,\n        CancellationToken ct = default) {\n        var cacheKey = $\"order:{orderId}\";\n        // Try distributed cache\n        var cachedJson = await _cache GetStringAsync(cacheKey, ct);\n        if (cachedJson is not null) {\n            return JsonSerializer Deserialize<OrderSummary>(cachedJson);\n        }\n        // Query database\n        await using var conn = _db CreateConnection();\n        var order = await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            cancellationToken: ct\n        );\n        if (order is not null) {\n            // Cache in Redis\n            var json = JsonSerializer Serialize(order);\n            await _cache SetStringAsync(\n                cacheKey,\n                json,\n                new DistributedCacheEntryOptions {\n                    AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(5)\n                },\n                ct\n            );\n        }\n        return order;\n    }\n}\n`\nCache Invalidation: Perspectives can invalidate cache when updating read models:\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    private readonly IDistributedCache _cache;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update database\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\"INSERT INTO order_summaries ( ) VALUES ( )\", @event, ct);\n        // Invalidate cache\n        await _cache RemoveAsync($\"order:{@event",
        "startIndex": 12297,
        "preview": "cache) { _db = db; _cache = cache; } public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { // Try cache firs..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-7",
        "text": "OrderSummaryPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory _db; private readonly IDistributedCache _cache; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { // Update database await using var conn = _db CreateConnection(); await conn ExecuteAsync(\"INSERT INTO order_summaries ( ) VALUES ( )\", @event, ct); // Invalidate cache await _cache RemoveAsync($\"order:{@event OrderId}\", ct);\n    }\n}\n`\n---\nTesting Lenses\nUnit Tests\n`csharp\npublic class OrderLensTests {\n    [Test]\n    public async Task GetOrderAsync_ExistingOrder_ReturnsOrderSummaryAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();  // Returns mock with test data\n        var lens = new OrderLens(mockDb);\n        var orderId = TestData ExistingOrderId;\n        // Act\n        var result = await lens GetOrderAsync(orderId, CancellationToken None);\n        // Assert\n        await Assert That(result) IsNotNull();\n        await Assert That(result OrderId) IsEqualTo(orderId);\n        await Assert That(result Total) IsGreaterThan(0m);\n    }\n    [Test]\n    public async Task GetOrderAsync_NonExistentOrder_ReturnsNullAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();  // Returns null for non-existent order\n        var lens = new OrderLens(mockDb);\n        var orderId = Guid NewGuid();  // Doesn't exist\n        // Act\n        var result = await lens GetOrderAsync(orderId, CancellationToken None);\n        // Assert\n        await Assert That(result) IsNull();\n    }\n    [Test]\n    public async Task GetOrdersPagedAsync_ValidPage_ReturnsPagedResultAsync() {\n        // Arrange\n        var mockDb = CreateMockDbWithOrders(25);  // 25 orders total\n        var lens = new OrderLens(mockDb);\n        // Act\n        var result = await lens GetOrdersPagedAsync(\n            pageNumber: 2,\n            pageSize: 10,\n            CancellationToken None\n        );\n        // Assert\n        await Assert That(result Items Length) IsEqualTo(10);  // Second page\n        await Assert That(result TotalCount) IsEqualTo(25);\n        await Assert That(result TotalPages) IsEqualTo(3);  // 25 / 10 = 3 pages\n        await Assert That(result HasPreviousPage) IsTrue();   // Page 2 has previous\n        await Assert That(result HasNextPage)",
        "startIndex": 14553,
        "preview": "OrderSummaryPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory _db; private readonly IDistributedCache _cache; public ..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-8",
        "text": "GetOrdersPagedAsync( pageNumber: 2, pageSize: 10, CancellationToken None ); // Assert await Assert That(result Items Length) IsEqualTo(10); // Second page await Assert That(result TotalCount) IsEqualTo(25); await Assert That(result TotalPages) IsEqualTo(3); // 25 / 10 = 3 pages await Assert That(result HasPreviousPage) IsTrue(); // Page 2 has previous await Assert That(result HasNextPage) IsTrue();       // Page 2 has next\n    }\n}\n`\nIntegration Tests\n`csharp\npublic class OrderLensIntegrationTests {\n    private IDbConnectionFactory _db;\n    private OrderLens _lens;\n    [Before(Test)]\n    public async Task SetupAsync() {\n        _db = CreateTestDatabase();  // Real PostgreSQL test database\n        _lens = new OrderLens(_db);\n        // Seed test data\n        await SeedTestDataAsync();\n    }\n    [Test]\n    public async Task GetOrdersByCustomerAsync_WithOrders_ReturnsAllCustomerOrdersAsync() {\n        // Arrange\n        var customerId = TestData CustomerWithOrdersId;\n        // Act\n        var orders = await _lens GetOrdersByCustomerAsync(customerId, CancellationToken None);\n        // Assert\n        await Assert That(orders Length) IsEqualTo(3);  // Customer has 3 orders\n        await Assert That(orders All(o => o CustomerId == customerId)) IsTrue();\n        await Assert That(orders) IsSortedDescending(o => o CreatedAt);  // Sorted by date\n    }\n    private async Task SeedTestDataAsync() {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (order_id, customer_id, total, status, created_at)\n            VALUES\n                (@OrderId1, @CustomerId, 100 00, 'Created', '2024-12-01'),\n                (@OrderId2, @CustomerId, 200 00, 'Shipped', '2024-12-05'),\n                (@OrderId3, @CustomerId, 150 00, 'Delivered', '2024-12-10')\n            \"\"\",\n            new {\n                OrderId1 = Guid NewGuid(),\n                OrderId2 = Guid NewGuid(),\n                OrderId3 = Guid NewGuid(),\n                CustomerId = TestData CustomerWithOrdersId\n            }\n        );\n    }\n}\n`\n---\nAdvanced Patterns\nPattern: Lens with Multiple Read Models\n`csharp\npublic class OrderDetailsLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public async Task<OrderDetailsView> GetOrderDetailsAsync(\n        Guid orderId,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Query 1: Order summary\n        var summary = await conn",
        "startIndex": 16401,
        "preview": "GetOrdersPagedAsync( pageNumber: 2, pageSize: 10, CancellationToken None ); // Assert await Assert That(result Items Length) IsEqualTo(10); // Second ..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-9",
        "text": "} ` --- Advanced Patterns Pattern: Lens with Multiple Read Models `csharp public class OrderDetailsLens : ILensQuery { private readonly IDbConnectionFactory _db; public async Task<OrderDetailsView> GetOrderDetailsAsync( Guid orderId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Query 1: Order summary var summary = await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        if (summary is null) {\n            throw new NotFoundException($\"Order {orderId} not found\");\n        }\n        // Query 2: Order items (separate read model)\n        var items = await conn QueryAsync<OrderItemDetail>(\n            \"SELECT * FROM order_item_details WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        // Query 3: Shipping info (separate read model)\n        var shipping = await conn QuerySingleOrDefaultAsync<ShippingInfo>(\n            \"SELECT * FROM shipping_info WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        // Combine into single DTO\n        return new OrderDetailsView(\n            Summary: summary,\n            Items: items ToArray(),\n            Shipping: shipping\n        );\n    }\n}\npublic record OrderDetailsView(\n    OrderSummary Summary,\n    OrderItemDetail[] Items,\n    ShippingInfo Shipping\n);\n`\nPattern: Graph QL Integration\n`csharp\npublic class OrderQueries {\n    private readonly IOrderLens _lens;\n    public OrderQueries(IOrderLens lens) {\n        _lens = lens;\n    }\n    [GraphQLName(\"order\")]\n    public async Task<OrderSummary > GetOrderAsync(Guid orderId, CancellationToken ct) {\n        return await _lens GetOrderAsync(orderId, ct);\n    }\n    [GraphQLName(\"orders\")]\n    public async Task<PagedResult<OrderSummary>> GetOrdersPagedAsync(\n        int pageNumber = 1,\n        int pageSize = 20,\n        CancellationToken ct = default) {\n        return await _lens",
        "startIndex": 18527,
        "preview": "} ` --- Advanced Patterns Pattern: Lens with Multiple Read Models `csharp public class OrderDetailsLens : ILensQuery { private readonly IDbConnectionF..."
      },
      {
        "id": "v0.1.0/core-concepts/lenses-chunk-10",
        "text": "{ private readonly IOrderLens _lens; public OrderQueries(IOrderLens lens) { _lens = lens; } [GraphQLName(\"order\")] public async Task<OrderSummary > GetOrderAsync(Guid orderId, CancellationToken ct) { return await _lens GetOrderAsync(orderId, ct); } [GraphQLName(\"orders\")] public async Task<PagedResult<OrderSummary>> GetOrdersPagedAsync( int pageNumber = 1, int pageSize = 20, CancellationToken ct = default) { return await _lens GetOrdersPagedAsync(pageNumber, pageSize, ct);\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Keep queries simple (single table or denormalized joins)\n‚úÖ Return DTOs specific to client needs\n‚úÖ Use async methods with CancellationToken\n‚úÖ Return null for \"not found\" (don't throw)\n‚úÖ Add indexes to read model tables for common queries\n‚úÖ Use pagination for large result sets\n‚úÖ Cache frequently accessed data\n‚úÖ Organize lenses by use case (customer, admin, analytics)\n‚úÖ Keep lenses stateless\nDON'T ‚ùå\n‚ùå Query normalized write models directly (use denormalized read models)\n‚ùå Perform complex joins across many tables (defeats purpose of CQRS)\n‚ùå Mutate data in lenses (read-only )\n‚ùå Call receptors from lenses (lenses are read-only)\n‚ùå Return IQueryable (forces deferred execution, breaks abstraction)\n‚ùå Store state in lens instances\n‚ùå Throw exceptions for \"not found\" (return null instead)\n‚ùå Return unbounded result sets (always paginate large datasets)\n---\nFurther Reading\nCore Concepts:\nPerspectives - Event listeners that maintain read models\nDispatcher - How to invoke receptors and publish events\nReceptors - Command handlers that produce events\nData Access:\nDapper Integration - Lightweight data access\nEF Core Integration - Full-featured ORM\nPerspective Storage - Schema design patterns\nExamples:\nECommerce: BFF Pattern - Real-world lens usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20216,
        "preview": "{ private readonly IOrderLens _lens; public OrderQueries(IOrderLens lens) { _lens = lens; } [GraphQLName(\"order\")] public async Task<OrderSummary > Ge..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/message-context",
    "title": "Message Context & Tracing",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/message-context",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-0",
        "text": "Message Context & Tracing\nWhizbang provides automatic distributed tracing through three key identifiers: MessageId, CorrelationId, and CausationId These track message relationships across services, enabling powerful observability and debugging Core Identifiers\n| Identifier | Purpose | Analogy |\n|------------|---------|---------|\n| MessageId | Unique ID for this message | Social Security Number (unique per person) |\n| CorrelationId | Groups related messages in a workflow | Family ID (groups related people) |\n| CausationId | Parent message that caused this message | Parent ID (who caused this person to exist) |\nVisual Example\n`\nUser clicks \"Create Order\" button\n         ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ CreateOrder Command                                         ‚îÇ\n‚îÇ MessageId:     msg-001                                      ‚îÇ\n‚îÇ CorrelationId: corr-abc (generated for this workflow)     ‚îÇ\n‚îÇ CausationId:   null (no parent)                            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îÇ\n              ‚îÇ OrderReceptor processes command\n              ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ OrderCreated Event                                          ‚îÇ\n‚îÇ MessageId:     msg-002                                      ‚îÇ\n‚îÇ CorrelationId: corr-abc (same as command)                 ‚îÇ\n‚îÇ CausationId:   msg-001 (caused by CreateOrder)            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îÇ\n              ‚îÇ Publishes to Azure Service Bus\n              ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ                 ‚îÇ                 ‚îÇ                  ‚îÇ\n    ‚Üì                 ‚Üì                 ‚Üì                  ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Inventory   ‚îÇ  ‚îÇ Payment     ‚îÇ  ‚îÇ Shipping    ‚îÇ  ‚îÇ Notification ‚îÇ\n‚îÇ Worker      ‚îÇ  ‚îÇ Worker      ‚îÇ  ‚îÇ Worker      ‚îÇ  ‚îÇ Worker       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n      ‚îÇ                ‚îÇ                ‚îÇ                ‚îÇ\n      ‚Üì                ‚Üì                ‚Üì                ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Inventory  ‚îÇ  ‚îÇ Payment    ‚îÇ  ‚îÇ Shipment   ‚îÇ  ‚îÇ Email      ‚îÇ\n‚îÇ Reserved   ‚îÇ  ‚îÇ Processed  ‚îÇ  ‚îÇ Created    ‚îÇ  ‚îÇ Sent       ‚îÇ\n‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ\n‚îÇ corr-abc   ‚îÇ  ‚îÇ corr-abc   ‚îÇ  ‚îÇ corr-abc   ‚îÇ  ‚îÇ corr-abc   ‚îÇ\n‚îÇ msg-002    ‚îÇ  ‚îÇ msg-002    ‚îÇ  ‚îÇ msg-002    ‚îÇ  ‚îÇ msg-002    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nAll events share corr-abc - enabling you to query all messages in this workflow ---\nMessageId\nPurpose: Unique identifier for each message (never reused)",
        "startIndex": 0,
        "preview": "Message Context & Tracing\nWhizbang provides automatic distributed tracing through three key identifiers: MessageId, CorrelationId, and CausationId The..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-1",
        "text": "‚îÇ corr-abc ‚îÇ ‚îÇ corr-abc ‚îÇ ‚îÇ corr-abc ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` All events share corr-abc - enabling you to query all messages in this workflow --- MessageId Purpose: Unique identifier for each message (never reused) Type: Strongly-typed value object using UUIDv7 `csharp\npublic record struct MessageId(Guid Value) {\n    public static MessageId New() => new(Guid CreateVersion7());\n    public override string ToString() => Value ToString();\n}\n`\nKey Characteristics:\nGlobally unique: No two messages ever have the same ID\nTime-ordered: UUIDv7 includes timestamp, sortable by creation time\nDatabase-friendly: Primary keys using MessageId don't fragment indexes\nImmutable: Once created, never changes\nUsage\n`csharp\n// Whizbang creates MessageId automatically\nvar receipt = await _dispatcher SendAsync(command);\nConsole WriteLine($\"Message ID: {receipt MessageId}\");\n// Output: Message ID: 018d8f8e-1234-7890-abcd-ef1234567890\n`\nYou rarely create MessageId manually - Whizbang handles this ---\nCorrelationId\nPurpose: Groups all messages related to the same workflow/transaction Type: Strongly-typed value object using UUIDv7 `csharp\npublic record struct CorrelationId(Guid Value) {\n    public static CorrelationId New() => new(Guid CreateVersion7());\n    public override string ToString() => Value ToString();\n}\n`\nKey Characteristics:\nWorkflow identifier: All messages in same workflow share same CorrelationId\nCross-service: Spans multiple services, receptors, perspectives\nQueryable: Find all messages for a specific customer action\nPersistent: Stored in database, logs, telemetry\nHow CorrelationId Flows\n`\nUser Request ‚Üí HTTP Request\n   CorrelationId: NEW (generated by API)\nCreateOrder Command\n   CorrelationId: INHERITED from HTTP request\nOrderCreated Event\n   CorrelationId: INHERITED from CreateOrder\nInventoryReserved Event (in different service)\n   CorrelationId: INHERITED from OrderCreated\nPaymentProcessed Event (in different service)\n   CorrelationId: INHERITED from InventoryReserved and so on\n`\nAll messages inherit the same CorrelationId Usage\n`csharp\n// Create new correlation for HTTP request\nvar correlationId = CorrelationId New();\n// Store in HTTP context\nHttpContext",
        "startIndex": 2768,
        "preview": "‚îÇ corr-abc ‚îÇ ‚îÇ corr-abc ‚îÇ ‚îÇ corr-abc ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îÇ msg-002 ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` A..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-2",
        "text": "from CreateOrder InventoryReserved Event (in different service) CorrelationId: INHERITED from OrderCreated PaymentProcessed Event (in different service) CorrelationId: INHERITED from InventoryReserved and so on ` All messages inherit the same CorrelationId Usage `csharp // Create new correlation for HTTP request var correlationId = CorrelationId New(); // Store in HTTP context HttpContext Items[\"CorrelationId\"] = correlationId;\n// Whizbang dispatcher automatically propagates it\nvar command = new CreateOrder(customerId, items);\nvar result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n// Result has same CorrelationId Console WriteLine($\"Correlation ID: {result CorrelationId}\");\n`\nQuerying by CorrelationId\n`csharp\n// Find all messages in a workflow\npublic async Task<Message[]> GetWorkflowMessagesAsync(\n    CorrelationId correlationId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Assuming messages are stored in event store\n    var messages = await conn QueryAsync<Message>(\n        \"\"\"\n        SELECT * FROM wh_event_store\n        WHERE correlation_id = @CorrelationId\n        ORDER BY created_at\n        \"\"\",\n        new { CorrelationId = correlationId Value },\n        cancellationToken: ct\n    );\n    return messages ToArray();\n}\n`\nResult: Complete trace of every message in the workflow ---\nCausationId\nPurpose: Identifies the parent message that caused this message to exist Type: Strongly-typed value object using Guid (refers to a MessageId) `csharp\npublic record struct CausationId(Guid Value) {\n    public static CausationId From(MessageId messageId) => new(messageId Value);\n    public override string ToString() => Value ToString();\n}\n`\nKey Characteristics:\nParent-child relationship: Links message to its creator\nCausality chain: Track how one message led to another\nDebugging: \"What caused this message to be created",
        "startIndex": 4745,
        "preview": "from CreateOrder InventoryReserved Event (in different service) CorrelationId: INHERITED from OrderCreated PaymentProcessed Event (in different servic..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-3",
        "text": "`csharp public record struct CausationId(Guid Value) { public static CausationId From(MessageId messageId) => new(messageId Value); public override string ToString() => Value ToString(); } ` Key Characteristics: Parent-child relationship: Links message to its creator Causality chain: Track how one message led to another Debugging: \"What caused this message to be created \"\nNullable: Root messages (HTTP requests) have no parent\nCausation Chain Example\n`\nCreateOrder Command\n‚îú‚îÄ MessageId:     msg-001\n‚îú‚îÄ CorrelationId: corr-abc\n‚îî‚îÄ CausationId:   null (no parent)\n      ‚Üì Creates ‚Üì\nOrderCreated Event\n‚îú‚îÄ MessageId:     msg-002\n‚îú‚îÄ CorrelationId: corr-abc\n‚îî‚îÄ CausationId:   msg-001 (caused by CreateOrder)\n      ‚Üì Creates ‚Üì\nInventoryReserved Event\n‚îú‚îÄ MessageId:     msg-003\n‚îú‚îÄ CorrelationId: corr-abc\n‚îî‚îÄ CausationId:   msg-002 (caused by OrderCreated)\n      ‚Üì Creates ‚Üì\nPaymentProcessed Event\n‚îú‚îÄ MessageId:     msg-004\n‚îú‚îÄ CorrelationId: corr-abc\n‚îî‚îÄ CausationId:   msg-003 (caused by InventoryReserved)\n`\nCausation chain: msg-001 ‚Üí msg-002 ‚Üí msg-003 ‚Üí msg-004\nUsage\n`csharp\n// Receptor creates event with causation\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Business logic return new OrderCreated(\n            MessageId: MessageId New(),              // New unique ID\n            CorrelationId: message CorrelationId,    // Inherit correlation\n            CausationId: CausationId From(message MessageId),  // Parent is CreateOrder\n            OrderId: Guid CreateVersion7(),\n            CustomerId: message CustomerId,\n            Items: message Items,\n            Total: CalculateTotal(message Items),\n            CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nWhizbang handles this automatically via MessageEnvelope ---\nMessageEnvelope\nWhizbang wraps all messages in a MessageEnvelope containing context:\n`csharp\npublic class MessageEnvelope {\n    public MessageId MessageId { get; init; }\n    public CorrelationId CorrelationId { get; init; }\n    public CausationId CausationId { get; init; }\n    public object Payload { get; init; }  // Your actual message\n    public List<MessageHop> Hops { get; init; }  // Trace hops\n    public DateTimeOffset CreatedAt { get; init; }\n}\n`\nYou rarely interact with MessageEnvelope directly - Whizbang manages it transparently Automatic Context Propagation\n`csharp\n// 1",
        "startIndex": 6276,
        "preview": "`csharp public record struct CausationId(Guid Value) { public static CausationId From(MessageId messageId) => new(messageId Value); public override st..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-4",
        "text": "get; init; } public object Payload { get; init; } // Your actual message public List<MessageHop> Hops { get; init; } // Trace hops public DateTimeOffset CreatedAt { get; init; } } ` You rarely interact with MessageEnvelope directly - Whizbang manages it transparently Automatic Context Propagation `csharp // 1 HTTP Request arrives\n[HttpPost(\"orders\")]\npublic async Task<ActionResult> CreateOrder(\n    [FromBody] CreateOrderRequest request,\n    CancellationToken ct) {\n    // 2 Create command (Whizbang generates MessageId, CorrelationId)\n    var command = new CreateOrder(request CustomerId, request Items);\n    // 3 Dispatch command\n    var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command, ct);\n    // 4 Result event has:\n    //    - New MessageId (unique)\n    //    - Same CorrelationId (inherited)\n    //    - CausationId = command MessageId (parent reference)\n    return CreatedAtAction(nameof(GetOrder), new { orderId = result OrderId }, result);\n}\n`\nWhizbang automatically:\nGenerates MessageId for command\nGenerates CorrelationId (or inherits from HTTP context)\nSets CausationId to command's MessageId when creating event\n---\nDistributed Tracing\nQuerying Workflow History\n`csharp\npublic class WorkflowTracer {\n    private readonly IDbConnectionFactory _db;\n    public async Task<WorkflowTrace> TraceWorkflowAsync(\n        CorrelationId correlationId,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Get all messages in workflow\n        var messages = await conn QueryAsync<TraceMessage>(\n            \"\"\"\n            SELECT\n                message_id,\n                causation_id,\n                message_type,\n                created_at,\n                payload\n            FROM wh_event_store\n            WHERE correlation_id = @CorrelationId\n            ORDER BY created_at\n            \"\"\",\n            new { CorrelationId = correlationId Value },\n            cancellationToken: ct\n        );\n        return new WorkflowTrace(\n            CorrelationId: correlationId,\n            Messages: messages ToArray()\n        );\n    }\n}\npublic record WorkflowTrace(\n    CorrelationId CorrelationId,\n    TraceMessage[] Messages\n) {\n    public void PrintTrace() {\n        Console WriteLine($\"Workflow: {CorrelationId}\");\n        foreach (var msg in Messages) {\n            Console WriteLine($\"  {msg CreatedAt:yyyy-MM-dd HH:mm:ss fff} | {msg MessageType}\");\n            if (msg CausationId is not null) {\n                Console WriteLine($\"    Caused by: {msg CausationId}\");\n            }\n        }\n    }\n}\n`\nOutput:\n`\nWorkflow: corr-abc\n  2024-12-12 10:00:00 123 | CreateOrder\n  2024-12-12 10:00:00 456 | OrderCreated\n    Caused by: msg-001\n  2024-12-12 10:00:01",
        "startIndex": 8398,
        "preview": "get; init; } public object Payload { get; init; } // Your actual message public List<MessageHop> Hops { get; init; } // Trace hops public DateTimeOffs..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-5",
        "text": "msg in Messages) { Console WriteLine($\" {msg CreatedAt:yyyy-MM-dd HH:mm:ss fff} | {msg MessageType}\"); if (msg CausationId is not null) { Console WriteLine($\" Caused by: {msg CausationId}\"); } } } } ` Output: ` Workflow: corr-abc 2024-12-12 10:00:00 123 | CreateOrder 2024-12-12 10:00:00 456 | OrderCreated Caused by: msg-001 2024-12-12 10:00:01 234 | InventoryReserved\n    Caused by: msg-002\n  2024-12-12 10:00:02 567 | PaymentProcessed\n    Caused by: msg-003\n  2024-12-12 10:00:03 890 | ShipmentCreated\n    Caused by: msg-004\n`\nVisualizing Causation Chains\n`csharp\npublic class CausationVisualizer {\n    public void VisualizeCausationChain(TraceMessage[] messages) {\n        var messageMap = messages ToDictionary(m => m MessageId);\n        foreach (var msg in messages) {\n            PrintMessageWithIndent(msg, messageMap, indent: 0);\n        }\n    }\n    private void PrintMessageWithIndent(\n        TraceMessage msg,\n        Dictionary<Guid, TraceMessage> map,\n        int indent) {\n        var prefix = new string(' ', indent * 2);\n        Console WriteLine($\"{prefix}‚îú‚îÄ {msg MessageType} ({msg MessageId})\");\n        // Find children (messages caused by this message)\n        var children = map Values Where(m => m CausationId == msg MessageId) ToArray();\n        foreach (var child in children) {\n            PrintMessageWithIndent(child, map, indent + 1);\n        }\n    }\n}\n`\nOutput:\n`\n‚îú‚îÄ CreateOrder (msg-001)\n  ‚îú‚îÄ OrderCreated (msg-002)\n    ‚îú‚îÄ InventoryReserved (msg-003)\n      ‚îú‚îÄ PaymentProcessed (msg-004)\n        ‚îú‚îÄ ShipmentCreated (msg-005)\n          ‚îú‚îÄ NotificationSent (msg-006)\n`\n---\nIntegration with Logging\nStructured Logging\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly ILogger<CreateOrderReceptor> _logger;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Log with correlation and causation context\n        using (_logger BeginScope(new Dictionary<string, object> {\n            [\"CorrelationId\"] = message CorrelationId,\n            [\"CausationId\"] = message CausationId ToString() \"null\",\n            [\"MessageId\"] = message MessageId\n        })) {\n            _logger LogInformation(\n                \"Processing CreateOrder for customer {CustomerId}\",\n                message CustomerId\n            );\n            // Business logic _logger LogInformation(\n                \"Order {OrderId} created successfully\",\n                orderId\n            );\n            return new OrderCreated(/ /);\n        }\n    }\n}\n`\nLog Output (JSON format):\n`json\n{\n  \"Timestamp\": \"2024-12-12T10:00:00",
        "startIndex": 10847,
        "preview": "msg in Messages) { Console WriteLine($\" {msg CreatedAt:yyyy-MM-dd HH:mm:ss fff} | {msg MessageType}\"); if (msg CausationId is not null) { Console Writ..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-6",
        "text": "CorrelationId, [\"CausationId\"] = message CausationId ToString() \"null\", [\"MessageId\"] = message MessageId })) { _logger LogInformation( \"Processing CreateOrder for customer {CustomerId}\", message CustomerId ); // Business logic _logger LogInformation( \"Order {OrderId} created successfully\", orderId ); return new OrderCreated(/ /); } } } ` Log Output (JSON format): `json { \"Timestamp\": \"2024-12-12T10:00:00 123Z\",\n  \"Level\": \"Information\",\n  \"Message\": \"Processing CreateOrder for customer 550e8400-e29b-41d4-a716-446655440000\",\n  \"CorrelationId\": \"corr-abc\",\n  \"CausationId\": \"null\",\n  \"MessageId\": \"msg-001\"\n}\n`\nBenefit: Query logs by CorrelationId to see all log entries for a workflow Application Insights Integration\n`csharp\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly TelemetryClient _telemetry;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        using var operation = _telemetry StartOperation<RequestTelemetry>(\"CreateOrder\");\n        operation Telemetry Properties[\"CorrelationId\"] = message CorrelationId ToString();\n        operation Telemetry Properties[\"CausationId\"] = message CausationId ToString() \"null\";\n        operation Telemetry Properties[\"MessageId\"] = message MessageId ToString();\n        try {\n            // Business logic operation Telemetry Success = true;\n            return new OrderCreated(/ /);\n        } catch (Exception ex) {\n            operation Telemetry Success = false;\n            _telemetry TrackException(ex);\n            throw;\n        }\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Let Whizbang generate MessageId automatically\n‚úÖ Inherit CorrelationId from parent message\n‚úÖ Set CausationId to parent's MessageId\n‚úÖ Log CorrelationId in structured logging\n‚úÖ Store CorrelationId in database for querying\n‚úÖ Use CorrelationId for end-to-end workflow tracing\n‚úÖ Use CausationId for debugging (what caused this )\n‚úÖ Propagate CorrelationId across HTTP boundaries\nDON'T ‚ùå\n‚ùå Reuse MessageId (must be unique per message)\n‚ùå Change CorrelationId mid-workflow (breaks tracing)\n‚ùå Forget to propagate CorrelationId across services\n‚ùå Use CorrelationId as business identifier (use OrderId, etc )\n‚ùå Store MessageId in business entities (use domain IDs like OrderId)\n‚ùå Skip logging CorrelationId (critical for debugging)\n---\nHTTP Context Integration\nASP",
        "startIndex": 13202,
        "preview": "CorrelationId, [\"CausationId\"] = message CausationId ToString() \"null\", [\"MessageId\"] = message MessageId })) { _logger LogInformation( \"Processing Cr..."
      },
      {
        "id": "v0.1.0/core-concepts/message-context-chunk-7",
        "text": "be unique per message) ‚ùå Change CorrelationId mid-workflow (breaks tracing) ‚ùå Forget to propagate CorrelationId across services ‚ùå Use CorrelationId as business identifier (use OrderId, etc ) ‚ùå Store MessageId in business entities (use domain IDs like OrderId) ‚ùå Skip logging CorrelationId (critical for debugging) --- HTTP Context Integration ASP NET Core Middleware\n`csharp\npublic class CorrelationIdMiddleware {\n    private readonly RequestDelegate _next;\n    public CorrelationIdMiddleware(RequestDelegate next) {\n        _next = next;\n    }\n    public async Task InvokeAsync(HttpContext context) {\n        // Extract or generate CorrelationId\n        var correlationId = context Request Headers[\"X-Correlation-ID\"] FirstOrDefault() CorrelationId New() ToString();\n        // Store in HttpContext\n        context Items[\"CorrelationId\"] = CorrelationId Parse(correlationId);\n        // Add to response headers\n        context Response Headers[\"X-Correlation-ID\"] = correlationId;\n        await _next(context);\n    }\n}\n// Register middleware\napp UseMiddleware<CorrelationIdMiddleware>();\n`\nPropagating to Downstream Services\n`csharp\npublic class HttpClientWithCorrelation {\n    private readonly HttpClient _httpClient;\n    private readonly IHttpContextAccessor _httpContext;\n    public async Task<HttpResponseMessage> PostAsync(string url, HttpContent content) {\n        // Get CorrelationId from current request\n        var correlationId = _httpContext HttpContext Items[\"CorrelationId\"] as CorrelationId CorrelationId New();\n        // Add to outgoing request\n        var request = new HttpRequestMessage(HttpMethod Post, url) {\n            Content = content\n        };\n        request Headers Add(\"X-Correlation-ID\", correlationId ToString());\n        return await _httpClient SendAsync(request);\n    }\n}\n`\n---\nFurther Reading\nCore Concepts:\nObservability - MessageEnvelope and hops for distributed tracing\nDispatcher - How messages are routed\nReceptors - Message handlers\nMessaging Patterns:\nOutbox Pattern - Reliable messaging with context\nMessage Envelopes - Hop-based observability\nInfrastructure:\nLogging & Telemetry - Application Insights integration\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15215,
        "preview": "be unique per message) ‚ùå Change CorrelationId mid-workflow (breaks tracing) ‚ùå Forget to propagate CorrelationId across services ‚ùå Use CorrelationId as..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/observability",
    "title": "Observability & Message Hops",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/observability",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/observability-chunk-0",
        "text": "Observability & Message Hops\nWhizbang implements hop-based observability, inspired by network packet routing Every message carries a MessageEnvelope containing hops - snapshots of contextual metadata at each stage of processing Core Concept: Network Packet Analogy\nJust like IP packets travel through routers, accumulating hops along their journey, Whizbang messages travel through receptors and services, accumulating context hops:\n`\nNetwork Packet:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ IP Header              ‚îÇ\n‚îÇ ‚îú‚îÄ Source IP           ‚îÇ\n‚îÇ ‚îú‚îÄ Dest IP             ‚îÇ\n‚îÇ ‚îî‚îÄ Hop Count: 3        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Payload (your data)    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nWhizbang Message:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ MessageEnvelope         ‚îÇ\n‚îÇ ‚îú‚îÄ MessageId            ‚îÇ\n‚îÇ ‚îú‚îÄ CorrelationId        ‚îÇ\n‚îÇ ‚îú‚îÄ CausationId          ‚îÇ\n‚îÇ ‚îî‚îÄ Hops: [Hop1, Hop2]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Payload (your message)  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey Insight: Hops capture where the message has been and what decisions were made along the way ---\nMessageEnvelope Structure\n`csharp\npublic class MessageEnvelope {\n    // Identity\n    public required MessageId MessageId { get; init; }\n    public required CorrelationId CorrelationId { get; init; }\n    public required CausationId CausationId { get; init; }\n    // Payload\n    public required object Payload { get; init; }\n    // Observability\n    public required List<MessageHop> Hops { get; init; }  // THE KEY TO OBSERVABILITY\n    // Metadata\n    public DateTimeOffset CreatedAt { get; init; }\n}\n`\nMessageEnvelope wraps every message, providing:\nIdentity: MessageId, CorrelationId, CausationId\nPayload: Your actual command/event/query\nObservability: List of hops showing the message's journey\n---\nMessageHop Structure\n`csharp\npublic class MessageHop {\n    // Hop Type\n    public required MessageHopType Type { get; init; }  // Current or Causation\n    // Routing\n    public string Topic { get; init; }\n    public string StreamKey { get; init; }\n    public int PartitionIndex { get; init; }\n    public long SequenceNumber { get; init; }\n    // Security\n    public SecurityContext SecurityContext { get; init; }  // UserId, TenantId, etc // Policy\n    public PolicyDecisionTrail",
        "startIndex": 0,
        "preview": "Observability & Message Hops\nWhizbang implements hop-based observability, inspired by network packet routing Every message carries a MessageEnvelope c..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-1",
        "text": "Current or Causation // Routing public string Topic { get; init; } public string StreamKey { get; init; } public int PartitionIndex { get; init; } public long SequenceNumber { get; init; } // Security public SecurityContext SecurityContext { get; init; } // UserId, TenantId, etc // Policy public PolicyDecisionTrail PolicyDecisionTrail { get; init; }\n    // Metadata (stitched across hops)\n    public Dictionary<string, string> Metadata { get; init; } = new();\n    // Debugging\n    public string CallerMemberName { get; init; }\n    public string CallerFilePath { get; init; }\n    public int CallerLineNumber { get; init; }\n    // Timing\n    public DateTimeOffset Timestamp { get; init; }\n    public TimeSpan Duration { get; init; }\n}\npublic enum MessageHopType {\n    Current,    // This message's context\n    Causation   // Parent message's context (inherited)\n}\n`\nMessageHop captures:\nRouting: Topic, stream, partition, sequence\nSecurity: Who is making this request Policy: What decisions were made Metadata: Custom key-value pairs\nDebugging: Source location (file, line, method)\nTiming: When did this happen, how long did it take ---\nHop Types\nCurrent Hop\nPurpose: Captures context for this message `csharp\nvar currentHop = new MessageHop {\n    Type = MessageHopType Current,\n    Topic = \"orders\",\n    StreamKey = \"customer-123\",\n    PartitionIndex = 42,\n    SecurityContext = new SecurityContext {\n        UserId = Guid Parse(\"user-456\"),\n        TenantId = Guid Parse(\"tenant-789\")\n    },\n    Metadata = new Dictionary<string, string> {\n        [\"ServiceName\"] = \"OrderService\",\n        [\"Version\"] = \"1 0 0\"\n    },\n    Timestamp = DateTimeOffset UtcNow\n};\n`\nUse Case: Know where this message originated, who created it, and what metadata it carries Causation Hop\nPurpose: Captures context from parent message (inherited) `csharp\n// When OrderCreated event is created from CreateOrder command:\nvar envelope = MessageEnvelope Create(\n    messageId: MessageId New(),\n    correlationId: command CorrelationId,  // Inherit\n    causationId: CausationId From(command MessageId),  // Parent reference\n    payload: orderCreatedEvent,\n    currentHop: / current hop /,\n    causationHops: command Hops  // INHERIT parent's hops",
        "startIndex": 2234,
        "preview": "Current or Causation // Routing public string Topic { get; init; } public string StreamKey { get; init; } public int PartitionIndex { get; init; } pub..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-2",
        "text": "Captures context from parent message (inherited) `csharp // When OrderCreated event is created from CreateOrder command: var envelope = MessageEnvelope Create( messageId: MessageId New(), correlationId: command CorrelationId, // Inherit causationId: CausationId From(command MessageId), // Parent reference payload: orderCreatedEvent, currentHop: / current hop /, causationHops: command Hops // INHERIT parent's hops );\n`\nResult: OrderCreated envelope contains:\nCurrent hop: Context for OrderCreated\nCausation hops: All hops from CreateOrder (parent)\nBenefit: Complete trace from HTTP request ‚Üí Command ‚Üí Event ‚Üí Downstream events ---\nHop Flow Example\nScenario: Create Order Workflow\n`\nHTTP POST /api/orders (API Gateway)\n   ‚îú‚îÄ Current Hop:\n   ‚îÇ  ‚îú‚îÄ Type: Current\n   ‚îÇ  ‚îú‚îÄ SecurityContext: { UserId: user-123, TenantId: tenant-456 }\n   ‚îÇ  ‚îú‚îÄ Metadata: { ServiceName: \"API Gateway\", RequestPath: \"/api/orders\" }\n   ‚îÇ  ‚îî‚îÄ Timestamp: 2024-12-12T10:00:00Z\n   ‚îî‚îÄ Causation Hops: (none)\n      ‚Üì Creates CreateOrder Command\nCreateOrder Command (OrderService)\n   ‚îú‚îÄ Current Hop:\n   ‚îÇ  ‚îú‚îÄ Type: Current\n   ‚îÇ  ‚îú‚îÄ Topic: \"orders\"\n   ‚îÇ  ‚îú‚îÄ StreamKey: \"customer-123\"\n   ‚îÇ  ‚îú‚îÄ SecurityContext: { UserId: user-123, TenantId: tenant-456 }  (inherited)\n   ‚îÇ  ‚îú‚îÄ Metadata: { ServiceName: \"OrderService\", ReceptorName: \"CreateOrderReceptor\" }\n   ‚îÇ  ‚îî‚îÄ Timestamp: 2024-12-12T10:00:00 123Z\n   ‚îî‚îÄ Causation Hops:\n      ‚îî‚îÄ Hop from API Gateway (inherited)\n      ‚Üì Creates OrderCreated Event\nOrderCreated Event\n   ‚îú‚îÄ Current Hop:\n   ‚îÇ  ‚îú‚îÄ Type: Current\n   ‚îÇ  ‚îú‚îÄ Topic: \"orders\"\n   ‚îÇ  ‚îú‚îÄ StreamKey: \"customer-123\"\n   ‚îÇ  ‚îú‚îÄ SecurityContext: { UserId: user-123, TenantId: tenant-456 }  (inherited)\n   ‚îÇ  ‚îú‚îÄ Metadata: { ServiceName: \"OrderService\", EventType: \"OrderCreated\" }\n   ‚îÇ  ‚îî‚îÄ Timestamp: 2024-12-12T10:00:00 456Z\n   ‚îî‚îÄ Causation Hops:\n      ‚îú‚îÄ Hop from API Gateway (inherited)\n      ‚îî‚îÄ Hop from CreateOrder Command (inherited)\n      ‚Üì Published to Azure Service Bus\n      ‚Üì Consumed by InventoryWorker\nInventoryReserved Event\n   ‚îú‚îÄ Current Hop:\n   ‚îÇ  ‚îú‚îÄ Type: Current\n   ‚îÇ  ‚îú‚îÄ Topic: \"inventory\"\n   ‚îÇ  ‚îú‚îÄ StreamKey: \"product-789\"\n   ‚îÇ  ‚îú‚îÄ SecurityContext: { UserId: user-123, TenantId: tenant-456 }  (inherited)\n   ‚îÇ  ‚îú‚îÄ Metadata: { ServiceName: \"InventoryWorker\", EventType: \"InventoryReserved\" }\n   ‚îÇ  ‚îî‚îÄ Timestamp: 2024-12-12T10:00:01",
        "startIndex": 4150,
        "preview": "Captures context from parent message (inherited) `csharp // When OrderCreated event is created from CreateOrder command: var envelope = MessageEnvelop..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-3",
        "text": "‚Üì Published to Azure Service Bus ‚Üì Consumed by InventoryWorker InventoryReserved Event ‚îú‚îÄ Current Hop: ‚îÇ ‚îú‚îÄ Type: Current ‚îÇ ‚îú‚îÄ Topic: \"inventory\" ‚îÇ ‚îú‚îÄ StreamKey: \"product-789\" ‚îÇ ‚îú‚îÄ SecurityContext: { UserId: user-123, TenantId: tenant-456 } (inherited) ‚îÇ ‚îú‚îÄ Metadata: { ServiceName: \"InventoryWorker\", EventType: \"InventoryReserved\" } ‚îÇ ‚îî‚îÄ Timestamp: 2024-12-12T10:00:01 234Z\n   ‚îî‚îÄ Causation Hops:\n      ‚îú‚îÄ Hop from API Gateway (inherited)\n      ‚îú‚îÄ Hop from CreateOrder Command (inherited)\n      ‚îî‚îÄ Hop from OrderCreated Event (inherited)\n`\nResult: InventoryReserved event contains complete trace back to original HTTP request ---\nSecurity Context\n`csharp\npublic record SecurityContext {\n    public Guid UserId { get; init; }\n    public Guid TenantId { get; init; }\n    public string[] Roles { get; init; }\n    public Dictionary<string, string> Claims { get; init; }\n}\n`\nUse Case: Authorization across services Example: Multi-Tenant Authorization\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IHttpContextAccessor _httpContext;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Extract security context from hops\n        var securityContext = message Hops FirstOrDefault(h => h Type == MessageHopType Current) SecurityContext;\n        if (securityContext TenantId is null) {\n            throw new UnauthorizedAccessException(\"No tenant context\");\n        }\n        // Validate customer belongs to tenant\n        if ( await _customerService BelongsToTenantAsync(\n            message CustomerId,\n            securityContext TenantId Value,\n            ct)) {\n            throw new ForbiddenException(\"Customer does not belong to tenant\");\n        }\n        // Business logic }\n}\n`\nBenefit: Security context flows automatically across services ---\nPolicy Decision Trail\n`csharp\npublic record PolicyDecisionTrail {\n    public List<PolicyDecision> Decisions { get; init; } = new();\n}\npublic record PolicyDecision {\n    public string PolicyName { get; init; }\n    public bool Allowed { get; init; }\n    public string Reason { get; init; }\n    public Dictionary<string, string> Context { get; init; } = new();\n}\n`\nUse Case: Audit which policies allowed/denied actions",
        "startIndex": 6053,
        "preview": "‚Üì Published to Azure Service Bus ‚Üì Consumed by InventoryWorker InventoryReserved Event ‚îú‚îÄ Current Hop: ‚îÇ ‚îú‚îÄ Type: Current ‚îÇ ‚îú‚îÄ Topic: \"inventory\" ‚îÇ ‚îú‚îÄ..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-4",
        "text": "get; init; } = new(); } public record PolicyDecision { public string PolicyName { get; init; } public bool Allowed { get; init; } public string Reason { get; init; } public Dictionary<string, string> Context { get; init; } = new(); } ` Use Case: Audit which policies allowed/denied actions Example: Rate Limiting Policy\n`csharp\npublic class RateLimitingPolicy : IPolicy {\n    public async Task<PolicyDecision> EvaluateAsync(\n        MessageEnvelope envelope,\n        CancellationToken ct = default) {\n        var securityContext = envelope Hops FirstOrDefault(h => h Type == MessageHopType Current) SecurityContext;\n        var userId = securityContext UserId;\n        if (userId is null) {\n            return new PolicyDecision {\n                PolicyName = \"RateLimiting\",\n                Allowed = false,\n                Reason = \"No user context\"\n            };\n        }\n        var count = await _rateLimiter GetRequestCountAsync(userId Value, ct);\n        if (count > 100) {  // Max 100 requests per minute\n            return new PolicyDecision {\n                PolicyName = \"RateLimiting\",\n                Allowed = false,\n                Reason = \"Rate limit exceeded\",\n                Context = new Dictionary<string, string> {\n                    [\"RequestCount\"] = count ToString(),\n                    [\"Limit\"] = \"100\"\n                }\n            };\n        }\n        return new PolicyDecision {\n            PolicyName = \"RateLimiting\",\n            Allowed = true,\n            Context = new Dictionary<string, string> {\n                [\"RequestCount\"] = count ToString()\n            }\n        };\n    }\n}\n`\nResult: Every hop contains policy decisions - full audit trail",
        "startIndex": 8030,
        "preview": "get; init; } = new(); } public record PolicyDecision { public string PolicyName { get; init; } public bool Allowed { get; init; } public string Reason..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-5",
        "text": "= new Dictionary<string, string> { [\"RequestCount\"] = count ToString(), [\"Limit\"] = \"100\" } }; } return new PolicyDecision { PolicyName = \"RateLimiting\", Allowed = true, Context = new Dictionary<string, string> { [\"RequestCount\"] = count ToString() } }; } } ` Result: Every hop contains policy decisions - full audit trail ---\nMetadata Stitching\nMetadata stitches across hops, accumulating context:\n`csharp\n// Hop 1 (API Gateway)\nMetadata: {\n    \"ServiceName\": \"API Gateway\",\n    \"RequestPath\": \"/api/orders\"\n}\n// Hop 2 (OrderService) - inherits + adds\nMetadata: {\n    \"ServiceName\": \"OrderService\",        // Overwrites\n    \"RequestPath\": \"/api/orders\",         // Inherited\n    \"ReceptorName\": \"CreateOrderReceptor\" // Added\n}\n// Hop 3 (InventoryWorker) - inherits + adds\nMetadata: {\n    \"ServiceName\": \"InventoryWorker\",     // Overwrites\n    \"RequestPath\": \"/api/orders\",         // Inherited\n    \"ReceptorName\": \"ReserveInventoryReceptor\", // Overwrites\n    \"InventoryCheck\": \"Passed\"            // Added\n}\n`\nPattern: Each hop can:\nInherit metadata from parent\nOverwrite existing keys\nAdd new keys\n---\nDebugging Information\n`csharp\npublic async ValueTask<OrderCreated> HandleAsync(\n    CreateOrder message,\n    [CallerMemberName] string memberName = \"\",\n    [CallerFilePath] string filePath = \"\",\n    [CallerLineNumber] int lineNumber = 0,\n    CancellationToken ct = default) {\n    var currentHop = new MessageHop {\n        Type = MessageHopType Current,\n        CallerMemberName = memberName,  // \"HandleAsync\"\n        CallerFilePath = filePath,      // \"/src/OrderService/Receptors/CreateOrderReceptor cs\"\n        CallerLineNumber = lineNumber,  // 42\n        Timestamp = DateTimeOffset UtcNow\n    };\n    // Add hop to envelope\n    message Envelope Hops Add(currentHop);\n    // Business logic }\n`\nBenefit: Know exactly which file/line created each hop Example: Error Debugging\n`\nError: InvalidOperationException in OrderCreated processing\nStack Trace from Hops:\nAPI Gateway\n   File: /src/API/Controllers/OrdersController cs:45\nOrderService - CreateOrderReceptor\n   File: /src/OrderService/Receptors/CreateOrderReceptor cs:78\nInventoryWorker - ReserveInventoryReceptor\n   File: /src/InventoryWorker/Receptors/ReserveInventoryReceptor cs:102  ‚Üê ERROR HERE\n`\nMuch easier than traditional stack traces in distributed systems ---\nTiming & Performance\n`csharp\npublic class MessageHop {\n    public DateTimeOffset Timestamp { get; init; }  // When hop was created\n    public TimeSpan",
        "startIndex": 9457,
        "preview": "= new Dictionary<string, string> { [\"RequestCount\"] = count ToString(), [\"Limit\"] = \"100\" } }; } return new PolicyDecision { PolicyName = \"RateLimitin..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-6",
        "text": "/src/API/Controllers/OrdersController cs:45 OrderService - CreateOrderReceptor File: /src/OrderService/Receptors/CreateOrderReceptor cs:78 InventoryWorker - ReserveInventoryReceptor File: /src/InventoryWorker/Receptors/ReserveInventoryReceptor cs:102 ‚Üê ERROR HERE ` Much easier than traditional stack traces in distributed systems --- Timing & Performance `csharp public class MessageHop { public DateTimeOffset Timestamp { get; init; } // When hop was created public TimeSpan Duration { get; init; }        // How long this hop took\n}\n`\nExample: Performance Profiling\n`csharp\nvar startTime = DateTimeOffset UtcNow;\n// Business logic var duration = DateTimeOffset UtcNow - startTime;\nvar currentHop = new MessageHop {\n    Type = MessageHopType Current,\n    Timestamp = startTime,\n    Duration = duration,  // How long this receptor took\n    Metadata = new Dictionary<string, string> {\n        [\"ReceptorName\"] = \"CreateOrderReceptor\"\n    }\n};\n`\nQuery Performance:\n`csharp\n// Find slow hops\nvar slowHops = envelope Hops Where(h => h Duration > TimeSpan FromMilliseconds(500)) OrderByDescending(h => h Duration) ToArray();\nforeach (var hop in slowHops) {\n    Console WriteLine($\"{hop Metadata[\"ReceptorName\"]}: {hop Duration TotalMilliseconds}ms\");\n}\n`\n---\nVisualizing Hops\n`csharp\npublic class HopVisualizer {\n    public void PrintHops(MessageEnvelope envelope) {\n        Console WriteLine($\"Message: {envelope MessageId}\");\n        Console WriteLine($\"Correlation: {envelope CorrelationId}\");\n        Console WriteLine($\"Causation: {envelope CausationId}\");\n        Console WriteLine();\n        Console WriteLine(\"Hops:\");\n        for (int i = 0; i < envelope Hops Count; i++) {\n            var hop = envelope Hops[i];\n            var prefix = new string(' ', i * 2);\n            Console WriteLine($\"{prefix}{i + 1} {hop Type}\");\n            Console WriteLine($\"{prefix}   Timestamp: {hop Timestamp:yyyy-MM-dd HH:mm:ss fff}\");\n            if (hop Duration is not null) {\n                Console WriteLine($\"{prefix}   Duration: {hop Duration Value TotalMilliseconds}ms\");\n            }\n            if (hop SecurityContext is not null) {\n                Console WriteLine($\"{prefix}   User: {hop SecurityContext UserId}\");\n                Console WriteLine($\"{prefix}   Tenant: {hop SecurityContext TenantId}\");\n            }\n            foreach (var kvp in hop Metadata) {\n                Console WriteLine($\"{prefix}   {kvp Key}: {kvp Value}\");\n            }\n            Console WriteLine();\n        }\n    }\n}\n`\nOutput:\n`\nMessage: msg-003\nCorrelation: corr-abc\nCausation: msg-002\nHops:\nCausation\n   Timestamp: 2024-12-12 10:00:00",
        "startIndex": 11623,
        "preview": "/src/API/Controllers/OrdersController cs:45 OrderService - CreateOrderReceptor File: /src/OrderService/Receptors/CreateOrderReceptor cs:78 InventoryWo..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-7",
        "text": "is not null) { Console WriteLine($\"{prefix} User: {hop SecurityContext UserId}\"); Console WriteLine($\"{prefix} Tenant: {hop SecurityContext TenantId}\"); } foreach (var kvp in hop Metadata) { Console WriteLine($\"{prefix} {kvp Key}: {kvp Value}\"); } Console WriteLine(); } } } ` Output: ` Message: msg-003 Correlation: corr-abc Causation: msg-002 Hops: Causation Timestamp: 2024-12-12 10:00:00 123\n   Duration: 15ms\n   User: user-123\n   Tenant: tenant-456\n   ServiceName: API Gateway\n   RequestPath: /api/orders\nCausation\n     Timestamp: 2024-12-12 10:00:00 456\n     Duration: 50ms\n     User: user-123\n     Tenant: tenant-456\n     ServiceName: OrderService\n     ReceptorName: CreateOrderReceptor\nCurrent\n       Timestamp: 2024-12-12 10:00:01",
        "startIndex": 13796,
        "preview": "is not null) { Console WriteLine($\"{prefix} User: {hop SecurityContext UserId}\"); Console WriteLine($\"{prefix} Tenant: {hop SecurityContext TenantId}\"..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-8",
        "text": "Console WriteLine(); } } } ` Output: ` Message: msg-003 Correlation: corr-abc Causation: msg-002 Hops: Causation Timestamp: 2024-12-12 10:00:00 123 Duration: 15ms User: user-123 Tenant: tenant-456 ServiceName: API Gateway RequestPath: /api/orders Causation Timestamp: 2024-12-12 10:00:00 456 Duration: 50ms User: user-123 Tenant: tenant-456 ServiceName: OrderService ReceptorName: CreateOrderReceptor Current Timestamp: 2024-12-12 10:00:01 234\n       Duration: 120ms\n       User: user-123\n       Tenant: tenant-456\n       ServiceName: InventoryWorker\n       ReceptorName: ReserveInventoryReceptor\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Add hops at each processing stage\n‚úÖ Include security context in first hop\n‚úÖ Inherit causation hops from parent message\n‚úÖ Stitch metadata across hops\n‚úÖ Record timing (Timestamp, Duration)\n‚úÖ Add debugging info (CallerMemberName, FilePath, LineNumber)\n‚úÖ Visualize hops for debugging\n‚úÖ Query hops for performance profiling\nDON'T ‚ùå\n‚ùå Skip adding hops (breaks tracing)\n‚ùå Forget to inherit causation hops\n‚ùå Store sensitive data in metadata (use SecurityContext)\n‚ùå Add excessive metadata (keep it lean)\n‚ùå Ignore hop timestamps (critical for debugging)\n---\nIntegration with Event Store\nHops are stored with events for full auditability:\n`sql\nCREATE TABLE wh_event_store (\n    event_id UUID PRIMARY KEY,\n    message_id UUID NOT NULL,\n    correlation_id UUID NOT NULL,\n    causation_id UUID NULL,\n    event_type VARCHAR(255) NOT NULL,\n    payload JSONB NOT NULL,\n    hops JSONB NOT NULL,  -- Stored as JSON\n    created_at TIMESTAMPTZ NOT NULL\n);\nCREATE INDEX idx_event_store_correlation_id ON wh_event_store(correlation_id);\nCREATE INDEX idx_event_store_causation_id ON wh_event_store(causation_id);\n`\nQuery hops:\n`sql\nSELECT\n    event_id,\n    event_type,\n    hops->>0->>'Metadata'->>'ServiceName' AS service_name,\n    hops->>0->>'Timestamp' AS timestamp,\n    hops->>0->>'Duration' AS duration\nFROM wh_event_store\nWHERE correlation_id = 'corr-abc'\nORDER BY created_at;\n`\n---\nFurther Reading\nCore Concepts:\nMessage Context - MessageId, CorrelationId, CausationId\nDispatcher - How messages flow through the system\nReceptors - Message handlers\nMessaging Patterns:\nMessage Envelopes - Deep dive into hop architecture\nOutbox Pattern - Reliable messaging with hops\nEvent Store - Storing hops with events\nInfrastructure:\nLogging & Telemetry - Application Insights integration\nPolicy Engine - Policy decision trails\n---\nVersion 0",
        "startIndex": 14144,
        "preview": "Console WriteLine(); } } } ` Output: ` Message: msg-003 Correlation: corr-abc Causation: msg-002 Hops: Causation Timestamp: 2024-12-12 10:00:00 123 Du..."
      },
      {
        "id": "v0.1.0/core-concepts/observability-chunk-9",
        "text": "messages flow through the system Receptors - Message handlers Messaging Patterns: Message Envelopes - Deep dive into hop architecture Outbox Pattern - Reliable messaging with hops Event Store - Storing hops with events Infrastructure: Logging & Telemetry - Application Insights integration Policy Engine - Policy decision trails --- Version 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 842,
        "preview": "messages flow through the system Receptors - Message handlers Messaging Patterns: Message Envelopes - Deep dive into hop architecture Outbox Pattern -..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/perspectives",
    "title": "Perspectives Guide",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/perspectives",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-0",
        "text": "Perspectives Guide\nPerspectives are event listeners that maintain read models (projections) optimized for queries They embody the \"Q\" in CQRS (Command Query Responsibility Segregation) - separate models for reading data Core Concept\nA Perspective is analogous to a viewpoint or lens through which you see data:\nListens to events (domain events)\nUpdates denormalized data (read models)\nOptimized for queries (no joins, fast reads)\nEventually consistent (updates after command completes)\nIPerspectiveOf Interface\n`csharp\nnamespace Whizbang Core;\npublic interface IPerspectiveOf<in TEvent>\n    where TEvent : notnull {\n    Task UpdateAsync(\n        TEvent @event,\n        CancellationToken cancellationToken = default\n    );\n}\n`\nType Parameters:\nTEvent: The event type this perspective listens to\nKey Characteristics:\nEvent-driven: Triggered automatically when events are published\nStateless: Like receptors, no instance state except injected dependencies\nEventually consistent: Updates happen asynchronously after command\nIdempotent: Same event processed multiple times = same result\n---\nBasic Example\n`csharp\nusing Whizbang Core;\nusing Dapper;\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    private readonly ILogger<OrderSummaryPerspective> _logger;\n    public OrderSummaryPerspective(\n        IDbConnectionFactory db,\n        ILogger<OrderSummaryPerspective> logger) {\n        _db = db;\n        _logger = logger;\n    }\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Insert denormalized order summary\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (\n                order_id, customer_id, item_count, total, status, created_at\n            ) VALUES (\n                @OrderId, @CustomerId, @ItemCount, @Total, @Status, @CreatedAt\n            )\n            \"\"\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                ItemCount = @event Items Length,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            },\n            commandTimeout: 30,\n            cancellationToken: ct\n        );\n        _logger LogInformation(\n            \"Updated order summary for {OrderId}, customer {CustomerId}, total {Total:C}\",\n            @event OrderId, @event CustomerId, @event",
        "startIndex": 0,
        "preview": "Perspectives Guide\nPerspectives are event listeners that maintain read models (projections) optimized for queries They embody the \"Q\" in CQRS (Command..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-1",
        "text": "VALUES ( @OrderId, @CustomerId, @ItemCount, @Total, @Status, @CreatedAt ) \"\"\", new { @event OrderId, @event CustomerId, ItemCount = @event Items Length, @event Total, Status = \"Created\", @event CreatedAt }, commandTimeout: 30, cancellationToken: ct ); _logger LogInformation( \"Updated order summary for {OrderId}, customer {CustomerId}, total {Total:C}\", @event OrderId, @event CustomerId, @event Total\n        );\n    }\n}\n`\n---\nCQRS Pattern\nWhizbang implements CQRS with:\nWrite side: Commands ‚Üí Receptors ‚Üí Events\nRead side: Events ‚Üí Perspectives ‚Üí Read Models ‚Üí Lenses\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ WRITE SIDE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                                           ‚îÇ\n‚îÇ  CreateOrder Command                      ‚îÇ\n‚îÇ       ‚Üì                                   ‚îÇ\n‚îÇ  CreateOrderReceptor                      ‚îÇ\n‚îÇ       ‚Üì                                   ‚îÇ\n‚îÇ  OrderCreated Event                       ‚îÇ\n‚îÇ                                           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                ‚îÇ\n                ‚îÇ dispatcher PublishAsync()\n                ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ READ SIDE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                                           ‚îÇ\n‚îÇ  OrderCreated Event                       ‚îÇ\n‚îÇ       ‚Üì                                   ‚îÇ\n‚îÇ  OrderSummaryPerspective UpdateAsync()   ‚îÇ\n‚îÇ       ‚Üì                                   ‚îÇ\n‚îÇ  order_summaries table (denormalized)    ‚îÇ\n‚îÇ       ‚Üì                                   ‚îÇ\n‚îÇ  OrderLens GetOrderAsync() ‚Üê Query       ‚îÇ\n‚îÇ                                           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\nOptimized reads: Denormalized data, no joins\nScalability: Read and write databases can scale independently\nFlexibility: Multiple read models for different use cases\nPerformance: Queries are simple, fast lookups\n---\nMultiple Perspectives\nKey Pattern: One event can trigger multiple perspectives `csharp\n// Event published once\nawait _dispatcher PublishAsync(orderCreated);\n// Triggers multiple perspectives automatically\n`\nExample: OrderCreated Event\n`csharp\n// Perspective 1: Order Summary (for UI)\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update order_summaries table for customer order history\n        await _db ExecuteAsync(\n            \"INSERT INTO order_summaries ( ) VALUES ( )\",\n            @event\n        );\n    }\n}\n// Perspective 2: Inventory Impact (for stock management)\npublic class InventoryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update inventory_levels table to reflect pending reservations\n        foreach (var item in @event Items) {\n            await _db",
        "startIndex": 2632,
        "preview": "VALUES ( @OrderId, @CustomerId, @ItemCount, @Total, @Status, @CreatedAt ) \"\"\", new { @event OrderId, @event CustomerId, ItemCount = @event Items Lengt..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-2",
        "text": "( ) VALUES ( )\", @event ); } } // Perspective 2: Inventory Impact (for stock management) public class InventoryPerspective : IPerspectiveOf<OrderCreated> { public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { // Update inventory_levels table to reflect pending reservations foreach (var item in @event Items) { await _db ExecuteAsync(\n                \"UPDATE inventory_levels SET pending = pending + @Quantity WHERE product_id = @ProductId\",\n                new { ProductId = item ProductId, Quantity = item Quantity }\n            );\n        }\n    }\n}\n// Perspective 3: Analytics (for reporting)\npublic class OrderAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update analytics_daily_sales table for dashboards\n        await _db ExecuteAsync(\n            \"INSERT INTO analytics_daily_sales (date, order_count, total_sales) VALUES (CURRENT_DATE, 1, @Total) ON CONFLICT (date) DO UPDATE SET order_count = order_count + 1, total_sales = total_sales + @Total\",\n            new { @event Total }\n        );\n    }\n}\n// Perspective 4: Customer Activity (for personalization)\npublic class CustomerActivityPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update customer_activity table for recommendations\n        await _db ExecuteAsync(\n            \"UPDATE customer_activity SET last_order_date = @CreatedAt, order_count = order_count + 1 WHERE customer_id = @CustomerId\",\n            new { @event CustomerId, @event CreatedAt }\n        );\n    }\n}\n`\nResult: Publishing OrderCreated updates four separate read models automatically ---\nListening to Multiple Events\nA single perspective can listen to multiple event types:\n`csharp\npublic class OrderSummaryPerspective :\n    IPerspectiveOf<OrderCreated>,\n    IPerspectiveOf<OrderShipped>,\n    IPerspectiveOf<OrderCancelled> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO order_summaries (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, 'Created', @CreatedAt)\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event Total,\n                @event",
        "startIndex": 5026,
        "preview": "( ) VALUES ( )\", @event ); } } // Perspective 2: Inventory Impact (for stock management) public class InventoryPerspective : IPerspectiveOf<OrderCreat..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-3",
        "text": "IPerspectiveOf<OrderShipped>, IPerspectiveOf<OrderCancelled> { private readonly IDbConnectionFactory _db; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"INSERT INTO order_summaries (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, 'Created', @CreatedAt)\", new { @event OrderId, @event CustomerId, @event Total, @event CreatedAt\n            },\n            cancellationToken: ct\n        );\n    }\n    public async Task UpdateAsync(OrderShipped @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"UPDATE order_summaries SET status = 'Shipped', shipped_at = @ShippedAt WHERE order_id = @OrderId\",\n            new {\n                @event OrderId,\n                @event ShippedAt\n            },\n            cancellationToken: ct\n        );\n    }\n    public async Task UpdateAsync(OrderCancelled @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"UPDATE order_summaries SET status = 'Cancelled', cancelled_at = @CancelledAt WHERE order_id = @OrderId\",\n            new {\n                @event OrderId,\n                @event CancelledAt\n            },\n            cancellationToken: ct\n        );\n    }\n}\n`\nPattern: One read model, multiple events that update it over time",
        "startIndex": 7190,
        "preview": "IPerspectiveOf<OrderShipped>, IPerspectiveOf<OrderCancelled> { private readonly IDbConnectionFactory _db; public async Task UpdateAsync(OrderCreated @..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-4",
        "text": "= default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"UPDATE order_summaries SET status = 'Cancelled', cancelled_at = @CancelledAt WHERE order_id = @OrderId\", new { @event OrderId, @event CancelledAt }, cancellationToken: ct ); } } ` Pattern: One read model, multiple events that update it over time ---\nRead Model Design\nDenormalization\nRead models are denormalized for query performance:\nWrite Model (normalized):\n`sql\n-- Normalized schema (write side)\nCREATE TABLE orders (\n    order_id UUID PRIMARY KEY,\n    customer_id UUID NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL\n);\nCREATE TABLE order_items (\n    order_item_id UUID PRIMARY KEY,\n    order_id UUID NOT NULL,\n    product_id UUID NOT NULL,\n    quantity INT NOT NULL,\n    unit_price DECIMAL(10,2) NOT NULL,\n    FOREIGN KEY (order_id) REFERENCES orders(order_id)\n);\nCREATE TABLE customers (\n    customer_id UUID PRIMARY KEY,\n    email VARCHAR(255) NOT NULL,\n    full_name VARCHAR(255) NOT NULL\n);\nCREATE TABLE products (\n    product_id UUID PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    price DECIMAL(10,2) NOT NULL\n);\n`\nRead Model (denormalized):\n`sql\n-- Denormalized schema (read side)\nCREATE TABLE order_summaries (\n    order_id UUID PRIMARY KEY,\n    customer_id UUID NOT NULL,\n    customer_email VARCHAR(255) NOT NULL,    -- Denormalized from customers\n    customer_name VARCHAR(255) NOT NULL,      -- Denormalized from customers\n    item_count INT NOT NULL,\n    total DECIMAL(10,2) NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL,\n    shipped_at TIMESTAMPTZ NULL,\n    cancelled_at TIMESTAMPTZ NULL\n);\n-- Simple index for fast lookups\nCREATE INDEX idx_order_summaries_customer_id ON order_summaries(customer_id);\nCREATE INDEX idx_order_summaries_created_at ON order_summaries(created_at DESC);\n`\nQuery Performance:\n`sql\n-- ‚ùå SLOW: Normalized (requires joins)\nSELECT o order_id, c email, c full_name, SUM(oi quantity * oi unit_price) AS total\nFROM orders o\nJOIN customers c ON o customer_id = c customer_id\nJOIN order_items oi ON o order_id = oi order_id\nWHERE o customer_id = ' '\nGROUP BY o order_id, c email, c",
        "startIndex": 8223,
        "preview": "= default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"UPDATE order_summaries SET status = 'Cancelled', cancelled_at = ..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-5",
        "text": "(requires joins) SELECT o order_id, c email, c full_name, SUM(oi quantity * oi unit_price) AS total FROM orders o JOIN customers c ON o customer_id = c customer_id JOIN order_items oi ON o order_id = oi order_id WHERE o customer_id = ' ' GROUP BY o order_id, c email, c full_name;\n-- ‚úÖ FAST: Denormalized (single table lookup)\nSELECT order_id, customer_email, customer_name, total\nFROM order_summaries\nWHERE customer_id = ' ';\n`\nMultiple Read Models\nDifferent perspectives for different use cases:\n`csharp\n// Read Model 1: Order summary for customer order history UI\npublic class OrderSummary {\n    public Guid OrderId { get; set; }\n    public Guid CustomerId { get; set; }\n    public string CustomerEmail { get; set; } = string Empty;\n    public string CustomerName { get; set; } = string Empty;\n    public int ItemCount { get; set; }\n    public decimal Total { get; set; }\n    public string Status { get; set; } = string Empty;\n    public DateTimeOffset CreatedAt { get; set; }\n}\n// Read Model 2: Order details for admin dashboard\npublic class OrderDetails {\n    public Guid OrderId { get; set; }\n    public Guid CustomerId { get; set; }\n    public OrderLineItem[] Items { get; set; } = [];\n    public decimal Subtotal { get; set; }\n    public decimal Tax { get; set; }\n    public decimal ShippingCost { get; set; }\n    public decimal Total { get; set; }\n    public string Status { get; set; } = string Empty;\n    public string ShippingAddress { get; set; } = string Empty;\n    public DateTimeOffset CreatedAt { get; set; }\n    public DateTimeOffset",
        "startIndex": 10065,
        "preview": "(requires joins) SELECT o order_id, c email, c full_name, SUM(oi quantity * oi unit_price) AS total FROM orders o JOIN customers c ON o customer_id = ..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-6",
        "text": "public decimal Tax { get; set; } public decimal ShippingCost { get; set; } public decimal Total { get; set; } public string Status { get; set; } = string Empty; public string ShippingAddress { get; set; } = string Empty; public DateTimeOffset CreatedAt { get; set; } public DateTimeOffset ShippedAt { get; set; }\n}\n// Read Model 3: Analytics for reporting\npublic class DailySalesAnalytics {\n    public DateOnly Date { get; set; }\n    public int OrderCount { get; set; }\n    public decimal TotalSales { get; set; }\n    public decimal AverageOrderValue { get; set; }\n}\n`\nEach read model has its own perspective and table schema optimized for its queries ---\nData Access Patterns\nDapper (Lightweight)\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (\n                order_id, customer_id, customer_email, customer_name,\n                item_count, total, status, created_at\n            ) VALUES (\n                @OrderId, @CustomerId, @CustomerEmail, @CustomerName,\n                @ItemCount, @Total, @Status, @CreatedAt\n            )\n            \"\"\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event CustomerEmail,\n                @event CustomerName,\n                ItemCount = @event Items Length,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            },\n            cancellationToken: ct\n        );\n    }\n}\n`\nEF Core (Full-Featured)\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly OrderReadDbContext _dbContext;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        var summary = new OrderSummaryEntity {\n            OrderId = @event OrderId,\n            CustomerId = @event CustomerId,\n            CustomerEmail = @event CustomerEmail,\n            CustomerName = @event CustomerName,\n            ItemCount = @event Items Length,\n            Total = @event Total,\n            Status = \"Created\",\n            CreatedAt = @event CreatedAt\n        };\n        _dbContext OrderSummaries Add(summary);\n        await _dbContext SaveChangesAsync(ct);\n    }\n}\n`\n---\nDependency Injection\nRegistration\nManual:\n`csharp\nbuilder Services AddTransient<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\nbuilder Services AddTransient<IPerspectiveOf<OrderCreated>, InventoryPerspective>();\n`\nAuto-Discovery (with Whizbang Generators):\n`csharp\nbuilder Services",
        "startIndex": 11350,
        "preview": "public decimal Tax { get; set; } public decimal ShippingCost { get; set; } public decimal Total { get; set; } public string Status { get; set; } = str..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-7",
        "text": "@event CustomerName, ItemCount = @event Items Length, Total = @event Total, Status = \"Created\", CreatedAt = @event CreatedAt }; _dbContext OrderSummaries Add(summary); await _dbContext SaveChangesAsync(ct); } } ` --- Dependency Injection Registration Manual: `csharp builder Services AddTransient<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>(); builder Services AddTransient<IPerspectiveOf<OrderCreated>, InventoryPerspective>(); ` Auto-Discovery (with Whizbang Generators): `csharp builder Services AddDiscoveredPerspectives();  // Finds all IPerspectiveOf implementations\n`\nLifetime\nRecommended: Transient (new instance per event)\nWhy May inject scoped services (e g , DbContext)\nStateless (no benefit to reusing instances)\nIsolated error handling (one failing perspective doesn't affect others)\n`csharp\nbuilder Services AddTransient<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\n`\n---\nError Handling\nIdempotency\nPerspectives should be idempotent (processing same event multiple times = same result):\n`csharp\npublic async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Use UPSERT to handle duplicate events\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO order_summaries (order_id, customer_id, total, status, created_at)\n        VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\n        ON CONFLICT (order_id) DO NOTHING  -- Ignore duplicates\n        \"\"\",\n        new {\n            @event OrderId,\n            @event CustomerId,\n            @event Total,\n            Status = \"Created\",\n            @event CreatedAt\n        },\n        cancellationToken: ct\n    );\n}\n`\nPostgreSQL patterns:\nON CONFLICT DO NOTHING - Ignore duplicates\nON CONFLICT DO UPDATE - Update if exists\nFailure Handling\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    private readonly ILogger<OrderSummaryPerspective> _logger;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        try {\n            await using var conn = _db CreateConnection();\n            await conn ExecuteAsync(\n                \"INSERT INTO order_summaries ( ) VALUES ( )\",\n                @event,\n                cancellationToken: ct\n            );\n            _logger LogInformation(\n                \"Updated order summary for {OrderId}\",\n                @event OrderId\n            );\n        } catch (Exception ex) when (ex is not OperationCanceledException) {\n            // Log error but don't throw - allow other perspectives to continue\n            _logger LogError(\n                ex,\n                \"Failed to update order summary for {OrderId}\",\n                @event OrderId\n            );\n            // Options:\n            // 1",
        "startIndex": 13837,
        "preview": "@event CustomerName, ItemCount = @event Items Length, Total = @event Total, Status = \"Created\", CreatedAt = @event CreatedAt }; _dbContext OrderSummar..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-8",
        "text": "); _logger LogInformation( \"Updated order summary for {OrderId}\", @event OrderId ); } catch (Exception ex) when (ex is not OperationCanceledException) { // Log error but don't throw - allow other perspectives to continue _logger LogError( ex, \"Failed to update order summary for {OrderId}\", @event OrderId ); // Options: // 1 Swallow error (eventual consistency - will be retried)\n            // 2 Throw (fails entire publish operation)\n            // 3 Store in dead letter queue for manual review\n            // For most cases: swallow and rely on event replay\n        }\n    }\n}\n`\nStrategies:\nSwallow errors: Log and continue (eventual consistency via event replay)\nThrow errors: Fail entire publish operation (transactional consistency)\nDead letter queue: Store failed events for manual review/retry\n---\nEvent Sourcing Integration\nPerspectives can rebuild from event history:\n`csharp\npublic class RebuildPerspectiveWorker : BackgroundService {\n    private readonly IEventStore _eventStore;\n    private readonly IPerspectiveOf<OrderCreated> _perspective;\n    protected override async Task ExecuteAsync(CancellationToken ct) {\n        // Truncate read model\n        await TruncateReadModelAsync(ct);\n        // Replay all events\n        await foreach (var @event in _eventStore GetAllEventsAsync<OrderCreated>(ct)) {\n            await _perspective UpdateAsync(@event, ct);\n        }\n    }\n    private async Task TruncateReadModelAsync(CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\"TRUNCATE TABLE order_summaries\", cancellationToken: ct);\n    }\n}\n`\nUse cases:\nRebuild corrupted read models\nAdd new perspectives to existing event history\nTime-travel queries (rebuild to specific point in time)\n---\nTesting Perspectives\nUnit Tests\n`csharp\npublic class OrderSummaryPerspectiveTests {\n    [Test]\n    public async Task UpdateAsync_OrderCreated_InsertsRowAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();\n        var logger = new NullLogger<OrderSummaryPerspective>();\n        var perspective = new OrderSummaryPerspective(mockDb, logger);\n        var @event = new OrderCreated(\n            OrderId: Guid NewGuid(),\n            CustomerId: Guid NewGuid(),\n            CustomerEmail: \"test@example com\",\n            CustomerName: \"John Doe\",\n            Items: [new OrderLineItem(Guid NewGuid(), 2, 19 99m)],\n            Total: 39 98m,\n            CreatedAt: DateTimeOffset UtcNow\n        );\n        // Act\n        await perspective UpdateAsync(@event, CancellationToken None);\n        // Assert\n        var summary = await mockDb",
        "startIndex": 16183,
        "preview": "); _logger LogInformation( \"Updated order summary for {OrderId}\", @event OrderId ); } catch (Exception ex) when (ex is not OperationCanceledException)..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-9",
        "text": "perspective = new OrderSummaryPerspective(mockDb, logger); var @event = new OrderCreated( OrderId: Guid NewGuid(), CustomerId: Guid NewGuid(), CustomerEmail: \"test@example com\", CustomerName: \"John Doe\", Items: [new OrderLineItem(Guid NewGuid(), 2, 19 99m)], Total: 39 98m, CreatedAt: DateTimeOffset UtcNow ); // Act await perspective UpdateAsync(@event, CancellationToken None); // Assert var summary = await mockDb QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { @event OrderId }\n        );\n        await Assert That(summary) IsNotNull();\n        await Assert That(summary CustomerId) IsEqualTo(@event CustomerId);\n        await Assert That(summary Total) IsEqualTo(39 98m);\n        await Assert That(summary Status) IsEqualTo(\"Created\");\n    }\n    [Test]\n    public async Task UpdateAsync_Idempotent_DuplicateEventsIgnoredAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();\n        var logger = new NullLogger<OrderSummaryPerspective>();\n        var perspective = new OrderSummaryPerspective(mockDb, logger);\n        var @event = new OrderCreated(/ /);\n        // Act - process same event twice\n        await perspective UpdateAsync(@event, CancellationToken None);\n        await perspective UpdateAsync(@event, CancellationToken None);  // Duplicate // Assert - only one row exists\n        var count = await mockDb ExecuteScalarAsync<int>(\n            \"SELECT COUNT(*) FROM order_summaries WHERE order_id = @OrderId\",\n            new { @event OrderId }\n        );\n        await Assert That(count) IsEqualTo(1);  // Not 2 }\n}\n`\n---\nAdvanced Patterns\nPattern: Aggregated Analytics\n`csharp\npublic class DailySalesAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Upsert daily aggregates\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO analytics_daily_sales (\n                date, order_count, total_sales, average_order_value\n            ) VALUES (\n                CURRENT_DATE, 1, @Total, @Total\n            )\n            ON CONFLICT (date) DO UPDATE SET\n                order_count = analytics_daily_sales order_count + 1,\n                total_sales = analytics_daily_sales total_sales + @Total,\n                average_order_value = (analytics_daily_sales total_sales + @Total) / (analytics_daily_sales order_count + 1)\n            \"\"\",\n            new { @event Total },\n            cancellationToken: ct\n        );\n    }\n}\n`\nPattern: Cross-Service Perspective (via Transport)\n`csharp\n// Service A: Order Service publishes OrderCreated\nawait _dispatcher",
        "startIndex": 18465,
        "preview": "perspective = new OrderSummaryPerspective(mockDb, logger); var @event = new OrderCreated( OrderId: Guid NewGuid(), CustomerId: Guid NewGuid(), Custome..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-10",
        "text": "order_count = analytics_daily_sales order_count + 1, total_sales = analytics_daily_sales total_sales + @Total, average_order_value = (analytics_daily_sales total_sales + @Total) / (analytics_daily_sales order_count + 1) \"\"\", new { @event Total }, cancellationToken: ct ); } } ` Pattern: Cross-Service Perspective (via Transport) `csharp // Service A: Order Service publishes OrderCreated await _dispatcher SendAsync(orderCreated);  // Stored in outbox\n// Background worker publishes to Azure Service Bus\nawait _transport PublishAsync(orderCreated);\n// Service B: Inventory Service perspective subscribes\npublic class InventoryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Update inventory read model in different service\n        await _db ExecuteAsync(\n            \"UPDATE inventory_summaries SET pending_orders = pending_orders + 1 WHERE product_id = ANY(@ProductIds)\",\n            new { ProductIds = @event Items Select(i => i ProductId) ToArray() },\n            cancellationToken: ct\n        );\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Make perspectives idempotent (same event multiple times = same result)\n‚úÖ Use UPSERT (ON CONFLICT",
        "startIndex": 20854,
        "preview": "order_count = analytics_daily_sales order_count + 1, total_sales = analytics_daily_sales total_sales + @Total, average_order_value = (analytics_daily_..."
      },
      {
        "id": "v0.1.0/core-concepts/perspectives-chunk-11",
        "text": "inventory_summaries SET pending_orders = pending_orders + 1 WHERE product_id = ANY(@ProductIds)\", new { ProductIds = @event Items Select(i => i ProductId) ToArray() }, cancellationToken: ct ); } } ` --- Best Practices DO ‚úÖ ‚úÖ Make perspectives idempotent (same event multiple times = same result) ‚úÖ Use UPSERT (ON CONFLICT DO UPDATE/NOTHING)\n‚úÖ Denormalize for query performance\n‚úÖ Create multiple read models for different use cases\n‚úÖ Log errors but don't throw (eventual consistency)\n‚úÖ Use transient lifetime for perspectives\n‚úÖ Keep perspectives stateless\n‚úÖ Index read model tables for fast queries\n‚úÖ Test idempotency explicitly\nDON'T ‚ùå\n‚ùå Perform complex joins in read models (defeats purpose of denormalization)\n‚ùå Call receptors from perspectives (perspectives are read-only)\n‚ùå Store state in perspective instances\n‚ùå Throw exceptions for transient errors (breaks eventual consistency)\n‚ùå Normalize read models (use denormalized schemas)\n‚ùå Mix write and read logic in same perspective\n‚ùå Ignore duplicate event handling (must be idempotent)\n---\nFurther Reading\nCore Concepts:\nDispatcher - How to publish events to perspectives\nLenses - Query interfaces for read models\nReceptors - Command handlers that produce events\nData Access:\nDapper Integration - Lightweight data access\nEF Core Integration - Full-featured ORM\nPerspective Storage - Schema design patterns\nExamples:\nECommerce: BFF Pattern - Real-world perspectives\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 21682,
        "preview": "inventory_summaries SET pending_orders = pending_orders + 1 WHERE product_id = ANY(@ProductIds)\", new { ProductIds = @event Items Select(i => i Produc..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/core-concepts/receptors",
    "title": "Receptors Guide",
    "category": "Core Concepts",
    "url": "/docs/v0.1.0/core-concepts/receptors",
    "chunks": [
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-0",
        "text": "Receptors Guide\nReceptors are stateless message handlers that encapsulate business logic and decision-making in Whizbang applications They receive commands/queries and return events/responses Core Concept\nA Receptor is analogous to a biological receptor:\nReceives signals (messages/commands)\nMakes decisions (business logic)\nProduces responses (events/responses)\nStateless (no internal state, everything via parameters)\nIReceptor Interface\n`csharp\nnamespace Whizbang Core;\npublic interface IReceptor<in TMessage, TResponse>\n    where TMessage : notnull {\n    ValueTask<TResponse> HandleAsync(\n        TMessage message,\n        CancellationToken cancellationToken = default\n    );\n}\n`\nType Parameters:\nTMessage: The incoming message/command type\nTResponse: The response/event type\nKey Characteristics:\nStateless: No instance fields, all data via parameters\nSingle Responsibility: One receptor per message type\nAsync: Returns ValueTask<T> for optimal performance\nType Safe: Compile-time enforcement of message ‚Üí response mapping\n---\nBasic Example\n`csharp\nusing Whizbang Core;\npublic record CreateOrder(\n    Guid CustomerId,\n    OrderLineItem[] Items\n);\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly ILogger<CreateOrderReceptor> _logger;\n    public CreateOrderReceptor(ILogger<CreateOrderReceptor> logger) {\n        _logger = logger;\n    }\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken cancellationToken = default) {\n        // Validation\n        if (message Items Length == 0) {\n            throw new ValidationException(\"Order must contain at least one item\");\n        }\n        // Business logic\n        var orderId = Guid CreateVersion7();\n        var total = message Items Sum(i => i Quantity * i UnitPrice);\n        _logger LogInformation(\n            \"Creating order {OrderId} for customer {CustomerId} with {ItemCount} items, total {Total:C}\",\n            orderId, message CustomerId, message Items Length, total\n        );\n        // Return event (fact of what happened)\n        return new OrderCreated(\n            OrderId: orderId,\n            CustomerId: message CustomerId,\n            Items: message Items,\n            Total: total,\n            CreatedAt: DateTimeOffset",
        "startIndex": 0,
        "preview": "Receptors Guide\nReceptors are stateless message handlers that encapsulate business logic and decision-making in Whizbang applications They receive com..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-1",
        "text": "Sum(i => i Quantity * i UnitPrice); _logger LogInformation( \"Creating order {OrderId} for customer {CustomerId} with {ItemCount} items, total {Total:C}\", orderId, message CustomerId, message Items Length, total ); // Return event (fact of what happened) return new OrderCreated( OrderId: orderId, CustomerId: message CustomerId, Items: message Items, Total: total, CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\n---\nReceptor Patterns\nPattern 1: Command ‚Üí Event\nUse Case: State-changing operations\n`csharp\npublic class CancelOrderReceptor : IReceptor<CancelOrder, OrderCancelled> {\n    private readonly IDbConnectionFactory _db;\n    private readonly ILogger<CancelOrderReceptor> _logger;\n    public CancelOrderReceptor(\n        IDbConnectionFactory db,\n        ILogger<CancelOrderReceptor> logger) {\n        _db = db;\n        _logger = logger;\n    }\n    public async ValueTask<OrderCancelled> HandleAsync(\n        CancelOrder message,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Load current state\n        var order = await conn QuerySingleOrDefaultAsync<Order>(\n            \"SELECT * FROM orders WHERE order_id = @OrderId\",\n            new { message OrderId },\n            ct\n        );\n        // Validation\n        if (order is null) {\n            throw new NotFoundException($\"Order {message OrderId} not found\");\n        }\n        if (order Status == \"Shipped\") {\n            throw new InvalidOperationException(\"Cannot cancel shipped order\");\n        }\n        _logger LogInformation(\n            \"Cancelling order {OrderId}, reason: {Reason}\",\n            message OrderId, message Reason\n        );\n        // Return event\n        return new OrderCancelled(\n            OrderId: message OrderId,\n            Reason: message Reason,\n            CancelledAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nKey Points:\nCommands are imperative (CancelOrder - intent to change state)\nEvents are past tense (OrderCancelled - fact of what happened)\nValidation before event creation\nEvent contains all relevant data for downstream consumers\nPattern 2: Query ‚Üí Response\nUse Case: Read operations\n`csharp\npublic record GetOrderDetails(Guid OrderId);\npublic record OrderDetails(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    string Status,\n    DateTimeOffset CreatedAt\n);\npublic class GetOrderDetailsReceptor : IReceptor<GetOrderDetails, OrderDetails> {\n    private readonly IOrderLens _lens;\n    public GetOrderDetailsReceptor(IOrderLens lens) {\n        _lens = lens;\n    }\n    public async ValueTask<OrderDetails> HandleAsync(\n        GetOrderDetails query,\n        CancellationToken ct = default) {\n        var order = await _lens GetOrderAsync(query",
        "startIndex": 2441,
        "preview": "Sum(i => i Quantity * i UnitPrice); _logger LogInformation( \"Creating order {OrderId} for customer {CustomerId} with {ItemCount} items, total {Total:C..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-2",
        "text": "OrderDetails( Guid OrderId, Guid CustomerId, OrderLineItem[] Items, decimal Total, string Status, DateTimeOffset CreatedAt ); public class GetOrderDetailsReceptor : IReceptor<GetOrderDetails, OrderDetails> { private readonly IOrderLens _lens; public GetOrderDetailsReceptor(IOrderLens lens) { _lens = lens; } public async ValueTask<OrderDetails> HandleAsync( GetOrderDetails query, CancellationToken ct = default) { var order = await _lens GetOrderAsync(query OrderId, ct);\n        if (order is null) {\n            throw new NotFoundException($\"Order {query OrderId} not found\");\n        }\n        return new OrderDetails(\n            OrderId: order OrderId,\n            CustomerId: order CustomerId,\n            Items: order Items,\n            Total: order Total,\n            Status: order Status,\n            CreatedAt: order CreatedAt\n        );\n    }\n}\n`\nKey Points:\nQueries are questions (GetOrderDetails)\nResponses are answers (OrderDetails)\nRead from optimized read models (via Lenses)\nNo side effects (pure read operation)\nPattern 3: Validation-Heavy Receptor\nUse Case: Complex business rules\n`csharp\npublic class ProcessPaymentReceptor : IReceptor<ProcessPayment, PaymentResult> {\n    private readonly IPaymentGateway _gateway;\n    private readonly IDbConnectionFactory _db;\n    private readonly ILogger<ProcessPaymentReceptor> _logger;\n    public ProcessPaymentReceptor(\n        IPaymentGateway gateway,\n        IDbConnectionFactory db,\n        ILogger<ProcessPaymentReceptor> logger) {\n        _gateway = gateway;\n        _db = db;\n        _logger = logger;\n    }\n    public async ValueTask<PaymentResult> HandleAsync(\n        ProcessPayment message,\n        CancellationToken ct = default) {\n        // Validation Step 1: Order exists and is valid\n        await ValidateOrderAsync(message OrderId, ct);\n        // Validation Step 2: Payment amount matches order total\n        await ValidateAmountAsync(message OrderId, message Amount, ct);\n        // Validation Step 3: Payment method is valid\n        ValidatePaymentMethod(message PaymentMethod);\n        // Business Logic: Process payment\n        try {\n            var transactionId = await _gateway ChargeAsync(\n                message PaymentMethod,\n                message Amount,\n                ct\n            );\n            _logger LogInformation(\n                \"Payment processed for order {OrderId}, transaction {TransactionId}\",\n                message OrderId, transactionId\n            );\n            return new PaymentResult(\n                OrderId: message OrderId,\n                Amount: message Amount,\n                TransactionId: transactionId,\n                IsSuccess: true,\n                ErrorCode: null\n            );\n        } catch (PaymentDeclinedException ex) {\n            _logger LogWarning(\n                ex,\n                \"Payment declined for order {OrderId}\",\n                message OrderId\n            );\n            return new PaymentResult(\n                OrderId: message OrderId,\n                Amount: message Amount,\n                TransactionId: null,\n                IsSuccess: false,\n                ErrorCode: ex",
        "startIndex": 4809,
        "preview": "OrderDetails( Guid OrderId, Guid CustomerId, OrderLineItem[] Items, decimal Total, string Status, DateTimeOffset CreatedAt ); public class GetOrderDet..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-3",
        "text": "OrderId, transactionId ); return new PaymentResult( OrderId: message OrderId, Amount: message Amount, TransactionId: transactionId, IsSuccess: true, ErrorCode: null ); } catch (PaymentDeclinedException ex) { _logger LogWarning( ex, \"Payment declined for order {OrderId}\", message OrderId ); return new PaymentResult( OrderId: message OrderId, Amount: message Amount, TransactionId: null, IsSuccess: false, ErrorCode: ex ErrorCode\n            );\n        }\n    }\n    private async Task ValidateOrderAsync(Guid orderId, CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        var order = await conn QuerySingleOrDefaultAsync<Order>(\n            \"SELECT * FROM orders WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        if (order is null) {\n            throw new NotFoundException($\"Order {orderId} not found\");\n        }\n        if (order Status = \"Created\") {\n            throw new InvalidOperationException(\n                $\"Order {orderId} is not in valid state for payment (status: {order Status})\"\n            );\n        }\n    }\n    private async Task ValidateAmountAsync(\n        Guid orderId,\n        decimal amount,\n        CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        var total = await conn ExecuteScalarAsync<decimal>(\n            \"SELECT total FROM orders WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        if (amount = total) {\n            throw new ValidationException(\n                $\"Payment amount {amount:C} does not match order total {total:C}\"\n            );\n        }\n    }\n    private static void ValidatePaymentMethod(PaymentMethod method) {\n        if (string IsNullOrWhiteSpace(method CardNumber)) {\n            throw new ValidationException(\"Card number is required\");\n        }\n        if (method ExpiryDate < DateOnly FromDateTime(DateTime",
        "startIndex": 7485,
        "preview": "OrderId, transactionId ); return new PaymentResult( OrderId: message OrderId, Amount: message Amount, TransactionId: transactionId, IsSuccess: true, E..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-4",
        "text": "OrderId = orderId }, ct ); if (amount = total) { throw new ValidationException( $\"Payment amount {amount:C} does not match order total {total:C}\" ); } } private static void ValidatePaymentMethod(PaymentMethod method) { if (string IsNullOrWhiteSpace(method CardNumber)) { throw new ValidationException(\"Card number is required\"); } if (method ExpiryDate < DateOnly FromDateTime(DateTime UtcNow)) {\n            throw new ValidationException(\"Card has expired\");\n        }\n    }\n}\n`\nKey Points:\nExtract validation into private methods\nValidate early, fail fast\nClear error messages\nStructured logging\n---\nDependency Injection\nConstructor Injection\nReceptors use constructor injection for dependencies:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    private readonly IInventoryService _inventory;\n    private readonly ILogger<CreateOrderReceptor> _logger;\n    // Dependencies injected via constructor\n    public CreateOrderReceptor(\n        IDbConnectionFactory db,\n        IInventoryService inventory,\n        ILogger<CreateOrderReceptor> logger) {\n        _db = db;\n        _inventory = inventory;\n        _logger = logger;\n    }\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Use injected dependencies\n        await using var conn = _db CreateConnection();\n        var hasStock = await _inventory CheckStockAsync(message Items, ct);\n        // }\n}\n`\nRegistration\nManual Registration:\n`csharp\nbuilder Services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n`\nAuto-Discovery (with Whizbang Generators):\n`csharp\nbuilder Services AddDiscoveredReceptors();  // Automatically finds all IReceptor implementations\n`\nLifetime\nRecommended: Transient (new instance per request)\nWhy May inject scoped services (e g , DbContext)\nStateless (no benefit to reusing instances)\nMinimal allocation cost\n`csharp\n// Correct\nbuilder Services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n// Avoid (unless you have specific performance needs)\nbuilder Services AddScoped<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\nbuilder Services AddSingleton<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n`\n---\nError Handling\nValidation Errors\nUse exceptions for validation failures:\n`csharp\npublic async ValueTask<OrderCreated> HandleAsync(\n    CreateOrder message,\n    CancellationToken ct = default) {\n    // Early validation\n    if (message Items Length == 0) {\n        throw new ValidationException(\"Order must contain at least one item\");\n    }\n    if (message Items Any(i => i",
        "startIndex": 9006,
        "preview": "OrderId = orderId }, ct ); if (amount = total) { throw new ValidationException( $\"Payment amount {amount:C} does not match order total {total:C}\" ); }..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-5",
        "text": "CreateOrderReceptor>(); ` --- Error Handling Validation Errors Use exceptions for validation failures: `csharp public async ValueTask<OrderCreated> HandleAsync( CreateOrder message, CancellationToken ct = default) { // Early validation if (message Items Length == 0) { throw new ValidationException(\"Order must contain at least one item\"); } if (message Items Any(i => i Quantity <= 0)) {\n        throw new ValidationException(\"All items must have quantity greater than zero\");\n    }\n    if (message Items Any(i => i UnitPrice <= 0)) {\n        throw new ValidationException(\"All items must have price greater than zero\");\n    }\n    // Business logic\n    // }\n`\nException Types:\nValidationException - Input validation failures (400 Bad Request)\nNotFoundException - Entity not found (404 Not Found)\nInvalidOperationException - Business rule violations (409 Conflict)\nUnauthorizedAccessException - Authorization failures (403 Forbidden)\nBusiness Logic Errors\nReturn error responses for expected failures:\n`csharp\npublic record PaymentResult(\n    Guid OrderId,\n    decimal Amount,\n    string TransactionId,\n    bool IsSuccess,\n    string ErrorCode\n);\npublic async ValueTask<PaymentResult> HandleAsync(\n    ProcessPayment message,\n    CancellationToken ct = default) {\n    try {\n        var transactionId = await _gateway ChargeAsync(\n            message PaymentMethod,\n            message Amount,\n            ct\n        );\n        return new PaymentResult(\n            OrderId: message OrderId,\n            Amount: message Amount,\n            TransactionId: transactionId,\n            IsSuccess: true,\n            ErrorCode: null\n        );\n    } catch (PaymentDeclinedException ex) {\n        // Don't throw - return error response\n        return new PaymentResult(\n            OrderId: message OrderId,\n            Amount: message Amount,\n            TransactionId: null,\n            IsSuccess: false,\n            ErrorCode: ex ErrorCode\n        );\n    }\n}\n`\nWhen to throw vs return error:\nThrow: Unexpected errors, validation failures, system errors\nReturn error: Expected business failures (payment declined, insufficient inventory)\n---\nAsync/Await Patterns\nValueTask vs Task\nUse ValueTask<T> for receptor signatures:\n`csharp\n// ‚úÖ CORRECT - ValueTask<T>\npublic async ValueTask<OrderCreated> HandleAsync(\n    CreateOrder message,\n    CancellationToken ct = default) {\n    // }\n// ‚ùå WRONG - Task<T>\npublic async Task<OrderCreated> HandleAsync(\n    CreateOrder message,\n    CancellationToken ct = default) {\n    // }\n`\nWhy ValueTask",
        "startIndex": 11340,
        "preview": "CreateOrderReceptor>(); ` --- Error Handling Validation Errors Use exceptions for validation failures: `csharp public async ValueTask<OrderCreated> Ha..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-6",
        "text": "Async/Await Patterns ValueTask vs Task Use ValueTask<T> for receptor signatures: `csharp // ‚úÖ CORRECT - ValueTask<T> public async ValueTask<OrderCreated> HandleAsync( CreateOrder message, CancellationToken ct = default) { // } // ‚ùå WRONG - Task<T> public async Task<OrderCreated> HandleAsync( CreateOrder message, CancellationToken ct = default) { // } ` Why ValueTask Can complete synchronously (no heap allocation for sync paths)\nCan be cached/pooled\nBetter performance for hot paths\nCancellation Token\nAlways accept and pass CancellationToken:\n`csharp\npublic async ValueTask<OrderCreated> HandleAsync(\n    CreateOrder message,\n    CancellationToken ct = default) {  // Accept ct\n    await using var conn = _db CreateConnection();\n    // Pass ct to all async operations\n    var customer = await conn QuerySingleOrDefaultAsync<Customer>(\n        \"SELECT * FROM customers WHERE customer_id = @CustomerId\",\n        new { message CustomerId },\n        ct  // ‚Üê Pass cancellation token\n    );\n    // }\n`\nBenefits:\nRequest cancellation support\nGraceful shutdown\nResource cleanup\n---\nTesting Receptors\nUnit Tests\nTest receptors in isolation:\n`csharp\npublic class CreateOrderReceptorTests {\n    [Test]\n    public async Task HandleAsync_ValidOrder_ReturnsOrderCreatedAsync() {\n        // Arrange\n        var logger = new NullLogger<CreateOrderReceptor>();\n        var receptor = new CreateOrderReceptor(logger);\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            Items: [\n                new OrderLineItem(Guid NewGuid(), 2, 19 99m),\n                new OrderLineItem(Guid NewGuid(), 1, 49 99m)\n            ]\n        );\n        // Act\n        var result = await receptor HandleAsync(command);\n        // Assert\n        await Assert That(result OrderId) IsNotEqualTo(Guid Empty);\n        await Assert That(result CustomerId) IsEqualTo(command CustomerId);\n        await Assert That(result Items Length) IsEqualTo(2);\n        await Assert That(result Total) IsEqualTo(89 97m);  // (2 * 19 99) + 49 99\n    }\n    [Test]\n    public async Task HandleAsync_EmptyItems_ThrowsValidationExceptionAsync() {\n        // Arrange\n        var logger = new NullLogger<CreateOrderReceptor>();\n        var receptor = new CreateOrderReceptor(logger);\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            Items: []  // Empty );\n        // Act & Assert\n        await Assert That(async () => await receptor HandleAsync(command)) ThrowsException<ValidationException>()",
        "startIndex": 13513,
        "preview": "Async/Await Patterns ValueTask vs Task Use ValueTask<T> for receptor signatures: `csharp // ‚úÖ CORRECT - ValueTask<T> public async ValueTask<OrderCreat..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-7",
        "text": "19 99) + 49 99 } [Test] public async Task HandleAsync_EmptyItems_ThrowsValidationExceptionAsync() { // Arrange var logger = new NullLogger<CreateOrderReceptor>(); var receptor = new CreateOrderReceptor(logger); var command = new CreateOrder( CustomerId: Guid NewGuid(), Items: [] // Empty ); // Act & Assert await Assert That(async () => await receptor HandleAsync(command)) ThrowsException<ValidationException>() WithMessage(\"Order must contain at least one item\");\n    }\n}\n`\nMocking Dependencies\nUse mocks for external dependencies:\n`csharp\npublic class CancelOrderReceptorTests {\n    [Test]\n    public async Task HandleAsync_ExistingOrder_ReturnsOrderCancelledAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();  // Returns mock with test data\n        var logger = new NullLogger<CancelOrderReceptor>();\n        var receptor = new CancelOrderReceptor(mockDb, logger);\n        var command = new CancelOrder(\n            OrderId: TestData ExistingOrderId,\n            Reason: \"Customer request\"\n        );\n        // Act\n        var result = await receptor HandleAsync(command);\n        // Assert\n        await Assert That(result OrderId) IsEqualTo(command OrderId);\n        await Assert That(result Reason) IsEqualTo(\"Customer request\");\n    }\n    [Test]\n    public async Task HandleAsync_NonExistentOrder_ThrowsNotFoundExceptionAsync() {\n        // Arrange\n        var mockDb = CreateMockDb();  // Returns null for non-existent order\n        var logger = new NullLogger<CancelOrderReceptor>();\n        var receptor = new CancelOrderReceptor(mockDb, logger);\n        var command = new CancelOrder(\n            OrderId: Guid NewGuid(),  // Doesn't exist\n            Reason: \"Customer request\"\n        );\n        // Act & Assert\n        await Assert That(async () => await receptor HandleAsync(command)) ThrowsException<NotFoundException>();\n    }\n}\n`\n---\nAdvanced Patterns\nPattern: Multi-Step Validation\n`csharp\npublic class ReserveInventoryReceptor : IReceptor<ReserveInventory, InventoryReserved> {\n    private readonly IDbConnectionFactory _db;\n    private readonly ILogger<ReserveInventoryReceptor> _logger;\n    public async ValueTask<InventoryReserved> HandleAsync(\n        ReserveInventory message,\n        CancellationToken ct = default) {\n        // Step 1: Validate order exists\n        var order = await ValidateOrderExistsAsync(message OrderId, ct);\n        // Step 2: Check inventory levels\n        var inventoryChecks = await CheckInventoryLevelsAsync(order Items, ct);\n        // Step 3: Validate all items in stock\n        ValidateAllItemsInStock(inventoryChecks);\n        // Step 4: Reserve inventory (business logic)\n        var reservations = await CreateReservationsAsync(\n            message OrderId,\n            inventoryChecks,\n            ct\n        );\n        // Return event\n        return new InventoryReserved(\n            OrderId: message OrderId,\n            Reservations: reservations,\n            ReservedAt: DateTimeOffset",
        "startIndex": 15699,
        "preview": "19 99) + 49 99 } [Test] public async Task HandleAsync_EmptyItems_ThrowsValidationExceptionAsync() { // Arrange var logger = new NullLogger<CreateOrder..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-8",
        "text": "2: Check inventory levels var inventoryChecks = await CheckInventoryLevelsAsync(order Items, ct); // Step 3: Validate all items in stock ValidateAllItemsInStock(inventoryChecks); // Step 4: Reserve inventory (business logic) var reservations = await CreateReservationsAsync( message OrderId, inventoryChecks, ct ); // Return event return new InventoryReserved( OrderId: message OrderId, Reservations: reservations, ReservedAt: DateTimeOffset UtcNow\n        );\n    }\n    private async Task<Order> ValidateOrderExistsAsync(Guid orderId, CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        var order = await conn QuerySingleOrDefaultAsync<Order>(\n            \"SELECT * FROM orders WHERE order_id = @OrderId\",\n            new { OrderId = orderId },\n            ct\n        );\n        if (order is null) {\n            throw new NotFoundException($\"Order {orderId} not found\");\n        }\n        return order;\n    }\n    private async Task<InventoryCheck[]> CheckInventoryLevelsAsync(\n        OrderLineItem[] items,\n        CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        var checks = new List<InventoryCheck>();\n        foreach (var item in items) {\n            var available = await conn ExecuteScalarAsync<int>(\n                \"SELECT available_quantity FROM inventory WHERE product_id = @ProductId\",\n                new { ProductId = item ProductId },\n                ct\n            );\n            checks Add(new InventoryCheck(\n                ProductId: item ProductId,\n                RequestedQuantity: item Quantity,\n                AvailableQuantity: available\n            ));\n        }\n        return checks ToArray();\n    }\n    private static void ValidateAllItemsInStock(InventoryCheck[] checks) {\n        var outOfStock = checks Where(c => c AvailableQuantity < c RequestedQuantity) ToArray();\n        if (outOfStock Length > 0) {\n            var productIds = string Join(\", \", outOfStock Select(c => c ProductId));\n            throw new InsufficientInventoryException(\n                $\"Insufficient inventory for products: {productIds}\"\n            );\n        }\n    }\n    private async Task<Reservation[]> CreateReservationsAsync(\n        Guid orderId,\n        InventoryCheck[] checks,\n        CancellationToken ct) {\n        await using var conn = _db CreateConnection();\n        var reservations = new List<Reservation>();\n        foreach (var check in checks) {\n            await conn ExecuteAsync(\n                \"UPDATE inventory SET available_quantity = available_quantity - @Quantity WHERE product_id = @ProductId\",\n                new { ProductId = check ProductId, Quantity = check RequestedQuantity },\n                ct\n            );\n            reservations Add(new Reservation(\n                ProductId: check ProductId,\n                Quantity: check RequestedQuantity\n            ));\n        }\n        return reservations",
        "startIndex": 18268,
        "preview": "2: Check inventory levels var inventoryChecks = await CheckInventoryLevelsAsync(order Items, ct); // Step 3: Validate all items in stock ValidateAllIt..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-9",
        "text": "= new List<Reservation>(); foreach (var check in checks) { await conn ExecuteAsync( \"UPDATE inventory SET available_quantity = available_quantity - @Quantity WHERE product_id = @ProductId\", new { ProductId = check ProductId, Quantity = check RequestedQuantity }, ct ); reservations Add(new Reservation( ProductId: check ProductId, Quantity: check RequestedQuantity )); } return reservations ToArray();\n    }\n}\ninternal record InventoryCheck(\n    Guid ProductId,\n    int RequestedQuantity,\n    int AvailableQuantity\n);\n`\nPattern: Saga Coordination\n`csharp\npublic class CompleteOrderReceptor : IReceptor<CompleteOrder, OrderCompleted> {\n    private readonly IDispatcher _dispatcher;\n    private readonly ILogger<CompleteOrderReceptor> _logger;\n    public async ValueTask<OrderCompleted> HandleAsync(\n        CompleteOrder message,\n        CancellationToken ct = default) {\n        // Step 1: Reserve inventory\n        var inventoryResult = await _dispatcher LocalInvokeAsync<ReserveInventory, InventoryReserved>(\n            new ReserveInventory(message OrderId),\n            ct\n        );\n        try {\n            // Step 2: Process payment\n            var paymentResult = await _dispatcher LocalInvokeAsync<ProcessPayment, PaymentResult>(\n                new ProcessPayment(message OrderId, message Amount, message PaymentMethod),\n                ct\n            );\n            if ( paymentResult IsSuccess) {\n                // Compensate: Release inventory\n                await _dispatcher LocalInvokeAsync<ReleaseInventory, InventoryReleased>(\n                    new ReleaseInventory(message OrderId),\n                    ct\n                );\n                throw new PaymentFailedException($\"Payment declined: {paymentResult ErrorCode}\");\n            }\n            // Step 3: Create shipment\n            var shipmentResult = await _dispatcher LocalInvokeAsync<CreateShipment, ShipmentCreated>(\n                new CreateShipment(message OrderId),\n                ct\n            );\n            return new OrderCompleted(\n                OrderId: message OrderId,\n                CompletedAt: DateTimeOffset UtcNow\n            );\n        } catch {\n            // Compensate: Release inventory if anything fails\n            await _dispatcher LocalInvokeAsync<ReleaseInventory, InventoryReleased>(\n                new ReleaseInventory(message OrderId),\n                ct\n            );\n            throw;\n        }\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Keep receptors stateless (no instance fields except injected dependencies)\n‚úÖ Use constructor injection for dependencies\n‚úÖ Validate early, fail fast\n‚úÖ Return events for commands (facts of what happened)\n‚úÖ Use ValueTask<T> for HandleAsync\n‚úÖ Always pass CancellationToken to async operations\n‚úÖ Log important decisions and errors\n‚úÖ Test receptors in isolation\n‚úÖ Extract complex validation into private methods\n‚úÖ Use Guid",
        "startIndex": 20750,
        "preview": "= new List<Reservation>(); foreach (var check in checks) { await conn ExecuteAsync( \"UPDATE inventory SET available_quantity = available_quantity - @Q..."
      },
      {
        "id": "v0.1.0/core-concepts/receptors-chunk-10",
        "text": "injection for dependencies ‚úÖ Validate early, fail fast ‚úÖ Return events for commands (facts of what happened) ‚úÖ Use ValueTask<T> for HandleAsync ‚úÖ Always pass CancellationToken to async operations ‚úÖ Log important decisions and errors ‚úÖ Test receptors in isolation ‚úÖ Extract complex validation into private methods ‚úÖ Use Guid CreateVersion7() for IDs (time-ordered)\nDON'T ‚ùå\n‚ùå Store state in instance fields (except injected dependencies)\n‚ùå Call other receptors directly (use Dispatcher)\n‚ùå Perform long-running operations (offload to background workers)\n‚ùå Catch and suppress exceptions without logging\n‚ùå Return null (throw exception or return error response)\n‚ùå Mix read and write logic (use separate receptors)\n‚ùå Ignore CancellationToken\n‚ùå Use Guid NewGuid() (use Guid CreateVersion7() for time-ordering)\n---\nFurther Reading\nCore Concepts:\nDispatcher - How to invoke receptors\nPerspectives - Event listeners for read models\nMessage Context - Correlation and causation tracking\nMessaging Patterns:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nTesting:\nReceptor Testing - Comprehensive testing guide\nExamples:\nECommerce: Order Service - Real-world receptor patterns\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 23232,
        "preview": "injection for dependencies ‚úÖ Validate early, fail fast ‚úÖ Return events for commands (facts of what happened) ‚úÖ Use ValueTask<T> for HandleAsync ‚úÖ Alwa..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/customization-examples/event-sourcing-cqrs",
    "title": "Event Sourcing & CQRS",
    "category": "Customization Examples",
    "url": "/docs/v0.1.0/customization-examples/event-sourcing-cqrs",
    "chunks": [
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-0",
        "text": "Event Sourcing & CQRS\nImplement full event sourcing with CQRS using Whizbang - event store, aggregate reconstruction, snapshots, temporal queries, and read model projections ---\nArchitecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Event Sourcing Architecture                               ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  WRITE SIDE (Commands)                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ  1 Load Aggregate from Event Store                  ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  2 Execute Command (domain logic)                   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  3 Generate Events                                  ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  4 Persist Events to Event Store                    ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  5 Publish Events to Bus                            ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ  Event Store (Append-Only Log)                       ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇEvent 1 ‚îÇEvent 2 ‚îÇEvent 3 ‚îÇEvent 4 ‚îÇEvent 5 ‚îÇ      ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îÇ                          ‚îÇ                                  ‚îÇ\n‚îÇ                          ‚ñº                                  ‚îÇ\n‚îÇ  READ SIDE (Queries)                                       ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ  Projections (Perspectives)                          ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - OrderSummaryProjection                            ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - CustomerActivityProjection                        ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - InventoryProjection                               ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nEvent Store Schema\nMigrations/001_CreateEventStore sql:\n`sql\nCREATE TABLE event_store (\n  event_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  stream_id UUID NOT NULL,\n  stream_type TEXT NOT NULL,\n  event_type TEXT NOT NULL,\n  event_version INTEGER NOT NULL,\n  event_data JSONB NOT NULL,\n  metadata JSONB NOT NULL DEFAULT '{}'::jsonb,\n  timestamp TIMESTAMP NOT NULL DEFAULT NOW(),\n  CONSTRAINT unique_stream_version UNIQUE (stream_id, event_version)\n);\nCREATE INDEX idx_event_store_stream_id ON event_store(stream_id);\nCREATE INDEX idx_event_store_timestamp ON event_store(timestamp DESC);\nCREATE INDEX idx_event_store_event_type ON event_store(event_type);\n-- Snapshots for performance (optional)\nCREATE TABLE event_store_snapshots (\n  snapshot_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  stream_id UUID NOT NULL UNIQUE,\n  stream_type TEXT NOT NULL,\n  version INTEGER NOT NULL,\n  state JSONB NOT NULL,\n  timestamp TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_snapshots_stream_id ON event_store_snapshots(stream_id);\n`\n---\nDomain Events\nOrderEvents",
        "startIndex": 0,
        "preview": "Event Sourcing & CQRS\nImplement full event sourcing with CQRS using Whizbang - event store, aggregate reconstruction, snapshots, temporal queries, and..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-1",
        "text": "event_store(event_type); -- Snapshots for performance (optional) CREATE TABLE event_store_snapshots ( snapshot_id UUID PRIMARY KEY DEFAULT gen_random_uuid(), stream_id UUID NOT NULL UNIQUE, stream_type TEXT NOT NULL, version INTEGER NOT NULL, state JSONB NOT NULL, timestamp TIMESTAMP NOT NULL DEFAULT NOW() ); CREATE INDEX idx_snapshots_stream_id ON event_store_snapshots(stream_id); ` --- Domain Events OrderEvents cs:\n`csharp\npublic record OrderCreatedEvent(\n  string CustomerId,\n  OrderItem[] Items,\n  decimal TotalAmount,\n  DateTime CreatedAt\n);\npublic record PaymentProcessedEvent(\n  string PaymentId,\n  decimal Amount,\n  DateTime ProcessedAt\n);\npublic record OrderShippedEvent(\n  string TrackingNumber,\n  DateTime ShippedAt\n);\npublic record OrderCancelledEvent(\n  string Reason,\n  DateTime CancelledAt\n);\n`\n---\nAggregate Root\nOrderAggregate cs:\n`csharp\npublic class OrderAggregate {\n  private readonly List<object> _uncommittedEvents = [];\n  // State\n  public Guid OrderId { get; private set; }\n  public string CustomerId { get; private set; }\n  public decimal TotalAmount { get; private set; }\n  public OrderStatus Status { get; private set; }\n  public int Version { get; private set; }\n  // Create new aggregate\n  public static OrderAggregate Create(\n    Guid orderId,\n    string customerId,\n    OrderItem[] items\n  ) {\n    var aggregate = new OrderAggregate();\n    var totalAmount = items Sum(i => i Quantity * i UnitPrice);\n    var @event = new OrderCreatedEvent(\n      CustomerId: customerId,\n      Items: items,\n      TotalAmount: totalAmount,\n      CreatedAt: DateTime UtcNow\n    );\n    aggregate Apply(@event);\n    aggregate _uncommittedEvents Add(@event);\n    return aggregate;\n  }\n  // Load from event history\n  public static OrderAggregate LoadFromHistory(IEnumerable<object> events) {\n    var aggregate = new OrderAggregate();\n    foreach (var @event in events) {\n      aggregate Apply(@event);\n      aggregate Version++;\n    }\n    return aggregate;\n  }\n  // Commands\n  public void ProcessPayment(string paymentId, decimal amount) {\n    if (Status = OrderStatus Pending) {\n      throw new InvalidOperationException($\"Cannot process payment for order in {Status} status\");\n    }\n    var @event = new PaymentProcessedEvent(\n      PaymentId: paymentId,\n      Amount: amount,\n      ProcessedAt: DateTime UtcNow\n    );\n    Apply(@event);\n    _uncommittedEvents Add(@event);\n  }\n  public void Ship(string trackingNumber) {\n    if (Status = OrderStatus",
        "startIndex": 3032,
        "preview": "event_store(event_type); -- Snapshots for performance (optional) CREATE TABLE event_store_snapshots ( snapshot_id UUID PRIMARY KEY DEFAULT gen_random_..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-2",
        "text": "public void ProcessPayment(string paymentId, decimal amount) { if (Status = OrderStatus Pending) { throw new InvalidOperationException($\"Cannot process payment for order in {Status} status\"); } var @event = new PaymentProcessedEvent( PaymentId: paymentId, Amount: amount, ProcessedAt: DateTime UtcNow ); Apply(@event); _uncommittedEvents Add(@event); } public void Ship(string trackingNumber) { if (Status = OrderStatus PaymentProcessed) {\n      throw new InvalidOperationException($\"Cannot ship order in {Status} status\");\n    }\n    var @event = new OrderShippedEvent(\n      TrackingNumber: trackingNumber,\n      ShippedAt: DateTime UtcNow\n    );\n    Apply(@event);\n    _uncommittedEvents Add(@event);\n  }\n  public void Cancel(string reason) {\n    if (Status == OrderStatus Shipped || Status == OrderStatus Delivered) {\n      throw new InvalidOperationException($\"Cannot cancel order in {Status} status\");\n    }\n    var @event = new OrderCancelledEvent(\n      Reason: reason,\n      CancelledAt: DateTime UtcNow\n    );\n    Apply(@event);\n    _uncommittedEvents Add(@event);\n  }\n  // Event application (state transitions)\n  private void Apply(OrderCreatedEvent @event) {\n    OrderId = Guid NewGuid();\n    CustomerId = @event CustomerId;\n    TotalAmount = @event TotalAmount;\n    Status = OrderStatus Pending;\n  }\n  private void Apply(PaymentProcessedEvent @event) {\n    Status = OrderStatus PaymentProcessed;\n  }\n  private void Apply(OrderShippedEvent @event) {\n    Status = OrderStatus Shipped;\n  }\n  private void Apply(OrderCancelledEvent @event) {\n    Status = OrderStatus Cancelled;\n  }\n  // Apply dynamic event\n  private void Apply(object @event) {\n    switch (@event) {\n      case OrderCreatedEvent e:\n        Apply(e);\n        break;\n      case PaymentProcessedEvent e:\n        Apply(e);\n        break;\n      case OrderShippedEvent e:\n        Apply(e);\n        break;\n      case OrderCancelledEvent e:\n        Apply(e);\n        break;\n      default:\n        throw new InvalidOperationException($\"Unknown event type: {@event GetType() Name}\");\n    }\n  }\n  // Get uncommitted events for persistence\n  public IEnumerable<object> GetUncommittedEvents() => _uncommittedEvents;\n  // Clear after persistence\n  public void MarkChangesAsCommitted() => _uncommittedEvents Clear();\n}\npublic enum OrderStatus {\n  Pending,\n  PaymentProcessed,\n  Shipped,\n  Delivered,\n  Cancelled\n}\n`\n---\nEvent Store Repository\nEventStoreRepository cs:\n`csharp\npublic class EventStoreRepository {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<EventStoreRepository> _logger;\n  public async Task<OrderAggregate > LoadAsync(\n    Guid streamId,\n    CancellationToken ct = default\n  ) {\n    // 1 Try to load from snapshot\n    var snapshot = await _db",
        "startIndex": 5083,
        "preview": "public void ProcessPayment(string paymentId, decimal amount) { if (Status = OrderStatus Pending) { throw new InvalidOperationException($\"Cannot proces..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-3",
        "text": "PaymentProcessed, Shipped, Delivered, Cancelled } ` --- Event Store Repository EventStoreRepository cs: `csharp public class EventStoreRepository { private readonly NpgsqlConnection _db; private readonly ILogger<EventStoreRepository> _logger; public async Task<OrderAggregate > LoadAsync( Guid streamId, CancellationToken ct = default ) { // 1 Try to load from snapshot var snapshot = await _db QuerySingleOrDefaultAsync<SnapshotRow>(\n      \"\"\"\n      SELECT version, state\n      FROM event_store_snapshots\n      WHERE stream_id = @StreamId\n      \"\"\",\n      new { StreamId = streamId }\n    );\n    var fromVersion = 0;\n    OrderAggregate aggregate = null;\n    if (snapshot = null) {\n      // Deserialize snapshot\n      var state = JsonSerializer Deserialize<OrderAggregateState>(snapshot State);\n      aggregate = OrderAggregate FromSnapshot(state );\n      fromVersion = snapshot Version + 1;\n      _logger LogInformation(\n        \"Loaded aggregate {StreamId} from snapshot at version {Version}\",\n        streamId,\n        snapshot Version\n      );\n    }\n    // 2 Load events after snapshot\n    var events = await _db QueryAsync<EventRow>(\n      \"\"\"\n      SELECT event_type, event_data, event_version\n      FROM event_store\n      WHERE stream_id = @StreamId AND event_version >= @FromVersion\n      ORDER BY event_version ASC\n      \"\"\",\n      new { StreamId = streamId, FromVersion = fromVersion }\n    );\n    if ( events Any() && aggregate == null) {\n      return null;  // Aggregate doesn't exist\n    }\n    // 3 Reconstruct aggregate from events\n    var domainEvents = events Select(e => DeserializeEvent(e EventType, e EventData));\n    if (aggregate == null) {\n      aggregate = OrderAggregate LoadFromHistory(domainEvents);\n    } else {\n      aggregate ApplyEvents(domainEvents);\n    }\n    _logger LogInformation(\n      \"Loaded aggregate {StreamId} with {EventCount} events\",\n      streamId,\n      events Count()\n    );\n    return aggregate;\n  }\n  public async Task SaveAsync(\n    OrderAggregate aggregate,\n    CancellationToken ct = default\n  ) {\n    var uncommittedEvents = aggregate GetUncommittedEvents() ToArray();\n    if ( uncommittedEvents Any()) {\n      return;  // No changes to persist\n    }\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      var currentVersion = aggregate Version - uncommittedEvents Length;\n      // Persist events\n      foreach (var @event in uncommittedEvents) {\n        currentVersion++;\n        await _db",
        "startIndex": 7407,
        "preview": "PaymentProcessed, Shipped, Delivered, Cancelled } ` --- Event Store Repository EventStoreRepository cs: `csharp public class EventStoreRepository { pr..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-4",
        "text": ") { var uncommittedEvents = aggregate GetUncommittedEvents() ToArray(); if ( uncommittedEvents Any()) { return; // No changes to persist } await using var tx = await _db BeginTransactionAsync(ct); try { var currentVersion = aggregate Version - uncommittedEvents Length; // Persist events foreach (var @event in uncommittedEvents) { currentVersion++; await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO event_store (stream_id, stream_type, event_type, event_version, event_data, metadata)\n          VALUES (@StreamId, @StreamType, @EventType, @EventVersion, @EventData::jsonb, @Metadata::jsonb)\n          \"\"\",\n          new {\n            StreamId = aggregate OrderId,\n            StreamType = \"Order\",\n            EventType = @event GetType() Name,\n            EventVersion = currentVersion,\n            EventData = JsonSerializer Serialize(@event),\n            Metadata = JsonSerializer Serialize(new { Timestamp = DateTime UtcNow })\n          },\n          transaction: tx\n        );\n      }\n      // Optional: Create snapshot every N events\n      if (currentVersion % 100 == 0) {\n        await SaveSnapshotAsync(aggregate, currentVersion, tx, ct);\n      }\n      await tx CommitAsync(ct);\n      aggregate MarkChangesAsCommitted();\n      _logger LogInformation(\n        \"Saved {EventCount} events for aggregate {StreamId}, version {Version}\",\n        uncommittedEvents Length,\n        aggregate OrderId,\n        currentVersion\n      );\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n  private async Task SaveSnapshotAsync(\n    OrderAggregate aggregate,\n    int version,\n    NpgsqlTransaction tx,\n    CancellationToken ct\n  ) {\n    var state = aggregate ToSnapshot();\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO event_store_snapshots (stream_id, stream_type, version, state)\n      VALUES (@StreamId, @StreamType, @Version, @State::jsonb)\n      ON CONFLICT (stream_id) DO UPDATE SET\n        version = @Version,\n        state = @State::jsonb,\n        timestamp = NOW()\n      \"\"\",\n      new {\n        StreamId = aggregate OrderId,\n        StreamType = \"Order\",\n        Version = version,\n        State = JsonSerializer Serialize(state)\n      },\n      transaction: tx\n    );\n    _logger LogInformation(\n      \"Created snapshot for aggregate {StreamId} at version {Version}\",\n      aggregate OrderId,\n      version\n    );\n  }\n  private object DeserializeEvent(string eventType, string eventData) {\n    var type = Type GetType($\"YourNamespace {eventType}\") throw new InvalidOperationException($\"Unknown event type: {eventType}\");\n    return JsonSerializer Deserialize(eventData, type) ;\n  }\n}\npublic record EventRow(string EventType, string EventData, int EventVersion);\npublic record SnapshotRow(int Version, string State);\n`\n---\nCommand Handler (Receptor)\nCreateOrderReceptor",
        "startIndex": 9481,
        "preview": ") { var uncommittedEvents = aggregate GetUncommittedEvents() ToArray(); if ( uncommittedEvents Any()) { return; // No changes to persist } await using..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-5",
        "text": "OrderId, version ); } private object DeserializeEvent(string eventType, string eventData) { var type = Type GetType($\"YourNamespace {eventType}\") throw new InvalidOperationException($\"Unknown event type: {eventType}\"); return JsonSerializer Deserialize(eventData, type) ; } } public record EventRow(string EventType, string EventData, int EventVersion); public record SnapshotRow(int Version, string State); ` --- Command Handler (Receptor) CreateOrderReceptor cs:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly EventStoreRepository _eventStore;\n  private readonly IMessageBus _bus;\n  private readonly ILogger<CreateOrderReceptor> _logger;\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    // 1 Create aggregate\n    var aggregate = OrderAggregate Create(\n      orderId: Guid NewGuid(),\n      customerId: command CustomerId,\n      items: command Items\n    );\n    // 2 Save to event store\n    await _eventStore SaveAsync(aggregate, ct);\n    // 3 Publish events to bus\n    foreach (var @event in aggregate GetUncommittedEvents()) {\n      await _bus PublishAsync(@event, ct);\n    }\n    _logger LogInformation(\n      \"Order {OrderId} created for customer {CustomerId}\",\n      aggregate OrderId,\n      command CustomerId\n    );\n    return new OrderCreated(\n      OrderId: aggregate OrderId ToString(),\n      CustomerId: command CustomerId,\n      Items: command Items,\n      TotalAmount: aggregate TotalAmount,\n      CreatedAt: DateTime UtcNow\n    );\n  }\n}\n`\n---\nTemporal Queries\nGet aggregate state at specific point in time:\n`csharp\npublic class EventStoreQueryService {\n  private readonly NpgsqlConnection _db;\n  public async Task<OrderAggregate > LoadAsOfAsync(\n    Guid streamId,\n    DateTime asOf,\n    CancellationToken ct = default\n  ) {\n    // Load events up to specified timestamp\n    var events = await _db QueryAsync<EventRow>(\n      \"\"\"\n      SELECT event_type, event_data\n      FROM event_store\n      WHERE stream_id = @StreamId AND timestamp <= @AsOf\n      ORDER BY event_version ASC\n      \"\"\",\n      new { StreamId = streamId, AsOf = asOf }\n    );\n    if ( events Any()) {\n      return null;\n    }\n    var domainEvents = events Select(e => DeserializeEvent(e EventType, e EventData));\n    return OrderAggregate LoadFromHistory(domainEvents);\n  }\n}\n`\nUsage:\n`csharp\n// Get order state as of yesterday\nvar orderYesterday = await queryService LoadAsOfAsync(\n  orderId,\n  asOf: DateTime UtcNow AddDays(-1)\n);\nConsole WriteLine($\"Order status yesterday: {orderYesterday Status}\");\n`\n---\nProjections (Read Models)\nOrderSummaryProjection",
        "startIndex": 11944,
        "preview": "OrderId, version ); } private object DeserializeEvent(string eventType, string eventData) { var type = Type GetType($\"YourNamespace {eventType}\") thro..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-6",
        "text": "} var domainEvents = events Select(e => DeserializeEvent(e EventType, e EventData)); return OrderAggregate LoadFromHistory(domainEvents); } } ` Usage: `csharp // Get order state as of yesterday var orderYesterday = await queryService LoadAsOfAsync( orderId, asOf: DateTime UtcNow AddDays(-1) ); Console WriteLine($\"Order status yesterday: {orderYesterday Status}\"); ` --- Projections (Read Models) OrderSummaryProjection cs:\n`csharp\npublic class OrderSummaryProjection :\n  IPerspectiveOf<OrderCreatedEvent>,\n  IPerspectiveOf<PaymentProcessedEvent>,\n  IPerspectiveOf<OrderShippedEvent> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<OrderSummaryProjection> _logger;\n  public async Task HandleAsync(\n    OrderCreatedEvent @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO order_summary (order_id, customer_id, total_amount, status, created_at)\n      VALUES (@OrderId, @CustomerId, @TotalAmount, 'Pending', @CreatedAt)\n      \"\"\",\n      new {\n        OrderId = Guid NewGuid(),  // From event metadata\n        CustomerId = @event CustomerId,\n        TotalAmount = @event TotalAmount,\n        CreatedAt = @event CreatedAt\n      }\n    );\n  }\n  public async Task HandleAsync(\n    PaymentProcessedEvent @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE order_summary\n      SET status = 'PaymentProcessed', payment_processed_at = @ProcessedAt\n      WHERE order_id = @OrderId\n      \"\"\",\n      new {\n        OrderId = Guid NewGuid(),  // From event metadata\n        ProcessedAt = @event ProcessedAt\n      }\n    );\n  }\n  public async Task HandleAsync(\n    OrderShippedEvent @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE order_summary\n      SET status = 'Shipped', shipped_at = @ShippedAt, tracking_number = @TrackingNumber\n      WHERE order_id = @OrderId\n      \"\"\",\n      new {\n        OrderId = Guid NewGuid(),  // From event metadata\n        ShippedAt = @event ShippedAt,\n        TrackingNumber = @event TrackingNumber\n      }\n    );\n  }\n}\n`\n---\nRebuilding Projections\nRebuild all projections from event store:\n`csharp\npublic class ProjectionRebuilder {\n  private readonly EventStoreRepository _eventStore;\n  private readonly OrderSummaryProjection _projection;\n  private readonly ILogger<ProjectionRebuilder> _logger;\n  public async Task RebuildOrderSummaryAsync(CancellationToken ct = default) {\n    _logger LogInformation(\"Starting projection rebuild \");\n    // 1 Truncate read model\n    await _db ExecuteAsync(\"TRUNCATE TABLE order_summary\");\n    // 2 Replay all events\n    var events = await _db",
        "startIndex": 14147,
        "preview": "} var domainEvents = events Select(e => DeserializeEvent(e EventType, e EventData)); return OrderAggregate LoadFromHistory(domainEvents); } } ` Usage:..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-7",
        "text": "`csharp public class ProjectionRebuilder { private readonly EventStoreRepository _eventStore; private readonly OrderSummaryProjection _projection; private readonly ILogger<ProjectionRebuilder> _logger; public async Task RebuildOrderSummaryAsync(CancellationToken ct = default) { _logger LogInformation(\"Starting projection rebuild \"); // 1 Truncate read model await _db ExecuteAsync(\"TRUNCATE TABLE order_summary\"); // 2 Replay all events var events = await _db QueryAsync<EventRow>(\n      \"\"\"\n      SELECT stream_id, event_type, event_data\n      FROM event_store\n      WHERE stream_type = 'Order'\n      ORDER BY event_version ASC\n      \"\"\"\n    );\n    var count = 0;\n    foreach (var eventRow in events) {\n      var @event = DeserializeEvent(eventRow EventType, eventRow EventData);\n      // Apply event to projection\n      await ApplyToProjectionAsync(@event, ct);\n      count++;\n      if (count % 1000 == 0) {\n        _logger LogInformation(\"Processed {Count} events \", count);\n      }\n    }\n    _logger LogInformation(\"Projection rebuild complete {Count} events processed \", count);\n  }\n  private async Task ApplyToProjectionAsync(object @event, CancellationToken ct) {\n    switch (@event) {\n      case OrderCreatedEvent e:\n        await _projection HandleAsync(e, ct);\n        break;\n      case PaymentProcessedEvent e:\n        await _projection HandleAsync(e, ct);\n        break;\n      case OrderShippedEvent e:\n        await _projection HandleAsync(e, ct);\n        break;\n    }\n  }\n}\n`\n---\nKey Takeaways\n‚úÖ Event Store - Append-only log of all domain events\n‚úÖ Aggregate Reconstruction - Rebuild state from event history\n‚úÖ Snapshots - Performance optimization for large event streams\n‚úÖ Temporal Queries - Query state at any point in time\n‚úÖ Projections - Event-driven read models (CQRS)\n‚úÖ Projection Rebuilding - Replay events to rebuild read models\n---\nPerformance Optimizations\nSnapshots\nCreate snapshots every 100 events to avoid replaying thousands of events Caching\nCache frequently accessed aggregates in memory:\n`csharp\npublic class CachedEventStoreRepository {\n  private readonly EventStoreRepository _inner;\n  private readonly IMemoryCache _cache;\n  public async Task<OrderAggregate > LoadAsync(Guid streamId, CancellationToken ct) {\n    if (_cache TryGetValue(streamId, out OrderAggregate cached)) {\n      return cached;\n    }\n    var aggregate = await _inner LoadAsync(streamId, ct);\n    if (aggregate = null) {\n      _cache Set(streamId, aggregate, TimeSpan FromMinutes(5));\n    }\n    return aggregate;\n  }\n}\n`\n---\nVersion 0 1",
        "startIndex": 16402,
        "preview": "`csharp public class ProjectionRebuilder { private readonly EventStoreRepository _eventStore; private readonly OrderSummaryProjection _projection; pri..."
      },
      {
        "id": "v0.1.0/customization-examples/event-sourcing-cqrs-chunk-8",
        "text": "private readonly IMemoryCache _cache; public async Task<OrderAggregate > LoadAsync(Guid streamId, CancellationToken ct) { if (_cache TryGetValue(streamId, out OrderAggregate cached)) { return cached; } var aggregate = await _inner LoadAsync(streamId, ct); if (aggregate = null) { _cache Set(streamId, aggregate, TimeSpan FromMinutes(5)); } return aggregate; } } ` --- Version 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 18488,
        "preview": "private readonly IMemoryCache _cache; public async Task<OrderAggregate > LoadAsync(Guid streamId, CancellationToken ct) { if (_cache TryGetValue(strea..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/customization-examples/microservices-orchestration",
    "title": "Microservices Orchestration",
    "category": "Customization Examples",
    "url": "/docs/v0.1.0/customization-examples/microservices-orchestration",
    "chunks": [
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-0",
        "text": "Microservices Orchestration\nImplement saga orchestration patterns with Whizbang for distributed workflows, compensation handling, and complex multi-service coordination ---\nOrchestration vs Choreography\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Choreography (Decentralized)                              ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  OrderService ‚Üí OrderCreated ‚Üí InventoryService            ‚îÇ\n‚îÇ                                      ‚Üì                      ‚îÇ\n‚îÇ                            InventoryReserved                ‚îÇ\n‚îÇ                                      ‚Üì                      ‚îÇ\n‚îÇ                              PaymentService                 ‚îÇ\n‚îÇ                                      ‚Üì                      ‚îÇ\n‚îÇ                             PaymentProcessed                ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  ‚ùå No central coordinator                                 ‚îÇ\n‚îÇ  ‚ùå Hard to track overall state                            ‚îÇ\n‚îÇ  ‚úÖ Loose coupling                                         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Orchestration (Centralized)                               ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ\n‚îÇ           ‚îÇ OrderSaga            ‚îÇ                         ‚îÇ\n‚îÇ           ‚îÇ (Process Manager)    ‚îÇ                         ‚îÇ\n‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ\n‚îÇ                      ‚îÇ                                      ‚îÇ\n‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ\n‚îÇ         ‚îÇ            ‚îÇ            ‚îÇ                        ‚îÇ\n‚îÇ         ‚ñº            ‚ñº            ‚ñº                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ  ‚îÇInventory ‚îÇ  ‚îÇ Payment  ‚îÇ  ‚îÇ Shipping ‚îÇ                ‚îÇ\n‚îÇ  ‚îÇ Service  ‚îÇ  ‚îÇ Service  ‚îÇ  ‚îÇ Service  ‚îÇ                ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  ‚úÖ Central coordinator                                    ‚îÇ\n‚îÇ  ‚úÖ Easy to track state                                    ‚îÇ\n‚îÇ  ‚úÖ Complex workflows                                      ‚îÇ\n‚îÇ  ‚ùå Tighter coupling                                       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nSaga State Machine\nOrderSagaState cs:\n`csharp\npublic record OrderSagaState {\n  public required string SagaId { get; init; }\n  public required string OrderId { get; init; }\n  public required SagaStatus Status { get; init; }\n  public required SagaStep CurrentStep { get; init; }\n  public string PaymentId { get; init; }\n  public string ShipmentId { get; init; }\n  public string ErrorMessage { get; init; }\n  public DateTime CreatedAt { get; init; }\n  public DateTime UpdatedAt { get; init; }\n  public Dictionary<string, string> Metadata { get; init; } = new();\n}\npublic enum SagaStatus {\n  Started,\n  InProgress,\n  Completed,\n  Compensating,\n  Compensated,\n  Failed\n}\npublic enum SagaStep {\n  OrderCreated,\n  InventoryReserving,\n  InventoryReserved,\n  PaymentProcessing,\n  PaymentProcessed,\n  ShipmentCreating,\n  ShipmentCreated,\n  OrderCompleted\n}\n`\n---\nSaga Orchestrator\nOrderSagaOrchestrator",
        "startIndex": 0,
        "preview": "Microservices Orchestration\nImplement saga orchestration patterns with Whizbang for distributed workflows, compensation handling, and complex multi-se..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-1",
        "text": "get; init; } public DateTime UpdatedAt { get; init; } public Dictionary<string, string> Metadata { get; init; } = new(); } public enum SagaStatus { Started, InProgress, Completed, Compensating, Compensated, Failed } public enum SagaStep { OrderCreated, InventoryReserving, InventoryReserved, PaymentProcessing, PaymentProcessed, ShipmentCreating, ShipmentCreated, OrderCompleted } ` --- Saga Orchestrator OrderSagaOrchestrator cs:\n`csharp\npublic class OrderSagaOrchestrator :\n  IPerspectiveOf<OrderCreated>,\n  IPerspectiveOf<InventoryReserved>,\n  IPerspectiveOf<InventoryInsufficient>,\n  IPerspectiveOf<PaymentProcessed>,\n  IPerspectiveOf<PaymentFailed>,\n  IPerspectiveOf<ShipmentCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly IMessageBus _bus;\n  private readonly ILogger<OrderSagaOrchestrator> _logger;\n  // Handle OrderCreated - Start saga\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    var sagaId = Guid NewGuid() ToString(\"N\");\n    // 1 Create saga state\n    var state = new OrderSagaState {\n      SagaId = sagaId,\n      OrderId = @event OrderId,\n      Status = SagaStatus InProgress,\n      CurrentStep = SagaStep InventoryReserving,\n      CreatedAt = DateTime UtcNow,\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    // 2 Send first command\n    var reserveInventoryCommand = new ReserveInventory(\n      OrderId: @event OrderId,\n      Items: @event Items\n    );\n    await _bus SendCommandAsync(reserveInventoryCommand, ct);\n    _logger LogInformation(\n      \"Order saga {SagaId} started for order {OrderId}\",\n      sagaId,\n      @event OrderId\n    );\n  }\n  // Handle InventoryReserved - Continue saga\n  public async Task HandleAsync(\n    InventoryReserved @event,\n    CancellationToken ct = default\n  ) {\n    var state = await LoadSagaStateByOrderIdAsync(@event OrderId, ct);\n    if (state == null) {\n      _logger LogWarning(\"Saga not found for order {OrderId}\", @event OrderId);\n      return;\n    }\n    // Update state\n    state = state with {\n      CurrentStep = SagaStep PaymentProcessing,\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    // Send next command\n    var processPaymentCommand = new ProcessPayment(\n      OrderId: @event OrderId,\n      Amount: @event TotalAmount\n    );\n    await _bus SendCommandAsync(processPaymentCommand, ct);\n    _logger LogInformation(\n      \"Saga {SagaId}: Inventory reserved, processing payment\",\n      state SagaId\n    );\n  }\n  // Handle InventoryInsufficient - Compensate\n  public async Task HandleAsync(\n    InventoryInsufficient @event,\n    CancellationToken ct = default\n  ) {\n    var state = await LoadSagaStateByOrderIdAsync(@event",
        "startIndex": 3373,
        "preview": "get; init; } public DateTime UpdatedAt { get; init; } public Dictionary<string, string> Metadata { get; init; } = new(); } public enum SagaStatus { St..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-2",
        "text": "var processPaymentCommand = new ProcessPayment( OrderId: @event OrderId, Amount: @event TotalAmount ); await _bus SendCommandAsync(processPaymentCommand, ct); _logger LogInformation( \"Saga {SagaId}: Inventory reserved, processing payment\", state SagaId ); } // Handle InventoryInsufficient - Compensate public async Task HandleAsync( InventoryInsufficient @event, CancellationToken ct = default ) { var state = await LoadSagaStateByOrderIdAsync(@event OrderId, ct);\n    if (state == null) return;\n    // Update state to compensating\n    state = state with {\n      Status = SagaStatus Compensating,\n      CurrentStep = SagaStep OrderCreated,\n      ErrorMessage = $\"Insufficient inventory for product {@event ProductId}\",\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    // Send compensation command\n    var cancelOrderCommand = new CancelOrder(\n      OrderId: @event OrderId,\n      Reason: \"Insufficient inventory\"\n    );\n    await _bus SendCommandAsync(cancelOrderCommand, ct);\n    _logger LogWarning(\n      \"Saga {SagaId}: Insufficient inventory, compensating\",\n      state SagaId\n    );\n  }\n  // Handle PaymentProcessed - Continue saga\n  public async Task HandleAsync(\n    PaymentProcessed @event,\n    CancellationToken ct = default\n  ) {\n    var state = await LoadSagaStateByOrderIdAsync(@event OrderId, ct);\n    if (state == null) return;\n    // Update state\n    state = state with {\n      CurrentStep = SagaStep ShipmentCreating,\n      PaymentId = @event PaymentId,\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    // Send next command\n    var createShipmentCommand = new CreateShipment(\n      OrderId: @event OrderId,\n      PaymentId: @event PaymentId\n    );\n    await _bus SendCommandAsync(createShipmentCommand, ct);\n    _logger LogInformation(\n      \"Saga {SagaId}: Payment processed, creating shipment\",\n      state SagaId\n    );\n  }\n  // Handle PaymentFailed - Compensate\n  public async Task HandleAsync(\n    PaymentFailed @event,\n    CancellationToken ct = default\n  ) {\n    var state = await LoadSagaStateByOrderIdAsync(@event OrderId, ct);\n    if (state == null) return;\n    // Update state to compensating\n    state = state with {\n      Status = SagaStatus Compensating,\n      CurrentStep = SagaStep InventoryReserved,\n      ErrorMessage = @event Reason,\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    // Send compensation command\n    var releaseInventoryCommand = new ReleaseInventory(\n      OrderId: @event OrderId\n    );\n    await _bus SendCommandAsync(releaseInventoryCommand, ct);\n    _logger LogWarning(\n      \"Saga {SagaId}: Payment failed, releasing inventory\",\n      state",
        "startIndex": 5686,
        "preview": "var processPaymentCommand = new ProcessPayment( OrderId: @event OrderId, Amount: @event TotalAmount ); await _bus SendCommandAsync(processPaymentComma..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-3",
        "text": "= state with { Status = SagaStatus Compensating, CurrentStep = SagaStep InventoryReserved, ErrorMessage = @event Reason, UpdatedAt = DateTime UtcNow }; await SaveSagaStateAsync(state, ct); // Send compensation command var releaseInventoryCommand = new ReleaseInventory( OrderId: @event OrderId ); await _bus SendCommandAsync(releaseInventoryCommand, ct); _logger LogWarning( \"Saga {SagaId}: Payment failed, releasing inventory\", state SagaId\n    );\n  }\n  // Handle ShipmentCreated - Complete saga\n  public async Task HandleAsync(\n    ShipmentCreated @event,\n    CancellationToken ct = default\n  ) {\n    var state = await LoadSagaStateByOrderIdAsync(@event OrderId, ct);\n    if (state == null) return;\n    // Update state to completed\n    state = state with {\n      Status = SagaStatus Completed,\n      CurrentStep = SagaStep OrderCompleted,\n      ShipmentId = @event ShipmentId,\n      UpdatedAt = DateTime UtcNow\n    };\n    await SaveSagaStateAsync(state, ct);\n    _logger LogInformation(\n      \"Saga {SagaId}: Order completed successfully\",\n      state SagaId\n    );\n  }\n  private async Task SaveSagaStateAsync(\n    OrderSagaState state,\n    CancellationToken ct\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO saga_state (\n        saga_id, order_id, status, current_step, payment_id, shipment_id, error_message, created_at, updated_at, metadata\n      )\n      VALUES (@SagaId, @OrderId, @Status, @CurrentStep, @PaymentId, @ShipmentId, @ErrorMessage, @CreatedAt, @UpdatedAt, @Metadata::jsonb)\n      ON CONFLICT (saga_id) DO UPDATE SET\n        status = @Status,\n        current_step = @CurrentStep,\n        payment_id = @PaymentId,\n        shipment_id = @ShipmentId,\n        error_message = @ErrorMessage,\n        updated_at = @UpdatedAt\n      \"\"\",\n      new {\n        state SagaId,\n        state OrderId,\n        Status = state Status ToString(),\n        CurrentStep = state CurrentStep ToString(),\n        state PaymentId,\n        state ShipmentId,\n        state ErrorMessage,\n        state CreatedAt,\n        state UpdatedAt,\n        Metadata = JsonSerializer Serialize(state Metadata)\n      }\n    );\n  }\n  private async Task<OrderSagaState > LoadSagaStateByOrderIdAsync(\n    string orderId,\n    CancellationToken ct\n  ) {\n    return await _db QuerySingleOrDefaultAsync<OrderSagaState>(\n      \"\"\"\n      SELECT saga_id, order_id, status, current_step, payment_id, shipment_id, error_message, created_at, updated_at\n      FROM saga_state\n      WHERE order_id = @OrderId\n      \"\"\",\n      new { OrderId = orderId }\n    );\n  }\n}\n`\n---\nSaga Database Schema\nMigrations/001_CreateSagaTables",
        "startIndex": 7944,
        "preview": "= state with { Status = SagaStatus Compensating, CurrentStep = SagaStep InventoryReserved, ErrorMessage = @event Reason, UpdatedAt = DateTime UtcNow }..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-4",
        "text": "); } private async Task<OrderSagaState > LoadSagaStateByOrderIdAsync( string orderId, CancellationToken ct ) { return await _db QuerySingleOrDefaultAsync<OrderSagaState>( \"\"\" SELECT saga_id, order_id, status, current_step, payment_id, shipment_id, error_message, created_at, updated_at FROM saga_state WHERE order_id = @OrderId \"\"\", new { OrderId = orderId } ); } } ` --- Saga Database Schema Migrations/001_CreateSagaTables sql:\n`sql\nCREATE TABLE saga_state (\n  saga_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL UNIQUE,\n  status TEXT NOT NULL,\n  current_step TEXT NOT NULL,\n  payment_id TEXT,\n  shipment_id TEXT,\n  error_message TEXT,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  metadata JSONB NOT NULL DEFAULT '{}'::jsonb\n);\nCREATE INDEX idx_saga_state_order_id ON saga_state(order_id);\nCREATE INDEX idx_saga_state_status ON saga_state(status);\nCREATE INDEX idx_saga_state_created_at ON saga_state(created_at DESC);\n`\n---\nTimeout Handling\nSaga timeouts for hung processes:\nSagaTimeoutMonitor cs:\n`csharp\npublic class SagaTimeoutMonitor : BackgroundService {\n  private readonly NpgsqlConnection _db;\n  private readonly IMessageBus _bus;\n  private readonly ILogger<SagaTimeoutMonitor> _logger;\n  protected override async Task ExecuteAsync(CancellationToken stoppingToken) {\n    while ( stoppingToken IsCancellationRequested) {\n      try {\n        // Find sagas stuck in progress for > 10 minutes\n        var stuckSagas = await _db QueryAsync<OrderSagaState>(\n          \"\"\"\n          SELECT saga_id, order_id, status, current_step, updated_at\n          FROM saga_state\n          WHERE status = 'InProgress'\n            AND updated_at < NOW() - INTERVAL '10 minutes'\n          \"\"\"\n        );\n        foreach (var saga in stuckSagas) {\n          _logger LogWarning(\n            \"Saga {SagaId} timed out at step {CurrentStep}, compensating\",\n            saga SagaId,\n            saga CurrentStep\n          );\n          // Trigger compensation\n          await CompensateSagaAsync(saga, stoppingToken);\n        }\n        await Task Delay(TimeSpan FromMinutes(1), stoppingToken);\n      } catch (Exception ex) when (ex is not OperationCanceledException) {\n        _logger LogError(ex, \"Error in saga timeout monitor\");\n        await Task Delay(TimeSpan FromSeconds(30), stoppingToken);\n      }\n    }\n  }\n  private async Task CompensateSagaAsync(\n    OrderSagaState saga,\n    CancellationToken ct\n  ) {\n    // Send compensation commands based on current step\n    switch (saga CurrentStep) {\n      case SagaStep PaymentProcessing:\n        // Release inventory\n        await _bus SendCommandAsync(\n          new ReleaseInventory(saga OrderId),\n          ct\n        );\n        break;\n      case SagaStep",
        "startIndex": 10108,
        "preview": "); } private async Task<OrderSagaState > LoadSagaStateByOrderIdAsync( string orderId, CancellationToken ct ) { return await _db QuerySingleOrDefaultAs..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-5",
        "text": "saga timeout monitor\"); await Task Delay(TimeSpan FromSeconds(30), stoppingToken); } } } private async Task CompensateSagaAsync( OrderSagaState saga, CancellationToken ct ) { // Send compensation commands based on current step switch (saga CurrentStep) { case SagaStep PaymentProcessing: // Release inventory await _bus SendCommandAsync( new ReleaseInventory(saga OrderId), ct ); break; case SagaStep ShipmentCreating:\n        // Refund payment and release inventory\n        await _bus SendCommandAsync(\n          new RefundPayment(saga OrderId, saga PaymentId ),\n          ct\n        );\n        await _bus SendCommandAsync(\n          new ReleaseInventory(saga OrderId),\n          ct\n        );\n        break;\n    }\n    // Update saga to compensating\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE saga_state\n      SET status = 'Compensating', error_message = 'Timeout', updated_at = NOW()\n      WHERE saga_id = @SagaId\n      \"\"\",\n      new { SagaId = saga SagaId }\n    );\n  }\n}\n`\n---\nSaga Visualization API\nSagasController cs:\n`csharp\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class SagasController : ControllerBase {\n  private readonly NpgsqlConnection _db;\n  [HttpGet(\"{sagaId}\")]\n  public async Task<IActionResult> GetSaga(string sagaId) {\n    var saga = await _db QuerySingleOrDefaultAsync<OrderSagaState>(\n      \"SELECT * FROM saga_state WHERE saga_id = @SagaId\",\n      new { SagaId = sagaId }\n    );\n    if (saga == null) {\n      return NotFound();\n    }\n    return Ok(new {\n      saga SagaId,\n      saga OrderId,\n      saga Status,\n      saga CurrentStep,\n      saga PaymentId,\n      saga ShipmentId,\n      saga ErrorMessage,\n      saga CreatedAt,\n      saga UpdatedAt,\n      Steps = GetSagaSteps(saga)\n    });\n  }\n  private object[] GetSagaSteps(OrderSagaState saga) {\n    var steps = new[] {\n      new { Step = \"OrderCreated\", Status = \"Completed\", Timestamp = saga CreatedAt },\n      new { Step = \"InventoryReserving\", Status = GetStepStatus(saga, SagaStep InventoryReserving), Timestamp = (DateTime )null },\n      new { Step = \"InventoryReserved\", Status = GetStepStatus(saga, SagaStep InventoryReserved), Timestamp = (DateTime )null },\n      new { Step = \"PaymentProcessing\", Status = GetStepStatus(saga, SagaStep PaymentProcessing), Timestamp = (DateTime )null },\n      new { Step = \"PaymentProcessed\", Status = GetStepStatus(saga, SagaStep PaymentProcessed), Timestamp = (DateTime )null },\n      new { Step = \"ShipmentCreating\", Status = GetStepStatus(saga, SagaStep ShipmentCreating), Timestamp = (DateTime",
        "startIndex": 12428,
        "preview": "saga timeout monitor\"); await Task Delay(TimeSpan FromSeconds(30), stoppingToken); } } } private async Task CompensateSagaAsync( OrderSagaState saga, ..."
      },
      {
        "id": "v0.1.0/customization-examples/microservices-orchestration-chunk-6",
        "text": "SagaStep InventoryReserved), Timestamp = (DateTime )null }, new { Step = \"PaymentProcessing\", Status = GetStepStatus(saga, SagaStep PaymentProcessing), Timestamp = (DateTime )null }, new { Step = \"PaymentProcessed\", Status = GetStepStatus(saga, SagaStep PaymentProcessed), Timestamp = (DateTime )null }, new { Step = \"ShipmentCreating\", Status = GetStepStatus(saga, SagaStep ShipmentCreating), Timestamp = (DateTime )null },\n      new { Step = \"ShipmentCreated\", Status = GetStepStatus(saga, SagaStep ShipmentCreated), Timestamp = (DateTime )null }\n    };\n    return steps;\n  }\n  private string GetStepStatus(OrderSagaState saga, SagaStep step) {\n    if (saga CurrentStep == step) return \"InProgress\";\n    if ((int)saga CurrentStep > (int)step) return \"Completed\";\n    return \"Pending\";\n  }\n}\n`\nResponse:\n`json\n{\n  \"sagaId\": \"abc123\",\n  \"orderId\": \"order-456\",\n  \"status\": \"InProgress\",\n  \"currentStep\": \"PaymentProcessing\",\n  \"steps\": [\n    { \"step\": \"OrderCreated\", \"status\": \"Completed\", \"timestamp\": \"2024-12-12T10:00:00Z\" },\n    { \"step\": \"InventoryReserving\", \"status\": \"Completed\", \"timestamp\": \"2024-12-12T10:01:00Z\" },\n    { \"step\": \"InventoryReserved\", \"status\": \"Completed\", \"timestamp\": \"2024-12-12T10:02:00Z\" },\n    { \"step\": \"PaymentProcessing\", \"status\": \"InProgress\", \"timestamp\": null },\n    { \"step\": \"PaymentProcessed\", \"status\": \"Pending\", \"timestamp\": null },\n    { \"step\": \"ShipmentCreating\", \"status\": \"Pending\", \"timestamp\": null },\n    { \"step\": \"ShipmentCreated\", \"status\": \"Pending\", \"timestamp\": null }\n  ]\n}\n`\n---\nKey Takeaways\n‚úÖ Centralized Coordination - Saga orchestrator manages workflow\n‚úÖ State Tracking - Saga state persisted at each step\n‚úÖ Compensation - Automatic rollback on failures\n‚úÖ Timeout Handling - Monitor and compensate hung sagas\n‚úÖ Visualization - API for tracking saga progress\n---\nWhen to Use Orchestration\n| Scenario | Orchestration | Choreography |\n|----------|--------------|--------------|\n| Simple workflows | ‚ùå Overkill | ‚úÖ Recommended |\n| Complex workflows | ‚úÖ Recommended | ‚ùå Hard to track |\n| Long-running processes | ‚úÖ Recommended | ‚ùå No visibility |\n| High failure rates | ‚úÖ Better control | ‚ùå Hard to compensate |\n| Loose coupling | ‚ùå Tighter coupling | ‚úÖ Decoupled |\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 14563,
        "preview": "SagaStep InventoryReserved), Timestamp = (DateTime )null }, new { Step = \"PaymentProcessing\", Status = GetStepStatus(saga, SagaStep PaymentProcessing)..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/customization-examples/multi-tenant-saas",
    "title": "Multi-Tenant SaaS",
    "category": "Customization Examples",
    "url": "/docs/v0.1.0/customization-examples/multi-tenant-saas",
    "chunks": [
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-0",
        "text": "Multi-Tenant SaaS\nBuild multi-tenant SaaS applications with Whizbang featuring tenant isolation, per-tenant databases, cross-tenant analytics, and tenant-specific customizations ---\nArchitecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Multi-Tenant SaaS Architecture                            ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                          ‚îÇ\n‚îÇ  ‚îÇ  HTTP Request‚îÇ  X-Tenant-Id: tenant-a                   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                          ‚îÇ\n‚îÇ         ‚îÇ                                                   ‚îÇ\n‚îÇ         ‚ñº                                                   ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ\n‚îÇ  ‚îÇ  Tenant Identification     ‚îÇ                            ‚îÇ\n‚îÇ  ‚îÇ  Middleware                ‚îÇ                            ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ\n‚îÇ         ‚îÇ                                                   ‚îÇ\n‚îÇ         ‚ñº                                                   ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ\n‚îÇ  ‚îÇ  Tenant-Aware Dispatcher   ‚îÇ                            ‚îÇ\n‚îÇ  ‚îÇ  (Routes to tenant DB)     ‚îÇ                            ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ\n‚îÇ         ‚îÇ                                                   ‚îÇ\n‚îÇ         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n‚îÇ         ‚ñº              ‚ñº              ‚ñº             ‚ñº      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ Tenant A ‚îÇ  ‚îÇ Tenant B ‚îÇ  ‚îÇ Tenant C ‚îÇ  ‚îÇ Shared   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ    DB    ‚îÇ  ‚îÇ    DB    ‚îÇ  ‚îÇ    DB    ‚îÇ  ‚îÇ    DB    ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey features:\n‚úÖ Database per tenant (strongest isolation)\n‚úÖ Tenant context propagation\n‚úÖ Cross-tenant analytics\n‚úÖ Tenant-specific customizations\n‚úÖ Tenant onboarding automation\n---\nTenant Identification\nTenant Context\nTenantContext cs:\n`csharp\npublic class TenantContext {\n  private static readonly AsyncLocal<string > _tenantId = new();\n  public static string CurrentTenantId {\n    get => _tenantId Value;\n    set => _tenantId Value = value;\n  }\n  public static void Set(string tenantId) {\n    if (string IsNullOrWhiteSpace(tenantId)) {\n      throw new ArgumentException(\"Tenant ID cannot be null or empty\", nameof(tenantId));\n    }\n    _tenantId Value = tenantId;\n  }\n  public static void Clear() {\n    _tenantId Value = null;\n  }\n}\n`\nTenant Middleware\nTenantIdentificationMiddleware cs:\n`csharp\npublic class TenantIdentificationMiddleware {\n  private readonly RequestDelegate _next;\n  private readonly ILogger<TenantIdentificationMiddleware> _logger;\n  public TenantIdentificationMiddleware(\n    RequestDelegate next,\n    ILogger<TenantIdentificationMiddleware> logger\n  ) {\n    _next = next;\n    _logger = logger;\n  }\n  public async Task InvokeAsync(HttpContext context) {\n    // 1 Extract tenant ID from header\n    var tenantId = context Request Headers[\"X-Tenant-Id\"] FirstOrDefault();\n    // 2",
        "startIndex": 0,
        "preview": "Multi-Tenant SaaS\nBuild multi-tenant SaaS applications with Whizbang featuring tenant isolation, per-tenant databases, cross-tenant analytics, and ten..."
      },
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-1",
        "text": "`csharp public class TenantIdentificationMiddleware { private readonly RequestDelegate _next; private readonly ILogger<TenantIdentificationMiddleware> _logger; public TenantIdentificationMiddleware( RequestDelegate next, ILogger<TenantIdentificationMiddleware> logger ) { _next = next; _logger = logger; } public async Task InvokeAsync(HttpContext context) { // 1 Extract tenant ID from header var tenantId = context Request Headers[\"X-Tenant-Id\"] FirstOrDefault(); // 2 Fallback: Extract from subdomain (e g , tenant-a example com)\n    if (string IsNullOrWhiteSpace(tenantId)) {\n      var host = context Request Host Host;\n      var parts = host Split(' ');\n      if (parts Length > 2) {\n        tenantId = parts[0];\n      }\n    }\n    // 3 Fallback: Extract from JWT claim\n    if (string IsNullOrWhiteSpace(tenantId)) {\n      tenantId = context User FindFirst(\"tenant_id\") Value;\n    }\n    if (string IsNullOrWhiteSpace(tenantId)) {\n      context Response StatusCode = 400;\n      await context Response WriteAsJsonAsync(new {\n        error = \"Tenant ID is required\"\n      });\n      return;\n    }\n    // 4 Set tenant context\n    TenantContext Set(tenantId);\n    _logger LogInformation(\"Request for tenant {TenantId}\", tenantId);\n    try {\n      await _next(context);\n    } finally {\n      TenantContext Clear();\n    }\n  }\n}\n`\nProgram cs registration:\n`csharp\napp UseMiddleware<TenantIdentificationMiddleware>();\n`\n---\nDatabase Per Tenant\nTenant Database Resolver\nITenantDatabaseResolver cs:\n`csharp\npublic interface ITenantDatabaseResolver {\n  string GetConnectionString(string tenantId);\n}\npublic class TenantDatabaseResolver : ITenantDatabaseResolver {\n  private readonly Dictionary<string, string> _tenantConnectionStrings;\n  public TenantDatabaseResolver(IConfiguration configuration) {\n    _tenantConnectionStrings = configuration GetSection(\"Tenants\") Get<Dictionary<string, TenantConfig>>() ToDictionary(\n        kvp => kvp Key,\n        kvp => kvp Value ConnectionString\n      ) new Dictionary<string, string>();\n  }\n  public string GetConnectionString(string tenantId) {\n    if (_tenantConnectionStrings TryGetValue(tenantId, out var connectionString)) {\n      return connectionString;\n    }\n    throw new InvalidOperationException($\"Tenant {tenantId} not found\");\n  }\n}\npublic record TenantConfig(\n  string ConnectionString,\n  string CustomDomain,\n  Dictionary<string, string> Settings\n);\n`\nappsettings json:\n`json\n{\n  \"Tenants\": {\n    \"tenant-a\": {\n      \"ConnectionString\": \"Host=localhost;Database=tenant_a;Username=postgres;Password=postgres\",\n      \"CustomDomain\": \"tenant-a example com\",\n      \"Settings\": {\n        \"MaxUsers\": \"100\",\n        \"Features\": \"analytics,exports\"\n      }\n    },\n    \"tenant-b\": {\n      \"ConnectionString\": \"Host=localhost;Database=tenant_b;Username=postgres;Password=postgres\",\n      \"CustomDomain\": \"tenant-b example com\",\n      \"Settings\": {\n        \"MaxUsers\": \"500\",\n        \"Features\": \"analytics,exports,api-access\"\n      }\n    }\n  }\n}\n`\nTenant-Aware Database Connection\nProgram cs:\n`csharp\nbuilder Services",
        "startIndex": 3139,
        "preview": "`csharp public class TenantIdentificationMiddleware { private readonly RequestDelegate _next; private readonly ILogger<TenantIdentificationMiddleware>..."
      },
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-2",
        "text": "` appsettings json: `json { \"Tenants\": { \"tenant-a\": { \"ConnectionString\": \"Host=localhost;Database=tenant_a;Username=postgres;Password=postgres\", \"CustomDomain\": \"tenant-a example com\", \"Settings\": { \"MaxUsers\": \"100\", \"Features\": \"analytics,exports\" } }, \"tenant-b\": { \"ConnectionString\": \"Host=localhost;Database=tenant_b;Username=postgres;Password=postgres\", \"CustomDomain\": \"tenant-b example com\", \"Settings\": { \"MaxUsers\": \"500\", \"Features\": \"analytics,exports,api-access\" } } } } ` Tenant-Aware Database Connection Program cs: `csharp builder Services AddScoped<NpgsqlConnection>(sp => {\n  var tenantId = TenantContext CurrentTenantId throw new InvalidOperationException(\"Tenant context not set\");\n  var resolver = sp GetRequiredService<ITenantDatabaseResolver>();\n  var connectionString = resolver GetConnectionString(tenantId);\n  return new NpgsqlConnection(connectionString);\n});\nbuilder Services AddSingleton<ITenantDatabaseResolver, TenantDatabaseResolver>();\n`\n---\nTenant-Aware Receptors\nCreateOrderReceptor cs:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly NpgsqlConnection _db;  // Tenant-specific database\n  private readonly IMessageContext _context;\n  private readonly ILogger<CreateOrderReceptor> _logger;\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    var tenantId = TenantContext CurrentTenantId throw new InvalidOperationException(\"Tenant context not set\");\n    _logger LogInformation(\n      \"Creating order for tenant {TenantId}, customer {CustomerId}\",\n      tenantId,\n      command CustomerId\n    );\n    // Database operations automatically scoped to tenant\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // Insert order (tenant-specific table)\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO orders (order_id, customer_id, total_amount, tenant_id, created_at)\n        VALUES (@OrderId, @CustomerId, @TotalAmount, @TenantId, NOW())\n        \"\"\",\n        new {\n          OrderId = Guid NewGuid() ToString(\"N\"),\n          CustomerId = command CustomerId,\n          TotalAmount = command Items Sum(i => i Quantity * i UnitPrice),\n          TenantId = tenantId\n        },\n        transaction: tx\n      );\n      // rest of implementation\n      await tx CommitAsync(ct);\n      return @event;\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n}\n`\n---\nMessage Context Propagation\nAutomatic tenant ID propagation in events:\nTenantAwareMessageContext cs:\n`csharp\npublic class TenantAwareMessageContext : IMessageContext {\n  private readonly IMessageContext _inner;\n  public TenantAwareMessageContext(IMessageContext inner) {\n    _inner = inner;\n  }\n  public Guid MessageId => _inner MessageId;\n  public Guid CorrelationId => _inner CorrelationId;\n  public Guid CausationId => _inner CausationId;\n  public string UserId => _inner",
        "startIndex": 5755,
        "preview": "` appsettings json: `json { \"Tenants\": { \"tenant-a\": { \"ConnectionString\": \"Host=localhost;Database=tenant_a;Username=postgres;Password=postgres\", \"Cu..."
      },
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-3",
        "text": "Automatic tenant ID propagation in events: TenantAwareMessageContext cs: `csharp public class TenantAwareMessageContext : IMessageContext { private readonly IMessageContext _inner; public TenantAwareMessageContext(IMessageContext inner) { _inner = inner; } public Guid MessageId => _inner MessageId; public Guid CorrelationId => _inner CorrelationId; public Guid CausationId => _inner CausationId; public string UserId => _inner UserId;\n  public IDictionary<string, string> Metadata {\n    get {\n      var metadata = new Dictionary<string, string>(_inner Metadata);\n      // Auto-inject tenant ID\n      if (TenantContext CurrentTenantId = null) {\n        metadata[\"tenant_id\"] = TenantContext CurrentTenantId;\n      }\n      return metadata;\n    }\n  }\n}\n`\nProgram cs:\n`csharp\nbuilder Services Decorate<IMessageContext, TenantAwareMessageContext>();\n`\nResult: All events automatically include tenant_id in metadata ---\nCross-Tenant Analytics\nShared Analytics Database\nAnalyticsDbConnection cs:\n`csharp\npublic class AnalyticsDbConnectionFactory {\n  private readonly string _connectionString;\n  public AnalyticsDbConnectionFactory(IConfiguration configuration) {\n    _connectionString = configuration GetConnectionString(\"AnalyticsDb\") throw new InvalidOperationException(\"AnalyticsDb connection string not configured\");\n  }\n  public NpgsqlConnection CreateConnection() {\n    return new NpgsqlConnection(_connectionString);\n  }\n}\n`\nCross-Tenant Analytics Perspective\nCrossTenantSalesPerspective cs:\n`csharp\npublic class CrossTenantSalesPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly AnalyticsDbConnectionFactory _analyticsDbFactory;\n  private readonly ILogger<CrossTenantSalesPerspective> _logger;\n  public CrossTenantSalesPerspective(\n    AnalyticsDbConnectionFactory analyticsDbFactory,\n    ILogger<CrossTenantSalesPerspective> logger\n  ) {\n    _analyticsDbFactory = analyticsDbFactory;\n    _logger = logger;\n  }\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    // Extract tenant ID from event metadata\n    var tenantId = @event Metadata GetValueOrDefault(\"tenant_id\") throw new InvalidOperationException(\"Tenant ID not found in event metadata\");\n    using var analyticsDb = _analyticsDbFactory CreateConnection();\n    await analyticsDb OpenAsync(ct);\n    // Aggregate across all tenants in shared analytics database\n    await analyticsDb ExecuteAsync(\n      \"\"\"\n      INSERT INTO cross_tenant_daily_sales (date, tenant_id, total_orders, total_revenue)\n      VALUES (CURRENT_DATE, @TenantId, 1, @TotalAmount)\n      ON CONFLICT (date, tenant_id) DO UPDATE SET\n        total_orders = cross_tenant_daily_sales total_orders + 1,\n        total_revenue = cross_tenant_daily_sales total_revenue + @TotalAmount\n      \"\"\",\n      new {\n        TenantId = tenantId,\n        TotalAmount = @event TotalAmount\n      }\n    );\n    _logger LogInformation(\n      \"Cross-tenant analytics updated for tenant {TenantId}: +${Amount}\",\n      tenantId,\n      @event",
        "startIndex": 8152,
        "preview": "Automatic tenant ID propagation in events: TenantAwareMessageContext cs: `csharp public class TenantAwareMessageContext : IMessageContext { private re..."
      },
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-4",
        "text": "tenant_id, total_orders, total_revenue) VALUES (CURRENT_DATE, @TenantId, 1, @TotalAmount) ON CONFLICT (date, tenant_id) DO UPDATE SET total_orders = cross_tenant_daily_sales total_orders + 1, total_revenue = cross_tenant_daily_sales total_revenue + @TotalAmount \"\"\", new { TenantId = tenantId, TotalAmount = @event TotalAmount } ); _logger LogInformation( \"Cross-tenant analytics updated for tenant {TenantId}: +${Amount}\", tenantId, @event TotalAmount\n    );\n  }\n}\n`\nSchema (shared analytics database):\n`sql\nCREATE TABLE cross_tenant_daily_sales (\n  date DATE NOT NULL,\n  tenant_id TEXT NOT NULL,\n  total_orders BIGINT NOT NULL DEFAULT 0,\n  total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0,\n  PRIMARY KEY (date, tenant_id)\n);\nCREATE INDEX idx_cross_tenant_sales_date ON cross_tenant_daily_sales(date DESC);\nCREATE INDEX idx_cross_tenant_sales_tenant ON cross_tenant_daily_sales(tenant_id);\n`\n---\nTenant Onboarding\nTenantProvisioningService cs:\n`csharp\npublic class TenantProvisioningService {\n  private readonly NpgsqlConnection _masterDb;\n  private readonly ILogger<TenantProvisioningService> _logger;\n  public async Task ProvisionTenantAsync(\n    string tenantId,\n    string adminEmail,\n    string companyName,\n    CancellationToken ct = default\n  ) {\n    _logger LogInformation(\"Provisioning tenant {TenantId}\", tenantId);\n    // 1 Create tenant database\n    await _masterDb ExecuteAsync(\n      $\"CREATE DATABASE tenant_{tenantId}\"\n    );\n    // 2 Run migrations on new database\n    var tenantConnectionString = $\"Host=localhost;Database=tenant_{tenantId};Username=postgres;Password=postgres\";\n    using var tenantDb = new NpgsqlConnection(tenantConnectionString);\n    await tenantDb OpenAsync(ct);\n    await ApplyMigrationsAsync(tenantDb, ct);\n    // 3 Create admin user\n    await tenantDb ExecuteAsync(\n      \"\"\"\n      INSERT INTO users (user_id, email, role, tenant_id, created_at)\n      VALUES (@UserId, @Email, 'admin', @TenantId, NOW())\n      \"\"\",\n      new {\n        UserId = Guid NewGuid() ToString(\"N\"),\n        Email = adminEmail,\n        TenantId = tenantId\n      }\n    );\n    // 4 Create default settings\n    await tenantDb ExecuteAsync(\n      \"\"\"\n      INSERT INTO tenant_settings (tenant_id, company_name, max_users, features, created_at)\n      VALUES (@TenantId, @CompanyName, 100, 'basic', NOW())\n      \"\"\",\n      new {\n        TenantId = tenantId,\n        CompanyName = companyName\n      }\n    );\n    _logger LogInformation(\"Tenant {TenantId} provisioned successfully\", tenantId);\n  }\n  private async Task ApplyMigrationsAsync(NpgsqlConnection db, CancellationToken ct) {\n    var migrationFiles = Directory GetFiles(\"Migrations\", \"* sql\") OrderBy(f => f);\n    foreach (var file in migrationFiles) {\n      var sql = await File ReadAllTextAsync(file, ct);\n      await db",
        "startIndex": 10753,
        "preview": "tenant_id, total_orders, total_revenue) VALUES (CURRENT_DATE, @TenantId, 1, @TotalAmount) ON CONFLICT (date, tenant_id) DO UPDATE SET total_orders = c..."
      },
      {
        "id": "v0.1.0/customization-examples/multi-tenant-saas-chunk-5",
        "text": "new { TenantId = tenantId, CompanyName = companyName } ); _logger LogInformation(\"Tenant {TenantId} provisioned successfully\", tenantId); } private async Task ApplyMigrationsAsync(NpgsqlConnection db, CancellationToken ct) { var migrationFiles = Directory GetFiles(\"Migrations\", \"* sql\") OrderBy(f => f); foreach (var file in migrationFiles) { var sql = await File ReadAllTextAsync(file, ct); await db ExecuteAsync(sql);\n    }\n  }\n}\n`\n---\nTenant-Specific Customizations\nFeature Flags per Tenant:\n`csharp\npublic class TenantFeatureService {\n  private readonly ITenantDatabaseResolver _resolver;\n  public async Task<bool> IsFeatureEnabledAsync(string feature) {\n    var tenantId = TenantContext CurrentTenantId throw new InvalidOperationException(\"Tenant context not set\");\n    var connectionString = _resolver GetConnectionString(tenantId);\n    using var db = new NpgsqlConnection(connectionString);\n    await db OpenAsync();\n    var features = await db QuerySingleOrDefaultAsync<string>(\n      \"SELECT features FROM tenant_settings WHERE tenant_id = @TenantId\",\n      new { TenantId = tenantId }\n    );\n    return features Contains(feature) false;\n  }\n}\n`\nUsage:\n`csharp\npublic async Task<OrderCreated> HandleAsync(CreateOrder command, CancellationToken ct) {\n  // Check if tenant has analytics feature\n  var hasAnalytics = await _featureService IsFeatureEnabledAsync(\"analytics\");\n  if (hasAnalytics) {\n    // Publish additional analytics events\n    await PublishAnalyticsEventAsync(@event, ct);\n  }\n  return @event;\n}\n`\n---\nKey Takeaways\n‚úÖ Database Per Tenant - Strongest isolation, independent scaling\n‚úÖ Tenant Context Propagation - Automatic tenant ID in all messages\n‚úÖ Cross-Tenant Analytics - Shared database for platform-wide metrics\n‚úÖ Tenant Onboarding - Automated provisioning with migrations\n‚úÖ Feature Flags - Tenant-specific customizations\n---\nAlternative Patterns\nShared Database with Row-Level Security\n`sql\n-- PostgreSQL Row-Level Security\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation_policy ON orders\n  USING (tenant_id = current_setting('app current_tenant')::text);\n-- Set tenant before query\nSET app current_tenant = 'tenant-a';\nSELECT * FROM orders;  -- Only returns tenant-a orders\n`\nPros: Single database, simpler infrastructure\nCons: Weaker isolation, shared resources\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 13105,
        "preview": "new { TenantId = tenantId, CompanyName = companyName } ); _logger LogInformation(\"Tenant {TenantId} provisioned successfully\", tenantId); } private as..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/customization-examples/real-time-analytics",
    "title": "Real-Time Analytics",
    "category": "Customization Examples",
    "url": "/docs/v0.1.0/customization-examples/real-time-analytics",
    "chunks": [
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-0",
        "text": "Real-Time Analytics\nBuild real-time analytics dashboards with Whizbang featuring streaming metrics, SignalR updates, live KPIs, and event-driven data aggregation ---\nArchitecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Real-Time Analytics Architecture                          ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                           ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  Domain Events (OrderCreated, etc )       ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ                        ‚îÇ\n‚îÇ                                    ‚ñº                        ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ              ‚îÇ Analytics Worker               ‚îÇ            ‚îÇ\n‚îÇ              ‚îÇ  - DailySalesPerspective       ‚îÇ            ‚îÇ\n‚îÇ              ‚îÇ  - RealtimeMetricsPerspective  ‚îÇ            ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n‚îÇ                         ‚îÇ                                   ‚îÇ\n‚îÇ                         ‚ñº                                   ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ              ‚îÇ PostgreSQL + Redis Cache       ‚îÇ            ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n‚îÇ                         ‚îÇ                                   ‚îÇ\n‚îÇ                         ‚ñº                                   ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ              ‚îÇ SignalR Hub                    ‚îÇ            ‚îÇ\n‚îÇ              ‚îÇ  - Broadcast metrics to clients‚îÇ            ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n‚îÇ                         ‚îÇ                                   ‚îÇ\n‚îÇ                         ‚ñº                                   ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n‚îÇ              ‚îÇ  Web Clients (Dashboards)      ‚îÇ            ‚îÇ\n‚îÇ              ‚îÇ  - Live KPI updates            ‚îÇ            ‚îÇ\n‚îÇ              ‚îÇ  - Charts auto-refresh         ‚îÇ            ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nSignalR Hub\nMetricsHub cs:\n`csharp\nusing Microsoft AspNetCore SignalR;\npublic class MetricsHub : Hub {\n  private readonly ILogger<MetricsHub> _logger;\n  public MetricsHub(ILogger<MetricsHub> logger) {\n    _logger = logger;\n  }\n  public override async Task OnConnectedAsync() {\n    _logger LogInformation(\n      \"Client {ConnectionId} connected to MetricsHub\",\n      Context ConnectionId\n    );\n    // Send current metrics on connect\n    await Clients Caller SendAsync(\n      \"ReceiveCurrentMetrics\",\n      await GetCurrentMetricsAsync()\n    );\n    await base OnConnectedAsync();\n  }\n  public override Task OnDisconnectedAsync(Exception exception) {\n    _logger LogInformation(\n      \"Client {ConnectionId} disconnected from MetricsHub\",\n      Context ConnectionId\n    );\n    return base OnDisconnectedAsync(exception);\n  }\n  private async Task<object> GetCurrentMetricsAsync() {\n    // Fetch current metrics from cache or database\n    return new {\n      TotalOrders = 1234,\n      TotalRevenue = 45678 90m,\n      AverageOrderValue = 37 02m,\n      Timestamp = DateTime UtcNow\n    };\n  }\n}\n`\nProgram cs registration:\n`csharp\nbuilder Services AddSignalR();\napp MapHub<MetricsHub>(\"/hubs/metrics\");\n`\n---\nReal-Time Metrics Perspective\nRealtimeMetricsPerspective",
        "startIndex": 0,
        "preview": "Real-Time Analytics\nBuild real-time analytics dashboards with Whizbang featuring streaming metrics, SignalR updates, live KPIs, and event-driven data ..."
      },
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-1",
        "text": "private async Task<object> GetCurrentMetricsAsync() { // Fetch current metrics from cache or database return new { TotalOrders = 1234, TotalRevenue = 45678 90m, AverageOrderValue = 37 02m, Timestamp = DateTime UtcNow }; } } ` Program cs registration: `csharp builder Services AddSignalR(); app MapHub<MetricsHub>(\"/hubs/metrics\"); ` --- Real-Time Metrics Perspective RealtimeMetricsPerspective cs:\n`csharp\npublic class RealtimeMetricsPerspective :\n  IPerspectiveOf<OrderCreated>,\n  IPerspectiveOf<PaymentProcessed> {\n  private readonly IHubContext<MetricsHub> _hubContext;\n  private readonly IDistributedCache _cache;\n  private readonly ILogger<RealtimeMetricsPerspective> _logger;\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    // 1 Update metrics in cache (Redis)\n    var metrics = await GetCurrentMetricsAsync(ct);\n    metrics = metrics with {\n      TotalOrders = metrics TotalOrders + 1,\n      TotalRevenue = metrics TotalRevenue + @event TotalAmount,\n      AverageOrderValue = (metrics TotalRevenue + @event TotalAmount) / (metrics TotalOrders + 1),\n      LastUpdated = DateTime UtcNow\n    };\n    await SaveMetricsAsync(metrics, ct);\n    // 2 Broadcast to all connected clients\n    await _hubContext Clients All SendAsync(\n      \"ReceiveMetricsUpdate\",\n      new {\n        metrics TotalOrders,\n        metrics TotalRevenue,\n        metrics AverageOrderValue,\n        Timestamp = DateTime UtcNow\n      },\n      ct\n    );\n    _logger LogInformation(\n      \"Broadcasted metrics update: {TotalOrders} orders, ${TotalRevenue}\",\n      metrics TotalOrders,\n      metrics TotalRevenue\n    );\n  }\n  public async Task HandleAsync(\n    PaymentProcessed @event,\n    CancellationToken ct = default\n  ) {\n    // Update payment-specific metrics\n    var metrics = await GetCurrentMetricsAsync(ct);\n    metrics = metrics with {\n      TotalPaymentsProcessed = metrics TotalPaymentsProcessed + 1,\n      LastUpdated = DateTime UtcNow\n    };\n    await SaveMetricsAsync(metrics, ct);\n    await _hubContext Clients All SendAsync(\n      \"ReceivePaymentMetricsUpdate\",\n      new {\n        metrics TotalPaymentsProcessed,\n        Timestamp = DateTime UtcNow\n      },\n      ct\n    );\n  }\n  private async Task<RealtimeMetrics> GetCurrentMetricsAsync(CancellationToken ct) {\n    var cached = await _cache GetStringAsync(\"realtime-metrics\", ct);\n    if (cached = null) {\n      return JsonSerializer Deserialize<RealtimeMetrics>(cached) ;\n    }\n    // Initialize if not exists\n    return new RealtimeMetrics {\n      TotalOrders = 0,\n      TotalRevenue = 0,\n      AverageOrderValue = 0,\n      TotalPaymentsProcessed = 0,\n      LastUpdated = DateTime UtcNow\n    };\n  }\n  private async Task SaveMetricsAsync(RealtimeMetrics metrics, CancellationToken ct) {\n    var json = JsonSerializer Serialize(metrics);\n    await _cache",
        "startIndex": 3470,
        "preview": "private async Task<object> GetCurrentMetricsAsync() { // Fetch current metrics from cache or database return new { TotalOrders = 1234, TotalRevenue = ..."
      },
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-2",
        "text": "= null) { return JsonSerializer Deserialize<RealtimeMetrics>(cached) ; } // Initialize if not exists return new RealtimeMetrics { TotalOrders = 0, TotalRevenue = 0, AverageOrderValue = 0, TotalPaymentsProcessed = 0, LastUpdated = DateTime UtcNow }; } private async Task SaveMetricsAsync(RealtimeMetrics metrics, CancellationToken ct) { var json = JsonSerializer Serialize(metrics); await _cache SetStringAsync(\n      \"realtime-metrics\",\n      json,\n      new DistributedCacheEntryOptions {\n        AbsoluteExpirationRelativeToNow = TimeSpan FromDays(1)\n      },\n      ct\n    );\n  }\n}\npublic record RealtimeMetrics {\n  public long TotalOrders { get; init; }\n  public decimal TotalRevenue { get; init; }\n  public decimal AverageOrderValue { get; init; }\n  public long TotalPaymentsProcessed { get; init; }\n  public DateTime LastUpdated { get; init; }\n}\n`\n---\nClient-Side (TypeScript)\nmetrics-dashboard ts:\n`typescript\nimport * as signalR from \"@microsoft/signalr\";\nclass MetricsDashboard {\n  private connection: signalR HubConnection;\n  constructor() {\n    // Connect to SignalR hub\n    this connection = new signalR HubConnectionBuilder() withUrl(\"/hubs/metrics\") withAutomaticReconnect() build();\n    this setupEventHandlers();\n    this connect();\n  }\n  private setupEventHandlers() {\n    // Receive current metrics on connect\n    this connection on(\"ReceiveCurrentMetrics\", (metrics: any) => {\n      console log(\"Current metrics:\", metrics);\n      this updateDashboard(metrics);\n    });\n    // Receive live updates\n    this connection on(\"ReceiveMetricsUpdate\", (metrics: any) => {\n      console log(\"Metrics update:\", metrics);\n      this updateDashboard(metrics);\n      this showNotification(New order: $${metrics TotalRevenue});\n    });\n    // Receive payment updates\n    this connection on(\"ReceivePaymentMetricsUpdate\", (metrics: any) => {\n      console log(\"Payment metrics update:\", metrics);\n      this updatePaymentMetrics(metrics);\n    });\n  }\n  private async connect() {\n    try {\n      await this connection start();\n      console log(\"Connected to MetricsHub\");\n    } catch (err) {\n      console error(\"Error connecting to MetricsHub:\", err);\n      setTimeout(() => this connect(), 5000);\n    }\n  }\n  private updateDashboard(metrics: any) {\n    document getElementById(\"total-orders\") textContent = metrics TotalOrders;\n    document getElementById(\"total-revenue\") textContent = $${metrics TotalRevenue toFixed(2)};\n    document getElementById(\"avg-order-value\") textContent = $${metrics AverageOrderValue toFixed(2)};\n    document getElementById(\"last-updated\") textContent = new Date(metrics Timestamp) toLocaleTimeString();\n  }\n  private updatePaymentMetrics(metrics: any) {\n    document getElementById(\"total-payments\") textContent = metrics TotalPaymentsProcessed;\n  }\n  private showNotification(message: string) {\n    // Show toast notification\n    const toast = document",
        "startIndex": 5930,
        "preview": "= null) { return JsonSerializer Deserialize<RealtimeMetrics>(cached) ; } // Initialize if not exists return new RealtimeMetrics { TotalOrders = 0, Tot..."
      },
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-3",
        "text": "textContent = metrics TotalOrders; document getElementById(\"total-revenue\") textContent = $${metrics TotalRevenue toFixed(2)}; document getElementById(\"avg-order-value\") textContent = $${metrics AverageOrderValue toFixed(2)}; document getElementById(\"last-updated\") textContent = new Date(metrics Timestamp) toLocaleTimeString(); } private updatePaymentMetrics(metrics: any) { document getElementById(\"total-payments\") textContent = metrics TotalPaymentsProcessed; } private showNotification(message: string) { // Show toast notification const toast = document createElement(\"div\");\n    toast className = \"toast\";\n    toast textContent = message;\n    document body appendChild(toast);\n    setTimeout(() => toast remove(), 3000);\n  }\n}\n// Initialize dashboard\nnew MetricsDashboard();\n`\nHTML:\n`html\n< DOCTYPE html>\n<html>\n<head>\n  <title>Real-Time Analytics Dashboard</title>\n  <style> metric-card {\n      display: inline-block;\n      padding: 20px;\n      margin: 10px;\n      background: #f5f5f5;\n      border-radius: 8px;\n    } metric-value {\n      font-size: 36px;\n      font-weight: bold;\n    } metric-label {\n      font-size: 14px;\n      color: #666;\n    } toast {\n      position: fixed;\n      bottom: 20px;\n      right: 20px;\n      padding: 15px;\n      background: #28a745;\n      color: white;\n      border-radius: 4px;\n    }\n  </style>\n</head>\n<body>\n  <h1>Real-Time Analytics Dashboard</h1>\n  <div class=\"metric-card\">\n    <div class=\"metric-value\" id=\"total-orders\">0</div>\n    <div class=\"metric-label\">Total Orders</div>\n  </div>\n  <div class=\"metric-card\">\n    <div class=\"metric-value\" id=\"total-revenue\">$0 00</div>\n    <div class=\"metric-label\">Total Revenue</div>\n  </div>\n  <div class=\"metric-card\">\n    <div class=\"metric-value\" id=\"avg-order-value\">$0 00</div>\n    <div class=\"metric-label\">Avg Order Value</div>\n  </div>\n  <div class=\"metric-card\">\n    <div class=\"metric-value\" id=\"total-payments\">0</div>\n    <div class=\"metric-label\">Total Payments</div>\n  </div>\n  <div>\n    <small>Last updated: <span id=\"last-updated\">-</span></small>\n  </div>\n  <script src=\"/dist/metrics-dashboard js\"></script>\n</body>\n</html>\n`\n---\nStreaming Aggregations\nSliding Window Analytics:\n`csharp\npublic class SlidingWindowAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IDistributedCache _cache;\n  private readonly IHubContext<MetricsHub> _hubContext;\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    // Add event to sliding window (last 5 minutes)\n    var windowKey = \"orders:last5min\";\n    var events = await GetWindowEventsAsync(windowKey, ct);\n    events Add(new OrderEventData {\n      OrderId = @event OrderId,\n      Amount = @event TotalAmount,\n      Timestamp = DateTime UtcNow\n    });\n    // Remove events older than 5 minutes\n    var cutoff = DateTime UtcNow AddMinutes(-5);\n    events = events Where(e => e Timestamp >= cutoff) ToList();\n    await SaveWindowEventsAsync(windowKey, events, ct);\n    // Calculate metrics for last 5 minutes\n    var metrics = new {\n      OrderCount = events",
        "startIndex": 8453,
        "preview": "textContent = metrics TotalOrders; document getElementById(\"total-revenue\") textContent = $${metrics TotalRevenue toFixed(2)}; document getElementById..."
      },
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-4",
        "text": "= @event TotalAmount, Timestamp = DateTime UtcNow }); // Remove events older than 5 minutes var cutoff = DateTime UtcNow AddMinutes(-5); events = events Where(e => e Timestamp >= cutoff) ToList(); await SaveWindowEventsAsync(windowKey, events, ct); // Calculate metrics for last 5 minutes var metrics = new { OrderCount = events Count,\n      TotalRevenue = events Sum(e => e Amount),\n      AverageOrderValue = events Any() events Average(e => e Amount) : 0,\n      WindowStart = cutoff,\n      WindowEnd = DateTime UtcNow\n    };\n    // Broadcast sliding window metrics\n    await _hubContext Clients All SendAsync(\n      \"ReceiveSlidingWindowUpdate\",\n      metrics,\n      ct\n    );\n  }\n  private async Task<List<OrderEventData>> GetWindowEventsAsync(\n    string key,\n    CancellationToken ct\n  ) {\n    var cached = await _cache GetStringAsync(key, ct);\n    return cached = null JsonSerializer Deserialize<List<OrderEventData>>(cached) : new List<OrderEventData>();\n  }\n  private async Task SaveWindowEventsAsync(\n    string key,\n    List<OrderEventData> events,\n    CancellationToken ct\n  ) {\n    var json = JsonSerializer Serialize(events);\n    await _cache SetStringAsync(\n      key,\n      json,\n      new DistributedCacheEntryOptions {\n        AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(10)\n      },\n      ct\n    );\n  }\n}\npublic record OrderEventData {\n  public required string OrderId { get; init; }\n  public required decimal Amount { get; init; }\n  public required DateTime Timestamp { get; init; }\n}\n`\n---\nPerformance Optimizations\nThrottling\nLimit broadcast frequency to avoid overwhelming clients:\n`csharp\npublic class ThrottledMetricsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IHubContext<MetricsHub> _hubContext;\n  private readonly SemaphoreSlim _semaphore = new(1, 1);\n  private DateTime _lastBroadcast = DateTime MinValue;\n  private static readonly TimeSpan BroadcastInterval = TimeSpan FromSeconds(1);\n  public async Task HandleAsync(OrderCreated @event, CancellationToken ct) {\n    // Update metrics immediately\n    await UpdateMetricsAsync(@event, ct);\n    // Throttle broadcasts (max once per second)\n    await _semaphore WaitAsync(ct);\n    try {\n      if (DateTime UtcNow - _lastBroadcast >= BroadcastInterval) {\n        await BroadcastMetricsAsync(ct);\n        _lastBroadcast = DateTime UtcNow;\n      }\n    } finally {\n      _semaphore Release();\n    }\n  }\n}\n`\nBatching\nBatch multiple updates before broadcasting:\n`csharp\npublic class BatchedMetricsPerspective {\n  private readonly Channel<OrderCreated> _channel = Channel",
        "startIndex": 10992,
        "preview": "= @event TotalAmount, Timestamp = DateTime UtcNow }); // Remove events older than 5 minutes var cutoff = DateTime UtcNow AddMinutes(-5); events = even..."
      },
      {
        "id": "v0.1.0/customization-examples/real-time-analytics-chunk-5",
        "text": "(max once per second) await _semaphore WaitAsync(ct); try { if (DateTime UtcNow - _lastBroadcast >= BroadcastInterval) { await BroadcastMetricsAsync(ct); _lastBroadcast = DateTime UtcNow; } } finally { _semaphore Release(); } } } ` Batching Batch multiple updates before broadcasting: `csharp public class BatchedMetricsPerspective { private readonly Channel<OrderCreated> _channel = Channel CreateUnbounded<OrderCreated>();\n  public BatchedMetricsPerspective(IHubContext<MetricsHub> hubContext) {\n    _ = Task Run(async () => await ProcessBatchesAsync(hubContext));\n  }\n  public async Task HandleAsync(OrderCreated @event, CancellationToken ct) {\n    await _channel Writer WriteAsync(@event, ct);\n  }\n  private async Task ProcessBatchesAsync(IHubContext<MetricsHub> hubContext) {\n    await foreach (var batch in _channel Reader ReadAllAsync() Buffer(TimeSpan FromSeconds(1), 100)) {\n      var metrics = new {\n        OrderCount = batch Count,\n        TotalRevenue = batch Sum(e => e TotalAmount),\n        Timestamp = DateTime UtcNow\n      };\n      await hubContext Clients All SendAsync(\"ReceiveBatchUpdate\", metrics);\n    }\n  }\n}\n`\n---\nKey Takeaways\n‚úÖ SignalR - Real-time WebSocket communication\n‚úÖ Event-Driven Updates - Perspectives broadcast to clients\n‚úÖ Redis Caching - Fast metric aggregation\n‚úÖ Sliding Windows - Last N minutes/hours analytics\n‚úÖ Throttling - Prevent client overload\n‚úÖ Batching - Reduce broadcast frequency\n---\nAlternative Architectures\nServer-Sent Events (SSE)\nSimpler than SignalR for one-way updates:\n`csharp\napp MapGet(\"/sse/metrics\", async (HttpContext context) => {\n  context Response Headers Add(\"Content-Type\", \"text/event-stream\");\n  context Response Headers Add(\"Cache-Control\", \"no-cache\");\n  while ( context RequestAborted IsCancellationRequested) {\n    var metrics = await GetCurrentMetricsAsync();\n    await context Response WriteAsync($\"data: {JsonSerializer Serialize(metrics)}\\n\\n\");\n    await context Response Body FlushAsync();\n    await Task Delay(TimeSpan FromSeconds(1));\n  }\n});\n`\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 13252,
        "preview": "(max once per second) await _semaphore WaitAsync(ct); try { if (DateTime UtcNow - _lastBroadcast >= BroadcastInterval) { await BroadcastMetricsAsync(c..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/data/dapper-integration",
    "title": "Dapper Integration",
    "category": "Data Access",
    "url": "/docs/v0.1.0/data/dapper-integration",
    "chunks": [
      {
        "id": "v0.1.0/data/dapper-integration-chunk-0",
        "text": "Dapper Integration\nDapper is Whizbang's recommended micro-ORM for lightweight, high-performance data access in Perspectives and Lenses It provides simple SQL execution with minimal overhead - perfect for read models Why Dapper | Feature | Dapper | EF Core |\n|---------|--------|---------|\n| Performance | ~20x faster queries | Slower (change tracking overhead) |\n| Control | Full SQL control | LINQ translated to SQL |\n| Learning curve | Simple (just SQL) | Complex (LINQ, migrations, tracking) |\n| Use case | Perspectives/Lenses | Complex domain models |\n| Recommended for | ‚úÖ Read models | Write models |\nWhizbang Philosophy: Use Dapper for reads (perspectives, lenses), EF Core for writes (optional, if needed) ---\nInstallation\n`bash\ndotnet add package Whizbang Data Dapper Postgres\n`\nIncludes:\nIDbConnectionFactory - Connection factory interface\nPostgresConnectionFactory - PostgreSQL implementation\nDapper (latest version)\nNpgsql (PostgreSQL driver)\n---\nIDbConnectionFactory\nWhizbang uses IDbConnectionFactory pattern for database connections Interface\n`csharp\npublic interface IDbConnectionFactory {\n    IDbConnection CreateConnection();\n}\n`\nBenefits:\n‚úÖ Testable: Easy to mock for unit tests\n‚úÖ Flexible: Swap implementations (PostgreSQL, SQLite, etc )\n‚úÖ Connection pooling: Npgsql handles pooling automatically\n‚úÖ Minimal: No dependencies on specific ORM\nPostgreSQL Implementation\n`csharp\npublic class PostgresConnectionFactory : IDbConnectionFactory {\n    private readonly string _connectionString;\n    public PostgresConnectionFactory(string connectionString) {\n        _connectionString = connectionString;\n    }\n    public IDbConnection CreateConnection() {\n        return new NpgsqlConnection(_connectionString);\n    }\n}\n`\nRegistration\n`csharp\n// appsettings json\n{\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"Host=localhost;Database=whizbang;Username=postgres;Password=your_password\"\n  }\n}\n// Program cs\nvar connectionString = builder Configuration GetConnectionString(\"DefaultConnection\") ;\nbuilder Services AddWhizbangDapper(connectionString);\n// OR manually:\nbuilder Services AddSingleton<IDbConnectionFactory>(\n    new PostgresConnectionFactory(connectionString)\n);\n`\n---\nBasic Usage\nQuery Single Row\n`csharp\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public OrderLens(IDbConnectionFactory db) {\n        _db = db;\n    }\n    public async Task<OrderSummary > GetOrderAsync(\n        Guid orderId,\n        CancellationToken ct = default) {\n        await using var conn = _db",
        "startIndex": 0,
        "preview": "Dapper Integration\nDapper is Whizbang's recommended micro-ORM for lightweight, high-performance data access in Perspectives and Lenses It provides sim..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-1",
        "text": "builder Services AddSingleton<IDbConnectionFactory>( new PostgresConnectionFactory(connectionString) ); ` --- Basic Usage Query Single Row `csharp public class OrderLens : ILensQuery { private readonly IDbConnectionFactory _db; public OrderLens(IDbConnectionFactory db) { _db = db; } public async Task<OrderSummary > GetOrderAsync( Guid orderId, CancellationToken ct = default) { await using var conn = _db CreateConnection();\n        return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"\"\"\n            SELECT\n                order_id,\n                customer_id,\n                total,\n                status,\n                created_at\n            FROM order_summaries\n            WHERE order_id = @OrderId\n            \"\"\",\n            new { OrderId = orderId },\n            commandTimeout: 30,\n            cancellationToken: ct\n        );\n    }\n}\n`\nKey Points:\nUse await using for automatic disposal\nQuerySingleOrDefaultAsync returns null if not found\nPass parameters as anonymous object\nAlways pass CancellationToken\nQuery Multiple Rows\n`csharp\npublic async Task<OrderSummary[]> GetOrdersByCustomerAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var orders = await conn QueryAsync<OrderSummary>(\n        \"\"\"\n        SELECT\n            order_id,\n            customer_id,\n            total,\n            status,\n            created_at\n        FROM order_summaries\n        WHERE customer_id = @CustomerId\n        ORDER BY created_at DESC\n        \"\"\",\n        new { CustomerId = customerId },\n        commandTimeout: 30,\n        cancellationToken: ct\n    );\n    return orders ToArray();\n}\n`\nExecute Non-Query\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (\n                order_id, customer_id, total, status, created_at\n            ) VALUES (\n                @OrderId, @CustomerId, @Total, @Status, @CreatedAt\n            )\n            \"\"\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            },\n            commandTimeout: 30,\n            cancellationToken: ct\n        );\n    }\n}\n`\n---\nPostgreSQL-Specific Features\nJSONB Columns\n`csharp\n// Query JSONB column\npublic async Task<Product[]> GetProductsByCategoryAsync(\n    string category,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var products = await conn",
        "startIndex": 2544,
        "preview": "builder Services AddSingleton<IDbConnectionFactory>( new PostgresConnectionFactory(connectionString) ); ` --- Basic Usage Query Single Row `csharp pub..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-2",
        "text": "CustomerId, @event Total, Status = \"Created\", @event CreatedAt }, commandTimeout: 30, cancellationToken: ct ); } } ` --- PostgreSQL-Specific Features JSONB Columns `csharp // Query JSONB column public async Task<Product[]> GetProductsByCategoryAsync( string category, CancellationToken ct = default) { await using var conn = _db CreateConnection(); var products = await conn QueryAsync<Product>(\n        \"\"\"\n        SELECT\n            product_id,\n            name,\n            price,\n            metadata\n        FROM products\n        WHERE metadata->>'category' = @Category\n        ORDER BY name\n        \"\"\",\n        new { Category = category },\n        cancellationToken: ct\n    );\n    return products ToArray();\n}\n// Store JSONB\npublic async Task UpdateProductMetadataAsync(\n    Guid productId,\n    Dictionary<string, string> metadata,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n        \"\"\"\n        UPDATE products\n        SET metadata = @Metadata::jsonb\n        WHERE product_id = @ProductId\n        \"\"\",\n        new {\n            ProductId = productId,\n            Metadata = JsonSerializer Serialize(metadata)\n        },\n        cancellationToken: ct\n    );\n}\n`\nArray Parameters\n`csharp\npublic async Task<Product[]> GetProductsByIdsAsync(\n    Guid[] productIds,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var products = await conn QueryAsync<Product>(\n        \"\"\"\n        SELECT * FROM products\n        WHERE product_id = ANY(@ProductIds)\n        \"\"\",\n        new { ProductIds = productIds },\n        cancellationToken: ct\n    );\n    return products ToArray();\n}\n`\nUPSERT (ON CONFLICT)\n`csharp\npublic async Task UpsertInventoryAsync(\n    Guid productId,\n    int quantity,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO inventory (product_id, available)\n        VALUES (@ProductId, @Quantity)\n        ON CONFLICT (product_id) DO UPDATE\n        SET available = EXCLUDED available\n        \"\"\",\n        new { ProductId = productId, Quantity = quantity },\n        cancellationToken: ct\n    );\n}\n`\n---\nTransactions\nBasic Transaction\n`csharp\npublic async Task CreateOrderWithItemsAsync(\n    Order order,\n    OrderItem[] items,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn OpenAsync(ct);\n    await using var transaction = await conn BeginTransactionAsync(ct);\n    try {\n        // Insert order\n        await conn",
        "startIndex": 4944,
        "preview": "CustomerId, @event Total, Status = \"Created\", @event CreatedAt }, commandTimeout: 30, cancellationToken: ct ); } } ` --- PostgreSQL-Specific Features ..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-3",
        "text": "quantity }, cancellationToken: ct ); } ` --- Transactions Basic Transaction `csharp public async Task CreateOrderWithItemsAsync( Order order, OrderItem[] items, CancellationToken ct = default) { await using var conn = _db CreateConnection(); await conn OpenAsync(ct); await using var transaction = await conn BeginTransactionAsync(ct); try { // Insert order await conn ExecuteAsync(\n            \"INSERT INTO orders (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\",\n            order,\n            transaction: transaction,\n            cancellationToken: ct\n        );\n        // Insert order items\n        foreach (var item in items) {\n            await conn ExecuteAsync(\n                \"INSERT INTO order_items (order_item_id, order_id, product_id, quantity, unit_price) VALUES (@OrderItemId, @OrderId, @ProductId, @Quantity, @UnitPrice)\",\n                item,\n                transaction: transaction,\n                cancellationToken: ct\n            );\n        }\n        await transaction CommitAsync(ct);\n    } catch {\n        await transaction RollbackAsync(ct);\n        throw;\n    }\n}\n`\nTransaction Scope (Distributed Transactions)\n`csharp\nusing var scope = new TransactionScope(TransactionScopeAsyncFlowOption Enabled);\nawait using var conn = _db CreateConnection();\n// All operations in this scope are transactional\nawait conn ExecuteAsync(\"INSERT INTO orders \");\nawait conn ExecuteAsync(\"INSERT INTO order_items \");\nscope Complete();  // Commit\n`\n---\nMapping\nCustom Type Mapping\n`csharp\n// Map custom types\nSqlMapper AddTypeHandler(new GuidTypeHandler());\nSqlMapper AddTypeHandler(new DateTimeOffsetTypeHandler());\npublic class GuidTypeHandler : SqlMapper TypeHandler<Guid> {\n    public override Guid Parse(object value) {\n        return Guid Parse((string)value);\n    }\n    public override void SetValue(IDbDataParameter parameter, Guid value) {\n        parameter Value = value ToString();\n    }\n}\n`\nColumn Name Mapping\n`csharp\n// Explicit column mapping\npublic async Task<OrderSummary > GetOrderAsync(Guid orderId) {\n    await using var conn = _db CreateConnection();\n    return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n        \"\"\"\n        SELECT\n            order_id AS OrderId,\n            customer_id AS CustomerId,\n            total AS Total,\n            status AS Status,\n            created_at AS CreatedAt\n        FROM order_summaries\n        WHERE order_id = @OrderId\n        \"\"\",\n        new { OrderId = orderId }\n    );\n}\n`\nNote: Dapper matches columns to properties by name (case-insensitive)",
        "startIndex": 7167,
        "preview": "quantity }, cancellationToken: ct ); } ` --- Transactions Basic Transaction `csharp public async Task CreateOrderWithItemsAsync( Order order, OrderIte..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-4",
        "text": "conn = _db CreateConnection(); return await conn QuerySingleOrDefaultAsync<OrderSummary>( \"\"\" SELECT order_id AS OrderId, customer_id AS CustomerId, total AS Total, status AS Status, created_at AS CreatedAt FROM order_summaries WHERE order_id = @OrderId \"\"\", new { OrderId = orderId } ); } ` Note: Dapper matches columns to properties by name (case-insensitive) ---\nPerformance Patterns\nBuffered vs Unbuffered\n`csharp\n// ‚úÖ Buffered (default) - loads all rows into memory\nvar orders = await conn QueryAsync<OrderSummary>(sql);\n// ‚ö†Ô∏è Unbuffered - streams rows (use for large result sets)\nvar orders = await conn QueryAsync<OrderSummary>(sql, buffered: false);\nawait foreach (var order in orders) {\n    // Process one at a time (low memory)\n}\n`\nBatch Operations\n`csharp\n// ‚úÖ Batch insert (single roundtrip)\nawait conn ExecuteAsync(\n    \"INSERT INTO order_items (order_item_id, order_id, product_id, quantity) VALUES (@OrderItemId, @OrderId, @ProductId, @Quantity)\",\n    items  // Pass array - Dapper executes once per item\n);\n// ‚ùå Loop insert (multiple roundtrips)\nforeach (var item in items) {\n    await conn ExecuteAsync(\"INSERT INTO order_items \", item);  // Slow }\n`\nConnection Pooling\nNpgsql handles connection pooling automatically:\n`\nConnection String:\nHost=localhost;Database=whizbang;Username=postgres;Password=pass;Minimum Pool Size=5;Maximum Pool Size=100\n`\nConfiguration:\nMinimum Pool Size: Connections kept open (default: 1)\nMaximum Pool Size: Max connections (default: 100)\nConnection Lifetime: Max seconds before recreate (default: 0 = infinite)\n---\nTesting\nUnit Tests with Mock\n`csharp\npublic class OrderLensTests {\n    [Test]\n    public async Task GetOrderAsync_ExistingOrder_ReturnsOrderAsync() {\n        // Arrange\n        var mockDb = CreateMockDbConnectionFactory();\n        var lens = new OrderLens(mockDb);\n        var orderId = Guid NewGuid();\n        // Act\n        var result = await lens GetOrderAsync(orderId);\n        // Assert\n        await Assert That(result) IsNotNull();\n        await Assert That(result OrderId)",
        "startIndex": 9397,
        "preview": "conn = _db CreateConnection(); return await conn QuerySingleOrDefaultAsync<OrderSummary>( \"\"\" SELECT order_id AS OrderId, customer_id AS CustomerId, t..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-5",
        "text": "Testing Unit Tests with Mock `csharp public class OrderLensTests { [Test] public async Task GetOrderAsync_ExistingOrder_ReturnsOrderAsync() { // Arrange var mockDb = CreateMockDbConnectionFactory(); var lens = new OrderLens(mockDb); var orderId = Guid NewGuid(); // Act var result = await lens GetOrderAsync(orderId); // Assert await Assert That(result) IsNotNull(); await Assert That(result OrderId) IsEqualTo(orderId);\n    }\n    private IDbConnectionFactory CreateMockDbConnectionFactory() {\n        // Use in-memory database or mock\n        return new InMemoryDbConnectionFactory(/ test data /);\n    }\n}\n`\nIntegration Tests with PostgreSQL\n`csharp\npublic class OrderLensIntegrationTests {\n    private IDbConnectionFactory _db;\n    private OrderLens _lens;\n    [Before(Test)]\n    public async Task SetupAsync() {\n        _db = CreateTestDatabase();  // Real PostgreSQL\n        _lens = new OrderLens(_db);\n        await SeedTestDataAsync();\n    }\n    [Test]\n    public async Task GetOrdersByCustomerAsync_WithOrders_ReturnsAllAsync() {\n        // Arrange\n        var customerId = TestData CustomerWithOrdersId;\n        // Act\n        var orders = await _lens GetOrdersByCustomerAsync(customerId);\n        // Assert\n        await Assert That(orders Length) IsEqualTo(3);\n    }\n    private async Task SeedTestDataAsync() {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO order_summaries (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\",\n            new {\n                OrderId = Guid NewGuid(),\n                CustomerId = TestData CustomerWithOrdersId,\n                Total = 100 00m,\n                Status = \"Created\",\n                CreatedAt = DateTimeOffset UtcNow\n            }\n        );\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use await using for connections (automatic disposal)\n‚úÖ Pass CancellationToken to all async methods\n‚úÖ Use QuerySingleOrDefaultAsync for single row (returns null if not found)\n‚úÖ Use QueryAsync for multiple rows\n‚úÖ Use ExecuteAsync for non-queries (INSERT, UPDATE, DELETE)\n‚úÖ Use transactions for multi-statement operations\n‚úÖ Use batch operations for multiple inserts/updates\n‚úÖ Set commandTimeout for long-running queries\n‚úÖ Use parameterized queries (prevents SQL injection)\n‚úÖ Use connection pooling (automatic with Npgsql)\nDON'T ‚ùå\n‚ùå Forget await using (connection leak",
        "startIndex": 11083,
        "preview": "Testing Unit Tests with Mock `csharp public class OrderLensTests { [Test] public async Task GetOrderAsync_ExistingOrder_ReturnsOrderAsync() { // Arran..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-6",
        "text": "rows ‚úÖ Use ExecuteAsync for non-queries (INSERT, UPDATE, DELETE) ‚úÖ Use transactions for multi-statement operations ‚úÖ Use batch operations for multiple inserts/updates ‚úÖ Set commandTimeout for long-running queries ‚úÖ Use parameterized queries (prevents SQL injection) ‚úÖ Use connection pooling (automatic with Npgsql) DON'T ‚ùå ‚ùå Forget await using (connection leak )\n‚ùå Use string concatenation for SQL (SQL injection risk)\n‚ùå Ignore CancellationToken (can't cancel long queries)\n‚ùå Open connections manually (let Dapper handle it)\n‚ùå Use Query instead of QueryAsync (blocks thread)\n‚ùå Use Execute instead of ExecuteAsync (blocks thread)\n‚ùå Skip transactions for multi-statement operations (data inconsistency)\n‚ùå Loop instead of batch (slow )\n---\nCommon Patterns\nPattern 1: Perspective Update\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (order_id, customer_id, total, status, created_at)\n            VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\n            ON CONFLICT (order_id) DO NOTHING\n            \"\"\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            },\n            cancellationToken: ct\n        );\n    }\n}\n`\nPattern 2: Lens Query\n`csharp\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public async Task<OrderSummary[]> GetRecentOrdersAsync(\n        int limit,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        var orders = await conn QueryAsync<OrderSummary>(\n            \"\"\"\n            SELECT * FROM order_summaries\n            ORDER BY created_at DESC\n            LIMIT @Limit\n            \"\"\",\n            new { Limit = limit },\n            cancellationToken: ct\n        );\n        return orders ToArray();\n    }\n}\n`\nPattern 3: Aggregation\n`csharp\npublic async Task<OrderStatistics> GetOrderStatisticsAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    return await conn",
        "startIndex": 13111,
        "preview": "rows ‚úÖ Use ExecuteAsync for non-queries (INSERT, UPDATE, DELETE) ‚úÖ Use transactions for multi-statement operations ‚úÖ Use batch operations for multiple..."
      },
      {
        "id": "v0.1.0/data/dapper-integration-chunk-7",
        "text": "* FROM order_summaries ORDER BY created_at DESC LIMIT @Limit \"\"\", new { Limit = limit }, cancellationToken: ct ); return orders ToArray(); } } ` Pattern 3: Aggregation `csharp public async Task<OrderStatistics> GetOrderStatisticsAsync( Guid customerId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleAsync<OrderStatistics>(\n        \"\"\"\n        SELECT\n            COUNT(*) AS TotalOrders,\n            SUM(total) AS TotalSpent,\n            AVG(total) AS AverageOrderValue,\n            MAX(created_at) AS LastOrderDate\n        FROM order_summaries\n        WHERE customer_id = @CustomerId\n        \"\"\",\n        new { CustomerId = customerId },\n        cancellationToken: ct\n    );\n}\n`\n---\nFurther Reading\nCore Concepts:\nPerspectives - Event-driven read models\nLenses - Query repositories\nData Access:\nEF Core Integration - Full-featured ORM\nPerspectives Storage - Read model schema design\nEvent Store - Event storage and replay\nExamples:\nECommerce: BFF Perspectives - Real-world Dapper usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15163,
        "preview": "* FROM order_summaries ORDER BY created_at DESC LIMIT @Limit \"\"\", new { Limit = limit }, cancellationToken: ct ); return orders ToArray(); } } ` Patte..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/data/efcore-integration",
    "title": "EF Core Integration",
    "category": "Data Access",
    "url": "/docs/v0.1.0/data/efcore-integration",
    "chunks": [
      {
        "id": "v0.1.0/data/efcore-integration-chunk-0",
        "text": "EF Core Integration\nEF Core is a full-featured Object-Relational Mapper (ORM) for NET, recommended for complex domain models and write operations in Whizbang applications While Dapper excels at read models, EF Core provides rich modeling capabilities, change tracking, and migrations EF Core vs Dapper\n| Feature | EF Core | Dapper |\n|---------|---------|--------|\n| Best for | Write models, complex domain logic | Read models, simple queries |\n| Performance | Slower (change tracking overhead) | ~20x faster for reads |\n| Learning curve | Complex (LINQ, migrations, tracking) | Simple (just SQL) |\n| Features | Migrations, change tracking, navigation properties | Direct SQL execution |\n| Type safety | Full LINQ type safety | SQL string-based |\n| Use in Whizbang | ‚úÖ Domain aggregates, write operations | ‚úÖ Perspectives, Lenses |\nWhizbang Philosophy: Use Dapper for reads (perspectives, lenses), EF Core for writes (domain models, commands) ---\nInstallation\n`bash\ndotnet add package Whizbang Data EFCore Postgres\n`\nIncludes:\nWhizbangDbContext - Base DbContext with conventions\nEF Core 10 x (latest version)\nNpgsql EntityFrameworkCore PostgreSQL (PostgreSQL provider)\nMigration utilities\nAdditional Tools (for migrations):\n`bash\ndotnet tool install --global dotnet-ef\n`\n---\nEF Core 10 Features\nJSONB Column Support\nEF Core 10 has native JSONB support for PostgreSQL:\n`csharp\npublic class Product {\n    public Guid Id { get; set; }\n    public string Name { get; set; } = default ;\n    // Native JSONB column\n    public ProductMetadata Metadata { get; set; } = default ;\n}\npublic class ProductMetadata {\n    public string Category { get; set; } = default ;\n    public string[] Tags { get; set; } = Array Empty<string>();\n    public Dictionary<string, string> Attributes { get; set; } = new();\n}\n// DbContext configuration\nprotected override void OnModelCreating(ModelBuilder modelBuilder) {\n    modelBuilder Entity<Product>(entity => {\n        entity",
        "startIndex": 0,
        "preview": "EF Core Integration\nEF Core is a full-featured Object-Relational Mapper (ORM) for NET, recommended for complex domain models and write operations in W..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-1",
        "text": "} public class ProductMetadata { public string Category { get; set; } = default ; public string[] Tags { get; set; } = Array Empty<string>(); public Dictionary<string, string> Attributes { get; set; } = new(); } // DbContext configuration protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder Entity<Product>(entity => { entity ToTable(\"products\");\n        // JSONB column (automatic in EF Core 10 for PostgreSQL)\n        entity OwnsOne(p => p Metadata, owned => {\n            owned ToJson();  // Stores as JSONB\n        });\n    });\n}\n`\nQuery JSONB:\n`csharp\n// Query nested JSONB properties\nvar products = await context Products Where(p => p Metadata Category == \"Electronics\") ToListAsync();\n// Query JSONB array contains\nvar products = await context Products Where(p => p Metadata Tags Contains(\"featured\")) ToListAsync();\n`\nUUIDv7 Support\nEF Core 10 with Npgsql supports UUIDv7 (time-ordered GUIDs):\n`csharp\npublic class Order {\n    public Guid Id { get; set; }  // Will be UUIDv7\n    public Guid CustomerId { get; set; }\n    public DateTimeOffset CreatedAt { get; set; }\n}\n// DbContext configuration\nprotected override void OnModelCreating(ModelBuilder modelBuilder) {\n    modelBuilder Entity<Order>(entity => {\n        entity ToTable(\"orders\");\n        entity Property(e => e Id) HasDefaultValueSql(\"uuid_generate_v7()\")  // PostgreSQL function ValueGeneratedOnAdd();\n        entity Property(e => e CreatedAt) HasDefaultValueSql(\"NOW()\");\n    });\n}\n`\nBenefits:\nTime-ordered: Natural chronological sorting\nDatabase-friendly: Sequential inserts, no index fragmentation\nTimestamp embedded: Extract creation time from ID\nComplex Types\nEF Core 10 supports complex types (value objects without separate tables):\n`csharp\npublic class Order {\n    public Guid Id { get; set; }\n    public Money Total { get; set; }  // Complex type\n    public Address ShippingAddress { get; set; }  // Complex type\n}\n[ComplexType]\npublic record Money(decimal Amount, string Currency);\n[ComplexType]\npublic record Address(\n    string Street,\n    string City,\n    string State,\n    string PostalCode\n);\n// DbContext configuration\nprotected override void OnModelCreating(ModelBuilder modelBuilder) {\n    modelBuilder",
        "startIndex": 1953,
        "preview": "} public class ProductMetadata { public string Category { get; set; } = default ; public string[] Tags { get; set; } = Array Empty<string>(); public D..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-2",
        "text": "Money Total { get; set; } // Complex type public Address ShippingAddress { get; set; } // Complex type } [ComplexType] public record Money(decimal Amount, string Currency); [ComplexType] public record Address( string Street, string City, string State, string PostalCode ); // DbContext configuration protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder Entity<Order>(entity => {\n        // Complex types map to columns: total_amount, total_currency\n        entity ComplexProperty(e => e Total);\n        // Maps to: address_street, address_city, address_state, address_postal_code\n        entity ComplexProperty(e => e ShippingAddress);\n    });\n}\n`\n---\nDbContext Setup\nBasic Configuration\n`csharp\npublic class ECommerceDbContext : DbContext {\n    public ECommerceDbContext(DbContextOptions<ECommerceDbContext> options)\n        : base(options) {\n    }\n    public DbSet<Order> Orders => Set<Order>();\n    public DbSet<Customer> Customers => Set<Customer>();\n    public DbSet<Product> Products => Set<Product>();\n    protected override void OnModelCreating(ModelBuilder modelBuilder) {\n        base OnModelCreating(modelBuilder);\n        // Apply configurations\n        modelBuilder ApplyConfigurationsFromAssembly(typeof(ECommerceDbContext) Assembly);\n    }\n}\n`\nEntity Type Configuration\n`csharp\npublic class OrderConfiguration : IEntityTypeConfiguration<Order> {\n    public void Configure(EntityTypeBuilder<Order> builder) {\n        builder ToTable(\"orders\");\n        builder HasKey(e => e Id);\n        builder Property(e => e Id) HasDefaultValueSql(\"uuid_generate_v7()\") ValueGeneratedOnAdd();\n        builder Property(e => e CustomerId) IsRequired();\n        builder Property(e => e Status) HasMaxLength(50) IsRequired();\n        builder Property(e => e Total) HasPrecision(18, 2)  // decimal(18,2) IsRequired();\n        builder Property(e => e CreatedAt) HasDefaultValueSql(\"NOW()\") ValueGeneratedOnAdd();\n        // Navigation properties\n        builder HasOne(e => e Customer) WithMany(c => c Orders) HasForeignKey(e => e CustomerId) OnDelete(DeleteBehavior Restrict);\n        builder HasMany(e => e Items) WithOne() HasForeignKey(\"OrderId\") OnDelete(DeleteBehavior Cascade);\n    }\n}\n`\nRegistration (Program cs)\n`csharp\nvar connectionString = builder Configuration GetConnectionString(\"DefaultConnection\") ;\nbuilder Services AddDbContext<ECommerceDbContext>(options => {\n    options UseNpgsql(connectionString, npgsqlOptions => {\n        npgsqlOptions MigrationsAssembly(\"ECommerce Infrastructure\");\n        npgsqlOptions UseQuerySplittingBehavior(QuerySplittingBehavior SplitQuery);\n    });\n    // Development settings\n    if (builder Environment IsDevelopment()) {\n        options EnableSensitiveDataLogging();\n        options EnableDetailedErrors();\n    }\n});\n`\n---\nMigrations\nCreating Migrations\n`bash\nAdd new migration\ndotnet ef migrations add InitialCreate --project src/ECommerce Infrastructure --startup-project src/ECommerce API\nApply migrations to database\ndotnet ef database update --project src/ECommerce Infrastructure --startup-project src/ECommerce",
        "startIndex": 3876,
        "preview": "Money Total { get; set; } // Complex type public Address ShippingAddress { get; set; } // Complex type } [ComplexType] public record Money(decimal Amo..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-3",
        "text": "UseQuerySplittingBehavior(QuerySplittingBehavior SplitQuery); }); // Development settings if (builder Environment IsDevelopment()) { options EnableSensitiveDataLogging(); options EnableDetailedErrors(); } }); ` --- Migrations Creating Migrations `bash Add new migration dotnet ef migrations add InitialCreate --project src/ECommerce Infrastructure --startup-project src/ECommerce API Apply migrations to database dotnet ef database update --project src/ECommerce Infrastructure --startup-project src/ECommerce API\nRemove last migration (if not applied)\ndotnet ef migrations remove --project src/ECommerce Infrastructure --startup-project src/ECommerce API\nList all migrations\ndotnet ef migrations list --project src/ECommerce Infrastructure --startup-project src/ECommerce API\n`\nMigration Example\n`csharp\npublic partial class InitialCreate : Migration {\n    protected override void Up(MigrationBuilder migrationBuilder) {\n        // Enable UUIDv7 extension\n        migrationBuilder Sql(\"CREATE EXTENSION IF NOT EXISTS \\\"uuid-ossp\\\";\");\n        migrationBuilder CreateTable(\n            name: \"orders\",\n            columns: table => new {\n                id = table Column<Guid>(nullable: false, defaultValueSql: \"uuid_generate_v7()\"),\n                customer_id = table Column<Guid>(nullable: false),\n                total = table Column<decimal>(type: \"decimal(18,2)\", nullable: false),\n                status = table Column<string>(maxLength: 50, nullable: false),\n                created_at = table Column<DateTimeOffset>(nullable: false, defaultValueSql: \"NOW()\")\n            },\n            constraints: table => {\n                table PrimaryKey(\"pk_orders\", x => x id);\n            }\n        );\n        migrationBuilder CreateIndex(\n            name: \"ix_orders_customer_id\",\n            table: \"orders\",\n            column: \"customer_id\"\n        );\n        migrationBuilder CreateIndex(\n            name: \"ix_orders_created_at\",\n            table: \"orders\",\n            column: \"created_at\"\n        );\n    }\n    protected override void Down(MigrationBuilder migrationBuilder) {\n        migrationBuilder DropTable(name: \"orders\");\n    }\n}\n`\nApply Migrations at Startup\n`csharp\n// Program cs - Apply migrations on startup (Development only)\nif (app Environment IsDevelopment()) {\n    using var scope = app Services CreateScope();\n    var context = scope ServiceProvider GetRequiredService<ECommerceDbContext>();\n    await context Database MigrateAsync();  // Apply pending migrations\n}\n`\n---\nBasic Usage\nInsert\n`csharp\npublic class OrderService {\n    private readonly ECommerceDbContext _context;\n    public async Task<Order> CreateOrderAsync(\n        Guid customerId,\n        OrderItem[] items,\n        CancellationToken ct = default) {\n        var order = new Order {\n            CustomerId = customerId,\n            Status = \"Created\",\n            Total = items Sum(i => i UnitPrice * i Quantity),\n            CreatedAt = DateTimeOffset",
        "startIndex": 6785,
        "preview": "UseQuerySplittingBehavior(QuerySplittingBehavior SplitQuery); }); // Development settings if (builder Environment IsDevelopment()) { options EnableSen..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-4",
        "text": "Basic Usage Insert `csharp public class OrderService { private readonly ECommerceDbContext _context; public async Task<Order> CreateOrderAsync( Guid customerId, OrderItem[] items, CancellationToken ct = default) { var order = new Order { CustomerId = customerId, Status = \"Created\", Total = items Sum(i => i UnitPrice * i Quantity), CreatedAt = DateTimeOffset UtcNow\n        };\n        // Add order items\n        foreach (var item in items) {\n            order Items Add(new OrderItem {\n                ProductId = item ProductId,\n                Quantity = item Quantity,\n                UnitPrice = item UnitPrice\n            });\n        }\n        _context Orders Add(order);\n        await _context SaveChangesAsync(ct);\n        return order;\n    }\n}\n`\nQuery\n`csharp\npublic async Task<Order > GetOrderAsync(\n    Guid orderId,\n    CancellationToken ct = default) {\n    return await _context Orders Include(o => o Items)  // Eager load items Include(o => o Customer)  // Eager load customer FirstOrDefaultAsync(o => o Id == orderId, ct);\n}\npublic async Task<Order[]> GetOrdersByCustomerAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    return await _context Orders Where(o => o CustomerId == customerId) OrderByDescending(o => o CreatedAt) ToArrayAsync(ct);\n}\n`\nUpdate\n`csharp\npublic async Task UpdateOrderStatusAsync(\n    Guid orderId,\n    string newStatus,\n    CancellationToken ct = default) {\n    var order = await _context Orders FirstOrDefaultAsync(o => o Id == orderId, ct);\n    if (order is null) {\n        throw new NotFoundException($\"Order {orderId} not found\");\n    }\n    order Status = newStatus;\n    order UpdatedAt = DateTimeOffset UtcNow;\n    await _context SaveChangesAsync(ct);\n}\n`\nDelete\n`csharp\npublic async Task DeleteOrderAsync(\n    Guid orderId,\n    CancellationToken ct = default) {\n    var order = await _context Orders FirstOrDefaultAsync(o => o Id == orderId, ct);\n    if (order is not null) {\n        _context Orders Remove(order);\n        await _context SaveChangesAsync(ct);\n    }\n}\n`\n---\nAdvanced Querying\nPagination\n`csharp\npublic async Task<PagedResult<Order>> GetOrdersPagedAsync(\n    int pageNumber,\n    int pageSize,\n    CancellationToken ct = default) {\n    var query = _context Orders OrderByDescending(o => o CreatedAt);\n    var total = await query CountAsync(ct);\n    var orders = await query Skip((pageNumber - 1) * pageSize)",
        "startIndex": 9222,
        "preview": "Basic Usage Insert `csharp public class OrderService { private readonly ECommerceDbContext _context; public async Task<Order> CreateOrderAsync( Guid c..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-5",
        "text": "Remove(order); await _context SaveChangesAsync(ct); } } ` --- Advanced Querying Pagination `csharp public async Task<PagedResult<Order>> GetOrdersPagedAsync( int pageNumber, int pageSize, CancellationToken ct = default) { var query = _context Orders OrderByDescending(o => o CreatedAt); var total = await query CountAsync(ct); var orders = await query Skip((pageNumber - 1) * pageSize) Take(pageSize) ToArrayAsync(ct);\n    return new PagedResult<Order> {\n        Items = orders,\n        TotalCount = total,\n        PageNumber = pageNumber,\n        PageSize = pageSize\n    };\n}\n`\nSearch\n`csharp\npublic async Task<Order[]> SearchOrdersAsync(\n    string searchTerm,\n    CancellationToken ct = default) {\n    return await _context Orders Include(o => o Customer) Where(o =>\n            o Id ToString() Contains(searchTerm) ||\n            o Customer Name Contains(searchTerm) ||\n            o Customer Email Contains(searchTerm)\n        ) OrderByDescending(o => o CreatedAt) Take(100) ToArrayAsync(ct);\n}\n`\nAggregations\n`csharp\npublic async Task<OrderStatistics> GetOrderStatisticsAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    var stats = await _context Orders Where(o => o CustomerId == customerId) GroupBy(o => o CustomerId) Select(g => new OrderStatistics {\n            TotalOrders = g Count(),\n            TotalSpent = g Sum(o => o Total),\n            AverageOrderValue = g Average(o => o Total),\n            LastOrderDate = g Max(o => o CreatedAt)\n        }) FirstOrDefaultAsync(ct);\n    return stats new OrderStatistics();\n}\n`\nRaw SQL Queries\n`csharp\npublic async Task<OrderSummary[]> GetTopCustomersAsync(\n    int limit,\n    CancellationToken ct = default) {\n    return await _context Database SqlQuery<OrderSummary>($\"\"\"\n            SELECT\n                customer_id AS CustomerId,\n                COUNT(*) AS TotalOrders,\n                SUM(total) AS TotalSpent\n            FROM orders\n            GROUP BY customer_id\n            ORDER BY SUM(total) DESC\n            LIMIT {limit}\n        \"\"\") ToArrayAsync(ct);\n}\n`\n---\nTransactions\nExplicit Transactions\n`csharp\npublic async Task TransferInventoryAsync(\n    Guid fromWarehouseId,\n    Guid toWarehouseId,\n    Guid productId,\n    int quantity,\n    CancellationToken ct = default) {\n    await using var transaction = await _context Database BeginTransactionAsync(ct);\n    try {\n        // Deduct from source warehouse\n        var fromInventory = await _context Inventory FirstAsync(i => i WarehouseId == fromWarehouseId && i ProductId == productId, ct);\n        fromInventory Available -= quantity;\n        // Add to destination warehouse\n        var toInventory = await _context Inventory",
        "startIndex": 11348,
        "preview": "Remove(order); await _context SaveChangesAsync(ct); } } ` --- Advanced Querying Pagination `csharp public async Task<PagedResult<Order>> GetOrdersPage..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-6",
        "text": "{ await using var transaction = await _context Database BeginTransactionAsync(ct); try { // Deduct from source warehouse var fromInventory = await _context Inventory FirstAsync(i => i WarehouseId == fromWarehouseId && i ProductId == productId, ct); fromInventory Available -= quantity; // Add to destination warehouse var toInventory = await _context Inventory FirstAsync(i => i WarehouseId == toWarehouseId && i ProductId == productId, ct);\n        toInventory Available += quantity;\n        await _context SaveChangesAsync(ct);\n        await transaction CommitAsync(ct);\n    } catch {\n        await transaction RollbackAsync(ct);\n        throw;\n    }\n}\n`\nImplicit Transactions\n`csharp\n// SaveChangesAsync wraps all changes in a transaction automatically\npublic async Task CreateOrderWithItemsAsync(\n    Order order,\n    OrderItem[] items,\n    CancellationToken ct = default) {\n    _context Orders Add(order);\n    foreach (var item in items) {\n        order Items Add(item);  // EF tracks relationship\n    }\n    await _context SaveChangesAsync(ct);  // ‚Üê Atomic transaction\n}\n`\n---\nChange Tracking\nNo-Tracking Queries\nUse AsNoTracking() for read-only queries (better performance):\n`csharp\n// ‚úÖ Read-only query (no change tracking overhead)\npublic async Task<Order[]> GetOrdersForDisplayAsync(CancellationToken ct = default) {\n    return await _context Orders AsNoTracking()  // ‚Üê No change tracking Include(o => o Items) ToArrayAsync(ct);\n}\n// ‚ùå Change tracking enabled (slower)\npublic async Task<Order[]> GetOrdersAsync(CancellationToken ct = default) {\n    return await _context Orders Include(o => o Items) ToArrayAsync(ct);  // EF tracks all entities for changes\n}\n`\nTracking State\n`csharp\npublic void DemoTrackingStates() {\n    var order = new Order { / / };\n    // EntityState Detached (not tracked)\n    Console WriteLine(_context Entry(order) State);  // Detached\n    _context Orders Add(order);\n    // EntityState Added (will INSERT on SaveChanges)\n    Console WriteLine(_context Entry(order) State);  // Added\n    _context SaveChanges();\n    // EntityState Unchanged (no pending changes)\n    Console WriteLine(_context Entry(order) State);  // Unchanged\n    order Status = \"Shipped\";\n    // EntityState Modified (will UPDATE on SaveChanges)\n    Console WriteLine(_context Entry(order) State);  // Modified\n    _context Orders Remove(order);\n    // EntityState Deleted (will DELETE on SaveChanges)\n    Console WriteLine(_context Entry(order)",
        "startIndex": 13536,
        "preview": "{ await using var transaction = await _context Database BeginTransactionAsync(ct); try { // Deduct from source warehouse var fromInventory = await _co..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-7",
        "text": "Console WriteLine(_context Entry(order) State); // Added _context SaveChanges(); // EntityState Unchanged (no pending changes) Console WriteLine(_context Entry(order) State); // Unchanged order Status = \"Shipped\"; // EntityState Modified (will UPDATE on SaveChanges) Console WriteLine(_context Entry(order) State); // Modified _context Orders Remove(order); // EntityState Deleted (will DELETE on SaveChanges) Console WriteLine(_context Entry(order) State);  // Deleted\n}\n`\n---\nPerformance Patterns\nSplit Queries\n`csharp\n// ‚úÖ Split query (multiple queries, better for large data)\nvar orders = await _context Orders Include(o => o Items) Include(o => o Customer) AsSplitQuery()  // ‚Üê Executes 3 queries (orders, items, customers) ToListAsync();\n// ‚ùå Single query (cartesian explosion for large data)\nvar orders = await _context Orders Include(o => o Items) Include(o => o Customer) AsSingleQuery()  // ‚Üê Executes 1 query with JOINs ToListAsync();\n`\nWhen to use:\nSplit Query: Multiple includes, large result sets\nSingle Query: Few includes, small result sets\nBatch Operations\n`csharp\n// ‚úÖ Batch insert (single SaveChanges)\npublic async Task BulkInsertOrdersAsync(Order[] orders, CancellationToken ct = default) {\n    _context Orders AddRange(orders);\n    await _context SaveChangesAsync(ct);  // Single database roundtrip\n}\n// ‚ùå Loop insert (multiple SaveChanges)\npublic async Task SlowInsertOrdersAsync(Order[] orders, CancellationToken ct = default) {\n    foreach (var order in orders) {\n        _context Orders Add(order);\n        await _context SaveChangesAsync(ct);  // N database roundtrips }\n}\n`\nCompiled Queries\n`csharp\n// Compiled query (cached expression tree)\nprivate static readonly Func<ECommerceDbContext, Guid, Task<Order >> GetOrderByIdQuery =\n    EF CompileAsyncQuery(\n        (ECommerceDbContext context, Guid orderId) =>\n            context Orders Include(o => o Items) FirstOrDefault(o => o Id == orderId)\n    );\npublic async Task<Order > GetOrderFastAsync(Guid orderId) {\n    return await GetOrderByIdQuery(_context, orderId);\n}\n`\nBenefit: Expression tree compiled once, reused on every call ---\nTesting\nIn-Memory Provider\n`csharp\npublic class OrderServiceTests {\n    private ECommerceDbContext CreateInMemoryContext() {\n        var options = new DbContextOptionsBuilder<ECommerceDbContext>() UseInMemoryDatabase(databaseName: Guid NewGuid() ToString())",
        "startIndex": 15909,
        "preview": "Console WriteLine(_context Entry(order) State); // Added _context SaveChanges(); // EntityState Unchanged (no pending changes) Console WriteLine(_cont..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-8",
        "text": "=> o Id == orderId) ); public async Task<Order > GetOrderFastAsync(Guid orderId) { return await GetOrderByIdQuery(_context, orderId); } ` Benefit: Expression tree compiled once, reused on every call --- Testing In-Memory Provider `csharp public class OrderServiceTests { private ECommerceDbContext CreateInMemoryContext() { var options = new DbContextOptionsBuilder<ECommerceDbContext>() UseInMemoryDatabase(databaseName: Guid NewGuid() ToString()) Options;\n        return new ECommerceDbContext(options);\n    }\n    [Test]\n    public async Task CreateOrderAsync_ValidOrder_CreatesOrderAsync() {\n        // Arrange\n        await using var context = CreateInMemoryContext();\n        var service = new OrderService(context);\n        var items = new[] {\n            new OrderItem { ProductId = Guid NewGuid(), Quantity = 2, UnitPrice = 10 00m }\n        };\n        // Act\n        var order = await service CreateOrderAsync(Guid NewGuid(), items);\n        // Assert\n        await Assert That(order Id) IsNotEqualTo(Guid Empty);\n        await Assert That(order Items) HasCount() EqualTo(1);\n        await Assert That(context Orders) HasCount() EqualTo(1);\n    }\n}\n`\nSQLite Provider (Better for Testing)\n`csharp\npublic class OrderServiceTests {\n    private ECommerceDbContext CreateSqliteContext() {\n        var connection = new SqliteConnection(\"DataSource=:memory:\");\n        connection Open();\n        var options = new DbContextOptionsBuilder<ECommerceDbContext>() UseSqlite(connection) Options;\n        var context = new ECommerceDbContext(options);\n        context Database EnsureCreated();  // Create schema\n        return context;\n    }\n    [Test]\n    public async Task GetOrderAsync_ExistingOrder_ReturnsOrderAsync() {\n        // Arrange\n        await using var context = CreateSqliteContext();\n        var order = new Order {\n            Id = Guid NewGuid(),\n            CustomerId = Guid NewGuid(),\n            Status = \"Created\",\n            Total = 100 00m,\n            CreatedAt = DateTimeOffset UtcNow\n        };\n        context Orders Add(order);\n        await context SaveChangesAsync();\n        var service = new OrderService(context);\n        // Act\n        var result = await service GetOrderAsync(order Id);\n        // Assert\n        await Assert That(result) IsNotNull();\n        await Assert That(result Id) IsEqualTo(order Id);\n    }\n}\n`\nWhy SQLite More accurate for testing (real SQL, constraints, indexes) Integration Tests with PostgreSQL\n`csharp\npublic class OrderServiceIntegrationTests {\n    private ECommerceDbContext _context = default ;\n    [Before(Test)]\n    public async Task SetupAsync() {\n        var connectionString = \"Host=localhost;Database=whizbang_test;Username=postgres;Password=test\";\n        var options = new DbContextOptionsBuilder<ECommerceDbContext>() UseNpgsql(connectionString) Options;\n        _context = new ECommerceDbContext(options);\n        // Recreate database for clean slate\n        await _context Database",
        "startIndex": 17938,
        "preview": "=> o Id == orderId) ); public async Task<Order > GetOrderFastAsync(Guid orderId) { return await GetOrderByIdQuery(_context, orderId); } ` Benefit: Exp..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-9",
        "text": "testing (real SQL, constraints, indexes) Integration Tests with PostgreSQL `csharp public class OrderServiceIntegrationTests { private ECommerceDbContext _context = default ; [Before(Test)] public async Task SetupAsync() { var connectionString = \"Host=localhost;Database=whizbang_test;Username=postgres;Password=test\"; var options = new DbContextOptionsBuilder<ECommerceDbContext>() UseNpgsql(connectionString) Options; _context = new ECommerceDbContext(options); // Recreate database for clean slate await _context Database EnsureDeletedAsync();\n        await _context Database EnsureCreatedAsync();\n    }\n    [After(Test)]\n    public async Task TeardownAsync() {\n        await _context DisposeAsync();\n    }\n    [Test]\n    public async Task CreateOrderAsync_WithRealDatabase_PersistsOrderAsync() {\n        // Arrange\n        var service = new OrderService(_context);\n        var items = new[] {\n            new OrderItem { ProductId = Guid NewGuid(), Quantity = 2, UnitPrice = 10 00m }\n        };\n        // Act\n        var order = await service CreateOrderAsync(Guid NewGuid(), items);\n        // Assert\n        await Assert That(order Id) IsNotEqualTo(Guid Empty);\n        // Verify in database\n        var savedOrder = await _context Orders Include(o => o Items) FirstOrDefaultAsync(o => o Id == order Id);\n        await Assert That(savedOrder) IsNotNull();\n        await Assert That(savedOrder Items) HasCount() EqualTo(1);\n    }\n}\n`\n---\nEF Core vs Dapper: When to Use What\nUse EF Core When:\n‚úÖ Write operations (commands, domain logic)\n‚úÖ Complex domain models with rich relationships\n‚úÖ Change tracking needed (detecting modifications)\n‚úÖ Navigation properties simplify code\n‚úÖ Migrations for schema evolution\n‚úÖ Type-safe queries via LINQ\nUse Dapper When:\n‚úÖ Read operations (perspectives, lenses)\n‚úÖ High performance required (~20x faster than EF Core)\n‚úÖ Simple queries without complex relationships\n‚úÖ SQL control needed (optimization, PostgreSQL-specific features)\n‚úÖ Denormalized read models (no navigation properties)\nHybrid Approach (Recommended)\n`csharp\n// ‚úÖ EF Core for write model (domain aggregates)\npublic class OrderService {\n    private readonly ECommerceDbContext _context;\n    public async Task<Order> CreateOrderAsync(CreateOrderCommand cmd) {\n        var order = new Order(cmd CustomerId, cmd Items);\n        _context Orders Add(order);\n        await _context",
        "startIndex": 20504,
        "preview": "testing (real SQL, constraints, indexes) Integration Tests with PostgreSQL `csharp public class OrderServiceIntegrationTests { private ECommerceDbCont..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-10",
        "text": "(optimization, PostgreSQL-specific features) ‚úÖ Denormalized read models (no navigation properties) Hybrid Approach (Recommended) `csharp // ‚úÖ EF Core for write model (domain aggregates) public class OrderService { private readonly ECommerceDbContext _context; public async Task<Order> CreateOrderAsync(CreateOrderCommand cmd) { var order = new Order(cmd CustomerId, cmd Items); _context Orders Add(order); await _context SaveChangesAsync();\n        return order;\n    }\n}\n// ‚úÖ Dapper for read model (perspectives/lenses)\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public async Task<OrderSummary[]> GetRecentOrdersAsync(int limit) {\n        await using var conn = _db CreateConnection();\n        var orders = await conn QueryAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries ORDER BY created_at DESC LIMIT @Limit\",\n            new { Limit = limit }\n        );\n        return orders ToArray();\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use DbContext per request (scoped lifetime)\n‚úÖ Use AsNoTracking() for read-only queries\n‚úÖ Use AsSplitQuery() for multiple includes\n‚úÖ Use migrations for schema changes\n‚úÖ Use IEntityTypeConfiguration for entity config\n‚úÖ Use UUIDv7 for primary keys\n‚úÖ Use JSONB for complex nested data\n‚úÖ Use complex types for value objects\n‚úÖ Use compiled queries for hot paths\n‚úÖ Use batch operations (AddRange, RemoveRange)\nDON'T ‚ùå\n‚ùå Reuse DbContext across requests (not thread-safe)\n‚ùå Use change tracking for read-only queries\n‚ùå Use EF Core for high-performance read models (use Dapper)\n‚ùå Manually write SQL migrations (use dotnet ef migrations add)\n‚ùå Use Guid NewGuid() for primary keys (use UUIDv7)\n‚ùå Call SaveChanges() in loops (batch instead)\n‚ùå Use Include() for every query (consider projections)\n‚ùå Ignore N+1 query problems (use Include or SplitQuery)\n---\nCommon Patterns\nPattern 1: Command Handler with EF Core\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly ECommerceDbContext _context;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        var order = new Order {\n            CustomerId = message",
        "startIndex": 22382,
        "preview": "(optimization, PostgreSQL-specific features) ‚úÖ Denormalized read models (no navigation properties) Hybrid Approach (Recommended) `csharp // ‚úÖ EF Core ..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-11",
        "text": "Ignore N+1 query problems (use Include or SplitQuery) --- Common Patterns Pattern 1: Command Handler with EF Core `csharp public class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> { private readonly ECommerceDbContext _context; public async ValueTask<OrderCreated> HandleAsync( CreateOrder message, CancellationToken ct = default) { var order = new Order { CustomerId = message CustomerId,\n            Status = \"Created\",\n            Total = message Items Sum(i => i UnitPrice * i Quantity),\n            CreatedAt = DateTimeOffset UtcNow\n        };\n        foreach (var item in message Items) {\n            order Items Add(new OrderItem {\n                ProductId = item ProductId,\n                Quantity = item Quantity,\n                UnitPrice = item UnitPrice\n            });\n        }\n        _context Orders Add(order);\n        await _context SaveChangesAsync(ct);\n        return new OrderCreated(\n            OrderId: order Id,\n            CustomerId: order CustomerId,\n            Total: order Total,\n            CreatedAt: order CreatedAt\n        );\n    }\n}\n`\nPattern 2: Query with Projection\n`csharp\npublic async Task<OrderListItem[]> GetOrderListAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    return await _context Orders Where(o => o CustomerId == customerId) OrderByDescending(o => o CreatedAt) Select(o => new OrderListItem {\n            OrderId = o Id,\n            Total = o Total,\n            Status = o Status,\n            CreatedAt = o CreatedAt,\n            ItemCount = o Items Count\n        }) ToArrayAsync(ct);\n}\n`\nBenefit: Projection avoids loading full entities (faster, less memory) Pattern 3: Optimistic Concurrency\n`csharp\npublic class Order {\n    public Guid Id { get; set; }\n    public string Status { get; set; } = default ;\n    [Timestamp]\n    public byte[] RowVersion { get; set; } = Array Empty<byte>();  // Concurrency token\n}\npublic async Task UpdateOrderStatusAsync(Guid orderId, string newStatus) {\n    var order = await _context Orders FirstAsync(o => o Id == orderId);\n    order Status = newStatus;\n    try {\n        await _context",
        "startIndex": 24168,
        "preview": "Ignore N+1 query problems (use Include or SplitQuery) --- Common Patterns Pattern 1: Command Handler with EF Core `csharp public class CreateOrderRece..."
      },
      {
        "id": "v0.1.0/data/efcore-integration-chunk-12",
        "text": "{ get; set; } = default ; [Timestamp] public byte[] RowVersion { get; set; } = Array Empty<byte>(); // Concurrency token } public async Task UpdateOrderStatusAsync(Guid orderId, string newStatus) { var order = await _context Orders FirstAsync(o => o Id == orderId); order Status = newStatus; try { await _context SaveChangesAsync();\n    } catch (DbUpdateConcurrencyException) {\n        // Row was modified by another process\n        throw new ConcurrencyException(\"Order was modified by another user\");\n    }\n}\n`\n---\nFurther Reading\nCore Concepts:\nPerspectives - Event-driven read models\nLenses - Query repositories\nReceptors - Message handlers\nData Access:\nDapper Integration - Lightweight data access\nPerspectives Storage - Read model schema design\nEvent Store - Event storage and replay\nExamples:\nECommerce: Order Service - EF Core in practice\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 25924,
        "preview": "{ get; set; } = default ; [Timestamp] public byte[] RowVersion { get; set; } = Array Empty<byte>(); // Concurrency token } public async Task UpdateOrd..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/data/event-store",
    "title": "Event Store",
    "category": "Data Access",
    "url": "/docs/v0.1.0/data/event-store",
    "chunks": [
      {
        "id": "v0.1.0/data/event-store-chunk-0",
        "text": "Event Store\nThe Event Store is the append-only log of all domain events in your system It provides event sourcing capabilities, stream-based processing, and time-travel queries for rebuilding read models from any point in history Event Sourcing Fundamentals\nEvent Sourcing stores state changes as a sequence of events rather than current state:\n`\nTraditional State Storage:        Event Sourcing:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Order Table         ‚îÇ         ‚îÇ  Event Stream        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ order_id: abc        ‚îÇ         ‚îÇ OrderCreated         ‚îÇ\n‚îÇ status: Shipped      ‚îÇ   ‚Üê‚îÄ‚îÄ   ‚îÇ OrderPaid            ‚îÇ\n‚îÇ total: $100          ‚îÇ         ‚îÇ OrderShipped         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  (current state)                  (full history)\n`\nBenefits:\nComplete Audit Trail: Every state change recorded forever\nTemporal Queries: \"What was the order status at 2PM yesterday \"\nReplay: Rebuild read models from events\nDebugging: Reproduce exact system state for troubleshooting\nAnalytics: Mine event history for business insights\n---\nEvent Stream Schema\nCore Tables\n`sql\n-- Event stream (append-only)\nCREATE TABLE wh_events (\n    event_id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),  -- Time-ordered\n    stream_id UUID NOT NULL,                               -- Aggregate/entity ID\n    stream_type VARCHAR(200) NOT NULL,                     -- 'Order', 'Customer', etc event_type VARCHAR(200) NOT NULL,                      -- 'OrderCreated', 'OrderShipped', etc event_data JSONB NOT NULL,                             -- Event payload\n    event_metadata JSONB DEFAULT '{}',                     -- Context (user, tenant, correlation)\n    sequence_number BIGINT NOT NULL,                       -- Position in stream (1, 2, 3,",
        "startIndex": 0,
        "preview": "Event Store\nThe Event Store is the append-only log of all domain events in your system It provides event sourcing capabilities, stream-based processin..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-1",
        "text": "stream_id UUID NOT NULL, -- Aggregate/entity ID stream_type VARCHAR(200) NOT NULL, -- 'Order', 'Customer', etc event_type VARCHAR(200) NOT NULL, -- 'OrderCreated', 'OrderShipped', etc event_data JSONB NOT NULL, -- Event payload event_metadata JSONB DEFAULT '{}', -- Context (user, tenant, correlation) sequence_number BIGINT NOT NULL, -- Position in stream (1, 2, 3, )\n    global_sequence BIGSERIAL NOT NULL UNIQUE,             -- Global ordering across all streams\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    -- Composite unique constraint (one sequence per stream)\n    CONSTRAINT uq_stream_sequence UNIQUE (stream_id, sequence_number)\n);\n-- Indexes\nCREATE INDEX idx_events_stream_id ON wh_events (stream_id, sequence_number);\nCREATE INDEX idx_events_stream_type ON wh_events (stream_type);\nCREATE INDEX idx_events_event_type ON wh_events (event_type);\nCREATE INDEX idx_events_timestamp ON wh_events (timestamp DESC);\nCREATE INDEX idx_events_global_sequence ON wh_events (global_sequence);\n`\nKey Design Decisions:\nUUIDv7 for event_id: Time-ordered, insert-friendly\nsequence_number: Position within a single stream (1, 2, 3, )\nglobal_sequence: Total ordering across all streams (for projections)\nJSONB for event_data: Flexible schema, queryable\nstream_type: Partition by aggregate type (Order, Customer, Product, etc",
        "startIndex": 1849,
        "preview": "stream_id UUID NOT NULL, -- Aggregate/entity ID stream_type VARCHAR(200) NOT NULL, -- 'Order', 'Customer', etc event_type VARCHAR(200) NOT NULL, -- 'O..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-2",
        "text": "(timestamp DESC); CREATE INDEX idx_events_global_sequence ON wh_events (global_sequence); ` Key Design Decisions: UUIDv7 for event_id: Time-ordered, insert-friendly sequence_number: Position within a single stream (1, 2, 3, ) global_sequence: Total ordering across all streams (for projections) JSONB for event_data: Flexible schema, queryable stream_type: Partition by aggregate type (Order, Customer, Product, etc )\n---\nEvent Processing Tracking\n`sql\n-- Receptor processing (log-style tracking)\nCREATE TABLE wh_receptor_processing (\n    event_id UUID NOT NULL,\n    receptor_name VARCHAR(200) NOT NULL,\n    status VARCHAR(50) NOT NULL,  -- 'Processed', 'Failed', 'Skipped'\n    processed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    error TEXT,\n    PRIMARY KEY (event_id, receptor_name),\n    FOREIGN KEY (event_id) REFERENCES wh_events (event_id) ON DELETE CASCADE\n);\nCREATE INDEX idx_receptor_processing_status ON wh_receptor_processing (status);\n-- Perspective checkpoints (stream-based projections)\nCREATE TABLE wh_perspective_checkpoints (\n    stream_id UUID NOT NULL,\n    perspective_name VARCHAR(200) NOT NULL,\n    last_event_id UUID NOT NULL,\n    last_sequence_number BIGINT NOT NULL,\n    status VARCHAR(50) NOT NULL,  -- 'UpToDate', 'Rebuilding', 'Failed'\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    error TEXT,\n    PRIMARY KEY (stream_id, perspective_name),\n    FOREIGN KEY (last_event_id) REFERENCES wh_events (event_id) ON DELETE CASCADE\n);\nCREATE INDEX idx_perspective_checkpoints_perspective ON wh_perspective_checkpoints (perspective_name);\nCREATE INDEX idx_perspective_checkpoints_status ON wh_perspective_checkpoints (status);\n`\nDesign Differences:\n| Aspect | Receptors (wh_receptor_processing) | Perspectives (wh_perspective_checkpoints) |\n|--------|-------------------------------------|------------------------------------------|\n| Tracking | Per event + receptor | Per stream + perspective |\n| Ordering | No ordering (parallel) | Ordered within stream |\n| Use Case | Side effects, notifications | Read model projections |\n| Replay | Re-process individual events | Rebuild from checkpoint |\n---\nAppending Events\nBasic Event Storage\n`csharp\npublic class EventStore : IEventStore {\n    private readonly IDbConnectionFactory _db;\n    public async Task<Guid> AppendAsync(\n        Guid streamId,\n        string streamType,\n        string eventType,\n        object eventData,\n        Dictionary<string, object> metadata = null,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Get next sequence number for stream\n        var nextSequence = await conn",
        "startIndex": 2863,
        "preview": "(timestamp DESC); CREATE INDEX idx_events_global_sequence ON wh_events (global_sequence); ` Key Design Decisions: UUIDv7 for event_id: Time-ordered, i..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-3",
        "text": "class EventStore : IEventStore { private readonly IDbConnectionFactory _db; public async Task<Guid> AppendAsync( Guid streamId, string streamType, string eventType, object eventData, Dictionary<string, object> metadata = null, CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Get next sequence number for stream var nextSequence = await conn QuerySingleAsync<long>(\n            \"SELECT COALESCE(MAX(sequence_number), 0) + 1 FROM wh_events WHERE stream_id = @StreamId\",\n            new { StreamId = streamId }\n        );\n        var eventId = Guid CreateVersion7();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO wh_events (\n                event_id, stream_id, stream_type, event_type, event_data, event_metadata, sequence_number, timestamp\n            ) VALUES (\n                @EventId, @StreamId, @StreamType, @EventType, @EventData::jsonb, @EventMetadata::jsonb, @SequenceNumber, @Timestamp\n            )\n            \"\"\",\n            new {\n                EventId = eventId,\n                StreamId = streamId,\n                StreamType = streamType,\n                EventType = eventType,\n                EventData = JsonSerializer Serialize(eventData),\n                EventMetadata = JsonSerializer Serialize(metadata new Dictionary<string, object>()),\n                SequenceNumber = nextSequence,\n                Timestamp = DateTimeOffset UtcNow\n            },\n            cancellationToken: ct\n        );\n        return eventId;\n    }\n}\n`\nOptimistic Concurrency (Expected Version)\n`csharp\npublic async Task<Guid> AppendAsync(\n    Guid streamId,\n    string streamType,\n    string eventType,\n    object eventData,\n    long expectedVersion = null,  // ‚Üê Optimistic concurrency\n    Dictionary<string, object> metadata = null,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn OpenAsync(ct);\n    await using var transaction = await conn BeginTransactionAsync(ct);\n    try {\n        // Get current version\n        var currentVersion = await conn QuerySingleOrDefaultAsync<long >(\n            \"SELECT MAX(sequence_number) FROM wh_events WHERE stream_id = @StreamId\",\n            new { StreamId = streamId },\n            transaction: transaction\n        );\n        var actualVersion = currentVersion 0;\n        // Check expected version\n        if (expectedVersion HasValue && actualVersion = expectedVersion Value) {\n            throw new ConcurrencyException(\n                $\"Stream {streamId} expected version {expectedVersion}, but was {actualVersion}\"\n            );\n        }\n        var nextSequence = actualVersion + 1;\n        var eventId = Guid CreateVersion7();\n        await conn",
        "startIndex": 5080,
        "preview": "class EventStore : IEventStore { private readonly IDbConnectionFactory _db; public async Task<Guid> AppendAsync( Guid streamId, string streamType, str..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-4",
        "text": "= streamId }, transaction: transaction ); var actualVersion = currentVersion 0; // Check expected version if (expectedVersion HasValue && actualVersion = expectedVersion Value) { throw new ConcurrencyException( $\"Stream {streamId} expected version {expectedVersion}, but was {actualVersion}\" ); } var nextSequence = actualVersion + 1; var eventId = Guid CreateVersion7(); await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO wh_events (\n                event_id, stream_id, stream_type, event_type, event_data, event_metadata, sequence_number, timestamp\n            ) VALUES (\n                @EventId, @StreamId, @StreamType, @EventType, @EventData::jsonb, @EventMetadata::jsonb, @SequenceNumber, @Timestamp\n            )\n            \"\"\",\n            new {\n                EventId = eventId,\n                StreamId = streamId,\n                StreamType = streamType,\n                EventType = eventType,\n                EventData = JsonSerializer Serialize(eventData),\n                EventMetadata = JsonSerializer Serialize(metadata new Dictionary<string, object>()),\n                SequenceNumber = nextSequence,\n                Timestamp = DateTimeOffset UtcNow\n            },\n            transaction: transaction,\n            cancellationToken: ct\n        );\n        await transaction CommitAsync(ct);\n        return eventId;\n    } catch {\n        await transaction RollbackAsync(ct);\n        throw;\n    }\n}\n`\n---\nReading Event Streams\nRead Full Stream\n`csharp\npublic async Task<StoredEvent[]> ReadStreamAsync(\n    Guid streamId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT\n            event_id, stream_id, stream_type, event_type,\n            event_data, event_metadata, sequence_number, global_sequence, timestamp\n        FROM wh_events\n        WHERE stream_id = @StreamId\n        ORDER BY sequence_number\n        \"\"\",\n        new { StreamId = streamId },\n        cancellationToken: ct\n    );\n    return events ToArray();\n}\n`\nRead Stream from Version\n`csharp\npublic async Task<StoredEvent[]> ReadStreamAsync(\n    Guid streamId,\n    long fromVersion,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT * FROM wh_events\n        WHERE stream_id = @StreamId\n          AND sequence_number >= @FromVersion\n        ORDER BY sequence_number\n        \"\"\",\n        new { StreamId = streamId, FromVersion = fromVersion },\n        cancellationToken: ct\n    );\n    return events ToArray();\n}\n`\nRead All Events (Global Stream)\n`csharp\npublic async Task<StoredEvent[]> ReadAllEventsAsync(\n    long fromGlobalSequence,\n    int limit = 1000,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var events = await conn",
        "startIndex": 5322,
        "preview": "= streamId }, transaction: transaction ); var actualVersion = currentVersion 0; // Check expected version if (expectedVersion HasValue && actualVersio..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-5",
        "text": "new { StreamId = streamId, FromVersion = fromVersion }, cancellationToken: ct ); return events ToArray(); } ` Read All Events (Global Stream) `csharp public async Task<StoredEvent[]> ReadAllEventsAsync( long fromGlobalSequence, int limit = 1000, CancellationToken ct = default) { await using var conn = _db CreateConnection(); var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT * FROM wh_events\n        WHERE global_sequence >= @FromGlobalSequence\n        ORDER BY global_sequence\n        LIMIT @Limit\n        \"\"\",\n        new { FromGlobalSequence = fromGlobalSequence, Limit = limit },\n        cancellationToken: ct\n    );\n    return events ToArray();\n}\n`\n---\nRebuilding Perspectives from Events\nCheckpoint-Based Replay\n`csharp\npublic class PerspectiveRebuilder {\n    private readonly IDbConnectionFactory _db;\n    private readonly IServiceProvider _services;\n    public async Task RebuildPerspectiveAsync(\n        Guid streamId,\n        string perspectiveName,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Get last checkpoint (if any)\n        var checkpoint = await conn QuerySingleOrDefaultAsync<PerspectiveCheckpoint>(\n            \"\"\"\n            SELECT * FROM wh_perspective_checkpoints\n            WHERE stream_id = @StreamId AND perspective_name = @PerspectiveName\n            \"\"\",\n            new { StreamId = streamId, PerspectiveName = perspectiveName }\n        );\n        var fromSequence = checkpoint LastSequenceNumber + 1 1;\n        // Read events from checkpoint\n        var events = await conn QueryAsync<StoredEvent>(\n            \"\"\"\n            SELECT * FROM wh_events\n            WHERE stream_id = @StreamId\n              AND sequence_number >= @FromSequence\n            ORDER BY sequence_number\n            \"\"\",\n            new { StreamId = streamId, FromSequence = fromSequence },\n            cancellationToken: ct\n        );\n        // Resolve perspective handler\n        var perspective = ResolvePerspective(perspectiveName);\n        // Replay events\n        foreach (var storedEvent in events) {\n            var @event = DeserializeEvent(storedEvent);\n            await perspective UpdateAsync(@event, ct);\n            // Update checkpoint\n            await conn ExecuteAsync(\n                \"\"\"\n                INSERT INTO wh_perspective_checkpoints (\n                    stream_id, perspective_name, last_event_id, last_sequence_number, status, updated_at\n                ) VALUES (\n                    @StreamId, @PerspectiveName, @EventId, @SequenceNumber, 'UpToDate', NOW()\n                )\n                ON CONFLICT (stream_id, perspective_name) DO UPDATE SET\n                    last_event_id = EXCLUDED last_event_id,\n                    last_sequence_number = EXCLUDED last_sequence_number,\n                    status = EXCLUDED status,\n                    updated_at = EXCLUDED updated_at\n                \"\"\",\n                new {\n                    StreamId = streamId,\n                    PerspectiveName = perspectiveName,\n                    EventId = storedEvent EventId,\n                    SequenceNumber = storedEvent",
        "startIndex": 9958,
        "preview": "new { StreamId = streamId, FromVersion = fromVersion }, cancellationToken: ct ); return events ToArray(); } ` Read All Events (Global Stream) `csharp ..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-6",
        "text": "updated_at ) VALUES ( @StreamId, @PerspectiveName, @EventId, @SequenceNumber, 'UpToDate', NOW() ) ON CONFLICT (stream_id, perspective_name) DO UPDATE SET last_event_id = EXCLUDED last_event_id, last_sequence_number = EXCLUDED last_sequence_number, status = EXCLUDED status, updated_at = EXCLUDED updated_at \"\"\", new { StreamId = streamId, PerspectiveName = perspectiveName, EventId = storedEvent EventId, SequenceNumber = storedEvent SequenceNumber\n                },\n                cancellationToken: ct\n            );\n        }\n    }\n}\n`\nFull Rebuild (Delete + Replay)\n`csharp\npublic async Task FullRebuildPerspectiveAsync(\n    string perspectiveName,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // 1 Delete existing perspective data\n    await conn ExecuteAsync($\"TRUNCATE TABLE {GetPerspectiveTableName(perspectiveName)}\");\n    // 2 Reset checkpoints\n    await conn ExecuteAsync(\n        \"DELETE FROM wh_perspective_checkpoints WHERE perspective_name = @PerspectiveName\",\n        new { PerspectiveName = perspectiveName }\n    );\n    // 3 Read all events (global sequence)\n    var events = await conn QueryAsync<StoredEvent>(\n        \"SELECT * FROM wh_events ORDER BY global_sequence\",\n        cancellationToken: ct\n    );\n    // 4 Resolve perspective handler\n    var perspective = ResolvePerspective(perspectiveName);\n    // 5 Replay ALL events\n    foreach (var storedEvent in events) {\n        var @event = DeserializeEvent(storedEvent);\n        // Check if perspective handles this event type\n        if (CanHandle(perspective, @event)) {\n            await perspective UpdateAsync(@event, ct);\n            // Update checkpoint\n            await conn ExecuteAsync(\n                \"\"\"\n                INSERT INTO wh_perspective_checkpoints (\n                    stream_id, perspective_name, last_event_id, last_sequence_number, status, updated_at\n                ) VALUES (\n                    @StreamId, @PerspectiveName, @EventId, @SequenceNumber, 'UpToDate', NOW()\n                )\n                ON CONFLICT (stream_id, perspective_name) DO UPDATE SET\n                    last_event_id = EXCLUDED last_event_id,\n                    last_sequence_number = EXCLUDED last_sequence_number,\n                    status = EXCLUDED status,\n                    updated_at = EXCLUDED updated_at\n                \"\"\",\n                new {\n                    StreamId = storedEvent StreamId,\n                    PerspectiveName = perspectiveName,\n                    EventId = storedEvent EventId,\n                    SequenceNumber = storedEvent SequenceNumber\n                },\n                cancellationToken: ct\n            );\n        }\n    }\n}\n`\n---\nSnapshots (Performance Optimization)\nProblem: Replaying 10,000 events to rebuild an aggregate is slow Solution: Store periodic snapshots of aggregate state",
        "startIndex": 12765,
        "preview": "updated_at ) VALUES ( @StreamId, @PerspectiveName, @EventId, @SequenceNumber, 'UpToDate', NOW() ) ON CONFLICT (stream_id, perspective_name) DO UPDATE ..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-7",
        "text": "= EXCLUDED updated_at \"\"\", new { StreamId = storedEvent StreamId, PerspectiveName = perspectiveName, EventId = storedEvent EventId, SequenceNumber = storedEvent SequenceNumber }, cancellationToken: ct ); } } } ` --- Snapshots (Performance Optimization) Problem: Replaying 10,000 events to rebuild an aggregate is slow Solution: Store periodic snapshots of aggregate state Snapshot Schema\n`sql\nCREATE TABLE wh_snapshots (\n    stream_id UUID NOT NULL,\n    snapshot_type VARCHAR(200) NOT NULL,  -- Aggregate type\n    snapshot_data JSONB NOT NULL,\n    sequence_number BIGINT NOT NULL,      -- Last event included in snapshot\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    PRIMARY KEY (stream_id, sequence_number)\n);\nCREATE INDEX idx_snapshots_stream_id ON wh_snapshots (stream_id, sequence_number DESC);\n`\nSnapshot Creation\n`csharp\npublic async Task CreateSnapshotAsync(\n    Guid streamId,\n    string snapshotType,\n    object snapshot,\n    long sequenceNumber,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO wh_snapshots (\n            stream_id, snapshot_type, snapshot_data, sequence_number, created_at\n        ) VALUES (\n            @StreamId, @SnapshotType, @SnapshotData::jsonb, @SequenceNumber, NOW()\n        )\n        \"\"\",\n        new {\n            StreamId = streamId,\n            SnapshotType = snapshotType,\n            SnapshotData = JsonSerializer Serialize(snapshot),\n            SequenceNumber = sequenceNumber\n        },\n        cancellationToken: ct\n    );\n}\n`\nSnapshot-Based Replay\n`csharp\npublic async Task<Order> RehydrateOrderAsync(\n    Guid orderId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // 1 Get latest snapshot\n    var snapshot = await conn QuerySingleOrDefaultAsync<StoredSnapshot>(\n        \"\"\"\n        SELECT * FROM wh_snapshots\n        WHERE stream_id = @StreamId\n        ORDER BY sequence_number DESC\n        LIMIT 1\n        \"\"\",\n        new { StreamId = orderId }\n    );\n    Order order;\n    long fromSequence;\n    if (snapshot is not null) {\n        // Deserialize snapshot\n        order = JsonSerializer Deserialize<Order>(snapshot SnapshotData) ;\n        fromSequence = snapshot SequenceNumber + 1;\n    } else {\n        // No snapshot, start from beginning\n        order = new Order();\n        fromSequence = 1;\n    }\n    // 2 Read events after snapshot\n    var events = await conn",
        "startIndex": 15201,
        "preview": "= EXCLUDED updated_at \"\"\", new { StreamId = storedEvent StreamId, PerspectiveName = perspectiveName, EventId = storedEvent EventId, SequenceNumber = s..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-8",
        "text": "fromSequence; if (snapshot is not null) { // Deserialize snapshot order = JsonSerializer Deserialize<Order>(snapshot SnapshotData) ; fromSequence = snapshot SequenceNumber + 1; } else { // No snapshot, start from beginning order = new Order(); fromSequence = 1; } // 2 Read events after snapshot var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT * FROM wh_events\n        WHERE stream_id = @StreamId\n          AND sequence_number >= @FromSequence\n        ORDER BY sequence_number\n        \"\"\",\n        new { StreamId = orderId, FromSequence = fromSequence },\n        cancellationToken: ct\n    );\n    // 3 Apply remaining events\n    foreach (var storedEvent in events) {\n        var @event = DeserializeEvent(storedEvent);\n        order Apply(@event);  // Aggregate applies event to mutate state\n    }\n    return order;\n}\n`\nSnapshot Strategy:\nCreate snapshot every N events (e g , every 100 events)\nKeep last 3 snapshots (delete older ones)\nBalance: More snapshots = faster replay, more storage\n---\nTemporal Queries (Time Travel)\nQuery State at Specific Time\n`csharp\npublic async Task<Order> GetOrderAsOfAsync(\n    Guid orderId,\n    DateTimeOffset asOfTime,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Read events up to specific time\n    var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT * FROM wh_events\n        WHERE stream_id = @StreamId\n          AND timestamp <= @AsOfTime\n        ORDER BY sequence_number\n        \"\"\",\n        new { StreamId = orderId, AsOfTime = asOfTime },\n        cancellationToken: ct\n    );\n    // Rebuild aggregate state from events\n    var order = new Order();\n    foreach (var storedEvent in events) {\n        var @event = DeserializeEvent(storedEvent);\n        order Apply(@event);\n    }\n    return order;\n}\n`\nPerspective Projection at Specific Time\n`csharp\npublic async Task RebuildPerspectiveAsOfAsync(\n    string perspectiveName,\n    DateTimeOffset asOfTime,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // 1 Truncate perspective table\n    await conn ExecuteAsync($\"TRUNCATE TABLE {GetPerspectiveTableName(perspectiveName)}\");\n    // 2 Read events up to specific time\n    var events = await conn",
        "startIndex": 17305,
        "preview": "fromSequence; if (snapshot is not null) { // Deserialize snapshot order = JsonSerializer Deserialize<Order>(snapshot SnapshotData) ; fromSequence = sn..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-9",
        "text": "` Perspective Projection at Specific Time `csharp public async Task RebuildPerspectiveAsOfAsync( string perspectiveName, DateTimeOffset asOfTime, CancellationToken ct = default) { await using var conn = _db CreateConnection(); // 1 Truncate perspective table await conn ExecuteAsync($\"TRUNCATE TABLE {GetPerspectiveTableName(perspectiveName)}\"); // 2 Read events up to specific time var events = await conn QueryAsync<StoredEvent>(\n        \"\"\"\n        SELECT * FROM wh_events\n        WHERE timestamp <= @AsOfTime\n        ORDER BY global_sequence\n        \"\"\",\n        new { AsOfTime = asOfTime },\n        cancellationToken: ct\n    );\n    // 3 Replay events\n    var perspective = ResolvePerspective(perspectiveName);\n    foreach (var storedEvent in events) {\n        var @event = DeserializeEvent(storedEvent);\n        if (CanHandle(perspective, @event)) {\n            await perspective UpdateAsync(@event, ct);\n        }\n    }\n}\n`\nUse Cases:\nDebugging: \"What did the order look like when the bug occurred \"\nCompliance: \"Show me customer data as of December 31st for audit\"\nAnalytics: \"How many active customers did we have at the end of Q3 \"\n---\nEvent Versioning\nProblem: Event Schema Changes\n`csharp\n// Version 1\npublic record OrderCreatedV1(\n    Guid OrderId,\n    Guid CustomerId,\n    decimal Total\n);\n// Version 2 (added new field)\npublic record OrderCreatedV2(\n    Guid OrderId,\n    Guid CustomerId,\n    decimal Total,\n    string Currency  // ‚Üê New field );\n`\nStrategy 1: Upcasting\n`csharp\npublic class EventUpcast {\n    public object Upcast(StoredEvent storedEvent) {\n        return storedEvent EventType switch {\n            \"OrderCreatedV1\" => UpcastV1ToV2(storedEvent),\n            \"OrderCreatedV2\" => JsonSerializer Deserialize<OrderCreatedV2>(storedEvent EventData),\n            _ => throw new UnknownEventTypeException(storedEvent EventType)\n        };\n    }\n    private OrderCreatedV2 UpcastV1ToV2(StoredEvent storedEvent) {\n        var v1 = JsonSerializer Deserialize<OrderCreatedV1>(storedEvent EventData) ;\n        return new OrderCreatedV2(\n            OrderId: v1 OrderId,\n            CustomerId: v1 CustomerId,\n            Total: v1",
        "startIndex": 19267,
        "preview": "` Perspective Projection at Specific Time `csharp public async Task RebuildPerspectiveAsOfAsync( string perspectiveName, DateTimeOffset asOfTime, Canc..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-10",
        "text": "{ public object Upcast(StoredEvent storedEvent) { return storedEvent EventType switch { \"OrderCreatedV1\" => UpcastV1ToV2(storedEvent), \"OrderCreatedV2\" => JsonSerializer Deserialize<OrderCreatedV2>(storedEvent EventData), _ => throw new UnknownEventTypeException(storedEvent EventType) }; } private OrderCreatedV2 UpcastV1ToV2(StoredEvent storedEvent) { var v1 = JsonSerializer Deserialize<OrderCreatedV1>(storedEvent EventData) ; return new OrderCreatedV2( OrderId: v1 OrderId, CustomerId: v1 CustomerId, Total: v1 Total,\n            Currency: \"USD\"  // ‚Üê Default value for missing field\n        );\n    }\n}\n`\nStrategy 2: Copy-and-Transform (Migration)\n`sql\n-- Add new event type with transformed data\nINSERT INTO wh_events (\n    event_id, stream_id, stream_type, event_type, event_data, event_metadata, sequence_number, timestamp\n)\nSELECT\n    uuid_generate_v7(),\n    stream_id,\n    stream_type,\n    'OrderCreatedV2',  -- New event type\n    jsonb_set(event_data, '{Currency}', '\"USD\"'),  -- Add default Currency\n    event_metadata,\n    sequence_number,\n    timestamp\nFROM wh_events\nWHERE event_type = 'OrderCreatedV1';\n-- Delete old events (after verification )\n-- DELETE FROM wh_events WHERE event_type = 'OrderCreatedV1';\n`\n---\nEvent Store Performance\nPartitioning by Stream Type\n`sql\nCREATE TABLE wh_events (\n    event_id UUID PRIMARY KEY,\n    stream_id UUID NOT NULL,\n    stream_type VARCHAR(200) NOT NULL,\n    -- other columns\n) PARTITION BY LIST (stream_type);\n-- Create partitions per stream type\nCREATE TABLE wh_events_orders PARTITION OF wh_events\nFOR VALUES IN ('Order');\nCREATE TABLE wh_events_customers PARTITION OF wh_events\nFOR VALUES IN ('Customer');\nCREATE TABLE wh_events_products PARTITION OF wh_events\nFOR VALUES IN ('Product');\n`\nBenefit: Queries filtered by stream_type only scan relevant partition Partitioning by Time Range\n`sql\nCREATE TABLE wh_events (\n    event_id UUID PRIMARY KEY,\n    stream_id UUID NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL,\n    -- other columns\n) PARTITION BY RANGE (timestamp);\n-- Monthly partitions\nCREATE TABLE wh_events_2024_12 PARTITION OF wh_events\nFOR VALUES FROM ('2024-12-01') TO ('2025-01-01');\nCREATE TABLE wh_events_2025_01 PARTITION OF wh_events\nFOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\n`\nBenefit: Time-based queries automatically prune old partitions",
        "startIndex": 21012,
        "preview": "{ public object Upcast(StoredEvent storedEvent) { return storedEvent EventType switch { \"OrderCreatedV1\" => UpcastV1ToV2(storedEvent), \"OrderCreatedV2..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-11",
        "text": "UUID NOT NULL, timestamp TIMESTAMPTZ NOT NULL, -- other columns ) PARTITION BY RANGE (timestamp); -- Monthly partitions CREATE TABLE wh_events_2024_12 PARTITION OF wh_events FOR VALUES FROM ('2024-12-01') TO ('2025-01-01'); CREATE TABLE wh_events_2025_01 PARTITION OF wh_events FOR VALUES FROM ('2025-01-01') TO ('2025-02-01'); ` Benefit: Time-based queries automatically prune old partitions Archiving Old Events\n`sql\n-- Archive events older than 1 year\nINSERT INTO wh_events_archive\nSELECT * FROM wh_events\nWHERE timestamp < NOW() - INTERVAL '1 year';\n-- Delete from main table\nDELETE FROM wh_events\nWHERE timestamp < NOW() - INTERVAL '1 year';\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Append-only - Never update or delete events\n‚úÖ Use UUIDv7 for event_id (time-ordered)\n‚úÖ Sequence numbers within streams (1, 2, 3, )\n‚úÖ Global sequence for cross-stream ordering\n‚úÖ JSONB for event_data (flexible, queryable)\n‚úÖ Snapshots for long streams (> 100 events)\n‚úÖ Upcasting for event versioning\n‚úÖ Partition by stream_type or timestamp for large stores\n‚úÖ Archive old events (> 1 year)\n‚úÖ Checkpoint-based replay for perspectives\nDON'T ‚ùå\n‚ùå Update events (immutable )\n‚ùå Delete events (append-only )\n‚ùå Use random UUIDs (index fragmentation)\n‚ùå Skip sequence numbers (breaks ordering)\n‚ùå Store large BLOBs in events (use object storage, store URL)\n‚ùå Replay without snapshots (slow )\n‚ùå Break event schemas (upcast instead)\n‚ùå Query events for current state (use perspectives/lenses)\n---\nCommon Patterns\nPattern 1: Event-Sourced Aggregate\n`csharp\npublic class Order {\n    public Guid Id { get; private set; }\n    public string Status { get; private set; } = \"Created\";\n    public decimal Total { get; private set; }\n    private readonly List<object> _uncommittedEvents = new();\n    public IReadOnlyList<object> GetUncommittedEvents() => _uncommittedEvents AsReadOnly();\n    public void ClearUncommittedEvents() => _uncommittedEvents Clear();\n    // Apply event to mutate state\n    public void Apply(object @event) {\n        switch (@event) {\n            case OrderCreated e:\n                Id = e",
        "startIndex": 22829,
        "preview": "UUID NOT NULL, timestamp TIMESTAMPTZ NOT NULL, -- other columns ) PARTITION BY RANGE (timestamp); -- Monthly partitions CREATE TABLE wh_events_2024_12..."
      },
      {
        "id": "v0.1.0/data/event-store-chunk-12",
        "text": "set; } = \"Created\"; public decimal Total { get; private set; } private readonly List<object> _uncommittedEvents = new(); public IReadOnlyList<object> GetUncommittedEvents() => _uncommittedEvents AsReadOnly(); public void ClearUncommittedEvents() => _uncommittedEvents Clear(); // Apply event to mutate state public void Apply(object @event) { switch (@event) { case OrderCreated e: Id = e OrderId;\n                Status = \"Created\";\n                Total = e Total;\n                break;\n            case OrderShipped e:\n                Status = \"Shipped\";\n                break;\n            default:\n                throw new UnknownEventException(@event GetType() Name);\n        }\n    }\n    // Business logic produces events\n    public void Ship() {\n        if (Status = \"Created\") {\n            throw new InvalidOperationException(\"Can only ship created orders\");\n        }\n        var @event = new OrderShipped(Id, DateTimeOffset UtcNow);\n        Apply(@event);  // Mutate state\n        _uncommittedEvents Add(@event);  // Track for persistence\n    }\n}\n`\nPattern 2: Repository with Event Store\n`csharp\npublic class OrderRepository {\n    private readonly IEventStore _eventStore;\n    public async Task<Order> GetByIdAsync(Guid orderId, CancellationToken ct = default) {\n        var events = await _eventStore ReadStreamAsync(orderId, ct);\n        var order = new Order();\n        foreach (var @event in events) {\n            order Apply(@event);\n        }\n        return order;\n    }\n    public async Task SaveAsync(Order order, CancellationToken ct = default) {\n        var uncommittedEvents = order GetUncommittedEvents();\n        foreach (var @event in uncommittedEvents) {\n            await _eventStore AppendAsync(\n                streamId: order Id,\n                streamType: \"Order\",\n                eventType: @event GetType() Name,\n                eventData: @event,\n                ct: ct\n            );\n        }\n        order ClearUncommittedEvents();\n    }\n}\n`\n---\nFurther Reading\nCore Concepts:\nPerspectives - Event-driven read models\nObservability - Message hops and tracing\nData Access:\nDapper Integration - Lightweight data access\nEF Core Integration - Full-featured ORM\nPerspectives Storage - Read model schema design\nMessaging:\nOutbox Pattern - Reliable event publishing\nWork Coordinator - Atomic batch processing\nExamples:\nECommerce: Event Sourcing - Real-world event store usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 24503,
        "preview": "set; } = \"Created\"; public decimal Total { get; private set; } private readonly List<object> _uncommittedEvents = new(); public IReadOnlyList<object> ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/data/perspectives-storage",
    "title": "Perspectives Storage",
    "category": "Data Access",
    "url": "/docs/v0.1.0/data/perspectives-storage",
    "chunks": [
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-0",
        "text": "Perspectives Storage\nPerspectives are event-driven read models that maintain denormalized, query-optimized views of your domain This guide covers schema design patterns, denormalization strategies, and PostgreSQL-specific features for building high-performance read models Read Models vs Write Models\n| Aspect | Write Models (Domain) | Read Models (Perspectives) |\n|--------|----------------------|---------------------------|\n| Normalization | Normalized (3NF) | Denormalized (flat) |\n| Purpose | Enforce business rules | Optimize queries |\n| Updates | Command-driven | Event-driven |\n| Consistency | Immediate (strong) | Eventual (async) |\n| Technology | EF Core (optional) | Dapper + PostgreSQL |\n| Schema | Foreign keys, constraints | Flat, JSONB, indexes |\nWhizbang Philosophy: Separate write models (domain aggregates) from read models (perspectives) for optimal performance ---\nDesign Principles\nDenormalization\nGoal: Minimize JOINs at query time by storing all data needed for a query in a single table `sql\n-- ‚ùå Normalized (requires JOINs)\nSELECT o order_id, o total, c name, c email\nFROM orders o\nINNER JOIN customers c ON o customer_id = c customer_id;\n-- ‚úÖ Denormalized (single table lookup)\nSELECT order_id, total, customer_name, customer_email\nFROM order_summaries\nWHERE order_id = ' ';\n`\nQuery-Driven Design\nStart with queries, design schema to support them:\n`sql\n-- Common queries drive schema design:\n-- 1 Get order by ID\nSELECT * FROM order_summaries WHERE order_id = ;\n-- 2 Get orders by customer\nSELECT * FROM order_summaries WHERE customer_id = ORDER BY created_at DESC;\n-- 3 Search orders\nSELECT * FROM order_summaries WHERE customer_name ILIKE OR customer_email ILIKE ;\n-- Schema includes customer_id, customer_name, customer_email for direct lookup\n`\nEventual Consistency\nAccept stale reads for massive performance gains:\n`\nCommand ‚Üí Write Model ‚Üí Event ‚Üí Perspective Update (async)\n                                      ‚Üì\n                                Read Model (slightly stale, but fast",
        "startIndex": 0,
        "preview": "Perspectives Storage\nPerspectives are event-driven read models that maintain denormalized, query-optimized views of your domain This guide covers sche..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-1",
        "text": "Search orders SELECT * FROM order_summaries WHERE customer_name ILIKE OR customer_email ILIKE ; -- Schema includes customer_id, customer_name, customer_email for direct lookup ` Eventual Consistency Accept stale reads for massive performance gains: ` Command ‚Üí Write Model ‚Üí Event ‚Üí Perspective Update (async) ‚Üì Read Model (slightly stale, but fast )\n`\nTypical lag: < 100ms in most systems\n---\nSchema Design Patterns\nPattern 1: Flat Denormalized Table\nUse Case: Simple read models with all data in columns `sql\nCREATE TABLE order_summaries (\n    order_id UUID PRIMARY KEY,\n    -- Order data\n    status VARCHAR(50) NOT NULL,\n    total DECIMAL(18, 2) NOT NULL,\n    item_count INT NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL,\n    updated_at TIMESTAMPTZ NOT NULL,\n    -- Denormalized customer data\n    customer_id UUID NOT NULL,\n    customer_name VARCHAR(200) NOT NULL,\n    customer_email VARCHAR(200) NOT NULL,\n    -- Denormalized shipping data\n    shipping_street VARCHAR(200),\n    shipping_city VARCHAR(100),\n    shipping_state VARCHAR(50),\n    shipping_postal_code VARCHAR(20),\n    -- Indexes for common queries\n    INDEX idx_customer_id (customer_id),\n    INDEX idx_created_at (created_at DESC),\n    INDEX idx_status (status)\n);\n`\nPerspective Update:\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (\n                order_id, status, total, item_count, created_at, updated_at,\n                customer_id, customer_name, customer_email,\n                shipping_street, shipping_city, shipping_state, shipping_postal_code\n            ) VALUES (\n                @OrderId, @Status, @Total, @ItemCount, @CreatedAt, @UpdatedAt,\n                @CustomerId, @CustomerName, @CustomerEmail,\n                @ShippingStreet, @ShippingCity, @ShippingState, @ShippingPostalCode\n            )\n            ON CONFLICT (order_id) DO UPDATE SET\n                status = EXCLUDED status,\n                updated_at = EXCLUDED updated_at\n            \"\"\",\n            new {\n                @event OrderId,\n                Status = \"Created\",\n                @event Total,\n                ItemCount = @event Items Length,\n                @event CreatedAt,\n                UpdatedAt = @event CreatedAt,\n                @event CustomerId,\n                @event CustomerName,\n                @event CustomerEmail,\n                @event ShippingAddress Street,\n                @event ShippingAddress City,\n                @event ShippingAddress State,\n                @event ShippingAddress PostalCode\n            },\n            cancellationToken: ct\n        );\n    }\n}\n`\n---\nPattern 2: JSONB for Flexible Data\nUse Case: Complex nested data, evolving schemas, metadata",
        "startIndex": 2031,
        "preview": "Search orders SELECT * FROM order_summaries WHERE customer_name ILIKE OR customer_email ILIKE ; -- Schema includes customer_id, customer_name, custome..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-2",
        "text": "= @event Items Length, @event CreatedAt, UpdatedAt = @event CreatedAt, @event CustomerId, @event CustomerName, @event CustomerEmail, @event ShippingAddress Street, @event ShippingAddress City, @event ShippingAddress State, @event ShippingAddress PostalCode }, cancellationToken: ct ); } } ` --- Pattern 2: JSONB for Flexible Data Use Case: Complex nested data, evolving schemas, metadata `sql\nCREATE TABLE product_catalog (\n    product_id UUID PRIMARY KEY,\n    -- Core columns\n    name VARCHAR(200) NOT NULL,\n    sku VARCHAR(100) NOT NULL UNIQUE,\n    price DECIMAL(18, 2) NOT NULL,\n    available INT NOT NULL DEFAULT 0,\n    -- JSONB for flexible metadata\n    metadata JSONB NOT NULL DEFAULT '{}',\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    -- GIN index for JSONB queries\n    INDEX idx_metadata_gin ON product_catalog USING GIN (metadata)\n);\n`\nExample JSONB Content:\n`json\n{\n  \"category\": \"Electronics\",\n  \"subcategory\": \"Laptops\",\n  \"brand\": \"TechCorp\",\n  \"tags\": [\"featured\", \"sale\", \"new-arrival\"],\n  \"specifications\": {\n    \"cpu\": \"Intel i7\",\n    \"ram\": \"16GB\",\n    \"storage\": \"512GB SSD\"\n  },\n  \"images\": [\n    {\"url\": \"https:// \", \"alt\": \"Front view\"},\n    {\"url\": \"https:// \", \"alt\": \"Side view\"}\n  ]\n}\n`\nQuery JSONB:\n`sql\n-- Filter by category\nSELECT * FROM product_catalog\nWHERE metadata->>'category' = 'Electronics';\n-- Filter by nested property\nSELECT * FROM product_catalog\nWHERE metadata->'specifications'->>'cpu' = 'Intel i7';\n-- Array contains\nSELECT * FROM product_catalog\nWHERE metadata->'tags' @> '[\"featured\"]';\n-- Full-text search in JSONB\nSELECT * FROM product_catalog\nWHERE metadata->>'brand' ILIKE '%TechCorp%';\n`\nPerspective Update:\n`csharp\npublic async Task UpdateAsync(ProductAdded @event, CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var metadata = new {\n        category = @event Category,\n        subcategory = @event Subcategory,\n        brand = @event Brand,\n        tags = @event Tags,\n        specifications = @event Specifications,\n        images = @event Images\n    };\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO product_catalog (\n            product_id, name, sku, price, available, metadata, created_at\n        ) VALUES (\n            @ProductId, @Name, @Sku, @Price, @Available, @Metadata::jsonb, @CreatedAt\n        )\n        \"\"\",\n        new {\n            @event ProductId,\n            @event",
        "startIndex": 4647,
        "preview": "= @event Items Length, @event CreatedAt, UpdatedAt = @event CreatedAt, @event CustomerId, @event CustomerName, @event CustomerEmail, @event ShippingAd..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-3",
        "text": "Subcategory, brand = @event Brand, tags = @event Tags, specifications = @event Specifications, images = @event Images }; await conn ExecuteAsync( \"\"\" INSERT INTO product_catalog ( product_id, name, sku, price, available, metadata, created_at ) VALUES ( @ProductId, @Name, @Sku, @Price, @Available, @Metadata::jsonb, @CreatedAt ) \"\"\", new { @event ProductId, @event Name,\n            @event Sku,\n            @event Price,\n            Available = @event InitialStock,\n            Metadata = JsonSerializer Serialize(metadata),\n            @event CreatedAt\n        },\n        cancellationToken: ct\n    );\n}\n`\n---\nPattern 3: Aggregated Data\nUse Case: Pre-computed aggregations for analytics dashboards `sql\nCREATE TABLE customer_statistics (\n    customer_id UUID PRIMARY KEY,\n    -- Aggregated metrics\n    total_orders INT NOT NULL DEFAULT 0,\n    total_spent DECIMAL(18, 2) NOT NULL DEFAULT 0,\n    average_order_value DECIMAL(18, 2) NOT NULL DEFAULT 0,\n    -- Temporal data\n    first_order_at TIMESTAMPTZ,\n    last_order_at TIMESTAMPTZ,\n    -- Behavioral flags\n    is_vip BOOLEAN NOT NULL DEFAULT FALSE,\n    is_at_risk BOOLEAN NOT NULL DEFAULT FALSE,\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n`\nPerspective Update (incremental):\n`csharp\npublic class CustomerStatisticsPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO customer_statistics (\n                customer_id, total_orders, total_spent, average_order_value,\n                first_order_at, last_order_at, is_vip, updated_at\n            ) VALUES (\n                @CustomerId, 1, @Total, @Total, @OrderDate, @OrderDate, FALSE, NOW()\n            )\n            ON CONFLICT (customer_id) DO UPDATE SET\n                total_orders = customer_statistics total_orders + 1,\n                total_spent = customer_statistics total_spent + @Total,\n                average_order_value = (customer_statistics total_spent + @Total) / (customer_statistics total_orders + 1),\n                last_order_at = @OrderDate,\n                is_vip = (customer_statistics total_spent + @Total) > 10000,  -- VIP threshold\n                updated_at = NOW()\n            \"\"\",\n            new {\n                @event CustomerId,\n                @event Total,\n                OrderDate = @event CreatedAt\n            },\n            cancellationToken: ct\n        );\n    }\n}\n`\nQuery:\n`csharp\npublic async Task<CustomerStatistics > GetCustomerStatsAsync(\n    Guid customerId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    return await conn",
        "startIndex": 6717,
        "preview": "Subcategory, brand = @event Brand, tags = @event Tags, specifications = @event Specifications, images = @event Images }; await conn ExecuteAsync( \"\"\" ..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-4",
        "text": "> 10000, -- VIP threshold updated_at = NOW() \"\"\", new { @event CustomerId, @event Total, OrderDate = @event CreatedAt }, cancellationToken: ct ); } } ` Query: `csharp public async Task<CustomerStatistics > GetCustomerStatsAsync( Guid customerId, CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleOrDefaultAsync<CustomerStatistics>(\n        \"SELECT * FROM customer_statistics WHERE customer_id = @CustomerId\",\n        new { CustomerId = customerId },\n        cancellationToken: ct\n    );\n}\n`\n---\nPattern 4: Time-Series Data\nUse Case: High-volume temporal data (metrics, logs, analytics) `sql\nCREATE TABLE order_metrics (\n    metric_id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),  -- Time-ordered\n    -- Dimensions\n    tenant_id UUID NOT NULL,\n    customer_id UUID,\n    product_id UUID,\n    -- Metrics\n    metric_type VARCHAR(50) NOT NULL,  -- 'order_created', 'order_shipped', etc metric_value DECIMAL(18, 2),\n    -- Temporal\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    date DATE NOT NULL GENERATED ALWAYS AS (DATE(timestamp)) STORED,\n    -- Metadata\n    metadata JSONB DEFAULT '{}'\n) PARTITION BY RANGE (date);\n-- Create partitions (monthly)\nCREATE TABLE order_metrics_2024_12 PARTITION OF order_metrics\nFOR VALUES FROM ('2024-12-01') TO ('2025-01-01');\nCREATE TABLE order_metrics_2025_01 PARTITION OF order_metrics\nFOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\n-- Indexes on partitions\nCREATE INDEX idx_order_metrics_2024_12_timestamp ON order_metrics_2024_12 (timestamp DESC);\nCREATE INDEX idx_order_metrics_2024_12_tenant_id ON order_metrics_2024_12 (tenant_id);\n`\nPerspective Update:\n`csharp\npublic async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO order_metrics (\n            tenant_id, customer_id, metric_type, metric_value, timestamp, metadata\n        ) VALUES (\n            @TenantId, @CustomerId, 'order_created', @Total, @Timestamp, @Metadata::jsonb\n        )\n        \"\"\",\n        new {\n            @event TenantId,\n            @event CustomerId,\n            @event Total,\n            Timestamp = @event CreatedAt,\n            Metadata = JsonSerializer Serialize(new {\n                order_id = @event OrderId,\n                item_count = @event Items",
        "startIndex": 9138,
        "preview": "> 10000, -- VIP threshold updated_at = NOW() \"\"\", new { @event CustomerId, @event Total, OrderDate = @event CreatedAt }, cancellationToken: ct ); } } ..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-5",
        "text": "await conn ExecuteAsync( \"\"\" INSERT INTO order_metrics ( tenant_id, customer_id, metric_type, metric_value, timestamp, metadata ) VALUES ( @TenantId, @CustomerId, 'order_created', @Total, @Timestamp, @Metadata::jsonb ) \"\"\", new { @event TenantId, @event CustomerId, @event Total, Timestamp = @event CreatedAt, Metadata = JsonSerializer Serialize(new { order_id = @event OrderId, item_count = @event Items Length\n            })\n        },\n        cancellationToken: ct\n    );\n}\n`\nQuery (time-range with partition pruning):\n`sql\n-- Query specific time range (PostgreSQL automatically prunes partitions)\nSELECT\n    DATE(timestamp) AS date,\n    COUNT(*) AS order_count,\n    SUM(metric_value) AS total_revenue\nFROM order_metrics\nWHERE tenant_id = '",
        "startIndex": 11179,
        "preview": "await conn ExecuteAsync( \"\"\" INSERT INTO order_metrics ( tenant_id, customer_id, metric_type, metric_value, timestamp, metadata ) VALUES ( @TenantId, ..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-6",
        "text": "JsonSerializer Serialize(new { order_id = @event OrderId, item_count = @event Items Length }) }, cancellationToken: ct ); } ` Query (time-range with partition pruning): `sql -- Query specific time range (PostgreSQL automatically prunes partitions) SELECT DATE(timestamp) AS date, COUNT(*) AS order_count, SUM(metric_value) AS total_revenue FROM order_metrics WHERE tenant_id = ' '\n  AND metric_type = 'order_created'\n  AND timestamp >= '2024-12-01'\n  AND timestamp < '2025-01-01'\nGROUP BY DATE(timestamp)\nORDER BY date;\n`\n---\nIndexing Strategies\nPrimary Key\n`sql\n-- ‚úÖ UUIDv7 (time-ordered, insert-friendly)\norder_id UUID PRIMARY KEY DEFAULT uuid_generate_v7()\n-- ‚ùå Random UUID (index fragmentation)\norder_id UUID PRIMARY KEY DEFAULT gen_random_uuid()\n`\nLookup Indexes\n`sql\n-- Single-column indexes for common filters\nCREATE INDEX idx_customer_id ON order_summaries (customer_id);\nCREATE INDEX idx_status ON order_summaries (status);\n-- Composite indexes for combined filters\nCREATE INDEX idx_customer_status ON order_summaries (customer_id, status);\n-- Descending indexes for ORDER BY DESC\nCREATE INDEX idx_created_at_desc ON order_summaries (created_at DESC);\n`\nJSONB Indexes\n`sql\n-- GIN index for JSONB queries\nCREATE INDEX idx_metadata_gin ON products USING GIN (metadata);\n-- Specific path index (more efficient)\nCREATE INDEX idx_metadata_category ON products ((metadata->>'category'));\n`\nPartial Indexes\n`sql\n-- Index only active orders (saves space)\nCREATE INDEX idx_active_orders ON order_summaries (customer_id)\nWHERE status IN ('Created', 'Processing', 'Shipped');\n-- Index only recent orders (saves space)\nCREATE INDEX idx_recent_orders ON order_summaries (created_at DESC)\nWHERE created_at > NOW() - INTERVAL '90 days';\n`\nFull-Text Search\n`sql\n-- Add tsvector column for full-text search\nALTER TABLE order_summaries\nADD COLUMN search_vector tsvector\nGENERATED ALWAYS AS (\n    setweight(to_tsvector('english', COALESCE(customer_name, '')), 'A') ||\n    setweight(to_tsvector('english', COALESCE(customer_email, '')), 'B')\n) STORED;\n-- GIN index for full-text search\nCREATE INDEX idx_search_vector ON order_summaries USING GIN (search_vector);\n-- Query\nSELECT * FROM order_summaries\nWHERE search_vector @@ to_tsquery('english', 'john & doe');\n`\n---\nMulti-Tenancy Patterns\nPattern 1: Tenant Column + Row-Level Security\n`sql\nCREATE TABLE order_summaries (\n    order_id UUID PRIMARY KEY,\n    tenant_id UUID NOT NULL,\n    --",
        "startIndex": 11520,
        "preview": "JsonSerializer Serialize(new { order_id = @event OrderId, item_count = @event Items Length }) }, cancellationToken: ct ); } ` Query (time-range with p..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-7",
        "text": "index for full-text search CREATE INDEX idx_search_vector ON order_summaries USING GIN (search_vector); -- Query SELECT * FROM order_summaries WHERE search_vector @@ to_tsquery('english', 'john & doe'); ` --- Multi-Tenancy Patterns Pattern 1: Tenant Column + Row-Level Security `sql CREATE TABLE order_summaries ( order_id UUID PRIMARY KEY, tenant_id UUID NOT NULL, -- other columns\n    INDEX idx_tenant_id (tenant_id)\n);\n-- Row-Level Security (RLS)\nALTER TABLE order_summaries ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON order_summaries\nUSING (tenant_id = current_setting('app current_tenant_id')::UUID);\n`\nApplication:\n`csharp\npublic async Task<OrderSummary[]> GetOrdersAsync(\n    Guid tenantId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    await conn OpenAsync(ct);\n    // Set tenant context\n    await conn ExecuteAsync($\"SET app current_tenant_id = '{tenantId}'\");\n    // Query (RLS automatically filters by tenant_id)\n    var orders = await conn QueryAsync<OrderSummary>(\n        \"SELECT * FROM order_summaries ORDER BY created_at DESC\",\n        cancellationToken: ct\n    );\n    return orders ToArray();\n}\n`\nPattern 2: Schema-Per-Tenant\n`sql\n-- Create schema per tenant\nCREATE SCHEMA tenant_abc123;\nCREATE SCHEMA tenant_def456;\n-- Same table structure in each schema\nCREATE TABLE tenant_abc123 order_summaries (\n    order_id UUID PRIMARY KEY,\n    -- columns (no tenant_id needed )\n);\nCREATE TABLE tenant_def456 order_summaries (\n    order_id UUID PRIMARY KEY,\n    -- columns\n);\n`\nApplication:\n`csharp\npublic async Task<OrderSummary[]> GetOrdersAsync(\n    string tenantSchemaName,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Query tenant-specific schema\n    var orders = await conn QueryAsync<OrderSummary>(\n        $\"SELECT * FROM {tenantSchemaName} order_summaries ORDER BY created_at DESC\",\n        cancellationToken: ct\n    );\n    return orders ToArray();\n}\n`\nBenefit: Complete data isolation, easier to move tenants to separate databases",
        "startIndex": 13574,
        "preview": "index for full-text search CREATE INDEX idx_search_vector ON order_summaries USING GIN (search_vector); -- Query SELECT * FROM order_summaries WHERE s..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-8",
        "text": "CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Query tenant-specific schema var orders = await conn QueryAsync<OrderSummary>( $\"SELECT * FROM {tenantSchemaName} order_summaries ORDER BY created_at DESC\", cancellationToken: ct ); return orders ToArray(); } ` Benefit: Complete data isolation, easier to move tenants to separate databases ---\nMaterialized Views (Alternative to Perspectives)\nMaterialized Views are an alternative to perspectives for complex queries:\n`sql\n-- Create materialized view\nCREATE MATERIALIZED VIEW order_daily_summary AS\nSELECT\n    DATE(created_at) AS order_date,\n    status,\n    COUNT(*) AS order_count,\n    SUM(total) AS total_revenue,\n    AVG(total) AS average_order_value\nFROM order_summaries\nGROUP BY DATE(created_at), status;\n-- Index for fast lookups\nCREATE INDEX idx_order_daily_summary_date ON order_daily_summary (order_date DESC);\n-- Refresh (manual)\nREFRESH MATERIALIZED VIEW order_daily_summary;\n-- Refresh (concurrent - doesn't block reads)\nREFRESH MATERIALIZED VIEW CONCURRENTLY order_daily_summary;\n`\nComparison:\n| Aspect | Perspectives (Event-Driven) | Materialized Views |\n|--------|----------------------------|-------------------|\n| Updates | Real-time (event-driven) | Manual/scheduled refresh |\n| Freshness | < 100ms typical lag | Depends on refresh frequency |\n| Flexibility | Custom business logic | SQL-only |\n| Performance | Excellent (indexed table) | Excellent (indexed view) |\n| Use Case | Real-time dashboards | Batch reports, analytics |\nRecommendation: Use perspectives for real-time, materialized views for batch reports ---\nMigration Strategies\nStrategy 1: Schema Migrations with EF Core\n`csharp\n// Migration: Add order_summaries table\npublic partial class AddOrderSummaries : Migration {\n    protected override void Up(MigrationBuilder migrationBuilder) {\n        migrationBuilder Sql(\"CREATE EXTENSION IF NOT EXISTS \\\"uuid-ossp\\\";\");\n        migrationBuilder CreateTable(\n            name: \"order_summaries\",\n            columns: table => new {\n                order_id = table Column<Guid>(nullable: false, defaultValueSql: \"uuid_generate_v7()\"),\n                status = table Column<string>(maxLength: 50, nullable: false),\n                total = table Column<decimal>(type: \"decimal(18,2)\", nullable: false),\n                created_at = table Column<DateTimeOffset>(nullable: false, defaultValueSql: \"NOW()\"),\n                customer_id = table Column<Guid>(nullable: false),\n                customer_name = table Column<string>(maxLength: 200, nullable: false),\n                customer_email = table Column<string>(maxLength: 200, nullable: false)\n            },\n            constraints: table => {\n                table",
        "startIndex": 15278,
        "preview": "CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Query tenant-specific schema var orders = await conn QueryAsync<Or..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-9",
        "text": "Column<Guid>(nullable: false, defaultValueSql: \"uuid_generate_v7()\"), status = table Column<string>(maxLength: 50, nullable: false), total = table Column<decimal>(type: \"decimal(18,2)\", nullable: false), created_at = table Column<DateTimeOffset>(nullable: false, defaultValueSql: \"NOW()\"), customer_id = table Column<Guid>(nullable: false), customer_name = table Column<string>(maxLength: 200, nullable: false), customer_email = table Column<string>(maxLength: 200, nullable: false) }, constraints: table => { table PrimaryKey(\"pk_order_summaries\", x => x order_id);\n            }\n        );\n        migrationBuilder CreateIndex(\n            name: \"ix_order_summaries_customer_id\",\n            table: \"order_summaries\",\n            column: \"customer_id\"\n        );\n        migrationBuilder CreateIndex(\n            name: \"ix_order_summaries_created_at\",\n            table: \"order_summaries\",\n            column: \"created_at\",\n            descending: true\n        );\n    }\n    protected override void Down(MigrationBuilder migrationBuilder) {\n        migrationBuilder DropTable(name: \"order_summaries\");\n    }\n}\n`\nStrategy 2: SQL Scripts\n`sql\n-- migrations/001_create_order_summaries sql\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\nCREATE TABLE order_summaries (\n    order_id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),\n    status VARCHAR(50) NOT NULL,\n    total DECIMAL(18, 2) NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    customer_id UUID NOT NULL,\n    customer_name VARCHAR(200) NOT NULL,\n    customer_email VARCHAR(200) NOT NULL\n);\nCREATE INDEX idx_order_summaries_customer_id ON order_summaries (customer_id);\nCREATE INDEX idx_order_summaries_created_at ON order_summaries (created_at DESC);\n`\nApply with psql:\n`bash\npsql -U postgres -d whizbang -f migrations/001_create_order_summaries",
        "startIndex": 17633,
        "preview": "Column<Guid>(nullable: false, defaultValueSql: \"uuid_generate_v7()\"), status = table Column<string>(maxLength: 50, nullable: false), total = table Col..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-10",
        "text": "NULL, total DECIMAL(18, 2) NOT NULL, created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(), customer_id UUID NOT NULL, customer_name VARCHAR(200) NOT NULL, customer_email VARCHAR(200) NOT NULL ); CREATE INDEX idx_order_summaries_customer_id ON order_summaries (customer_id); CREATE INDEX idx_order_summaries_created_at ON order_summaries (created_at DESC); ` Apply with psql: `bash psql -U postgres -d whizbang -f migrations/001_create_order_summaries sql\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Denormalize aggressively - Store all data needed for queries in one table\n‚úÖ Use UUIDv7 for primary keys (time-ordered, insert-friendly)\n‚úÖ Use JSONB for flexible, evolving data\n‚úÖ Index common filters - customer_id, status, created_at\n‚úÖ Use partial indexes - Index only relevant data (active records, recent records)\n‚úÖ Use GIN indexes for JSONB queries\n‚úÖ Use partitioning for high-volume time-series data\n‚úÖ Test query performance with EXPLAIN ANALYZE\n‚úÖ Monitor index usage - Drop unused indexes\nDON'T ‚ùå\n‚ùå Normalize perspectives (defeats the purpose)\n‚ùå Use random UUIDs (index fragmentation)\n‚ùå Skip indexes on foreign keys (customer_id, product_id)\n‚ùå Over-index (every index slows writes)\n‚ùå Store BLOBs in PostgreSQL (use object storage)\n‚ùå Use triggers for perspective updates (use events)\n‚ùå Use materialized views for real-time data (use perspectives)\n---\nPerformance Tuning\nQuery Analysis\n`sql\n-- Analyze query performance\nEXPLAIN ANALYZE\nSELECT * FROM order_summaries\nWHERE customer_id = ' '\nORDER BY created_at DESC\nLIMIT 10;\n`\nLook for:\nSeq Scan (bad) ‚Üí Add index\nIndex Scan (good)\nBitmap Heap Scan (good for low selectivity)\nIndex Usage Monitoring\n`sql\n-- Find unused indexes\nSELECT\n    schemaname,\n    tablename,\n    indexname,\n    idx_scan AS index_scans\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\n  AND indexrelname NOT LIKE 'pg_%'\nORDER BY schemaname, tablename;\n`\nTable Bloat Monitoring\n`sql\n-- Check table bloat (dead rows)\nSELECT\n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'",
        "startIndex": 18928,
        "preview": "NULL, total DECIMAL(18, 2) NOT NULL, created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(), customer_id UUID NOT NULL, customer_name VARCHAR(200) NOT NULL, cu..."
      },
      {
        "id": "v0.1.0/data/perspectives-storage-chunk-11",
        "text": "Scan (good for low selectivity) Index Usage Monitoring `sql -- Find unused indexes SELECT schemaname, tablename, indexname, idx_scan AS index_scans FROM pg_stat_user_indexes WHERE idx_scan = 0 AND indexrelname NOT LIKE 'pg_%' ORDER BY schemaname, tablename; ` Table Bloat Monitoring `sql -- Check table bloat (dead rows) SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||' '||tablename)) AS total_size,\n    n_dead_tup AS dead_tuples\nFROM pg_stat_user_tables\nWHERE n_dead_tup > 1000\nORDER BY n_dead_tup DESC;\n-- Fix bloat\nVACUUM ANALYZE order_summaries;\n`\n---\nFurther Reading\nCore Concepts:\nPerspectives - Event-driven read models\nLenses - Query repositories\nData Access:\nDapper Integration - Lightweight data access\nEF Core Integration - Full-featured ORM\nEvent Store - Event storage and replay\nMessaging:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nExamples:\nECommerce: BFF Perspectives - Real-world perspective design\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20491,
        "preview": "Scan (good for low selectivity) Index Usage Monitoring `sql -- Find unused indexes SELECT schemaname, tablename, indexname, idx_scan AS index_scans FR..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-dispatchers",
    "title": "Custom Dispatchers",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-dispatchers",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-dispatchers-chunk-0",
        "text": "Custom Dispatchers\nCustom dispatchers enable alternative message routing strategies beyond the default dispatcher Implement mediator patterns, event sourcing dispatchers, or multi-tenant routing :::note\nWhizbang's default dispatcher provides AOT-compatible, zero-reflection routing Custom dispatchers are for specialized architectural patterns :::\n---\nWhy Custom Dispatchers | Pattern | Default Dispatcher | Custom Dispatcher |\n|---------|-------------------|-------------------|\n| Direct Routing | ‚úÖ Perfect | No customization needed |\n| Mediator Pattern | ‚ùå Not built-in | ‚úÖ Custom mediator |\n| Event Sourcing | ‚ùå Append-only needed | ‚úÖ Event store dispatcher |\n| Multi-Tenant | ‚ùå Requires policies | ‚úÖ Tenant-aware routing |\nWhen to use custom dispatchers:\n‚úÖ Mediator pattern requirements\n‚úÖ Event sourcing architecture\n‚úÖ Complex multi-tenant routing\n‚úÖ Custom middleware pipelines\n---\nMediator Dispatcher\nPattern 1: MediatR-Style Dispatcher\n`csharp\npublic class MediatorDispatcher : IDispatcher {\n  private readonly IServiceProvider _services;\n  public MediatorDispatcher(IServiceProvider services) {\n    _services = services;\n  }\n  public async Task<TResponse> SendAsync<TResponse>(\n    object request,\n    CancellationToken ct = default\n  ) {\n    var requestType = request GetType();\n    var handlerType = typeof(IRequestHandler<,>) MakeGenericType(requestType, typeof(TResponse));\n    var handler = _services GetRequiredService(handlerType);\n    var method = handlerType GetMethod(\"Handle\");\n    var result = await (Task<TResponse>)method Invoke(handler, new[] { request, ct }) ;\n    return result;\n  }\n}\npublic interface IRequestHandler<in TRequest, TResponse> {\n  Task<TResponse> Handle(TRequest request, CancellationToken ct);\n}\n`\n---\nEvent Sourcing Dispatcher\nPattern 2: Append-Only Event Store\n`csharp\npublic class EventSourcingDispatcher : IDispatcher {\n  private readonly IEventStore _eventStore;\n  private readonly IDispatcher _innerDispatcher;\n  public EventSourcingDispatcher(\n    IEventStore eventStore,\n    IDispatcher innerDispatcher\n  ) {\n    _eventStore = eventStore;\n    _innerDispatcher = innerDispatcher;\n  }\n  public async Task<TResponse> SendAsync<TResponse>(\n    object command,\n    CancellationToken ct = default\n  ) {\n    // Dispatch command ‚Üí get event response\n    var @event = await _innerDispatcher SendAsync<TResponse>(command, ct);\n    // Append event to event store\n    var streamId = GetStreamId(command);\n    await _eventStore",
        "startIndex": 0,
        "preview": "Custom Dispatchers\nCustom dispatchers enable alternative message routing strategies beyond the default dispatcher Implement mediator patterns, event s..."
      },
      {
        "id": "v0.1.0/extensibility/custom-dispatchers-chunk-1",
        "text": "eventStore, IDispatcher innerDispatcher ) { _eventStore = eventStore; _innerDispatcher = innerDispatcher; } public async Task<TResponse> SendAsync<TResponse>( object command, CancellationToken ct = default ) { // Dispatch command ‚Üí get event response var @event = await _innerDispatcher SendAsync<TResponse>(command, ct); // Append event to event store var streamId = GetStreamId(command); await _eventStore AppendAsync(streamId, @event, ct);\n    return @event;\n  }\n  private Guid GetStreamId(object command) {\n    // Extract aggregate ID from command\n    var aggregateIdProperty = command GetType() GetProperty(\"AggregateId\");\n    return (Guid)aggregateIdProperty GetValue(command) ;\n  }\n}\n`\n---\nFurther Reading\nCore Concepts:\nDispatcher - Default dispatcher\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 2470,
        "preview": "eventStore, IDispatcher innerDispatcher ) { _eventStore = eventStore; _innerDispatcher = innerDispatcher; } public async Task<TResponse> SendAsync<TRe..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-health-checks",
    "title": "Custom Health Checks",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-health-checks",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-health-checks-chunk-0",
        "text": "Custom Health Checks\nCustom health checks enable monitoring application health for Kubernetes, load balancers, and observability tools Implement checks for transports, databases, caches, external APIs, and custom services :::note\nFor built-in health checks, see Health Checks This guide focuses on implementing custom health checks :::\n---\nWhy Custom Health Checks Built-in checks cover common scenarios, but custom checks enable monitoring of:\n| Component | Built-In Check | Custom Check |\n|-----------|---------------|--------------|\n| Azure Service Bus | ‚úÖ Built-in | No customization needed |\n| PostgreSQL | ‚úÖ Built-in | No customization needed |\n| Redis | ‚ùå Not included | ‚úÖ Custom Redis check |\n| Kafka | ‚ùå Not included | ‚úÖ Custom Kafka check |\n| External APIs | ‚ùå Not included | ‚úÖ Custom HTTP check |\n| Custom Services | ‚ùå Not included | ‚úÖ Custom logic check |\nUse Cases:\n‚úÖ Monitor transport connectivity\n‚úÖ Verify database availability\n‚úÖ Check external API dependencies\n‚úÖ Validate custom service health\n‚úÖ Kubernetes readiness/liveness probes\n---\nIHealthCheck Interface\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\npublic interface IHealthCheck {\n  Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  );\n}\n`\nHealthCheckResult States:\nHealthy: Service operational\nDegraded: Service operational but impaired\nUnhealthy: Service not operational\n---\nTransport Health Checks\nPattern 1: Kafka Transport Check\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\nusing Confluent Kafka;\npublic class KafkaHealthCheck : IHealthCheck {\n  private readonly IProducer<string, string> _producer;\n  private readonly ILogger<KafkaHealthCheck> _logger;\n  public KafkaHealthCheck(\n    IProducer<string, string> producer,\n    ILogger<KafkaHealthCheck> logger\n  ) {\n    _producer = producer;\n    _logger = logger;\n  }\n  public Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    try {\n      // Get cluster metadata (verifies connectivity)\n      var metadata = _producer GetMetadata(TimeSpan FromSeconds(5));\n      var brokerCount = metadata Brokers Count;\n      if (brokerCount == 0) {\n        return Task FromResult(HealthCheckResult",
        "startIndex": 0,
        "preview": "Custom Health Checks\nCustom health checks enable monitoring application health for Kubernetes, load balancers, and observability tools Implement check..."
      },
      {
        "id": "v0.1.0/extensibility/custom-health-checks-chunk-1",
        "text": "ILogger<KafkaHealthCheck> logger ) { _producer = producer; _logger = logger; } public Task<HealthCheckResult> CheckHealthAsync( HealthCheckContext context, CancellationToken ct = default ) { try { // Get cluster metadata (verifies connectivity) var metadata = _producer GetMetadata(TimeSpan FromSeconds(5)); var brokerCount = metadata Brokers Count; if (brokerCount == 0) { return Task FromResult(HealthCheckResult Unhealthy(\n          \"No Kafka brokers available\"\n        ));\n      }\n      return Task FromResult(HealthCheckResult Healthy(\n        $\"Kafka healthy, {brokerCount} brokers connected\"\n      ));\n    } catch (KafkaException ex) {\n      _logger LogError(ex, \"Kafka health check failed\");\n      return Task FromResult(HealthCheckResult Unhealthy(\n        \"Kafka cluster unreachable\",\n        ex\n      ));\n    }\n  }\n}\n`\nPattern 2: Redis Cache Check\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\nusing StackExchange Redis;\npublic class RedisHealthCheck : IHealthCheck {\n  private readonly IConnectionMultiplexer _redis;\n  public RedisHealthCheck(IConnectionMultiplexer redis) {\n    _redis = redis;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    try {\n      var db = _redis GetDatabase();\n      // Ping Redis\n      var latency = await db PingAsync();\n      if (latency > TimeSpan FromSeconds(1)) {\n        return HealthCheckResult Degraded(\n          $\"Redis responding slowly ({latency TotalMilliseconds:F0}ms)\"\n        );\n      }\n      return HealthCheckResult Healthy(\n        $\"Redis healthy ({latency TotalMilliseconds:F0}ms latency)\"\n      );\n    } catch (Exception ex) {\n      return HealthCheckResult Unhealthy(\n        \"Redis unavailable\",\n        ex\n      );\n    }\n  }\n}\n`\n---\nDatabase Health Checks\nPattern 3: PostgreSQL Check (Advanced)\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\nusing Npgsql;\npublic class PostgresHealthCheck : IHealthCheck {\n  private readonly string _connectionString;\n  private readonly int _timeoutSeconds;\n  public PostgresHealthCheck(string connectionString, int timeoutSeconds = 5) {\n    _connectionString = connectionString;\n    _timeoutSeconds = timeoutSeconds;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    try {\n      await using var conn = new NpgsqlConnection(_connectionString);\n      // Set connection timeout\n      var csBuilder = new NpgsqlConnectionStringBuilder(_connectionString) {\n        Timeout = _timeoutSeconds\n      };\n      conn ConnectionString = csBuilder ToString();\n      await conn OpenAsync(ct);\n      // Execute simple query to verify connectivity\n      await using var cmd = new NpgsqlCommand(\"SELECT 1\", conn);\n      await cmd",
        "startIndex": 2275,
        "preview": "ILogger<KafkaHealthCheck> logger ) { _producer = producer; _logger = logger; } public Task<HealthCheckResult> CheckHealthAsync( HealthCheckContext con..."
      },
      {
        "id": "v0.1.0/extensibility/custom-health-checks-chunk-2",
        "text": "{ try { await using var conn = new NpgsqlConnection(_connectionString); // Set connection timeout var csBuilder = new NpgsqlConnectionStringBuilder(_connectionString) { Timeout = _timeoutSeconds }; conn ConnectionString = csBuilder ToString(); await conn OpenAsync(ct); // Execute simple query to verify connectivity await using var cmd = new NpgsqlCommand(\"SELECT 1\", conn); await cmd ExecuteScalarAsync(ct);\n      // Check connection pool stats\n      var poolStats = conn GetConnectionState();\n      return HealthCheckResult Healthy(\n        $\"PostgreSQL healthy (pool: {poolStats})\"\n      );\n    } catch (TimeoutException ex) {\n      return HealthCheckResult Unhealthy(\n        $\"PostgreSQL connection timeout ({_timeoutSeconds}s)\",\n        ex\n      );\n    } catch (Exception ex) {\n      return HealthCheckResult Unhealthy(\n        \"PostgreSQL unavailable\",\n        ex\n      );\n    }\n  }\n}\n`\n---\nExternal API Health Checks\nPattern 4: HTTP Dependency Check\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\npublic class ExternalApiHealthCheck : IHealthCheck {\n  private readonly HttpClient _http;\n  private readonly string _healthEndpoint;\n  public ExternalApiHealthCheck(\n    HttpClient http,\n    string healthEndpoint = \"/health\"\n  ) {\n    _http = http;\n    _healthEndpoint = healthEndpoint;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    try {\n      var response = await _http GetAsync(_healthEndpoint, ct);\n      if (response IsSuccessStatusCode) {\n        return HealthCheckResult Healthy(\n          $\"External API healthy (status {response StatusCode})\"\n        );\n      }\n      return HealthCheckResult Degraded(\n        $\"External API degraded (status {response StatusCode})\"\n      );\n    } catch (HttpRequestException ex) {\n      return HealthCheckResult Unhealthy(\n        \"External API unreachable\",\n        ex\n      );\n    }\n  }\n}\n`\n---\nComposite Health Checks\nPattern 5: Multi-Component Check\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\npublic class WhizbangSystemHealthCheck : IHealthCheck {\n  private readonly IEnumerable<IHealthCheck> _checks;\n  public WhizbangSystemHealthCheck(IEnumerable<IHealthCheck> checks) {\n    _checks = checks;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    var results = new List<(string Name, HealthCheckResult Result)>();\n    foreach (var check in _checks) {\n      var name = check GetType() Name;\n      var result = await check CheckHealthAsync(context, ct);\n      results Add((name, result));\n    }\n    // Aggregate results\n    var unhealthy = results Where(r => r Result Status == HealthStatus Unhealthy)",
        "startIndex": 4677,
        "preview": "{ try { await using var conn = new NpgsqlConnection(_connectionString); // Set connection timeout var csBuilder = new NpgsqlConnectionStringBuilder(_c..."
      },
      {
        "id": "v0.1.0/extensibility/custom-health-checks-chunk-3",
        "text": "= default ) { var results = new List<(string Name, HealthCheckResult Result)>(); foreach (var check in _checks) { var name = check GetType() Name; var result = await check CheckHealthAsync(context, ct); results Add((name, result)); } // Aggregate results var unhealthy = results Where(r => r Result Status == HealthStatus Unhealthy) ToList();\n    var degraded = results Where(r => r Result Status == HealthStatus Degraded) ToList();\n    if (unhealthy Any()) {\n      var failedChecks = string Join(\", \", unhealthy Select(r => r Name));\n      return HealthCheckResult Unhealthy(\n        $\"System unhealthy: {failedChecks} failed\"\n      );\n    }\n    if (degraded Any()) {\n      var degradedChecks = string Join(\", \", degraded Select(r => r Name));\n      return HealthCheckResult Degraded(\n        $\"System degraded: {degradedChecks} impaired\"\n      );\n    }\n    return HealthCheckResult Healthy(\"All systems operational\");\n  }\n}\n`\n---\nRegistration and Configuration\n`csharp\n// Startup cs\nbuilder Services AddHealthChecks() AddCheck<KafkaHealthCheck>(\"kafka\", tags: new[] { \"transport\" }) AddCheck<RedisHealthCheck>(\"redis\", tags: new[] { \"cache\" }) AddCheck<PostgresHealthCheck>(\"postgres\", tags: new[] { \"database\" }) AddCheck<ExternalApiHealthCheck>(\"external_api\", tags: new[] { \"external\" });\n// Health check endpoint\napp MapHealthChecks(\"/health\");\n// Filtered endpoints (Kubernetes)\napp MapHealthChecks(\"/health/ready\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"transport\") || check Tags Contains(\"database\")\n});\napp MapHealthChecks(\"/health/live\", new HealthCheckOptions {\n  Predicate = check => true  // All checks\n});\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Set timeouts for external checks (5s max)\n‚úÖ Use tags for filtering (readiness vs liveness)\n‚úÖ Return meaningful descriptions in results\n‚úÖ Handle exceptions gracefully (Unhealthy state)\n‚úÖ Test health checks in isolation\nDON'T ‚ùå\n‚ùå Perform expensive operations (full table scans)\n‚ùå Throw exceptions (return Unhealthy instead)\n‚ùå Skip timeouts (infinite waits)\n‚ùå Check every dependency (focus on critical)\n---\nFurther Reading\nInfrastructure:\nHealth Checks - Built-in health checks\nTransports:\nCustom Transports - Transport implementations\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 7056,
        "preview": "= default ) { var results = new List<(string Name, HealthCheckResult Result)>(); foreach (var check in _checks) { var name = check GetType() Name; var..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-id-generators",
    "title": "Custom ID Generators",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-id-generators",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-id-generators-chunk-0",
        "text": "Custom ID Generators\nCustom ID generators provide alternative ID schemes beyond UUIDv7 Implement Snowflake IDs, ULID, CUID, or custom distributed ID generation strategies :::note\nWhizbang uses UUIDv7 by default for time-ordered, database-friendly IDs Custom generators are for specialized scenarios :::\n---\nWhy Custom ID Generators | ID Scheme | Benefits | Trade-offs |\n|-----------|----------|------------|\n| UUIDv7 (default) | Time-ordered, standard | 128-bit size |\n| Snowflake | 64-bit, Twitter-scale | Requires clock sync |\n| ULID | Lexicographically sortable | Custom parsing |\n| CUID | Collision-resistant | Custom format |\nWhen to use custom IDs:\n‚úÖ 64-bit ID requirements\n‚úÖ Specific ordering needs\n‚úÖ Custom collision resistance\n‚úÖ Legacy system compatibility\n---\nSnowflake ID Generator\nPattern 1: Twitter Snowflake\n`csharp\npublic class SnowflakeIdGenerator {\n  private readonly long _epoch = 1_640_995_200_000L;  // Jan 1, 2022\n  private readonly long _machineId;\n  private readonly object _lock = new();\n  private long _sequence = 0L;\n  private long _lastTimestamp = -1L;\n  public SnowflakeIdGenerator(long machineId) {\n    if (machineId < 0 || machineId > 1023) {\n      throw new ArgumentException(\"Machine ID must be 0-1023\");\n    }\n    _machineId = machineId;\n  }\n  public long NextId() {\n    lock (_lock) {\n      var timestamp = DateTimeOffset UtcNow ToUnixTimeMilliseconds();\n      if (timestamp < _lastTimestamp) {\n        throw new InvalidOperationException(\"Clock moved backwards\");\n      }\n      if (timestamp == _lastTimestamp) {\n        _sequence = (_sequence + 1) & 4095;  // 12-bit sequence\n        if (_sequence == 0) {\n          // Sequence overflow - wait for next millisecond\n          timestamp = WaitNextMillis(_lastTimestamp);\n        }\n      } else {\n        _sequence = 0;\n      }\n      _lastTimestamp = timestamp;\n      // 41 bits: timestamp | 10 bits: machine | 12 bits: sequence\n      return ((timestamp - _epoch) << 22) |\n             (_machineId << 12) |\n             _sequence;\n    }\n  }\n  private long WaitNextMillis(long lastTimestamp) {\n    var timestamp = DateTimeOffset UtcNow ToUnixTimeMilliseconds();\n    while (timestamp <= lastTimestamp) {\n      timestamp = DateTimeOffset UtcNow",
        "startIndex": 0,
        "preview": "Custom ID Generators\nCustom ID generators provide alternative ID schemes beyond UUIDv7 Implement Snowflake IDs, ULID, CUID, or custom distributed ID g..."
      },
      {
        "id": "v0.1.0/extensibility/custom-id-generators-chunk-1",
        "text": "} _lastTimestamp = timestamp; // 41 bits: timestamp | 10 bits: machine | 12 bits: sequence return ((timestamp - _epoch) << 22) | (_machineId << 12) | _sequence; } } private long WaitNextMillis(long lastTimestamp) { var timestamp = DateTimeOffset UtcNow ToUnixTimeMilliseconds(); while (timestamp <= lastTimestamp) { timestamp = DateTimeOffset UtcNow ToUnixTimeMilliseconds();\n    }\n    return timestamp;\n  }\n}\n`\nUsage:\n`csharp\nvar generator = new SnowflakeIdGenerator(machineId: 42);\nvar id = generator NextId();  // 64-bit time-ordered ID\n`\n---\nULID Generator\nPattern 2: Universally Unique Lexicographically Sortable ID\n`csharp\nusing Ulid;\npublic class UlidGenerator {\n  public static string NewId() {\n    return Ulid NewUlid() ToString();  // 26-character string\n  }\n  public static Ulid Parse(string ulidString) {\n    return Ulid Parse(ulidString);\n  }\n}\n`\nUsage:\n`csharp\nvar id = UlidGenerator NewId();  // \"01ARZ3NDEKTSV4RRFFQ69G5FAV\"\n`\n---\nFurther Reading\nCore Concepts:\nMessage Context - MessageId, CorrelationId\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 2230,
        "preview": "} _lastTimestamp = timestamp; // 41 bits: timestamp | 10 bits: machine | 12 bits: sequence return ((timestamp - _epoch) << 22) | (_machineId << 12) | ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-perspectives",
    "title": "Custom Perspectives",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-perspectives",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-0",
        "text": "Custom Perspectives\nCustom perspectives extend the basic IPerspectiveOf<TEvent> pattern with advanced capabilities like time-travel (event replay), snapshots, caching layers, batch processing, and custom storage backends :::note\nFor basic perspective usage, see Perspectives Guide This guide focuses on advanced customization patterns for specialized scenarios :::\n---\nWhy Custom Perspective Patterns",
        "startIndex": 0,
        "preview": "Custom Perspectives\nCustom perspectives extend the basic IPerspectiveOf<TEvent> pattern with advanced capabilities like time-travel (event replay), sn..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-1",
        "text": "Custom Perspectives Custom perspectives extend the basic IPerspectiveOf<TEvent> pattern with advanced capabilities like time-travel (event replay), snapshots, caching layers, batch processing, and custom storage backends :::note For basic perspective usage, see Perspectives Guide This guide focuses on advanced customization patterns for specialized scenarios ::: --- Why Custom Perspective Patterns Built-in IPerspectiveOf<TEvent> handles most cases, but some scenarios benefit from custom patterns:\n| Scenario | Standard Perspective | Custom Pattern |\n|----------|---------------------|----------------|\n| Event ‚Üí Read Model | ‚úÖ Perfect fit | No customization needed |\n| Time-Travel Queries | ‚ùå No built-in support | ‚úÖ Checkpoint-based replay |\n| Performance (Large Events) | ‚ùå Full replay expensive | ‚úÖ Snapshot + incremental |\n| Caching Layer | ‚ùå Database-only | ‚úÖ In-memory + database |\n| Batch Updates | ‚ùå One-at-a-time | ‚úÖ Batched for throughput |\n| Custom Storage | ‚ùå SQL-only | ‚úÖ Custom backends (Redis, Elasticsearch) |\n| Hierarchical Models | ‚ùå Flat models | ‚úÖ Parent-child relationships |\nWhen to customize:\n‚úÖ Time-travel / event replay scenarios\n‚úÖ High-frequency events (> 10K/sec per stream)\n‚úÖ Large event streams (> 1M events)\n‚úÖ Specialized storage (search engines, caches)\n‚úÖ Complex read model requirements\nWhen NOT to customize:\n‚ùå Simple event ‚Üí table updates\n‚ùå Low-volume scenarios (< 100 events/sec)\n‚ùå Standard SQL read models\n---\nArchitecture\nCheckpoint-Based Perspective System\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Event Store (wh_event_store)                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ stream_id  | event_id (UUIDv7) | payload      ‚îÇ ‚îÇ\n‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ\n‚îÇ  ‚îÇ order-123  | uuid-001          | OrderCreated ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ order-123  | uuid-002          | OrderPaid    ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ order-123  | uuid-003          | OrderShipped ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                      ‚îÇ\n                      ‚îÇ Events flow to perspectives\n                      ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Perspective Checkpoint (wh_perspective_checkpoints) ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ stream_id  | perspective_name | last_event_id ‚îÇ ‚îÇ\n‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ\n‚îÇ  ‚îÇ order-123  | OrderSummary     | uuid-003      ‚îÇ ‚îÇ ‚Üê Processed up to OrderShipped\n‚îÇ  ‚îÇ order-123  | InventorySummary | uuid-002      ‚îÇ ‚îÇ ‚Üê Processed up to OrderPaid\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                      ‚îÇ\n                      ‚îÇ Perspectives update read models\n                      ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Read Model (order_summaries)                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ order_id  | customer_id | status   | total    ‚îÇ ‚îÇ\n‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ\n‚îÇ  ‚îÇ order-123 | cust-456    | Shipped  | $99",
        "startIndex": 405,
        "preview": "Custom Perspectives Custom perspectives extend the basic IPerspectiveOf<TEvent> pattern with advanced capabilities like time-travel (event replay), sn..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-2",
        "text": "‚îÇ ‚îÇ ‚Üê Processed up to OrderPaid ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ Perspectives update read models ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Read Model (order_summaries) ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ order_id | customer_id | status | total ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ order-123 | cust-456 | Shipped | $99 99   ‚îÇ ‚îÇ ‚Üê Denormalized view\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey Concepts:\nEvent Store: Immutable log of all events per stream\nCheckpoint: Last processed event per (stream, perspective)\nTime-Travel: Replay events from any checkpoint\nMultiple Perspectives: Same events, different read models\n---\nCustom Base Classes\nPattern 1: Checkpoint-Aware Perspective Base\nUse Case: Automatically track checkpoint after processing each event `csharp\nusing Whizbang Core;\nusing Whizbang Core Messaging;\npublic abstract class CheckpointPerspective<TEvent> : IPerspectiveOf<TEvent> where TEvent : IEvent {\n  private readonly IWorkCoordinator _coordinator;\n  protected readonly ILogger Logger;\n  protected CheckpointPerspective(\n    IWorkCoordinator coordinator,\n    ILogger logger\n  ) {\n    _coordinator = coordinator;\n    Logger = logger;\n  }\n  public async Task UpdateAsync(TEvent @event, CancellationToken ct = default) {\n    // 1 Process event (implemented by subclass)\n    await ProcessEventAsync(@event, ct);\n    // 2 Update checkpoint automatically\n    await UpdateCheckpointAsync(@event, ct);\n    Logger LogInformation(\n      \"Processed {EventType} for stream {StreamId}, checkpoint updated to {EventId}\",\n      typeof(TEvent) Name,\n      @event StreamId,\n      @event EventId\n    );\n  }\n  /// <summary>\n  /// Implement event processing logic here /// Checkpoint is updated automatically after success /// </summary>\n  protected abstract Task ProcessEventAsync(TEvent @event, CancellationToken ct);\n  /// <summary>\n  /// Get the perspective name for checkpoint tracking /// Default: class name Override for custom names /// </summary>\n  protected virtual string GetPerspectiveName() => GetType() Name;\n  private async Task UpdateCheckpointAsync(TEvent @event, CancellationToken ct) {\n    var completion = new PerspectiveCheckpointCompletion {\n      StreamId = @event StreamId,\n      PerspectiveName = GetPerspectiveName(),\n      LastEventId = @event EventId,\n      Status = PerspectiveProcessingStatus Completed\n    };\n    // Update checkpoint via work coordinator\n    await _coordinator ProcessWorkBatchAsync(\n      instanceId: Guid NewGuid(),\n      serviceName: \"Perspective\",\n      hostName: Environment MachineName,\n      processId: Environment",
        "startIndex": 3159,
        "preview": "‚îÇ ‚îÇ ‚Üê Processed up to OrderPaid ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ Pe..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-3",
        "text": "Name; private async Task UpdateCheckpointAsync(TEvent @event, CancellationToken ct) { var completion = new PerspectiveCheckpointCompletion { StreamId = @event StreamId, PerspectiveName = GetPerspectiveName(), LastEventId = @event EventId, Status = PerspectiveProcessingStatus Completed }; // Update checkpoint via work coordinator await _coordinator ProcessWorkBatchAsync( instanceId: Guid NewGuid(), serviceName: \"Perspective\", hostName: Environment MachineName, processId: Environment ProcessId,\n      metadata: null,\n      outboxCompletions: [],\n      outboxFailures: [],\n      inboxCompletions: [],\n      inboxFailures: [],\n      receptorCompletions: [],\n      receptorFailures: [],\n      perspectiveCompletions: [completion],  // ‚Üê Update checkpoint\n      perspectiveFailures: [],\n      newOutboxMessages: [],\n      newInboxMessages: [],\n      renewOutboxLeaseIds: [],\n      renewInboxLeaseIds: [],\n      cancellationToken: ct\n    );\n  }\n}\n`\nUsage:\n`csharp\npublic record OrderCreated(\n  Guid StreamId,\n  Guid EventId,\n  Guid OrderId,\n  Guid CustomerId,\n  decimal Total\n) : IEvent;\npublic class OrderSummaryPerspective : CheckpointPerspective<OrderCreated> {\n  private readonly IDbConnectionFactory _db;\n  public OrderSummaryPerspective(\n    IWorkCoordinator coordinator,\n    ILogger<OrderSummaryPerspective> logger,\n    IDbConnectionFactory db\n  ) : base(coordinator, logger) {\n    _db = db;\n  }\n  // Checkpoint updated automatically after ProcessEventAsync completes\n  protected override async Task ProcessEventAsync(\n    OrderCreated @event,\n    CancellationToken ct\n  ) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"INSERT INTO order_summaries (order_id, customer_id, total, status) VALUES (@OrderId, @CustomerId, @Total, 'Created')\",\n      new { @event OrderId, @event CustomerId, @event Total },\n      ct\n    );\n  }\n}\n`\nBenefits:\nAutomatic Checkpoint Tracking: No manual checkpoint management\nTime-Travel Ready: Can replay from any checkpoint\nConsistent Pattern: Same checkpoint logic across perspectives\n---\nPattern 2: Snapshot Perspective Base\nUse Case: Periodic snapshots instead of full event replay for large streams `csharp\nusing Whizbang Core;\npublic abstract class SnapshotPerspective<TEvent, TSnapshot> : IPerspectiveOf<TEvent>\n  where TEvent : IEvent\n  where TSnapshot : class, new() {\n  private readonly IPerspectiveStore<TSnapshot> _store;\n  protected readonly ILogger Logger;\n  // Snapshot every N events (configurable)\n  protected virtual int SnapshotInterval => 100;\n  protected SnapshotPerspective(\n    IPerspectiveStore<TSnapshot> store,\n    ILogger logger\n  ) {\n    _store = store;\n    Logger = logger;\n  }\n  public async Task UpdateAsync(TEvent @event, CancellationToken ct = default) {\n    // 1",
        "startIndex": 5499,
        "preview": "Name; private async Task UpdateCheckpointAsync(TEvent @event, CancellationToken ct) { var completion = new PerspectiveCheckpointCompletion { StreamId ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-4",
        "text": "class, new() { private readonly IPerspectiveStore<TSnapshot> _store; protected readonly ILogger Logger; // Snapshot every N events (configurable) protected virtual int SnapshotInterval => 100; protected SnapshotPerspective( IPerspectiveStore<TSnapshot> store, ILogger logger ) { _store = store; Logger = logger; } public async Task UpdateAsync(TEvent @event, CancellationToken ct = default) { // 1 Load current snapshot (or create new)\n    var snapshot = await LoadSnapshotAsync(@event StreamId ToString(), ct) new TSnapshot();\n    // 2 Apply event to snapshot\n    ApplyEvent(@event, snapshot);\n    // 3 Save updated snapshot\n    await _store UpsertAsync(@event StreamId ToString(), snapshot, ct);\n    Logger LogDebug(\n      \"Applied {EventType} to snapshot for stream {StreamId}\",\n      typeof(TEvent) Name,\n      @event StreamId\n    );\n  }\n  /// <summary>\n  /// Apply event to snapshot (implement delta update) /// </summary>\n  protected abstract void ApplyEvent(TEvent @event, TSnapshot snapshot);\n  /// <summary>\n  /// Load snapshot from store /// </summary>\n  protected virtual async Task<TSnapshot > LoadSnapshotAsync(\n    string streamId,\n    CancellationToken ct\n  ) {\n    // IPerspectiveStore doesn't expose reads - this is write-only\n    // For reads, use a separate query service/lens\n    return new TSnapshot();  // Simplified for example\n  }\n}\n`\nUsage:\n`csharp\npublic record OrderSnapshot {\n  public Guid OrderId { get; set; }\n  public Guid CustomerId { get; set; }\n  public decimal Total { get; set; }\n  public string Status { get; set; } = \"Created\";\n  public int EventCount { get; set; }  // Track events applied\n}\npublic class OrderSnapshotPerspective : SnapshotPerspective<OrderCreated, OrderSnapshot> {\n  public OrderSnapshotPerspective(\n    IPerspectiveStore<OrderSnapshot> store,\n    ILogger<OrderSnapshotPerspective> logger\n  ) : base(store, logger) { }\n  protected override void ApplyEvent(OrderCreated @event, OrderSnapshot snapshot) {\n    // Delta update - only change what's new\n    snapshot OrderId = @event OrderId;\n    snapshot CustomerId = @event CustomerId;\n    snapshot Total = @event Total;\n    snapshot Status = \"Created\";\n    snapshot EventCount++;\n    Logger LogInformation(\n      \"Applied OrderCreated to snapshot, now at {EventCount} events\",\n      snapshot",
        "startIndex": 7782,
        "preview": "class, new() { private readonly IPerspectiveStore<TSnapshot> _store; protected readonly ILogger Logger; // Snapshot every N events (configurable) prot..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-5",
        "text": "{ } protected override void ApplyEvent(OrderCreated @event, OrderSnapshot snapshot) { // Delta update - only change what's new snapshot OrderId = @event OrderId; snapshot CustomerId = @event CustomerId; snapshot Total = @event Total; snapshot Status = \"Created\"; snapshot EventCount++; Logger LogInformation( \"Applied OrderCreated to snapshot, now at {EventCount} events\", snapshot EventCount\n    );\n  }\n}\n`\nBenefits:\nFast Rebuild: Snapshot + recent events (not full replay)\nPerformance: O(recent events) instead of O(all events)\nScalability: Works with millions of events per stream\n---\nTime-Travel Perspectives\nPattern 3: Event Replay Perspective\nUse Case: Rebuild read model from event history for any point in time `csharp\nusing Whizbang Core;\npublic class TimeravelOrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IEventStore _eventStore;\n  private readonly IDbConnectionFactory _db;\n  private readonly ILogger<TimeravelOrderSummaryPerspective> _logger;\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    // Standard event processing\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"INSERT INTO order_summaries ( ) VALUES ( )\",\n      @event,\n      ct\n    );\n  }\n  /// <summary>\n  /// Rebuild read model from event history up to specific event /// Enables \"what did the order look like at 2:00 PM yesterday \"\n  /// </summary>\n  public async Task RebuildToEventAsync(\n    Guid streamId,\n    Guid targetEventId,\n    CancellationToken ct = default\n  ) {\n    _logger LogInformation(\n      \"Rebuilding OrderSummary for stream {StreamId} up to event {EventId}\",\n      streamId,\n      targetEventId\n    );\n    // 1 Clear existing read model for this stream\n    await ClearReadModelAsync(streamId, ct);\n    // 2 Replay events in order until target event\n    await foreach (var @event in _eventStore GetEventsAsync<OrderCreated>(\n      streamId,\n      untilEventId: targetEventId,  // Stop at target\n      ct\n    )) {\n      await UpdateAsync(@event, ct);\n    }\n    _logger LogInformation(\n      \"Rebuilt OrderSummary for stream {StreamId} to event {EventId}\",\n      streamId,\n      targetEventId\n    );\n  }\n  /// <summary>\n  /// Rebuild entire read model from scratch /// </summary>\n  public async Task RebuildAllAsync(CancellationToken ct = default) {\n    _logger LogInformation(\"Rebuilding all OrderSummary read models\");\n    // 1",
        "startIndex": 9710,
        "preview": "{ } protected override void ApplyEvent(OrderCreated @event, OrderSnapshot snapshot) { // Delta update - only change what's new snapshot OrderId = @eve..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-6",
        "text": "at target ct )) { await UpdateAsync(@event, ct); } _logger LogInformation( \"Rebuilt OrderSummary for stream {StreamId} to event {EventId}\", streamId, targetEventId ); } /// <summary> /// Rebuild entire read model from scratch /// </summary> public async Task RebuildAllAsync(CancellationToken ct = default) { _logger LogInformation(\"Rebuilding all OrderSummary read models\"); // 1 Truncate read model table\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\"TRUNCATE TABLE order_summaries\", ct);\n    // 2 Replay all events\n    await foreach (var @event in _eventStore GetAllEventsAsync<OrderCreated>(ct)) {\n      await UpdateAsync(@event, ct);\n    }\n    _logger LogInformation(\"Rebuilt all OrderSummary read models\");\n  }\n  private async Task ClearReadModelAsync(Guid streamId, CancellationToken ct) {\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"DELETE FROM order_summaries WHERE stream_id = @StreamId\",\n      new { StreamId = streamId },\n      ct\n    );\n  }\n}\n`\nUsage:\n`csharp\n// Standard event processing\nawait perspective UpdateAsync(orderCreated, ct);\n// Time-travel: rebuild to specific event\nvar specificEventId = Guid Parse(\" \");  // Event from 2:00 PM yesterday\nawait perspective RebuildToEventAsync(orderId, specificEventId, ct);\n// Rebuild entire read model (after schema change)\nawait perspective RebuildAllAsync(ct);\n`\nUse Cases:\nDebugging: What did the order look like when bug occurred Auditing: Reconstruct state at regulatory compliance checkpoint\nSchema Evolution: Rebuild read model after adding new fields\nTesting: Verify read model correctness by replaying production events\n---\nPerformance Optimization\nPattern 4: Batching Perspective\nUse Case: Batch multiple events for single database roundtrip `csharp\nusing Whizbang Core;\nusing System Threading Channels;\npublic class BatchingOrderSummaryPerspective : IPerspectiveOf<OrderCreated>, IAsyncDisposable {\n  private readonly IDbConnectionFactory _db;\n  private readonly ILogger<BatchingOrderSummaryPerspective> _logger;\n  private readonly Channel<OrderCreated> _eventQueue;\n  private readonly Task _batchProcessor;\n  private readonly CancellationTokenSource _cts;\n  // Batch settings\n  private const int BatchSize = 100;\n  private static readonly TimeSpan BatchTimeout = TimeSpan FromMilliseconds(500);\n  public BatchingOrderSummaryPerspective(\n    IDbConnectionFactory db,\n    ILogger<BatchingOrderSummaryPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n    // Bounded channel for backpressure\n    _eventQueue = Channel",
        "startIndex": 11775,
        "preview": "at target ct )) { await UpdateAsync(@event, ct); } _logger LogInformation( \"Rebuilt OrderSummary for stream {StreamId} to event {EventId}\", streamId, ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-7",
        "text": "readonly Channel<OrderCreated> _eventQueue; private readonly Task _batchProcessor; private readonly CancellationTokenSource _cts; // Batch settings private const int BatchSize = 100; private static readonly TimeSpan BatchTimeout = TimeSpan FromMilliseconds(500); public BatchingOrderSummaryPerspective( IDbConnectionFactory db, ILogger<BatchingOrderSummaryPerspective> logger ) { _db = db; _logger = logger; // Bounded channel for backpressure _eventQueue = Channel CreateBounded<OrderCreated>(new BoundedChannelOptions(10000) {\n      FullMode = BoundedChannelFullMode Wait\n    });\n    _cts = new CancellationTokenSource();\n    _batchProcessor = Task Run(() => ProcessBatchesAsync(_cts Token));\n  }\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    // Queue event for batch processing\n    await _eventQueue Writer WriteAsync(@event, ct);\n  }\n  private async Task ProcessBatchesAsync(CancellationToken ct) {\n    var batch = new List<OrderCreated>(BatchSize);\n    while ( ct IsCancellationRequested) {\n      try {\n        // Read up to BatchSize events or timeout\n        while (batch Count < BatchSize) {\n          using var timeoutCts = CancellationTokenSource CreateLinkedTokenSource(ct);\n          timeoutCts CancelAfter(BatchTimeout);\n          try {\n            var @event = await _eventQueue Reader ReadAsync(timeoutCts Token);\n            batch Add(@event);\n          } catch (OperationCanceledException) {\n            // Timeout or cancellation - process what we have\n            break;\n          }\n        }\n        // Process batch if we have any events\n        if (batch Count > 0) {\n          await ProcessBatchAsync(batch, ct);\n          batch Clear();\n        }\n      } catch (Exception ex) when (ex is not OperationCanceledException) {\n        _logger LogError(ex, \"Error processing event batch\");\n        await Task Delay(TimeSpan FromSeconds(1), ct);  // Backoff\n      }\n    }\n  }\n  private async Task ProcessBatchAsync(List<OrderCreated> events, CancellationToken ct) {\n    await using var conn = _db CreateConnection();\n    // Single INSERT for entire batch\n    await conn ExecuteAsync(\n      \"\"\"\n      INSERT INTO order_summaries (order_id, customer_id, total, status, created_at)\n      VALUES (@OrderId, @CustomerId, @Total, 'Created', @CreatedAt)\n      ON CONFLICT (order_id) DO NOTHING\n      \"\"\",\n      events,  // ‚Üê Dapper executes once per item, but single roundtrip\n      ct\n    );\n    _logger LogInformation(\n      \"Processed batch of {Count} events\",\n      events Count\n    );\n  }\n  public async ValueTask DisposeAsync() {\n    // Shutdown gracefully\n    _eventQueue Writer Complete();\n    _cts Cancel();\n    try {\n      await _batchProcessor WaitAsync(TimeSpan FromSeconds(10));\n    } catch (TimeoutException) {\n      _logger",
        "startIndex": 13975,
        "preview": "readonly Channel<OrderCreated> _eventQueue; private readonly Task _batchProcessor; private readonly CancellationTokenSource _cts; // Batch settings pr..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-8",
        "text": "NOTHING \"\"\", events, // ‚Üê Dapper executes once per item, but single roundtrip ct ); _logger LogInformation( \"Processed batch of {Count} events\", events Count ); } public async ValueTask DisposeAsync() { // Shutdown gracefully _eventQueue Writer Complete(); _cts Cancel(); try { await _batchProcessor WaitAsync(TimeSpan FromSeconds(10)); } catch (TimeoutException) { _logger LogWarning(\"Batch processor did not complete within timeout\");\n    }\n    _cts Dispose();\n  }\n}\n`\nPerformance:\nThroughput: 10x improvement (100 events/batch vs 1 event/call)\nLatency: Slightly higher (max 500ms batching delay)\nDatabase Load: 10x reduction in connections/queries\n---\nPattern 5: Cached Perspective\nUse Case: In-memory cache + database for read-heavy scenarios `csharp\nusing Whizbang Core;\nusing Microsoft Extensions Caching Memory;\npublic class CachedOrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IDbConnectionFactory _db;\n  private readonly IMemoryCache _cache;\n  private readonly ILogger<CachedOrderSummaryPerspective> _logger;\n  private static readonly MemoryCacheEntryOptions CacheOptions = new() {\n    AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(5),\n    SlidingExpiration = TimeSpan FromMinutes(1)\n  };\n  public CachedOrderSummaryPerspective(\n    IDbConnectionFactory db,\n    IMemoryCache cache,\n    ILogger<CachedOrderSummaryPerspective> logger\n  ) {\n    _db = db;\n    _cache = cache;\n    _logger = logger;\n  }\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    // 1 Update database (source of truth)\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"INSERT INTO order_summaries (order_id, customer_id, total, status) VALUES (@OrderId, @CustomerId, @Total, 'Created')\",\n      new { @event OrderId, @event CustomerId, @event Total },\n      ct\n    );\n    // 2 Update cache\n    var cacheKey = GetCacheKey(@event OrderId);\n    var summary = new OrderSummary {\n      OrderId = @event OrderId,\n      CustomerId = @event CustomerId,\n      Total = @event Total,\n      Status = \"Created\"\n    };\n    _cache Set(cacheKey, summary, CacheOptions);\n    _logger LogDebug(\n      \"Updated order summary for {OrderId} in database and cache\",\n      @event OrderId\n    );\n  }\n  /// <summary>\n  /// Read from cache, fall back to database if cache miss /// </summary>\n  public async Task<OrderSummary > GetAsync(Guid orderId, CancellationToken ct = default) {\n    var cacheKey = GetCacheKey(orderId);\n    // Try cache first\n    if (_cache",
        "startIndex": 16303,
        "preview": "NOTHING \"\"\", events, // ‚Üê Dapper executes once per item, but single roundtrip ct ); _logger LogInformation( \"Processed batch of {Count} events\", event..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-9",
        "text": "LogDebug( \"Updated order summary for {OrderId} in database and cache\", @event OrderId ); } /// <summary> /// Read from cache, fall back to database if cache miss /// </summary> public async Task<OrderSummary > GetAsync(Guid orderId, CancellationToken ct = default) { var cacheKey = GetCacheKey(orderId); // Try cache first if (_cache TryGetValue(cacheKey, out OrderSummary cached)) {\n      _logger LogDebug(\"Cache hit for order {OrderId}\", orderId);\n      return cached;\n    }\n    // Cache miss - load from database\n    _logger LogDebug(\"Cache miss for order {OrderId}, loading from database\", orderId);\n    await using var conn = _db CreateConnection();\n    var summary = await conn QuerySingleOrDefaultAsync<OrderSummary>(\n      \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n      new { OrderId = orderId },\n      ct\n    );\n    if (summary is not null) {\n      // Populate cache for next time\n      _cache Set(cacheKey, summary, CacheOptions);\n    }\n    return summary;\n  }\n  private static string GetCacheKey(Guid orderId) => $\"order-summary:{orderId}\";\n}\npublic record OrderSummary {\n  public Guid OrderId { get; set; }\n  public Guid CustomerId { get; set; }\n  public decimal Total { get; set; }\n  public string Status { get; set; } = string Empty;\n}\n`\nPerformance:\nCache Hit Rate: 95%+ for read-heavy workloads\nLatency: ~1¬µs (cache) vs ~5ms (database)\nDatabase Load: 95% reduction in reads\n---\nCustom Storage Backends\nPattern 6: IPerspectiveStore Implementation\nUse Case: Custom storage backend (Redis, Elasticsearch, etc ) `csharp\nusing Whizbang Core Perspectives;\nusing StackExchange Redis;\nusing System Text Json;\n/// <summary>\n/// Redis-based perspective store for high-performance read models /// </summary>\npublic class RedisPerspectiveStore<TModel> : IPerspectiveStore<TModel> where TModel : class {\n  private readonly IConnectionMultiplexer _redis;\n  private readonly ILogger<RedisPerspectiveStore<TModel>> _logger;\n  private readonly string _keyPrefix;\n  private static readonly JsonSerializerOptions JsonOptions = new() {\n    PropertyNamingPolicy = JsonNamingPolicy CamelCase\n  };\n  public RedisPerspectiveStore(\n    IConnectionMultiplexer redis,\n    ILogger<RedisPerspectiveStore<TModel>> logger,\n    string keyPrefix = null\n  ) {\n    _redis = redis;\n    _logger = logger;\n    _keyPrefix = keyPrefix typeof(TModel) Name",
        "startIndex": 18463,
        "preview": "LogDebug( \"Updated order summary for {OrderId} in database and cache\", @event OrderId ); } /// <summary> /// Read from cache, fall back to database if..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-10",
        "text": "class { private readonly IConnectionMultiplexer _redis; private readonly ILogger<RedisPerspectiveStore<TModel>> _logger; private readonly string _keyPrefix; private static readonly JsonSerializerOptions JsonOptions = new() { PropertyNamingPolicy = JsonNamingPolicy CamelCase }; public RedisPerspectiveStore( IConnectionMultiplexer redis, ILogger<RedisPerspectiveStore<TModel>> logger, string keyPrefix = null ) { _redis = redis; _logger = logger; _keyPrefix = keyPrefix typeof(TModel) Name ToLowerInvariant();\n  }\n  public async Task UpsertAsync(\n    string id,\n    TModel model,\n    CancellationToken ct = default\n  ) {\n    var db = _redis GetDatabase();\n    var key = GetRedisKey(id);\n    // Serialize model to JSON\n    var json = JsonSerializer Serialize(model, JsonOptions);\n    // Store in Redis with expiration\n    await db StringSetAsync(\n      key,\n      json,\n      expiry: TimeSpan FromHours(24)  // TTL for read models\n    );\n    _logger LogDebug(\n      \"Upserted {ModelType} with id {Id} to Redis\",\n      typeof(TModel) Name,\n      id\n    );\n  }\n  /// <summary>\n  /// Get model from Redis (not part of IPerspectiveStore, but useful for reads) /// </summary>\n  public async Task<TModel > GetAsync(string id, CancellationToken ct = default) {\n    var db = _redis GetDatabase();\n    var key = GetRedisKey(id);\n    var json = await db StringGetAsync(key);\n    if (json IsNullOrEmpty) {\n      return null;\n    }\n    return JsonSerializer Deserialize<TModel>(json , JsonOptions);\n  }\n  private string GetRedisKey(string id) => $\"{_keyPrefix}:{id}\";\n}\n`\nUsage:\n`csharp\n// Register Redis perspective store\nbuilder Services AddSingleton<IConnectionMultiplexer>(\n  ConnectionMultiplexer Connect(\"localhost:6379\")\n);\nbuilder Services AddSingleton<IPerspectiveStore<OrderSummary>, RedisPerspectiveStore<OrderSummary>>();\n// Use in perspective\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IPerspectiveStore<OrderSummary> _store;\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    var summary = new OrderSummary {\n      OrderId = @event OrderId,\n      CustomerId = @event CustomerId,\n      Total = @event Total,\n      Status = \"Created\"\n    };\n    // Store in Redis (via IPerspectiveStore abstraction)\n    await _store UpsertAsync(@event OrderId ToString(), summary, ct);\n  }\n}\n`\nBenefits:\nStorage Flexibility: Redis, Elasticsearch, MongoDB, etc Abstraction: Perspectives don't know storage details\nTestability: Mock IPerspectiveStore for unit tests\n---\nAdvanced Patterns\nPattern 7: Hierarchical Perspective\nUse Case: Parent-child read models (order ‚Üí order items)",
        "startIndex": 20485,
        "preview": "class { private readonly IConnectionMultiplexer _redis; private readonly ILogger<RedisPerspectiveStore<TModel>> _logger; private readonly string _keyP..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-11",
        "text": "in Redis (via IPerspectiveStore abstraction) await _store UpsertAsync(@event OrderId ToString(), summary, ct); } } ` Benefits: Storage Flexibility: Redis, Elasticsearch, MongoDB, etc Abstraction: Perspectives don't know storage details Testability: Mock IPerspectiveStore for unit tests --- Advanced Patterns Pattern 7: Hierarchical Perspective Use Case: Parent-child read models (order ‚Üí order items) `csharp\nusing Whizbang Core;\npublic class OrderDetailsPerspective :\n  IPerspectiveOf<OrderCreated>,\n  IPerspectiveOf<OrderItemAdded> {\n  private readonly IDbConnectionFactory _db;\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Insert parent record\n    await conn ExecuteAsync(\n      \"INSERT INTO order_details (order_id, customer_id, total, status) VALUES (@OrderId, @CustomerId, @Total, 'Created')\",\n      new { @event OrderId, @event CustomerId, @event Total },\n      ct\n    );\n  }\n  public async Task UpdateAsync(OrderItemAdded @event, CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    // Insert child record\n    await conn ExecuteAsync(\n      \"INSERT INTO order_detail_items (order_id, product_id, quantity, unit_price) VALUES (@OrderId, @ProductId, @Quantity, @UnitPrice)\",\n      new { @event OrderId, @event ProductId, @event Quantity, @event UnitPrice },\n      ct\n    );\n    // Update parent aggregate\n    await conn ExecuteAsync(\n      \"UPDATE order_details SET total = total + (@Quantity * @UnitPrice) WHERE order_id = @OrderId\",\n      new { @event OrderId, @event Quantity, @event UnitPrice },\n      ct\n    );\n  }\n}\n`\nSchema:\n`sql\nCREATE TABLE order_details (\n    order_id UUID PRIMARY KEY,\n    customer_id UUID NOT NULL,\n    total DECIMAL(10,2) NOT NULL,\n    status VARCHAR(50) NOT NULL\n);\nCREATE TABLE order_detail_items (\n    order_item_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    order_id UUID NOT NULL REFERENCES order_details(order_id),\n    product_id UUID NOT NULL,\n    quantity INT NOT NULL,\n    unit_price DECIMAL(10,2) NOT NULL\n);\n`\n---\nPattern 8: Transformation Perspective\nUse Case: Transform events before storing (enrich, filter, aggregate) `csharp\nusing Whizbang Core;\npublic class EnrichedOrderPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly IDbConnectionFactory _db;\n  private readonly ICustomerService _customerService;\n  private readonly ILogger<EnrichedOrderPerspective> _logger;\n  public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n    // 1",
        "startIndex": 3672,
        "preview": "in Redis (via IPerspectiveStore abstraction) await _store UpsertAsync(@event OrderId ToString(), summary, ct); } } ` Benefits: Storage Flexibility: Re..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-12",
        "text": "); ` --- Pattern 8: Transformation Perspective Use Case: Transform events before storing (enrich, filter, aggregate) `csharp using Whizbang Core; public class EnrichedOrderPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory _db; private readonly ICustomerService _customerService; private readonly ILogger<EnrichedOrderPerspective> _logger; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { // 1 Enrich event with customer data\n    var customer = await _customerService GetCustomerAsync(@event CustomerId, ct);\n    // 2 Transform and store enriched data\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"\"\"\n      INSERT INTO enriched_orders (\n          order_id, customer_id, customer_name, customer_email, customer_tier,\n          total, status, created_at\n      ) VALUES (\n          @OrderId, @CustomerId, @CustomerName, @CustomerEmail, @CustomerTier,\n          @Total, 'Created', @CreatedAt\n      )\n      \"\"\",\n      new {\n        @event OrderId,\n        @event CustomerId,\n        CustomerName = customer FullName,       // ‚Üê Enriched\n        CustomerEmail = customer Email,         // ‚Üê Enriched\n        CustomerTier = customer LoyaltyTier,    // ‚Üê Enriched\n        @event Total,\n        @event CreatedAt\n      },\n      ct\n    );\n    _logger LogInformation(\n      \"Enriched order {OrderId} with customer data for {CustomerName}\",\n      @event OrderId,\n      customer FullName\n    );\n  }\n}\n`\n---\nTesting Custom Perspectives\nTesting Checkpoint Perspectives\n`csharp\npublic class CheckpointPerspectiveTests {\n  [Test]\n  public async Task UpdateAsync_UpdatesCheckpointAfterProcessingAsync() {\n    // Arrange\n    var mockCoordinator = CreateMockWorkCoordinator();\n    var mockDb = CreateMockDb();\n    var logger = new NullLogger<OrderSummaryPerspective>();\n    var perspective = new OrderSummaryPerspective(mockCoordinator, logger, mockDb);\n    var @event = new OrderCreated(\n      StreamId: Guid NewGuid(),\n      EventId: Guid NewGuid(),\n      OrderId: Guid NewGuid(),\n      CustomerId: Guid NewGuid(),\n      Total: 99 99m\n    );\n    // Act\n    await perspective UpdateAsync(@event);\n    // Assert - checkpoint updated\n    var checkpoints = mockCoordinator GetPerspectiveCheckpoints();\n    await Assert That(checkpoints) HasCount() EqualTo(1);\n    await Assert That(checkpoints[0] StreamId) IsEqualTo(@event StreamId);\n    await Assert That(checkpoints[0] LastEventId) IsEqualTo(@event EventId);\n    await Assert That(checkpoints[0] PerspectiveName) IsEqualTo(\"OrderSummaryPerspective\");\n  }\n}\n`\nTesting Time-Travel Perspectives\n`csharp\npublic class TimeravelPerspectiveTests {\n  [Test]\n  public async Task RebuildToEventAsync_ReplaysEventsUpToTargetAsync() {\n    // Arrange\n    var mockEventStore = CreateMockEventStore(eventCount: 10);\n    var mockDb = CreateMockDb();\n    var logger = new NullLogger<TimeravelOrderSummaryPerspective>();\n    var perspective = new TimeravelOrderSummaryPerspective(mockEventStore, mockDb, logger);\n    var streamId = Guid",
        "startIndex": 24815,
        "preview": "); ` --- Pattern 8: Transformation Perspective Use Case: Transform events before storing (enrich, filter, aggregate) `csharp using Whizbang Core; publ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-perspectives-chunk-13",
        "text": "EventId); await Assert That(checkpoints[0] PerspectiveName) IsEqualTo(\"OrderSummaryPerspective\"); } } ` Testing Time-Travel Perspectives `csharp public class TimeravelPerspectiveTests { [Test] public async Task RebuildToEventAsync_ReplaysEventsUpToTargetAsync() { // Arrange var mockEventStore = CreateMockEventStore(eventCount: 10); var mockDb = CreateMockDb(); var logger = new NullLogger<TimeravelOrderSummaryPerspective>(); var perspective = new TimeravelOrderSummaryPerspective(mockEventStore, mockDb, logger); var streamId = Guid NewGuid();\n    var targetEventId = mockEventStore GetEventId(streamId, eventIndex: 5);  // Event #5\n    // Act - rebuild to event #5 (should process events 1-5)\n    await perspective RebuildToEventAsync(streamId, targetEventId);\n    // Assert - only 5 events processed\n    var summaries = await mockDb QueryAsync<OrderSummary>(\n      \"SELECT * FROM order_summaries WHERE stream_id = @StreamId\",\n      new { StreamId = streamId }\n    );\n    await Assert That(summaries) HasCount() EqualTo(5);  // Not 10 }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Track checkpoints for time-travel scenarios\n‚úÖ Use snapshots for large event streams (> 1M events)\n‚úÖ Batch updates for high-throughput scenarios (> 10K events/sec)\n‚úÖ Cache read models for read-heavy workloads\n‚úÖ Make perspectives idempotent (same event = same result)\n‚úÖ Test time-travel scenarios (rebuild from any point)\n‚úÖ Log checkpoint progress for debugging\nDON'T ‚ùå\n‚ùå Store state in perspective instances (stateless only)\n‚ùå Skip checkpoint updates (breaks time-travel)\n‚ùå Replay all events for every query (use snapshots)\n‚ùå Block perspective processing (async all the way)\n‚ùå Ignore idempotency (duplicate events will happen)\n‚ùå Mix read and write logic in perspectives\n---\nFurther Reading\nCore Concepts:\nPerspectives Guide - Basic perspective usage\nDispatcher - Publishing events\nEvent Store - Event storage patterns\nExtensibility:\nCustom Receptors - Advanced receptor patterns\nCustom Storage - Storage backend implementations\nData Access:\nPerspectives Storage - Schema design\nWork Coordination - Checkpoint tracking\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 27412,
        "preview": "EventId); await Assert That(checkpoints[0] PerspectiveName) IsEqualTo(\"OrderSummaryPerspective\"); } } ` Testing Time-Travel Perspectives `csharp publi..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-policies",
    "title": "Custom Policies",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-policies",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-0",
        "text": "Custom Policies\nCustom policies extend the basic policy system with advanced patterns like weighted evaluation, priority-based matching, async predicates (database lookups), dynamic registration, caching, and A/B testing :::note\nFor basic policy usage, see Policy-Based Routing This guide focuses on advanced policy extensibility :::\n---\nWhy Custom Policy Patterns Built-in PolicyEngine uses first-match evaluation, but some scenarios benefit from custom patterns:\n| Scenario | Standard PolicyEngine | Custom Pattern |\n|----------|----------------------|----------------|\n| First-Match Evaluation | ‚úÖ Perfect fit | No customization needed |\n| Weighted/Priority Policies | ‚ùå No priorities | ‚úÖ Weighted policy engine |\n| Async Predicates | ‚ùå Sync only | ‚úÖ Async policy engine |\n| Policy Caching | ‚ùå Evaluate every time | ‚úÖ Cached policy results |\n| Dynamic Registration | ‚ùå Static at startup | ‚úÖ Runtime policy updates |\n| A/B Testing | ‚ùå No traffic splitting | ‚úÖ Percentage-based routing |\nWhen to customize:\n‚úÖ Complex policy priority/weighting\n‚úÖ Async predicates (database, API calls)\n‚úÖ Dynamic policy updates (feature flags)\n‚úÖ High-frequency evaluation (caching needed)\n‚úÖ A/B testing / canary deployments\n---\nWeighted Policy Engine\nPattern 1: Priority-Based Evaluation\nUse Case: Policies have explicit priorities instead of first-match `csharp\nusing Whizbang Core Policies;\npublic class WeightedPolicyEngine : IPolicyEngine {\n  private readonly List<WeightedPolicy> _policies = [];\n  private readonly ILogger<WeightedPolicyEngine> _logger;\n  public WeightedPolicyEngine(ILogger<WeightedPolicyEngine> logger) {\n    _logger = logger;\n  }\n  public void AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure,\n    int priority = 0  // ‚Üê Custom parameter\n  ) {\n    _policies Add(new WeightedPolicy {\n      Name = name,\n      Predicate = predicate,\n      Configure = configure,\n      Priority = priority\n    });\n    // Sort by priority (highest first)\n    _policies Sort((a, b) => b Priority CompareTo(a Priority));\n    _logger LogDebug(\n      \"Added policy {PolicyName} with priority {Priority}\",\n      name,\n      priority\n    );\n  }\n  // Standard AddPolicy delegates to weighted version\n  void IPolicyEngine",
        "startIndex": 0,
        "preview": "Custom Policies\nCustom policies extend the basic policy system with advanced patterns like weighted evaluation, priority-based matching, async predica..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-1",
        "text": "WeightedPolicy { Name = name, Predicate = predicate, Configure = configure, Priority = priority }); // Sort by priority (highest first) _policies Sort((a, b) => b Priority CompareTo(a Priority)); _logger LogDebug( \"Added policy {PolicyName} with priority {Priority}\", name, priority ); } // Standard AddPolicy delegates to weighted version void IPolicyEngine AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    AddPolicy(name, predicate, configure, priority: 0);\n  }\n  public async Task<PolicyConfiguration > MatchAsync(PolicyContext context) {\n    foreach (var policy in _policies) {  // Ordered by priority\n      try {\n        if (policy Predicate(context)) {\n          var config = new PolicyConfiguration();\n          policy Configure(config);\n          context Trail RecordDecision(\n            policyName: policy Name,\n            rule: $\"Priority: {policy Priority}\",\n            matched: true,\n            configuration: config,\n            reason: $\"Matched with priority {policy Priority}\"\n          );\n          return config;\n        }\n      } catch (Exception ex) {\n        context Trail RecordDecision(\n          policyName: policy Name,\n          rule: $\"Priority: {policy Priority}\",\n          matched: false,\n          configuration: null,\n          reason: $\"Evaluation failed: {ex Message}\"\n        );\n      }\n    }\n    return null;  // No match\n  }\n  private class WeightedPolicy {\n    public required string Name { get; init; }\n    public required Func<PolicyContext, bool> Predicate { get; init; }\n    public required Action<PolicyConfiguration> Configure { get; init; }\n    public int Priority { get; init; }\n  }\n}\n`\nUsage:\n`csharp\nvar engine = new WeightedPolicyEngine(logger);\n// High-priority tenant routing (priority 100)\nengine AddPolicy(\n  name: \"PremiumTenantRouting\",\n  predicate: ctx => ctx GetMetadata(\"tier\") ToString() == \"premium\",\n  configure: config => config PublishToServiceBus(\"premium-events\"),\n  priority: 100  // ‚Üê Evaluated first\n);\n// Medium-priority standard routing (priority 50)\nengine AddPolicy(\n  name: \"StandardRouting\",\n  predicate: ctx => true,\n  configure: config => config PublishToServiceBus(\"standard-events\"),\n  priority: 50\n);\n// Evaluation: PremiumTenantRouting checked first (higher priority)\n`\n---\nAsync Policy Engine\nPattern 2: Async Predicate Evaluation\nUse Case: Predicates need database lookups, API calls, feature flags `csharp\nusing Whizbang Core",
        "startIndex": 2267,
        "preview": "WeightedPolicy { Name = name, Predicate = predicate, Configure = configure, Priority = priority }); // Sort by priority (highest first) _policies Sort..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-2",
        "text": "routing (priority 50) engine AddPolicy( name: \"StandardRouting\", predicate: ctx => true, configure: config => config PublishToServiceBus(\"standard-events\"), priority: 50 ); // Evaluation: PremiumTenantRouting checked first (higher priority) ` --- Async Policy Engine Pattern 2: Async Predicate Evaluation Use Case: Predicates need database lookups, API calls, feature flags `csharp using Whizbang Core Policies;\npublic class AsyncPolicyEngine : IPolicyEngine {\n  private readonly List<AsyncPolicy> _policies = [];\n  private readonly ILogger<AsyncPolicyEngine> _logger;\n  public AsyncPolicyEngine(ILogger<AsyncPolicyEngine> logger) {\n    _logger = logger;\n  }\n  /// <summary>\n  /// Add async policy with async predicate /// </summary>\n  public void AddAsyncPolicy(\n    string name,\n    Func<PolicyContext, CancellationToken, Task<bool>> asyncPredicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    _policies Add(new AsyncPolicy {\n      Name = name,\n      AsyncPredicate = asyncPredicate,\n      Configure = configure\n    });\n  }\n  // Standard AddPolicy wraps sync predicate in async\n  void IPolicyEngine AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    AddAsyncPolicy(\n      name,\n      asyncPredicate: (ctx, ct) => Task FromResult(predicate(ctx)),\n      configure\n    );\n  }\n  public async Task<PolicyConfiguration > MatchAsync(\n    PolicyContext context,\n    CancellationToken ct = default\n  ) {\n    foreach (var policy in _policies) {\n      try {\n        if (await policy AsyncPredicate(context, ct)) {\n          var config = new PolicyConfiguration();\n          policy Configure(config);\n          context Trail RecordDecision(\n            policyName: policy Name,\n            rule: \"Async evaluation\",\n            matched: true,\n            configuration: config,\n            reason: \"Async predicate matched\"\n          );\n          return config;\n        }\n      } catch (Exception ex) {\n        context Trail RecordDecision(\n          policyName: policy Name,\n          rule: \"Async evaluation\",\n          matched: false,\n          configuration: null,\n          reason: $\"Async evaluation failed: {ex Message}\"\n        );\n      }\n    }\n    return null;\n  }\n  // Overload standard MatchAsync\n  Task<PolicyConfiguration > IPolicyEngine MatchAsync(PolicyContext context) =>\n    MatchAsync(context, CancellationToken None);\n  private class AsyncPolicy {\n    public required string Name { get; init; }\n    public required Func<PolicyContext, CancellationToken, Task<bool>> AsyncPredicate { get; init; }\n    public required Action<PolicyConfiguration> Configure { get; init; }\n  }\n}\n`\nUsage:\n`csharp\nvar engine = new AsyncPolicyEngine(logger);\n// Async predicate: lookup feature flag from database\nengine",
        "startIndex": 4395,
        "preview": "routing (priority 50) engine AddPolicy( name: \"StandardRouting\", predicate: ctx => true, configure: config => config PublishToServiceBus(\"standard-eve..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-3",
        "text": "None); private class AsyncPolicy { public required string Name { get; init; } public required Func<PolicyContext, CancellationToken, Task<bool>> AsyncPredicate { get; init; } public required Action<PolicyConfiguration> Configure { get; init; } } } ` Usage: `csharp var engine = new AsyncPolicyEngine(logger); // Async predicate: lookup feature flag from database engine AddAsyncPolicy(\n  name: \"FeatureFlagRouting\",\n  asyncPredicate: async (ctx, ct) => {\n    var featureService = ctx GetService<IFeatureFlagService>();\n    return await featureService IsEnabledAsync(\"new-routing\", ct);\n  },\n  configure: config => config PublishToServiceBus(\"new-events\")\n);\n// Async predicate: lookup tenant configuration\nengine AddAsyncPolicy(\n  name: \"TenantConfigRouting\",\n  asyncPredicate: async (ctx, ct) => {\n    var tenantId = ctx GetMetadata(\"tenantId\") ToString();\n    if (tenantId is null) return false;\n    var tenantService = ctx GetService<ITenantService>();\n    var tenant = await tenantService GetTenantAsync(tenantId, ct);\n    return tenant IsActive == true;\n  },\n  configure: config => config PublishToServiceBus(\"active-tenant-events\")\n);\n`\n---\nCached Policy Engine\nPattern 3: Policy Result Caching\nUse Case: Reduce policy evaluation overhead for high-frequency messages `csharp\nusing Whizbang Core Policies;\nusing Microsoft Extensions Caching Memory;\npublic class CachedPolicyEngine : IPolicyEngine {\n  private readonly IPolicyEngine _innerEngine;\n  private readonly IMemoryCache _cache;\n  private readonly ILogger<CachedPolicyEngine> _logger;\n  private static readonly MemoryCacheEntryOptions CacheOptions = new() {\n    AbsoluteExpirationRelativeToNow = TimeSpan FromMinutes(5),\n    SlidingExpiration = TimeSpan FromMinutes(1)\n  };\n  public CachedPolicyEngine(\n    IPolicyEngine innerEngine,\n    IMemoryCache cache,\n    ILogger<CachedPolicyEngine> logger\n  ) {\n    _innerEngine = innerEngine;\n    _cache = cache;\n    _logger = logger;\n  }\n  void IPolicyEngine AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    _innerEngine AddPolicy(name, predicate, configure);\n  }\n  public async Task<PolicyConfiguration > MatchAsync(PolicyContext context) {\n    // Generate cache key from context\n    var cacheKey = GenerateCacheKey(context);\n    // Try cache first\n    if (_cache TryGetValue(cacheKey, out PolicyConfiguration cached)) {\n      _logger LogDebug(\n        \"Policy cache hit for key {CacheKey}\",\n        cacheKey\n      );\n      return cached;\n    }\n    // Cache miss - evaluate policies\n    _logger LogDebug(\n      \"Policy cache miss for key {CacheKey}, evaluating policies\",\n      cacheKey\n    );\n    var config = await _innerEngine MatchAsync(context);\n    // Cache result (including null)\n    _cache",
        "startIndex": 6780,
        "preview": "None); private class AsyncPolicy { public required string Name { get; init; } public required Func<PolicyContext, CancellationToken, Task<bool>> Async..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-4",
        "text": "if (_cache TryGetValue(cacheKey, out PolicyConfiguration cached)) { _logger LogDebug( \"Policy cache hit for key {CacheKey}\", cacheKey ); return cached; } // Cache miss - evaluate policies _logger LogDebug( \"Policy cache miss for key {CacheKey}, evaluating policies\", cacheKey ); var config = await _innerEngine MatchAsync(context); // Cache result (including null) _cache Set(cacheKey, config, CacheOptions);\n    return config;\n  }\n  private static string GenerateCacheKey(PolicyContext context) {\n    // Cache key based on message type + metadata\n    var tenantId = context GetMetadata(\"tenantId\") ToString() \"default\";\n    var environment = context Environment;\n    var messageType = context MessageType Name;\n    return $\"policy:{messageType}:{tenantId}:{environment}\";\n  }\n  /// <summary>\n  /// Clear policy cache (e g , after policy updates) /// </summary>\n  public void ClearCache() {\n    if (_cache is MemoryCache memoryCache) {\n      memoryCache Compact(1 0);  // Remove 100% of entries\n      _logger LogInformation(\"Policy cache cleared\");\n    }\n  }\n}\n`\nUsage:\n`csharp\nvar baseEngine = new PolicyEngine();\nvar cachedEngine = new CachedPolicyEngine(baseEngine, memoryCache, logger);\n// Add policies to base engine\nbaseEngine AddPolicy( );\n// Use cached engine - first call evaluates, subsequent calls use cache\nvar config1 = await cachedEngine MatchAsync(context);  // Cache miss - evaluate\nvar config2 = await cachedEngine MatchAsync(context);  // Cache hit - instant\n// Clear cache after policy updates\ncachedEngine ClearCache();\n`\nPerformance:\nCache Hit: ~1¬µs (memory lookup)\nCache Miss: ~100¬µs (full evaluation)\nImprovement: ~100x for cached scenarios\n---\nDynamic Policy Registration\nPattern 4: Runtime Policy Updates\nUse Case: Add/remove policies at runtime based on feature flags, tenant config `csharp\nusing Whizbang Core Policies;\npublic class DynamicPolicyEngine : IPolicyEngine {\n  private readonly List<Policy> _policies = [];\n  private readonly ReaderWriterLockSlim _lock = new();\n  private readonly ILogger<DynamicPolicyEngine> _logger;\n  public DynamicPolicyEngine(ILogger<DynamicPolicyEngine> logger) {\n    _logger = logger;\n  }\n  void IPolicyEngine AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    _lock EnterWriteLock();\n    try {\n      _policies",
        "startIndex": 9191,
        "preview": "if (_cache TryGetValue(cacheKey, out PolicyConfiguration cached)) { _logger LogDebug( \"Policy cache hit for key {CacheKey}\", cacheKey ); return cached..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-5",
        "text": "Whizbang Core Policies; public class DynamicPolicyEngine : IPolicyEngine { private readonly List<Policy> _policies = []; private readonly ReaderWriterLockSlim _lock = new(); private readonly ILogger<DynamicPolicyEngine> _logger; public DynamicPolicyEngine(ILogger<DynamicPolicyEngine> logger) { _logger = logger; } void IPolicyEngine AddPolicy( string name, Func<PolicyContext, bool> predicate, Action<PolicyConfiguration> configure ) { _lock EnterWriteLock(); try { _policies Add(new Policy {\n        Name = name,\n        Predicate = predicate,\n        Configure = configure\n      });\n      _logger LogInformation(\"Added policy {PolicyName}\", name);\n    } finally {\n      _lock ExitWriteLock();\n    }\n  }\n  /// <summary>\n  /// Remove policy by name (custom method) /// </summary>\n  public bool RemovePolicy(string name) {\n    _lock EnterWriteLock();\n    try {\n      var removed = _policies RemoveAll(p => p Name == name);\n      if (removed > 0) {\n        _logger LogInformation(\"Removed policy {PolicyName}\", name);\n        return true;\n      }\n      return false;\n    } finally {\n      _lock ExitWriteLock();\n    }\n  }\n  public async Task<PolicyConfiguration > MatchAsync(PolicyContext context) {\n    _lock EnterReadLock();\n    try {\n      foreach (var policy in _policies) {\n        try {\n          if (policy Predicate(context)) {\n            var config = new PolicyConfiguration();\n            policy Configure(config);\n            return config;\n          }\n        } catch (Exception ex) {\n          _logger LogWarning(\n            ex,\n            \"Policy {PolicyName} evaluation failed\",\n            policy Name\n          );\n        }\n      }\n      return null;\n    } finally {\n      _lock ExitReadLock();\n    }\n  }\n  private class Policy {\n    public required string Name { get; init; }\n    public required Func<PolicyContext, bool> Predicate { get; init; }\n    public required Action<PolicyConfiguration> Configure { get; init; }\n  }\n}\n`\nUsage:\n`csharp\nvar engine = new DynamicPolicyEngine(logger);\n// Add initial policies\nengine AddPolicy(\"DefaultRouting\", ctx => true, config => config PublishToServiceBus(\"default\"));\n// Runtime: Add tenant-specific policy when tenant onboards\nawait OnTenantOnboardedAsync(tenantId: \"tenant-a\");\npublic async Task OnTenantOnboardedAsync(string tenantId) {\n  engine AddPolicy(\n    name: $\"Tenant{tenantId}Routing\",\n    predicate: ctx => ctx GetMetadata(\"tenantId\") ToString() == tenantId,\n    configure: config => config PublishToServiceBus($\"{tenantId}-events\")\n  );\n}\n// Runtime: Remove policy when tenant offboards\nawait OnTenantOffboardedAsync(tenantId: \"tenant-a\");\npublic async Task OnTenantOffboardedAsync(string tenantId) {\n  engine",
        "startIndex": 11173,
        "preview": "Whizbang Core Policies; public class DynamicPolicyEngine : IPolicyEngine { private readonly List<Policy> _policies = []; private readonly ReaderWriter..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-6",
        "text": "tenant-specific policy when tenant onboards await OnTenantOnboardedAsync(tenantId: \"tenant-a\"); public async Task OnTenantOnboardedAsync(string tenantId) { engine AddPolicy( name: $\"Tenant{tenantId}Routing\", predicate: ctx => ctx GetMetadata(\"tenantId\") ToString() == tenantId, configure: config => config PublishToServiceBus($\"{tenantId}-events\") ); } // Runtime: Remove policy when tenant offboards await OnTenantOffboardedAsync(tenantId: \"tenant-a\"); public async Task OnTenantOffboardedAsync(string tenantId) { engine RemovePolicy($\"Tenant{tenantId}Routing\");\n}\n`\n---\nA/B Testing Policy Engine\nPattern 5: Percentage-Based Traffic Splitting\nUse Case: Route X% of traffic to new feature for canary/gradual rollout `csharp\nusing Whizbang Core Policies;\npublic class ABTestingPolicyEngine : IPolicyEngine {\n  private readonly IPolicyEngine _innerEngine;\n  private readonly ILogger<ABTestingPolicyEngine> _logger;\n  private readonly Dictionary<string, ABTestConfig> _abTests = [];\n  public ABTestingPolicyEngine(\n    IPolicyEngine innerEngine,\n    ILogger<ABTestingPolicyEngine> logger\n  ) {\n    _innerEngine = innerEngine;\n    _logger = logger;\n  }\n  /// <summary>\n  /// Configure A/B test: route percentage of traffic to variant /// </summary>\n  public void ConfigureABTest(\n    string testName,\n    double percentageToVariant,  // 0 0 - 100 0\n    Action<PolicyConfiguration> variantConfig,\n    Action<PolicyConfiguration> controlConfig\n  ) {\n    _abTests[testName] = new ABTestConfig {\n      TestName = testName,\n      PercentageToVariant = percentageToVariant,\n      VariantConfig = variantConfig,\n      ControlConfig = controlConfig\n    };\n    _logger LogInformation(\n      \"Configured A/B test {TestName}: {Percentage}% to variant\",\n      testName,\n      percentageToVariant\n    );\n  }\n  void IPolicyEngine AddPolicy(\n    string name,\n    Func<PolicyContext, bool> predicate,\n    Action<PolicyConfiguration> configure\n  ) {\n    _innerEngine AddPolicy(name, predicate, configure);\n  }\n  public async Task<PolicyConfiguration > MatchAsync(PolicyContext context) {\n    // Check if message participates in A/B test\n    var testName = context GetMetadata(\"abTestName\") ToString();\n    if (testName = null && _abTests TryGetValue(testName, out var abTest)) {\n      // Determine variant via consistent hashing (same message ‚Üí same variant)\n      var messageId = context Envelope MessageId Value ToString() Guid NewGuid() ToString();\n      var hash = Math Abs(messageId GetHashCode());\n      var percentage = (hash % 100);  // 0-99\n      bool isVariant = percentage < abTest PercentageToVariant;\n      var config = new PolicyConfiguration();\n      if (isVariant) {\n        abTest VariantConfig(config);\n        _logger LogDebug(\n          \"A/B test {TestName}: Routed to VARIANT (hash {Hash}%)\",\n          testName,\n          percentage\n        );\n      } else {\n        abTest",
        "startIndex": 13387,
        "preview": "tenant-specific policy when tenant onboards await OnTenantOnboardedAsync(tenantId: \"tenant-a\"); public async Task OnTenantOnboardedAsync(string tenant..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-7",
        "text": "NewGuid() ToString(); var hash = Math Abs(messageId GetHashCode()); var percentage = (hash % 100); // 0-99 bool isVariant = percentage < abTest PercentageToVariant; var config = new PolicyConfiguration(); if (isVariant) { abTest VariantConfig(config); _logger LogDebug( \"A/B test {TestName}: Routed to VARIANT (hash {Hash}%)\", testName, percentage ); } else { abTest ControlConfig(config);\n        _logger LogDebug(\n          \"A/B test {TestName}: Routed to CONTROL (hash {Hash}%)\",\n          testName,\n          percentage\n        );\n      }\n      return config;\n    }\n    // No A/B test - use standard policy evaluation\n    return await _innerEngine MatchAsync(context);\n  }\n  private class ABTestConfig {\n    public required string TestName { get; init; }\n    public double PercentageToVariant { get; init; }\n    public required Action<PolicyConfiguration> VariantConfig { get; init; }\n    public required Action<PolicyConfiguration> ControlConfig { get; init; }\n  }\n}\n`\nUsage:\n`csharp\nvar baseEngine = new PolicyEngine();\nvar abEngine = new ABTestingPolicyEngine(baseEngine, logger);\n// Configure A/B test: 10% to new routing, 90% to old routing\nabEngine ConfigureABTest(\n  testName: \"new-routing-experiment\",\n  percentageToVariant: 10 0,\n  variantConfig: config => config PublishToServiceBus(\"new-events\"),  // 10%\n  controlConfig: config => config PublishToServiceBus(\"old-events\")   // 90%\n);\n// Messages with abTestName metadata participate in A/B test\nvar context = PolicyContextPool Rent(\n  message: message,\n  envelope: envelope,\n  services: services,\n  environment: \"production\"\n);\n// Add A/B test metadata\ncontext Envelope Metadata[\"abTestName\"] = \"new-routing-experiment\";\n// Evaluation: 10% ‚Üí new-events, 90% ‚Üí old-events (consistent per message ID)\nvar config = await abEngine MatchAsync(context);\n`\n---\nTesting Custom Policies\nTesting Weighted Policies\n`csharp\npublic class WeightedPolicyEngineTests {\n  [Test]\n  public async Task MatchAsync_HighPriorityMatchesFirst_SkipsLowerPriorityAsync() {\n    // Arrange\n    var logger = new NullLogger<WeightedPolicyEngine>();\n    var engine = new WeightedPolicyEngine(logger);\n    engine AddPolicy(\n      name: \"LowPriority\",\n      predicate: ctx => true,  // Would match\n      configure: config => config PublishToServiceBus(\"low\"),\n      priority: 10\n    );\n    engine AddPolicy(\n      name: \"HighPriority\",\n      predicate: ctx => true,  // Matches first\n      configure: config => config",
        "startIndex": 15750,
        "preview": "NewGuid() ToString(); var hash = Math Abs(messageId GetHashCode()); var percentage = (hash % 100); // 0-99 bool isVariant = percentage < abTest Percen..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-8",
        "text": "async Task MatchAsync_HighPriorityMatchesFirst_SkipsLowerPriorityAsync() { // Arrange var logger = new NullLogger<WeightedPolicyEngine>(); var engine = new WeightedPolicyEngine(logger); engine AddPolicy( name: \"LowPriority\", predicate: ctx => true, // Would match configure: config => config PublishToServiceBus(\"low\"), priority: 10 ); engine AddPolicy( name: \"HighPriority\", predicate: ctx => true, // Matches first configure: config => config PublishToServiceBus(\"high\"),\n      priority: 100\n    );\n    var context = new PolicyContext(new TestMessage(), null, null, \"test\");\n    // Act\n    var result = await engine MatchAsync(context);\n    // Assert - HighPriority matched (higher priority)\n    await Assert That(result) IsNotNull();\n    await Assert That(result PublishTargets[0] Destination) IsEqualTo(\"high\");\n  }\n}\n`\nTesting Async Policies\n`csharp\npublic class AsyncPolicyEngineTests {\n  [Test]\n  public async Task MatchAsync_AsyncPredicate_CallsDatabaseAsync() {\n    // Arrange\n    var logger = new NullLogger<AsyncPolicyEngine>();\n    var engine = new AsyncPolicyEngine(logger);\n    var dbCallCount = 0;\n    engine AddAsyncPolicy(\n      name: \"DatabasePolicy\",\n      asyncPredicate: async (ctx, ct) => {\n        dbCallCount++;  // Track async call\n        await Task Delay(10, ct);  // Simulate database\n        return true;\n      },\n      configure: config => config PublishToServiceBus(\"test\")\n    );\n    var context = new PolicyContext(new TestMessage(), null, null, \"test\");\n    // Act\n    var result = await engine MatchAsync(context);\n    // Assert - Async predicate executed\n    await Assert That(result) IsNotNull();\n    await Assert That(dbCallCount) IsEqualTo(1);\n  }\n}\n`\nTesting Cached Policies\n`csharp\npublic class CachedPolicyEngineTests {\n  [Test]\n  public async Task MatchAsync_SecondCall_UsesCacheAsync() {\n    // Arrange\n    var baseEngine = new PolicyEngine();\n    var memoryCache = new MemoryCache(new MemoryCacheOptions());\n    var logger = new NullLogger<CachedPolicyEngine>();\n    var cachedEngine = new CachedPolicyEngine(baseEngine, memoryCache, logger);\n    var evaluationCount = 0;\n    baseEngine AddPolicy(\n      name: \"TestPolicy\",\n      predicate: ctx => {\n        evaluationCount++;  // Track evaluations\n        return true;\n      },\n      configure: config => config PublishToServiceBus(\"test\")\n    );\n    var context = new PolicyContext(new TestMessage(), null, null, \"test\");\n    // Act - First call (cache miss)\n    var result1 = await cachedEngine MatchAsync(context);\n    // Act - Second call (cache hit)\n    var result2 = await cachedEngine MatchAsync(context);\n    // Assert - Only evaluated once (cached)\n    await Assert That(result1) IsNotNull();\n    await Assert That(result2)",
        "startIndex": 17833,
        "preview": "async Task MatchAsync_HighPriorityMatchesFirst_SkipsLowerPriorityAsync() { // Arrange var logger = new NullLogger<WeightedPolicyEngine>(); var engine ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-policies-chunk-9",
        "text": "); var context = new PolicyContext(new TestMessage(), null, null, \"test\"); // Act - First call (cache miss) var result1 = await cachedEngine MatchAsync(context); // Act - Second call (cache hit) var result2 = await cachedEngine MatchAsync(context); // Assert - Only evaluated once (cached) await Assert That(result1) IsNotNull(); await Assert That(result2) IsNotNull();\n    await Assert That(evaluationCount) IsEqualTo(1);  // Not 2 }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Wrap base PolicyEngine for compatibility\n‚úÖ Use thread-safe collections for dynamic policies\n‚úÖ Cache policy results for high-frequency scenarios\n‚úÖ Log policy decisions via PolicyDecisionTrail\n‚úÖ Test async predicates with real dependencies\n‚úÖ Clear cache after updates (dynamic policies)\n‚úÖ Use consistent hashing for A/B tests\nDON'T ‚ùå\n‚ùå Block async operations in predicates\n‚ùå Throw exceptions from predicates (caught and logged)\n‚ùå Cache results with tenant-specific data (isolation issue)\n‚ùå Skip thread safety for dynamic policies\n‚ùå Use reflection in predicates (breaks AOT)\n‚ùå Forget to invalidate cache after policy changes\n---\nFurther Reading\nInfrastructure:\nPolicy-Based Routing - Basic policy usage\nObject Pooling - PolicyContext pooling\nCore Concepts:\nMessage Context - Envelope metadata\nAdvanced:\nMulti-Tenancy - Tenant isolation patterns\nPerformance Tuning - Optimization strategies\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 18112,
        "preview": "); var context = new PolicyContext(new TestMessage(), null, null, \"test\"); // Act - First call (cache miss) var result1 = await cachedEngine MatchAsyn..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-receptors",
    "title": "Custom Receptors",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-receptors",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-0",
        "text": "Custom Receptors\nCustom receptors extend the basic IReceptor<TMessage, TResponse> pattern with advanced capabilities like streaming, lifecycle management, custom base classes, and specialized execution patterns :::note\nFor basic receptor usage, see Receptors Guide This guide focuses on advanced customization patterns for specialized scenarios :::\n---\nWhy Custom Receptor Patterns Built-in IReceptor<T, TResponse> handles most cases, but some scenarios benefit from custom patterns:\n| Scenario | Standard Receptor | Custom Pattern |\n|----------|------------------|----------------|\n| Request/Response | ‚úÖ Perfect fit | No customization needed |\n| Streaming Results | ‚ùå Returns single response | ‚úÖ IAsyncEnumerable streaming |\n| Shared Logic | ‚ùå Copy-paste across receptors | ‚úÖ Custom base class |\n| Resource Lifecycle | ‚ùå Manual setup/teardown | ‚úÖ Lifecycle hooks |\n| Complex Validation | ‚ùå Repetitive code | ‚úÖ Base class validation |\n| Multi-Tenancy | ‚ùå Manual tenant resolution | ‚úÖ Base class with tenant context |\n| Performance Critical | ‚ùå Defensive allocations | ‚úÖ Zero-allocation patterns |\nWhen to customize:\n‚úÖ Shared behavior across many receptors\n‚úÖ Streaming/pagination scenarios\n‚úÖ Complex lifecycle management\n‚úÖ Domain-specific validation\n‚úÖ Multi-tenant applications\nWhen NOT to customize:\n‚ùå One-off requirements (use standard receptor)\n‚ùå Simple request/response (over-engineering)\n‚ùå Adding state (receptors must be stateless)\n---\nArchitecture\nReceptor Execution Pipeline\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Dispatcher InvokeAsync<TMessage, TResponse>()         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                     ‚îÇ\n                     ‚Üì\n           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n           ‚îÇ  Resolve Receptor   ‚îÇ ‚Üê DI Container\n           ‚îÇ  IReceptor<T, R>    ‚îÇ\n           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                      ‚îÇ\n                      ‚Üì\n         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ  Pipeline Behaviors    ‚îÇ ‚Üê IPipelineBehavior<T, R>\n         ‚îÇ  (Logging, Validation) ‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚îÇ\n                    ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ  receptor HandleAsync(message)    ‚îÇ ‚Üê Your Custom Receptor\n    ‚îÇ                                   ‚îÇ\n    ‚îÇ  Lifecycle:                       ‚îÇ\n    ‚îÇ  1 Constructor (DI)              ‚îÇ\n    ‚îÇ  2 HandleAsync (business logic)  ‚îÇ\n    ‚îÇ  3",
        "startIndex": 0,
        "preview": "Custom Receptors\nCustom receptors extend the basic IReceptor<TMessage, TResponse> pattern with advanced capabilities like streaming, lifecycle managem..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-1",
        "text": "Container ‚îÇ IReceptor<T, R> ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Pipeline Behaviors ‚îÇ ‚Üê IPipelineBehavior<T, R> ‚îÇ (Logging, Validation) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ receptor HandleAsync(message) ‚îÇ ‚Üê Your Custom Receptor ‚îÇ ‚îÇ ‚îÇ Lifecycle: ‚îÇ ‚îÇ 1 Constructor (DI) ‚îÇ ‚îÇ 2 HandleAsync (business logic) ‚îÇ ‚îÇ 3 Dispose (if IAsyncDisposable) ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚îÇ\n                    ‚Üì\n           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n           ‚îÇ  Return TResponse ‚îÇ\n           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nCustom Receptor Base Class Pattern\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  ReceptorBase<TMessage, TResponse>             ‚îÇ\n‚îÇ                                                ‚îÇ\n‚îÇ  + Constructor(IServiceProvider)               ‚îÇ\n‚îÇ  + abstract ValidateAsync(message)             ‚îÇ\n‚îÇ  + abstract ExecuteAsync(message)              ‚îÇ\n‚îÇ  + LogInformation(message)                     ‚îÇ\n‚îÇ  + GetService<T>()                             ‚îÇ\n‚îÇ  + HandleAsync(message) [sealed]               ‚îÇ\n‚îÇ    ‚îú‚îÄ ValidateAsync(message)                   ‚îÇ\n‚îÇ    ‚îú‚îÄ ExecuteAsync(message)                    ‚îÇ\n‚îÇ    ‚îî‚îÄ Log result                               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚ñ≤\n                    ‚îÇ Inherits\n                    ‚îÇ\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ  CreateOrderReceptor          ‚îÇ\n    ‚îÇ                               ‚îÇ\n    ‚îÇ  + ValidateAsync(message)     ‚îÇ ‚Üê Override\n    ‚îÇ  + ExecuteAsync(message)      ‚îÇ ‚Üê Override\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nCustom Base Classes\nPattern 1: Base Class with Shared Logic\nUse Case: Multiple receptors sharing common validation, logging, or setup logic `csharp\nusing Whizbang Core;\n/// <summary>\n/// Base class for receptors with shared validation and logging /// </summary>\npublic abstract class ReceptorBase<TMessage, TResponse> : IReceptor<TMessage, TResponse> {\n  protected readonly ILogger<ReceptorBase<TMessage, TResponse>> Logger;\n  protected readonly IServiceProvider Services;\n  protected ReceptorBase(\n    ILogger<ReceptorBase<TMessage, TResponse>> logger,\n    IServiceProvider services\n  ) {\n    Logger = logger;\n    Services = services;\n  }\n  /// <summary>\n  /// Template method pattern: validates, executes, logs /// </summary>\n  public async ValueTask<TResponse> HandleAsync(\n    TMessage message,\n    CancellationToken ct = default\n  ) {\n    Logger LogInformation(\n      \"Handling {MessageType}\",\n      typeof(TMessage) Name\n    );\n    // 1 Validate (can be overridden)\n    await ValidateAsync(message, ct);\n    // 2 Execute business logic (must be implemented)\n    var response = await ExecuteAsync(message, ct);\n    // 3 Log result\n    Logger LogInformation(\n      \"Handled {MessageType} successfully\",\n      typeof(TMessage) Name\n    );\n    return response;\n  }\n  /// <summary>\n  /// Override to add message-specific validation /// Default: no validation",
        "startIndex": 2414,
        "preview": "Container ‚îÇ IReceptor<T, R> ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Pipeline Behaviors ‚îÇ ‚Üê IPipelineBehavior<T, R> ‚îÇ (Logging, Vali..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-2",
        "text": "// 1 Validate (can be overridden) await ValidateAsync(message, ct); // 2 Execute business logic (must be implemented) var response = await ExecuteAsync(message, ct); // 3 Log result Logger LogInformation( \"Handled {MessageType} successfully\", typeof(TMessage) Name ); return response; } /// <summary> /// Override to add message-specific validation /// Default: no validation /// </summary>\n  protected virtual ValueTask ValidateAsync(\n    TMessage message,\n    CancellationToken ct\n  ) {\n    return ValueTask CompletedTask;\n  }\n  /// <summary>\n  /// Implement business logic here /// </summary>\n  protected abstract ValueTask<TResponse> ExecuteAsync(\n    TMessage message,\n    CancellationToken ct\n  );\n  /// <summary>\n  /// Helper: Resolve service from DI container /// </summary>\n  protected T GetService<T>() where T : notnull {\n    return Services GetRequiredService<T>();\n  }\n}\n`\nUsage:\n`csharp\npublic record CreateOrder(Guid CustomerId, OrderLineItem[] Items);\npublic record OrderCreated(Guid OrderId, Guid CustomerId, decimal Total);\npublic class CreateOrderReceptor : ReceptorBase<CreateOrder, OrderCreated> {\n  private readonly IDbConnectionFactory _db;\n  public CreateOrderReceptor(\n    ILogger<ReceptorBase<CreateOrder, OrderCreated>> logger,\n    IServiceProvider services,\n    IDbConnectionFactory db\n  ) : base(logger, services) {\n    _db = db;\n  }\n  // Override: Add validation logic\n  protected override ValueTask ValidateAsync(\n    CreateOrder message,\n    CancellationToken ct\n  ) {\n    if (message Items Length == 0) {\n      throw new ValidationException(\"Order must contain at least one item\");\n    }\n    if (message Items Any(i => i Quantity <= 0)) {\n      throw new ValidationException(\"All items must have quantity > 0\");\n    }\n    return ValueTask CompletedTask;\n  }\n  // Implement: Business logic\n  protected override async ValueTask<OrderCreated> ExecuteAsync(\n    CreateOrder message,\n    CancellationToken ct\n  ) {\n    var orderId = Guid CreateVersion7();\n    var total = message Items Sum(i => i Quantity * i UnitPrice);\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"INSERT INTO orders (order_id, customer_id, total) VALUES (@OrderId, @CustomerId, @Total)\",\n      new { OrderId = orderId, message CustomerId, Total = total },\n      ct\n    );\n    return new OrderCreated(orderId, message",
        "startIndex": 5031,
        "preview": "// 1 Validate (can be overridden) await ValidateAsync(message, ct); // 2 Execute business logic (must be implemented) var response = await ExecuteAsyn..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-3",
        "text": "CreateVersion7(); var total = message Items Sum(i => i Quantity * i UnitPrice); await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"INSERT INTO orders (order_id, customer_id, total) VALUES (@OrderId, @CustomerId, @Total)\", new { OrderId = orderId, message CustomerId, Total = total }, ct ); return new OrderCreated(orderId, message CustomerId, total);\n  }\n}\n`\nBenefits:\nDRY: Shared validation, logging, setup logic\nTemplate Method Pattern: Enforces consistent execution flow\nEasy Testing: Test base class once, focus on business logic in subclasses\n---\nPattern 2: Transactional Receptor Base\nUse Case: Automatically wrap HandleAsync in a database transaction `csharp\nusing Whizbang Core;\nusing System Data;\npublic abstract class TransactionalReceptor<TMessage, TResponse> : IReceptor<TMessage, TResponse> {\n  private readonly IDbConnectionFactory _db;\n  protected readonly ILogger Logger;\n  protected TransactionalReceptor(\n    IDbConnectionFactory db,\n    ILogger logger\n  ) {\n    _db = db;\n    Logger = logger;\n  }\n  public async ValueTask<TResponse> HandleAsync(\n    TMessage message,\n    CancellationToken ct = default\n  ) {\n    await using var conn = _db CreateConnection();\n    await conn OpenAsync(ct);\n    await using var tx = await conn BeginTransactionAsync(\n      IsolationLevel ReadCommitted,\n      ct\n    );\n    try {\n      // Execute business logic within transaction\n      var response = await ExecuteAsync(message, conn, tx, ct);\n      // Commit on success\n      await tx CommitAsync(ct);\n      Logger LogInformation(\n        \"Transaction committed for {MessageType}\",\n        typeof(TMessage) Name\n      );\n      return response;\n    } catch {\n      // Rollback on failure\n      await tx RollbackAsync(ct);\n      Logger LogWarning(\n        \"Transaction rolled back for {MessageType}\",\n        typeof(TMessage) Name\n      );\n      throw;\n    }\n  }\n  /// <summary>\n  /// Execute business logic within transaction",
        "startIndex": 7018,
        "preview": "CreateVersion7(); var total = message Items Sum(i => i Quantity * i UnitPrice); await using var conn = _db CreateConnection(); await conn ExecuteAsync..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-4",
        "text": "ct); // Commit on success await tx CommitAsync(ct); Logger LogInformation( \"Transaction committed for {MessageType}\", typeof(TMessage) Name ); return response; } catch { // Rollback on failure await tx RollbackAsync(ct); Logger LogWarning( \"Transaction rolled back for {MessageType}\", typeof(TMessage) Name ); throw; } } /// <summary> /// Execute business logic within transaction /// </summary>\n  protected abstract ValueTask<TResponse> ExecuteAsync(\n    TMessage message,\n    IDbConnection connection,\n    IDbTransaction transaction,\n    CancellationToken ct\n  );\n}\n`\nUsage:\n`csharp\npublic record TransferFunds(Guid FromAccountId, Guid ToAccountId, decimal Amount);\npublic record FundsTransferred(Guid TransactionId, DateTimeOffset CompletedAt);\npublic class TransferFundsReceptor : TransactionalReceptor<TransferFunds, FundsTransferred> {\n  public TransferFundsReceptor(\n    IDbConnectionFactory db,\n    ILogger<TransferFundsReceptor> logger\n  ) : base(db, logger) { }\n  protected override async ValueTask<FundsTransferred> ExecuteAsync(\n    TransferFunds message,\n    IDbConnection conn,\n    IDbTransaction tx,\n    CancellationToken ct\n  ) {\n    // Both operations in same transaction\n    await conn ExecuteAsync(\n      \"UPDATE accounts SET balance = balance - @Amount WHERE account_id = @AccountId\",\n      new { message FromAccountId, message Amount },\n      transaction: tx,\n      cancellationToken: ct\n    );\n    await conn ExecuteAsync(\n      \"UPDATE accounts SET balance = balance + @Amount WHERE account_id = @AccountId\",\n      new { message ToAccountId, message Amount },\n      transaction: tx,\n      cancellationToken: ct\n    );\n    var transactionId = Guid CreateVersion7();\n    return new FundsTransferred(transactionId, DateTimeOffset UtcNow);\n  }\n}\n`\nBenefits:\nAtomic Operations: All-or-nothing guarantees\nAutomatic Rollback: No manual transaction management\nConsistent Pattern: Same transaction handling across receptors\n---\nPattern 3: Multi-Tenant Receptor Base\nUse Case: Automatically resolve tenant context for all receptors `csharp\nusing Whizbang Core;\npublic interface ITenantContext {\n  Guid TenantId { get; }\n  string TenantName { get; }\n}\npublic abstract class TenantReceptor<TMessage, TResponse> : IReceptor<TMessage, TResponse> {\n  protected readonly ITenantContext Tenant;\n  protected readonly ILogger Logger;\n  protected TenantReceptor(\n    ITenantContext tenant,\n    ILogger logger\n  ) {\n    Tenant = tenant;\n    Logger = logger;\n  }\n  public async ValueTask<TResponse> HandleAsync(\n    TMessage message,\n    CancellationToken ct = default\n  ) {\n    Logger LogInformation(\n      \"Processing {MessageType} for tenant {TenantId}\",\n      typeof(TMessage) Name,\n      Tenant",
        "startIndex": 8618,
        "preview": "ct); // Commit on success await tx CommitAsync(ct); Logger LogInformation( \"Transaction committed for {MessageType}\", typeof(TMessage) Name ); return ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-5",
        "text": "TResponse> : IReceptor<TMessage, TResponse> { protected readonly ITenantContext Tenant; protected readonly ILogger Logger; protected TenantReceptor( ITenantContext tenant, ILogger logger ) { Tenant = tenant; Logger = logger; } public async ValueTask<TResponse> HandleAsync( TMessage message, CancellationToken ct = default ) { Logger LogInformation( \"Processing {MessageType} for tenant {TenantId}\", typeof(TMessage) Name, Tenant TenantId\n    );\n    // Validate tenant access\n    await ValidateTenantAccessAsync(message, ct);\n    // Execute with tenant context\n    var response = await ExecuteAsync(message, ct);\n    return response;\n  }\n  /// <summary>\n  /// Override to validate tenant-specific access rules /// Default: allows all access /// </summary>\n  protected virtual ValueTask ValidateTenantAccessAsync(\n    TMessage message,\n    CancellationToken ct\n  ) {\n    return ValueTask CompletedTask;\n  }\n  /// <summary>\n  /// Execute business logic with tenant context /// </summary>\n  protected abstract ValueTask<TResponse> ExecuteAsync(\n    TMessage message,\n    CancellationToken ct\n  );\n}\n`\nUsage:\n`csharp\npublic record CreateProduct(string Name, decimal Price);\npublic record ProductCreated(Guid ProductId, Guid TenantId);\npublic class CreateProductReceptor : TenantReceptor<CreateProduct, ProductCreated> {\n  private readonly IDbConnectionFactory _db;\n  public CreateProductReceptor(\n    ITenantContext tenant,\n    ILogger<CreateProductReceptor> logger,\n    IDbConnectionFactory db\n  ) : base(tenant, logger) {\n    _db = db;\n  }\n  protected override async ValueTask<ProductCreated> ExecuteAsync(\n    CreateProduct message,\n    CancellationToken ct\n  ) {\n    var productId = Guid CreateVersion7();\n    await using var conn = _db CreateConnection();\n    await conn ExecuteAsync(\n      \"INSERT INTO products (product_id, tenant_id, name, price) VALUES (@ProductId, @TenantId, @Name, @Price)\",\n      new {\n        ProductId = productId,\n        TenantId = Tenant TenantId,  // ‚Üê Automatic tenant isolation\n        message Name,\n        message Price\n      },\n      ct\n    );\n    return new ProductCreated(productId, Tenant TenantId);\n  }\n}\n`\nBenefits:\nAutomatic Tenant Isolation: No manual tenant filtering\nTenant-Aware Logging: All logs include tenant context\nSecurity by Default: Tenant validation enforced\n---\nStreaming Receptors\nPattern 4: IAsyncEnumerable Streaming\nUse Case: Stream large result sets without loading everything into memory `csharp\nusing Whizbang Core;\n/// <summary>\n/// Streaming receptor for paginated/large results",
        "startIndex": 10939,
        "preview": "TResponse> : IReceptor<TMessage, TResponse> { protected readonly ITenantContext Tenant; protected readonly ILogger Logger; protected TenantReceptor( I..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-6",
        "text": "Automatic Tenant Isolation: No manual tenant filtering Tenant-Aware Logging: All logs include tenant context Security by Default: Tenant validation enforced --- Streaming Receptors Pattern 4: IAsyncEnumerable Streaming Use Case: Stream large result sets without loading everything into memory `csharp using Whizbang Core; /// <summary> /// Streaming receptor for paginated/large results /// </summary>\npublic interface IStreamingReceptor<in TMessage, out TResponse> {\n  /// <summary>\n  /// Streams results as they become available /// </summary>\n  IAsyncEnumerable<TResponse> StreamAsync(\n    TMessage message,\n    CancellationToken ct = default\n  );\n}\n`\nImplementation:\n`csharp\npublic record GetOrderHistory(Guid CustomerId);\npublic record OrderSummary(Guid OrderId, decimal Total, DateTimeOffset CreatedAt);\npublic class GetOrderHistoryReceptor : IStreamingReceptor<GetOrderHistory, OrderSummary> {\n  private readonly IDbConnectionFactory _db;\n  private readonly ILogger<GetOrderHistoryReceptor> _logger;\n  public GetOrderHistoryReceptor(\n    IDbConnectionFactory db,\n    ILogger<GetOrderHistoryReceptor> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  public async IAsyncEnumerable<OrderSummary> StreamAsync(\n    GetOrderHistory query,\n    [EnumeratorCancellation] CancellationToken ct = default\n  ) {\n    await using var conn = _db CreateConnection();\n    // Stream results without loading all into memory\n    await using var reader = await conn ExecuteReaderAsync(\n      \"SELECT order_id, total, created_at FROM orders WHERE customer_id = @CustomerId ORDER BY created_at DESC\",\n      new { query CustomerId },\n      ct\n    );\n    while (await reader ReadAsync(ct)) {\n      yield return new OrderSummary(\n        OrderId: reader GetGuid(0),\n        Total: reader GetDecimal(1),\n        CreatedAt: reader GetDateTime(2)\n      );\n    }\n    _logger LogInformation(\n      \"Streamed order history for customer {CustomerId}\",\n      query CustomerId\n    );\n  }\n}\n`\nUsage:\n`csharp\npublic class OrderHistoryController : ControllerBase {\n  private readonly GetOrderHistoryReceptor _receptor;\n  [HttpGet(\"orders/history/{customerId}\")]\n  public async IAsyncEnumerable<OrderSummary> GetOrderHistory(\n    Guid customerId,\n    [EnumeratorCancellation] CancellationToken ct\n  ) {\n    var query = new GetOrderHistory(customerId);\n    await foreach (var order in _receptor StreamAsync(query, ct)) {\n      yield return order;  // Stream to client\n    }\n  }\n}\n`\nBenefits:\nMemory Efficient: No buffering of entire result set\nResponsive: First results arrive immediately\nCancellable: Stop streaming mid-flight\n---\nLifecycle Management\nPattern 5: IAsyncDisposable Receptor\nUse Case: Receptor manages expensive resources (connections, file handles)",
        "startIndex": 13064,
        "preview": "Automatic Tenant Isolation: No manual tenant filtering Tenant-Aware Logging: All logs include tenant context Security by Default: Tenant validation en..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-7",
        "text": "in _receptor StreamAsync(query, ct)) { yield return order; // Stream to client } } } ` Benefits: Memory Efficient: No buffering of entire result set Responsive: First results arrive immediately Cancellable: Stop streaming mid-flight --- Lifecycle Management Pattern 5: IAsyncDisposable Receptor Use Case: Receptor manages expensive resources (connections, file handles) `csharp\nusing Whizbang Core;\npublic record ImportCsv(string FilePath);\npublic record CsvImported(int RowsImported);\npublic class ImportCsvReceptor : IReceptor<ImportCsv, CsvImported>, IAsyncDisposable {\n  private readonly ILogger<ImportCsvReceptor> _logger;\n  private FileStream _fileStream;\n  private StreamReader _reader;\n  public ImportCsvReceptor(ILogger<ImportCsvReceptor> logger) {\n    _logger = logger;\n  }\n  public async ValueTask<CsvImported> HandleAsync(\n    ImportCsv message,\n    CancellationToken ct = default\n  ) {\n    // Open file\n    _fileStream = File OpenRead(message FilePath);\n    _reader = new StreamReader(_fileStream);\n    int rowsImported = 0;\n    // Skip header\n    await _reader ReadLineAsync(ct);\n    // Process rows\n    while ( _reader EndOfStream) {\n      var line = await _reader ReadLineAsync(ct);\n      if (string IsNullOrWhiteSpace(line)) continue;\n      // Process row rowsImported++;\n    }\n    _logger LogInformation(\n      \"Imported {RowCount} rows from {FilePath}\",\n      rowsImported,\n      message FilePath\n    );\n    return new CsvImported(rowsImported);\n  }\n  // Automatic cleanup by dispatcher\n  public async ValueTask DisposeAsync() {\n    if (_reader is not null) {\n      await _reader DisposeAsync();\n    }\n    if (_fileStream is not null) {\n      await _fileStream DisposeAsync();\n    }\n    _logger LogDebug(\"Disposed ImportCsvReceptor resources\");\n  }\n}\n`\nRegistration:\n`csharp\n// Transient lifetime ensures new instance per invocation\nbuilder Services AddTransient<IReceptor<ImportCsv, CsvImported>, ImportCsvReceptor>();\n`\nBenefits:\nAutomatic Cleanup: Dispatcher calls DisposeAsync after HandleAsync\nException Safe: Resources disposed even if HandleAsync throws\nClear Pattern: Standard NET async disposal\n---\nPerformance Optimization\nPattern 6: Zero-Allocation Void Receptor\nUse Case: High-throughput event processing with no response needed `csharp\nusing Whizbang Core;\npublic record OrderShipped(Guid OrderId, string TrackingNumber);\n/// <summary>\n/// Zero-allocation receptor for void (no response) operations",
        "startIndex": 3798,
        "preview": "in _receptor StreamAsync(query, ct)) { yield return order; // Stream to client } } } ` Benefits: Memory Efficient: No buffering of entire result set R..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-8",
        "text": "Safe: Resources disposed even if HandleAsync throws Clear Pattern: Standard NET async disposal --- Performance Optimization Pattern 6: Zero-Allocation Void Receptor Use Case: High-throughput event processing with no response needed `csharp using Whizbang Core; public record OrderShipped(Guid OrderId, string TrackingNumber); /// <summary> /// Zero-allocation receptor for void (no response) operations /// </summary>\npublic class OrderShippedReceptor : IReceptor<OrderShipped> {\n  private readonly ILogger<OrderShippedReceptor> _logger;\n  public OrderShippedReceptor(ILogger<OrderShippedReceptor> logger) {\n    _logger = logger;\n  }\n  public ValueTask HandleAsync(\n    OrderShipped message,\n    CancellationToken ct = default\n  ) {\n    // Synchronous execution - return ValueTask CompletedTask (zero allocation)\n    _logger LogInformation(\n      \"Order {OrderId} shipped with tracking {TrackingNumber}\",\n      message OrderId,\n      message TrackingNumber\n    );\n    // If async work needed:\n    // return new ValueTask(AsyncWork(message, ct));\n    return ValueTask CompletedTask;  // ‚Üê Zero allocation }\n}\n`\nPerformance:\nZero Allocations: ValueTask CompletedTask is cached\nSynchronous Path: No async state machine overhead\nHigh Throughput: Ideal for 100K+ msg/sec scenarios\n---\nPattern 7: Pooled Resources\nUse Case: Reuse expensive objects across receptor invocations `csharp\nusing Whizbang Core;\nusing System Buffers;\npublic record ProcessLargeFile(string FilePath);\npublic record FileProcessed(int BytesProcessed);\npublic class ProcessLargeFileReceptor : IReceptor<ProcessLargeFile, FileProcessed> {\n  private readonly ILogger<ProcessLargeFileReceptor> _logger;\n  private readonly ArrayPool<byte> _bufferPool;\n  public ProcessLargeFileReceptor(ILogger<ProcessLargeFileReceptor> logger) {\n    _logger = logger;\n    _bufferPool = ArrayPool<byte> Shared;\n  }\n  public async ValueTask<FileProcessed> HandleAsync(\n    ProcessLargeFile message,\n    CancellationToken ct = default\n  ) {\n    // Rent buffer from pool (no allocation)\n    byte[] buffer = _bufferPool Rent(8192);\n    try {\n      await using var fileStream = File OpenRead(message FilePath);\n      int totalBytesRead = 0;\n      int bytesRead;\n      while ((bytesRead = await fileStream ReadAsync(buffer, ct)) > 0) {\n        // Process buffer totalBytesRead += bytesRead;\n      }\n      _logger LogInformation(\n        \"Processed {Bytes} bytes from {FilePath}\",\n        totalBytesRead,\n        message FilePath\n      );\n      return new FileProcessed(totalBytesRead);\n    } finally {\n      // Return buffer to pool\n      _bufferPool",
        "startIndex": 17493,
        "preview": "Safe: Resources disposed even if HandleAsync throws Clear Pattern: Standard NET async disposal --- Performance Optimization Pattern 6: Zero-Allocation..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-9",
        "text": "= File OpenRead(message FilePath); int totalBytesRead = 0; int bytesRead; while ((bytesRead = await fileStream ReadAsync(buffer, ct)) > 0) { // Process buffer totalBytesRead += bytesRead; } _logger LogInformation( \"Processed {Bytes} bytes from {FilePath}\", totalBytesRead, message FilePath ); return new FileProcessed(totalBytesRead); } finally { // Return buffer to pool _bufferPool Return(buffer);\n    }\n  }\n}\n`\nBenefits:\nReduced GC Pressure: No repeated allocations\nBetter Performance: ~10x faster than repeated allocations\nIndustry Standard: ArrayPool<T> used throughout NET\n---\nAdvanced Patterns\nPattern 8: Resilient Receptor (Retry + Circuit Breaker)\nUse Case: Automatically retry transient failures `csharp\nusing Whizbang Core;\nusing Polly;\nusing Polly CircuitBreaker;\npublic abstract class ResilientReceptor<TMessage, TResponse> : IReceptor<TMessage, TResponse> {\n  protected readonly ILogger Logger;\n  private readonly ResiliencePipeline _pipeline;\n  protected ResilientReceptor(ILogger logger) {\n    Logger = logger;\n    // Configure retry + circuit breaker\n    _pipeline = new ResiliencePipelineBuilder() AddRetry(new RetryStrategyOptions {\n        MaxRetryAttempts = 3,\n        Delay = TimeSpan FromSeconds(1),\n        BackoffType = DelayBackoffType Exponential,\n        OnRetry = args => {\n          Logger LogWarning(\n            \"Retry attempt {Attempt} for {MessageType}\",\n            args AttemptNumber,\n            typeof(TMessage) Name\n          );\n          return ValueTask CompletedTask;\n        }\n      }) AddCircuitBreaker(new CircuitBreakerStrategyOptions {\n        FailureRatio = 0 5,\n        MinimumThroughput = 10,\n        SamplingDuration = TimeSpan FromSeconds(30),\n        BreakDuration = TimeSpan FromSeconds(60),\n        OnOpened = args => {\n          Logger LogError(\"Circuit breaker opened for {MessageType}\", typeof(TMessage) Name);\n          return ValueTask CompletedTask;\n        }\n      }) Build();\n  }\n  public async ValueTask<TResponse> HandleAsync(\n    TMessage message,\n    CancellationToken ct = default\n  ) {\n    // Execute with resilience pipeline\n    return await _pipeline ExecuteAsync(\n      async ct => await ExecuteAsync(message, ct),\n      ct\n    );\n  }\n  /// <summary>\n  /// Implement business logic here - retries/circuit breaker applied automatically",
        "startIndex": 19695,
        "preview": "= File OpenRead(message FilePath); int totalBytesRead = 0; int bytesRead; while ((bytesRead = await fileStream ReadAsync(buffer, ct)) > 0) { // Proces..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-10",
        "text": "Name); return ValueTask CompletedTask; } }) Build(); } public async ValueTask<TResponse> HandleAsync( TMessage message, CancellationToken ct = default ) { // Execute with resilience pipeline return await _pipeline ExecuteAsync( async ct => await ExecuteAsync(message, ct), ct ); } /// <summary> /// Implement business logic here - retries/circuit breaker applied automatically /// </summary>\n  protected abstract ValueTask<TResponse> ExecuteAsync(\n    TMessage message,\n    CancellationToken ct\n  );\n}\n`\nUsage:\n`csharp\npublic record CallExternalApi(string Endpoint);\npublic record ApiResponse(string Data);\npublic class CallExternalApiReceptor : ResilientReceptor<CallExternalApi, ApiResponse> {\n  private readonly HttpClient _http;\n  public CallExternalApiReceptor(\n    ILogger<CallExternalApiReceptor> logger,\n    HttpClient http\n  ) : base(logger) {\n    _http = http;\n  }\n  protected override async ValueTask<ApiResponse> ExecuteAsync(\n    CallExternalApi message,\n    CancellationToken ct\n  ) {\n    // Automatically retried on transient failures\n    var response = await _http GetStringAsync(message Endpoint, ct);\n    return new ApiResponse(response);\n  }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use base classes for shared logic across multiple receptors\n‚úÖ Implement IAsyncDisposable for resource cleanup\n‚úÖ Use IAsyncEnumerable for streaming large result sets\n‚úÖ Pool expensive resources (buffers, connections)\n‚úÖ Return ValueTask CompletedTask for synchronous void receptors\n‚úÖ Add resilience patterns (retry, circuit breaker) for external calls\n‚úÖ Test base classes independently from concrete implementations\nDON'T ‚ùå\n‚ùå Add instance state (except injected dependencies)\n‚ùå Use singleton lifetime for receptors with scoped dependencies\n‚ùå Create deep inheritance hierarchies (max 2 levels)\n‚ùå Mix business logic with framework concerns (use pipeline behaviors)\n‚ùå Block async operations with Result or Wait()\n‚ùå Forget to pass CancellationToken through call chain\n---\nTesting Custom Receptors\nTesting Base Classes\n`csharp\npublic class ReceptorBaseTests {\n  [Test]\n  public async Task HandleAsync_CallsValidateAndExecuteAsync() {\n    // Arrange\n    var logger = new NullLogger<ReceptorBase<TestMessage, TestResponse>>();\n    var services = new ServiceCollection() BuildServiceProvider();\n    var receptor = new TestReceptor(logger, services);\n    var message = new TestMessage();\n    // Act\n    var response = await receptor HandleAsync(message);\n    // Assert\n    await Assert That(receptor ValidateCalled)",
        "startIndex": 21644,
        "preview": "Name); return ValueTask CompletedTask; } }) Build(); } public async ValueTask<TResponse> HandleAsync( TMessage message, CancellationToken ct = default..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-11",
        "text": "`csharp public class ReceptorBaseTests { [Test] public async Task HandleAsync_CallsValidateAndExecuteAsync() { // Arrange var logger = new NullLogger<ReceptorBase<TestMessage, TestResponse>>(); var services = new ServiceCollection() BuildServiceProvider(); var receptor = new TestReceptor(logger, services); var message = new TestMessage(); // Act var response = await receptor HandleAsync(message); // Assert await Assert That(receptor ValidateCalled) IsTrue();\n    await Assert That(receptor ExecuteCalled) IsTrue();\n    await Assert That(response) IsNotNull();\n  }\n}\n// Test receptor exposing internal state for testing\ninternal class TestReceptor : ReceptorBase<TestMessage, TestResponse> {\n  public bool ValidateCalled { get; private set; }\n  public bool ExecuteCalled { get; private set; }\n  public TestReceptor(\n    ILogger<ReceptorBase<TestMessage, TestResponse>> logger,\n    IServiceProvider services\n  ) : base(logger, services) { }\n  protected override ValueTask ValidateAsync(TestMessage message, CancellationToken ct) {\n    ValidateCalled = true;\n    return ValueTask CompletedTask;\n  }\n  protected override ValueTask<TestResponse> ExecuteAsync(TestMessage message, CancellationToken ct) {\n    ExecuteCalled = true;\n    return ValueTask FromResult(new TestResponse());\n  }\n}\n`\nTesting Streaming Receptors\n`csharp\npublic class StreamingReceptorTests {\n  [Test]\n  public async Task StreamAsync_YieldsAllResultsAsync() {\n    // Arrange\n    var db = CreateMockDb();  // Returns 3 test orders\n    var logger = new NullLogger<GetOrderHistoryReceptor>();\n    var receptor = new GetOrderHistoryReceptor(db, logger);\n    var query = new GetOrderHistory(CustomerId: Guid NewGuid());\n    // Act\n    var results = new List<OrderSummary>();\n    await foreach (var item in receptor StreamAsync(query)) {\n      results Add(item);\n    }\n    // Assert\n    await Assert That(results) HasCount() EqualTo(3);\n  }\n  [Test]\n  public async Task StreamAsync_SupportsEarlyCancellationAsync() {\n    // Arrange\n    var db = CreateMockDb();  // Returns 100 orders\n    var logger = new NullLogger<GetOrderHistoryReceptor>();\n    var receptor = new GetOrderHistoryReceptor(db, logger);\n    var query = new GetOrderHistory(CustomerId: Guid NewGuid());\n    var cts = new CancellationTokenSource();\n    // Act - cancel after first item\n    var count = 0;\n    await foreach (var item in receptor StreamAsync(query, cts Token)) {\n      count++;\n      if (count == 1) {\n        cts Cancel();\n      }\n    }\n    // Assert - only 1 item processed\n    await Assert That(count)",
        "startIndex": 23764,
        "preview": "`csharp public class ReceptorBaseTests { [Test] public async Task HandleAsync_CallsValidateAndExecuteAsync() { // Arrange var logger = new NullLogger<..."
      },
      {
        "id": "v0.1.0/extensibility/custom-receptors-chunk-12",
        "text": "new GetOrderHistory(CustomerId: Guid NewGuid()); var cts = new CancellationTokenSource(); // Act - cancel after first item var count = 0; await foreach (var item in receptor StreamAsync(query, cts Token)) { count++; if (count == 1) { cts Cancel(); } } // Assert - only 1 item processed await Assert That(count) IsEqualTo(1);\n  }\n}\n`\n---\nFurther Reading\nCore Concepts:\nReceptors Guide - Basic receptor usage\nDispatcher - Invoking receptors\nPipeline Behaviors - Cross-cutting concerns\nExtensibility:\nCustom Perspectives - Custom event listeners\nCustom Transports - Custom messaging implementations\nAdvanced:\nPerformance Tuning - Optimization strategies\nTesting Receptors - Comprehensive testing guide\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 25861,
        "preview": "new GetOrderHistory(CustomerId: Guid NewGuid()); var cts = new CancellationTokenSource(); // Act - cancel after first item var count = 0; await foreac..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-serializers",
    "title": "Custom Serializers",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-serializers",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-serializers-chunk-0",
        "text": "Custom Serializers\nCustom serializers enable alternative message formats beyond JSON Implement Protobuf, MessagePack, Avro, or custom binary formats while maintaining AOT compatibility :::note\nWhizbang uses JSON by default with JsonContextRegistry for AOT support Custom serializers are for specialized scenarios requiring different formats :::\n---\nWhy Custom Serializers | Scenario | JSON (Default) | Custom Serializer |\n|----------|---------------|-------------------|\n| Human-Readable | ‚úÖ Perfect | No need |\n| Compact Binary | ‚ùå Text overhead | ‚úÖ Protobuf/MessagePack |\n| Schema Evolution | ‚ùå Manual | ‚úÖ Protobuf/Avro |\n| Cross-Language | ‚úÖ Universal | ‚úÖ Protobuf |\n| Performance | ‚úÖ Fast enough | ‚úÖ MessagePack faster |\nWhen to use custom serializers:\n‚úÖ Extreme performance requirements\n‚úÖ Bandwidth constraints (IoT, mobile)\n‚úÖ Schema evolution needs\n‚úÖ Cross-language interop (gRPC)\n---\nProtobuf Serializer\nPattern 1: Protobuf with AOT\n`csharp\nusing Google Protobuf;\nusing System Text Json;\npublic class ProtobufSerializer : IMessageSerializer {\n  public byte[] Serialize<T>(T message) where T : IMessage<T> {\n    return message ToByteArray();  // AOT-safe\n  }\n  public T Deserialize<T>(byte[] data) where T : IMessage<T>, new() {\n    var parser = new MessageParser<T>(() => new T());\n    return parser ParseFrom(data);  // AOT-safe\n  }\n}\n`\nUsage:\n`csharp\n// Define protobuf message\nmessage OrderCreated {\n  string order_id = 1;\n  string customer_id = 2;\n  double total = 3;\n}\n// Serialize\nvar serializer = new ProtobufSerializer();\nvar @event = new OrderCreated {\n  OrderId = orderId ToString(),\n  CustomerId = customerId ToString(),\n  Total = 99 99\n};\nvar bytes = serializer Serialize(@event);\n// Deserialize\nvar deserialized = serializer",
        "startIndex": 0,
        "preview": "Custom Serializers\nCustom serializers enable alternative message formats beyond JSON Implement Protobuf, MessagePack, Avro, or custom binary formats w..."
      },
      {
        "id": "v0.1.0/extensibility/custom-serializers-chunk-1",
        "text": "string order_id = 1; string customer_id = 2; double total = 3; } // Serialize var serializer = new ProtobufSerializer(); var @event = new OrderCreated { OrderId = orderId ToString(), CustomerId = customerId ToString(), Total = 99 99 }; var bytes = serializer Serialize(@event); // Deserialize var deserialized = serializer Deserialize<OrderCreated>(bytes);\n`\n---\nMessagePack Serializer\nPattern 2: MessagePack with AOT\n`csharp\nusing MessagePack;\n[MessagePackObject]\npublic record OrderCreated {\n  [Key(0)] public Guid OrderId { get; init; }\n  [Key(1)] public Guid CustomerId { get; init; }\n  [Key(2)] public decimal Total { get; init; }\n}\npublic class MessagePackSerializer : IMessageSerializer {\n  private readonly MessagePackSerializerOptions _options;\n  public MessagePackSerializer() {\n    _options = MessagePackSerializerOptions Standard WithResolver(MessagePack Resolvers ContractlessStandardResolver Instance);\n  }\n  public byte[] Serialize<T>(T message) {\n    return MessagePackSerializer Serialize(message, _options);\n  }\n  public T Deserialize<T>(byte[] data) {\n    return MessagePackSerializer Deserialize<T>(data, _options);\n  }\n}\n`\n---\nFurther Reading\nSource Generators:\nJSON Contexts - AOT-compatible JSON\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 1750,
        "preview": "string order_id = 1; string customer_id = 2; double total = 3; } // Serialize var serializer = new ProtobufSerializer(); var @event = new OrderCreated..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-storage",
    "title": "Custom Storage",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-storage",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-storage-chunk-0",
        "text": "Custom Storage\nCustom storage backends enable alternative data stores beyond PostgreSQL Implement Redis, MongoDB, Elasticsearch, Cassandra, or custom databases for perspective read models :::note\nWhizbang uses PostgreSQL by default Custom storage is for specialized scenarios requiring different persistence strategies :::\n---\nWhy Custom Storage | Backend | Use Case | Benefits |\n|---------|----------|----------|\n| PostgreSQL (default) | Relational data | ACID, SQL queries |\n| Redis | High-speed cache | In-memory, fast reads |\n| MongoDB | Document store | Schema flexibility |\n| Elasticsearch | Search/analytics | Full-text search |\n| Cassandra | Time-series | Horizontal scaling |\nWhen to use custom storage:\n‚úÖ Specialized query patterns\n‚úÖ Extreme performance needs\n‚úÖ Existing infrastructure\n‚úÖ Multi-region replication\n---\nIPerspectiveStore<TModel>\n`csharp\npublic interface IPerspectiveStore<TModel> where TModel : class {\n  Task UpsertAsync(\n    string id,\n    TModel model,\n    CancellationToken ct = default\n  );\n}\n`\n---\nMongoDB Implementation\nPattern 1: MongoDB Perspective Store\n`csharp\nusing MongoDB Driver;\npublic class MongoPerspectiveStore<TModel> : IPerspectiveStore<TModel>\n  where TModel : class {\n  private readonly IMongoCollection<TModel> _collection;\n  public MongoPerspectiveStore(IMongoDatabase database, string collectionName) {\n    _collection = database GetCollection<TModel>(collectionName);\n  }\n  public async Task UpsertAsync(\n    string id,\n    TModel model,\n    CancellationToken ct = default\n  ) {\n    var filter = Builders<TModel> Filter Eq(\"_id\", id);\n    await _collection ReplaceOneAsync(\n      filter,\n      model,\n      new ReplaceOptions { IsUpsert = true },\n      ct\n    );\n  }\n}\n`\n---\nElasticsearch Implementation\nPattern 2: Elasticsearch Perspective Store\n`csharp\nusing Elastic Clients Elasticsearch;\npublic class ElasticsearchPerspectiveStore<TModel> : IPerspectiveStore<TModel>\n  where TModel : class {\n  private readonly ElasticsearchClient _client;\n  private readonly string _indexName;\n  public ElasticsearchPerspectiveStore(\n    ElasticsearchClient client,\n    string indexName\n  ) {\n    _client = client;\n    _indexName = indexName;\n  }\n  public async Task UpsertAsync(\n    string id,\n    TModel model,\n    CancellationToken ct = default\n  ) {\n    await _client IndexAsync(\n      model,\n      idx => idx Index(_indexName)",
        "startIndex": 0,
        "preview": "Custom Storage\nCustom storage backends enable alternative data stores beyond PostgreSQL Implement Redis, MongoDB, Elasticsearch, Cassandra, or custom ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-storage-chunk-1",
        "text": "where TModel : class { private readonly ElasticsearchClient _client; private readonly string _indexName; public ElasticsearchPerspectiveStore( ElasticsearchClient client, string indexName ) { _client = client; _indexName = indexName; } public async Task UpsertAsync( string id, TModel model, CancellationToken ct = default ) { await _client IndexAsync( model, idx => idx Index(_indexName) Id(id),\n      ct\n    );\n  }\n}\n`\n---\nFurther Reading\nData Access:\nPerspectives Storage - PostgreSQL schema\nExtensibility:\nCustom Perspectives - Advanced perspective patterns\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 2375,
        "preview": "where TModel : class { private readonly ElasticsearchClient _client; private readonly string _indexName; public ElasticsearchPerspectiveStore( Elastic..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-transports",
    "title": "Custom Transports",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-transports",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-0",
        "text": "Custom Transports\nCustom transports enable Whizbang to work with any messaging system by implementing the ITransport interface Support HTTP, gRPC, Kafka, RabbitMQ, NATS, or any custom communication protocol :::note\nFor built-in transports, see Azure Service Bus and In-Memory This guide focuses on implementing custom transport backends :::\n---\nWhy Custom Transports Built-in transports cover common scenarios, but custom transports enable:\n| Scenario | Built-In Transport | Custom Transport |\n|----------|-------------------|------------------|\n| Azure Service Bus | ‚úÖ Built-in | No customization needed |\n| In-Memory (Testing) | ‚úÖ Built-in | No customization needed |\n| HTTP/REST APIs | ‚ùå Not included | ‚úÖ HTTP client transport |\n| gRPC | ‚ùå Not included | ‚úÖ gRPC channel transport |\n| Kafka | ‚ùå Not included | ‚úÖ Kafka producer/consumer |\n| RabbitMQ | ‚ùå Not included | ‚úÖ AMQP channel transport |\n| NATS | ‚ùå Not included | ‚úÖ NATS client transport |\n| Redis Pub/Sub | ‚ùå Not included | ‚úÖ Redis channel transport |\nWhen to implement custom transport:\n‚úÖ Existing messaging infrastructure (Kafka, RabbitMQ)\n‚úÖ HTTP/gRPC microservices\n‚úÖ Legacy systems integration\n‚úÖ Custom protocols (IoT, WebSockets)\n‚úÖ Multi-cloud deployments\n---\nArchitecture\nITransport Interface\n`csharp\nnamespace Whizbang Core Transports;\npublic interface ITransport {\n  /// <summary>\n  /// Whether transport is initialized and ready /// </summary>\n  bool IsInitialized { get; }\n  /// <summary>\n  /// Initialize transport and verify connectivity /// Idempotent - safe to call multiple times /// </summary>\n  Task InitializeAsync(CancellationToken ct = default);\n  /// <summary>\n  /// Capabilities this transport supports /// </summary>\n  TransportCapabilities Capabilities { get; }\n  /// <summary>\n  /// Publish message (fire-and-forget) /// </summary>\n  Task PublishAsync(\n    IMessageEnvelope envelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  );\n  /// <summary>\n  /// Subscribe to messages from destination /// Returns subscription handle for lifecycle management",
        "startIndex": 0,
        "preview": "Custom Transports\nCustom transports enable Whizbang to work with any messaging system by implementing the ITransport interface Support HTTP, gRPC, Kaf..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-1",
        "text": "= default); /// <summary> /// Capabilities this transport supports /// </summary> TransportCapabilities Capabilities { get; } /// <summary> /// Publish message (fire-and-forget) /// </summary> Task PublishAsync( IMessageEnvelope envelope, TransportDestination destination, CancellationToken ct = default ); /// <summary> /// Subscribe to messages from destination /// Returns subscription handle for lifecycle management /// </summary>\n  Task<ISubscription> SubscribeAsync(\n    Func<IMessageEnvelope, CancellationToken, Task> handler,\n    TransportDestination destination,\n    CancellationToken ct = default\n  );\n  /// <summary>\n  /// Send request and wait for response (request/response pattern) /// Only supported if Capabilities includes RequestResponse /// </summary>\n  Task<IMessageEnvelope> SendAsync<TRequest, TResponse>(\n    IMessageEnvelope requestEnvelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) where TRequest : notnull where TResponse : notnull;\n}\n`\nTransport Capabilities\n`csharp\n[Flags]\npublic enum TransportCapabilities {\n  None = 0,\n  RequestResponse = 1 << 0,    // Send/Receive (HTTP, gRPC)\n  PublishSubscribe = 1 << 1,   // Pub/Sub (Kafka, Service Bus)\n  Streaming = 1 << 2,          // IAsyncEnumerable streaming\n  Reliable = 1 << 3,           // At-least-once delivery\n  Ordered = 1 << 4,            // FIFO ordering\n  ExactlyOnce = 1 << 5         // Exactly-once semantics\n}\n`\nExample Capability Declarations:\n| Transport | Capabilities |\n|-----------|-------------|\n| HTTP | RequestResponse |\n| gRPC | RequestResponse \\| Streaming |\n| Kafka | PublishSubscribe \\| Reliable \\| Ordered |\n| RabbitMQ | PublishSubscribe \\| Reliable |\n| In-Memory | PublishSubscribe \\| Reliable \\| Ordered \\| ExactlyOnce |\n| Azure Service Bus | PublishSubscribe \\| Reliable \\| Ordered |\n---\nHTTP Transport Implementation\nPattern 1: HTTP Client Transport\nUse Case: Call remote HTTP APIs using Whizbang message patterns `csharp\nusing Whizbang Core;\nusing Whizbang Core Transports;\nusing System Net Http Json;\nusing System Text",
        "startIndex": 2090,
        "preview": "= default); /// <summary> /// Capabilities this transport supports /// </summary> TransportCapabilities Capabilities { get; } /// <summary> /// Publis..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-2",
        "text": "Ordered \\| ExactlyOnce | | Azure Service Bus | PublishSubscribe \\| Reliable \\| Ordered | --- HTTP Transport Implementation Pattern 1: HTTP Client Transport Use Case: Call remote HTTP APIs using Whizbang message patterns `csharp using Whizbang Core; using Whizbang Core Transports; using System Net Http Json; using System Text Json;\npublic class HttpTransport : ITransport {\n  private readonly HttpClient _http;\n  private readonly JsonSerializerOptions _jsonOptions;\n  private readonly ILogger<HttpTransport> _logger;\n  private bool _isInitialized;\n  public HttpTransport(\n    HttpClient http,\n    JsonSerializerOptions jsonOptions,\n    ILogger<HttpTransport> logger\n  ) {\n    _http = http;\n    _jsonOptions = jsonOptions;\n    _logger = logger;\n  }\n  public bool IsInitialized => _isInitialized;\n  public TransportCapabilities Capabilities =>\n    TransportCapabilities RequestResponse;  // HTTP supports request/response only\n  public async Task InitializeAsync(CancellationToken ct = default) {\n    // Verify HTTP endpoint is reachable\n    try {\n      var healthCheck = await _http GetAsync(\"/health\", ct);\n      healthCheck EnsureSuccessStatusCode();\n      _isInitialized = true;\n      _logger LogInformation(\"HTTP transport initialized successfully\");\n    } catch (HttpRequestException ex) {\n      throw new InvalidOperationException(\"HTTP transport initialization failed\", ex);\n    }\n  }\n  public Task PublishAsync(\n    IMessageEnvelope envelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    throw new NotSupportedException(\"HTTP transport does not support publish (use SendAsync instead)\");\n  }\n  public Task<ISubscription> SubscribeAsync(\n    Func<IMessageEnvelope, CancellationToken, Task> handler,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    throw new NotSupportedException(\"HTTP transport does not support subscribe (use polling or webhooks)\");\n  }\n  public async Task<IMessageEnvelope> SendAsync<TRequest, TResponse>(\n    IMessageEnvelope requestEnvelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) where TRequest : notnull where TResponse : notnull {\n    // Serialize request envelope\n    var envelopeType = requestEnvelope GetType();\n    var typeInfo = _jsonOptions GetTypeInfo(envelopeType) throw new InvalidOperationException($\"No JsonTypeInfo for {envelopeType Name}\");\n    // POST envelope to remote endpoint\n    var response = await _http PostAsJsonAsync(\n      destination Address,  // e g , \"https://api example com/orders/create\"\n      requestEnvelope,\n      typeInfo,\n      ct\n    );\n    response EnsureSuccessStatusCode();\n    // Deserialize response envelope\n    var responseEnvelopeType = typeof(MessageEnvelope<TResponse>);\n    var responseTypeInfo = _jsonOptions GetTypeInfo(responseEnvelopeType) throw new InvalidOperationException($\"No JsonTypeInfo for {responseEnvelopeType",
        "startIndex": 3739,
        "preview": "Ordered \\| ExactlyOnce | | Azure Service Bus | PublishSubscribe \\| Reliable \\| Ordered | --- HTTP Transport Implementation Pattern 1: HTTP Client Tran..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-3",
        "text": "JsonTypeInfo for {envelopeType Name}\"); // POST envelope to remote endpoint var response = await _http PostAsJsonAsync( destination Address, // e g , \"https://api example com/orders/create\" requestEnvelope, typeInfo, ct ); response EnsureSuccessStatusCode(); // Deserialize response envelope var responseEnvelopeType = typeof(MessageEnvelope<TResponse>); var responseTypeInfo = _jsonOptions GetTypeInfo(responseEnvelopeType) throw new InvalidOperationException($\"No JsonTypeInfo for {responseEnvelopeType Name}\");\n    var responseEnvelope = await response Content ReadFromJsonAsync(responseTypeInfo, ct)\n      as IMessageEnvelope;\n    if (responseEnvelope is null) {\n      throw new InvalidOperationException(\"Failed to deserialize response envelope\");\n    }\n    _logger LogInformation(\n      \"HTTP request sent to {Address}, received response {MessageId}\",\n      destination Address,\n      responseEnvelope MessageId\n    );\n    return responseEnvelope;\n  }\n}\n`\nRegistration:\n`csharp\nbuilder Services AddHttpClient<HttpTransport>(client => {\n  client BaseAddress = new Uri(\"https://api example com\");\n  client Timeout = TimeSpan FromSeconds(30);\n});\nbuilder Services AddSingleton<ITransport, HttpTransport>();\n`\nUsage:\n`csharp\nvar request = MessageEnvelope Create(\n  messageId: MessageId New(),\n  correlationId: CorrelationId New(),\n  causationId: null,\n  payload: new CreateOrder(orderId, customerId, items)\n);\nvar destination = new TransportDestination(Address: \"/orders/create\");\nvar response = await transport SendAsync<CreateOrder, OrderCreated>(request, destination);\n`\n---\ngRPC Transport Implementation\nPattern 2: gRPC Channel Transport\nUse Case: High-performance RPC with streaming support `csharp\nusing Whizbang Core;\nusing Whizbang Core Transports;\nusing Grpc Net Client;\nusing System Text Json;\npublic class GrpcTransport : ITransport {\n  private readonly GrpcChannel _channel;\n  private readonly JsonSerializerOptions _jsonOptions;\n  private readonly ILogger<GrpcTransport> _logger;\n  private bool _isInitialized;\n  public GrpcTransport(\n    GrpcChannel channel,\n    JsonSerializerOptions jsonOptions,\n    ILogger<GrpcTransport> logger\n  ) {\n    _channel = channel;\n    _jsonOptions = jsonOptions;\n    _logger = logger;\n  }\n  public bool IsInitialized => _isInitialized;\n  public TransportCapabilities Capabilities =>\n    TransportCapabilities RequestResponse |\n    TransportCapabilities Streaming;  // gRPC supports both\n  public async Task InitializeAsync(CancellationToken ct = default) {\n    // Verify gRPC channel is connected\n    await _channel ConnectAsync(ct);\n    _isInitialized = true;\n    _logger LogInformation(\n      \"gRPC transport initialized for {Target}\",\n      _channel",
        "startIndex": 6344,
        "preview": "JsonTypeInfo for {envelopeType Name}\"); // POST envelope to remote endpoint var response = await _http PostAsJsonAsync( destination Address, // e g , ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-4",
        "text": "_logger = logger; } public bool IsInitialized => _isInitialized; public TransportCapabilities Capabilities => TransportCapabilities RequestResponse | TransportCapabilities Streaming; // gRPC supports both public async Task InitializeAsync(CancellationToken ct = default) { // Verify gRPC channel is connected await _channel ConnectAsync(ct); _isInitialized = true; _logger LogInformation( \"gRPC transport initialized for {Target}\", _channel Target\n    );\n  }\n  public async Task<IMessageEnvelope> SendAsync<TRequest, TResponse>(\n    IMessageEnvelope requestEnvelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) where TRequest : notnull where TResponse : notnull {\n    // Create gRPC client for service\n    var client = CreateClient(destination Address);  // e g , \"OrderService\"\n    // Serialize request envelope to protobuf/JSON\n    var request = SerializeEnvelope(requestEnvelope);\n    // Invoke gRPC method\n    var response = await client ProcessMessageAsync(request, cancellationToken: ct);\n    // Deserialize response envelope\n    var responseEnvelope = DeserializeEnvelope<TResponse>(response);\n    _logger LogInformation(\n      \"gRPC request sent to {Service}, method {Method}\",\n      destination Address,\n      destination RoutingKey\n    );\n    return responseEnvelope;\n  }\n  // Simplified for example - actual implementation depends on protobuf schema\n  private dynamic CreateClient(string serviceName) {\n    // Use reflection or code generation to create gRPC client\n    // e g , var client = new OrderService OrderServiceClient(_channel);\n    throw new NotImplementedException(\"gRPC client creation\");\n  }\n  private object SerializeEnvelope(IMessageEnvelope envelope) {\n    // Convert MessageEnvelope to protobuf message\n    throw new NotImplementedException(\"Protobuf serialization\");\n  }\n  private IMessageEnvelope DeserializeEnvelope<T>(object response) {\n    // Convert protobuf message to MessageEnvelope<T>\n    throw new NotImplementedException(\"Protobuf deserialization\");\n  }\n  public Task PublishAsync(\n    IMessageEnvelope envelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    throw new NotSupportedException(\"gRPC transport is request/response only (use streaming for pub/sub)\");\n  }\n  public Task<ISubscription> SubscribeAsync(\n    Func<IMessageEnvelope, CancellationToken, Task> handler,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    // For streaming gRPC, implement server-side streaming subscription\n    throw new NotImplementedException(\"gRPC streaming subscription\");\n  }\n}\n`\n---\nKafka Transport Implementation\nPattern 3: Kafka Producer/Consumer Transport\nUse Case: High-throughput event streaming with ordering and persistence `csharp\nusing Whizbang Core;\nusing Whizbang Core Transports;\nusing Confluent Kafka;\nusing System",
        "startIndex": 8540,
        "preview": "_logger = logger; } public bool IsInitialized => _isInitialized; public TransportCapabilities Capabilities => TransportCapabilities RequestResponse | ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-5",
        "text": "default ) { // For streaming gRPC, implement server-side streaming subscription throw new NotImplementedException(\"gRPC streaming subscription\"); } } ` --- Kafka Transport Implementation Pattern 3: Kafka Producer/Consumer Transport Use Case: High-throughput event streaming with ordering and persistence `csharp using Whizbang Core; using Whizbang Core Transports; using Confluent Kafka; using System Text Json;\npublic class KafkaTransport : ITransport {\n  private readonly IProducer<string, string> _producer;\n  private readonly ConsumerConfig _consumerConfig;\n  private readonly JsonSerializerOptions _jsonOptions;\n  private readonly ILogger<KafkaTransport> _logger;\n  private bool _isInitialized;\n  public KafkaTransport(\n    ProducerConfig producerConfig,\n    ConsumerConfig consumerConfig,\n    JsonSerializerOptions jsonOptions,\n    ILogger<KafkaTransport> logger\n  ) {\n    _producer = new ProducerBuilder<string, string>(producerConfig) Build();\n    _consumerConfig = consumerConfig;\n    _jsonOptions = jsonOptions;\n    _logger = logger;\n  }\n  public bool IsInitialized => _isInitialized;\n  public TransportCapabilities Capabilities =>\n    TransportCapabilities PublishSubscribe |\n    TransportCapabilities Reliable |\n    TransportCapabilities Ordered;  // Kafka guarantees within partitions\n  public async Task InitializeAsync(CancellationToken ct = default) {\n    // Verify Kafka cluster is reachable\n    try {\n      // Produce a test message to verify connectivity\n      var metadata = _producer GetMetadata(TimeSpan FromSeconds(5));\n      _isInitialized = true;\n      _logger LogInformation(\n        \"Kafka transport initialized, connected to {BrokerCount} brokers\",\n        metadata Brokers Count\n      );\n    } catch (KafkaException ex) {\n      throw new InvalidOperationException(\"Kafka transport initialization failed\", ex);\n    }\n  }\n  public async Task PublishAsync(\n    IMessageEnvelope envelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    // Serialize envelope to JSON\n    var envelopeType = envelope GetType();\n    var typeInfo = _jsonOptions GetTypeInfo(envelopeType) throw new InvalidOperationException($\"No JsonTypeInfo for {envelopeType Name}\");\n    var json = JsonSerializer Serialize(envelope, typeInfo);\n    // Create Kafka message\n    var message = new Message<string, string> {\n      Key = envelope StreamKey envelope MessageId Value ToString(),  // Partition by stream\n      Value = json,\n      Headers = new Headers {\n        { \"MessageId\", System Text Encoding UTF8 GetBytes(envelope MessageId Value ToString()) },\n        { \"CorrelationId\", System Text Encoding UTF8 GetBytes(envelope CorrelationId Value ToString()) },\n        { \"EnvelopeType\", System Text Encoding UTF8 GetBytes(envelopeType AssemblyQualifiedName",
        "startIndex": 3734,
        "preview": "default ) { // For streaming gRPC, implement server-side streaming subscription throw new NotImplementedException(\"gRPC streaming subscription\"); } } ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-6",
        "text": "Key = envelope StreamKey envelope MessageId Value ToString(), // Partition by stream Value = json, Headers = new Headers { { \"MessageId\", System Text Encoding UTF8 GetBytes(envelope MessageId Value ToString()) }, { \"CorrelationId\", System Text Encoding UTF8 GetBytes(envelope CorrelationId Value ToString()) }, { \"EnvelopeType\", System Text Encoding UTF8 GetBytes(envelopeType AssemblyQualifiedName ) }\n      }\n    };\n    // Publish to topic\n    var result = await _producer ProduceAsync(\n      destination Address,  // Kafka topic name\n      message,\n      ct\n    );\n    _logger LogInformation(\n      \"Published message {MessageId} to Kafka topic {Topic}, partition {Partition}, offset {Offset}\",\n      envelope MessageId,\n      destination Address,\n      result Partition Value,\n      result Offset Value\n    );\n  }\n  public async Task<ISubscription> SubscribeAsync(\n    Func<IMessageEnvelope, CancellationToken, Task> handler,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    // Create Kafka consumer\n    var consumer = new ConsumerBuilder<string, string>(_consumerConfig) Build();\n    // Subscribe to topic\n    consumer Subscribe(destination Address);  // Kafka topic name\n    _logger LogInformation(\n      \"Subscribed to Kafka topic {Topic}, consumer group {ConsumerGroup}\",\n      destination Address,\n      _consumerConfig GroupId\n    );\n    // Background task to consume messages\n    var consumeTask = Task Run(async () => {\n      try {\n        while ( ct IsCancellationRequested) {\n          var consumeResult = consumer Consume(ct);\n          if (consumeResult Message = null) {\n            try {\n              // Deserialize envelope\n              var envelopeTypeName = System Text Encoding UTF8 GetString(\n                consumeResult Message Headers GetLastBytes(\"EnvelopeType\")\n              );\n              var envelopeType = Type GetType(envelopeTypeName) throw new InvalidOperationException($\"Unknown envelope type: {envelopeTypeName}\");\n              var typeInfo = _jsonOptions GetTypeInfo(envelopeType) throw new InvalidOperationException($\"No JsonTypeInfo for {envelopeType Name}\");\n              var envelope = JsonSerializer Deserialize(\n                consumeResult Message Value,\n                typeInfo\n              ) as IMessageEnvelope throw new InvalidOperationException(\"Failed to deserialize envelope\");\n              // Invoke handler\n              await handler(envelope, ct);\n              // Commit offset after successful processing\n              consumer Commit(consumeResult);\n              _logger LogDebug(\n                \"Processed Kafka message from topic {Topic}, partition {Partition}, offset {Offset}\",\n                consumeResult Topic,\n                consumeResult Partition Value,\n                consumeResult Offset Value\n              );\n            } catch (Exception ex) {\n              _logger LogError(\n                ex,\n                \"Error processing Kafka message from topic {Topic}, partition {Partition}, offset {Offset}\",\n                consumeResult Topic,\n                consumeResult Partition",
        "startIndex": 13361,
        "preview": "Key = envelope StreamKey envelope MessageId Value ToString(), // Partition by stream Value = json, Headers = new Headers { { \"MessageId\", System Text ..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-7",
        "text": "offset after successful processing consumer Commit(consumeResult); _logger LogDebug( \"Processed Kafka message from topic {Topic}, partition {Partition}, offset {Offset}\", consumeResult Topic, consumeResult Partition Value, consumeResult Offset Value ); } catch (Exception ex) { _logger LogError( ex, \"Error processing Kafka message from topic {Topic}, partition {Partition}, offset {Offset}\", consumeResult Topic, consumeResult Partition Value,\n                consumeResult Offset Value\n              );\n              // Don't commit - message will be retried\n            }\n          }\n        }\n      } catch (OperationCanceledException) {\n        // Expected on shutdown\n      } finally {\n        consumer Close();\n      }\n    }, ct);\n    return new KafkaSubscription(consumer, consumeTask);\n  }\n  public Task<IMessageEnvelope> SendAsync<TRequest, TResponse>(\n    IMessageEnvelope requestEnvelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) where TRequest : notnull where TResponse : notnull {\n    throw new NotSupportedException(\"Kafka transport does not support request/response (use pub/sub instead)\");\n  }\n}\n/// <summary>\n/// Subscription handle for Kafka consumer /// </summary>\ninternal class KafkaSubscription : ISubscription {\n  private readonly IConsumer<string, string> _consumer;\n  private readonly Task _consumeTask;\n  public KafkaSubscription(IConsumer<string, string> consumer, Task consumeTask) {\n    _consumer = consumer;\n    _consumeTask = consumeTask;\n  }\n  public async ValueTask DisposeAsync() {\n    // Stop consuming\n    _consumer Close();\n    // Wait for consume task to complete\n    try {\n      await _consumeTask WaitAsync(TimeSpan FromSeconds(10));\n    } catch (TimeoutException) {\n      // Consume task didn't complete in time\n    }\n    _consumer Dispose();\n  }\n}\n`\nRegistration:\n`csharp\nvar producerConfig = new ProducerConfig {\n  BootstrapServers = \"localhost:9092\",\n  Acks = Acks All,  // Wait for all replicas\n  EnableIdempotence = true  // Exactly-once producer\n};\nvar consumerConfig = new ConsumerConfig {\n  BootstrapServers = \"localhost:9092\",\n  GroupId = \"whizbang-consumer-group\",\n  AutoOffsetReset = AutoOffsetReset Earliest,\n  EnableAutoCommit = false  // Manual commit after processing\n};\nbuilder Services AddSingleton<ITransport>(sp =>\n  new KafkaTransport(\n    producerConfig,\n    consumerConfig,\n    sp GetRequiredService<JsonSerializerOptions>(),\n    sp GetRequiredService<ILogger<KafkaTransport>>()\n  )\n);\n`\n---\nAdvanced Patterns\nPattern 4: Transport with Health Checks\n`csharp\nusing Whizbang Core Transports;\nusing Microsoft Extensions Diagnostics",
        "startIndex": 15786,
        "preview": "offset after successful processing consumer Commit(consumeResult); _logger LogDebug( \"Processed Kafka message from topic {Topic}, partition {Partition..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-8",
        "text": "\"localhost:9092\", GroupId = \"whizbang-consumer-group\", AutoOffsetReset = AutoOffsetReset Earliest, EnableAutoCommit = false // Manual commit after processing }; builder Services AddSingleton<ITransport>(sp => new KafkaTransport( producerConfig, consumerConfig, sp GetRequiredService<JsonSerializerOptions>(), sp GetRequiredService<ILogger<KafkaTransport>>() ) ); ` --- Advanced Patterns Pattern 4: Transport with Health Checks `csharp using Whizbang Core Transports; using Microsoft Extensions Diagnostics HealthChecks;\npublic class KafkaTransportHealthCheck : IHealthCheck {\n  private readonly KafkaTransport _transport;\n  public KafkaTransportHealthCheck(ITransport transport) {\n    _transport = (KafkaTransport)transport;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken ct = default\n  ) {\n    if ( _transport IsInitialized) {\n      return HealthCheckResult Unhealthy(\"Kafka transport not initialized\");\n    }\n    try {\n      // Verify producer is healthy\n      var metadata = _transport GetMetadata(TimeSpan FromSeconds(2));\n      var brokerCount = metadata Brokers Count;\n      if (brokerCount == 0) {\n        return HealthCheckResult Degraded(\"No Kafka brokers available\");\n      }\n      return HealthCheckResult Healthy($\"Kafka transport healthy, {brokerCount} brokers connected\");\n    } catch (KafkaException ex) {\n      return HealthCheckResult Unhealthy(\"Kafka transport unhealthy\", ex);\n    }\n  }\n}\n// Registration\nbuilder Services AddHealthChecks() AddCheck<KafkaTransportHealthCheck>(\"kafka_transport\");\n`\n---\nPattern 5: Batching Transport (High Throughput)\n`csharp\nusing Whizbang Core Transports;\nusing System Threading Channels;\npublic class BatchingTransport : ITransport {\n  private readonly ITransport _innerTransport;\n  private readonly Channel<(IMessageEnvelope, TransportDestination)> _queue;\n  private readonly Task _batchProcessor;\n  private readonly CancellationTokenSource _cts;\n  private const int BatchSize = 100;\n  private static readonly TimeSpan BatchTimeout = TimeSpan FromMilliseconds(100);\n  public BatchingTransport(ITransport innerTransport) {\n    _innerTransport = innerTransport;\n    _queue = Channel CreateBounded<(IMessageEnvelope, TransportDestination)>(10000);\n    _cts = new CancellationTokenSource();\n    _batchProcessor = Task Run(() => ProcessBatchesAsync(_cts Token));\n  }\n  public bool IsInitialized => _innerTransport IsInitialized;\n  public TransportCapabilities Capabilities => _innerTransport Capabilities;\n  public Task InitializeAsync(CancellationToken ct = default) =>\n    _innerTransport InitializeAsync(ct);\n  public async Task PublishAsync(\n    IMessageEnvelope envelope,\n    TransportDestination destination,\n    CancellationToken ct = default\n  ) {\n    // Queue message for batching\n    await _queue Writer WriteAsync((envelope, destination), ct);\n  }\n  private async Task ProcessBatchesAsync(CancellationToken ct) {\n    var batch = new List<(IMessageEnvelope, TransportDestination)>(BatchSize);\n    while ( ct IsCancellationRequested) {\n      // Collect batch\n      while (batch",
        "startIndex": 18320,
        "preview": "\"localhost:9092\", GroupId = \"whizbang-consumer-group\", AutoOffsetReset = AutoOffsetReset Earliest, EnableAutoCommit = false // Manual commit after pro..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-9",
        "text": "_innerTransport InitializeAsync(ct); public async Task PublishAsync( IMessageEnvelope envelope, TransportDestination destination, CancellationToken ct = default ) { // Queue message for batching await _queue Writer WriteAsync((envelope, destination), ct); } private async Task ProcessBatchesAsync(CancellationToken ct) { var batch = new List<(IMessageEnvelope, TransportDestination)>(BatchSize); while ( ct IsCancellationRequested) { // Collect batch while (batch Count < BatchSize) {\n        using var timeoutCts = CancellationTokenSource CreateLinkedTokenSource(ct);\n        timeoutCts CancelAfter(BatchTimeout);\n        try {\n          var item = await _queue Reader ReadAsync(timeoutCts Token);\n          batch Add(item);\n        } catch (OperationCanceledException) {\n          break;  // Timeout or cancellation\n        }\n      }\n      // Publish batch in parallel\n      if (batch Count > 0) {\n        await Task WhenAll(\n          batch Select(item =>\n            _innerTransport PublishAsync(item Item1, item Item2, ct)\n          )\n        );\n        batch Clear();\n      }\n    }\n  }\n  // Other ITransport methods delegate to _innerTransport\n  public Task<ISubscription> SubscribeAsync( ) =>\n    _innerTransport SubscribeAsync(handler, destination, ct);\n  public Task<IMessageEnvelope> SendAsync<TRequest, TResponse>( ) =>\n    _innerTransport SendAsync<TRequest, TResponse>(requestEnvelope, destination, ct);\n}\n`\nUsage:\n`csharp\n// Wrap existing transport with batching\nvar kafkaTransport = new KafkaTransport( );\nvar batchingTransport = new BatchingTransport(kafkaTransport);\nbuilder Services AddSingleton<ITransport>(batchingTransport);\n`\nBenefits:\n10x Throughput: Batch 100 messages in single Kafka produce call\nLower Latency: Parallel publishing within batch\nBackpressure: Bounded channel prevents memory issues\n---\nTesting Custom Transports\nTesting Initialization\n`csharp\npublic class KafkaTransportTests {\n  [Test]\n  public async Task InitializeAsync_ValidBroker_SucceedsAsync() {\n    // Arrange\n    var producerConfig = new ProducerConfig { BootstrapServers = \"localhost:9092\" };\n    var consumerConfig = new ConsumerConfig { BootstrapServers = \"localhost:9092\", GroupId = \"test\" };\n    var jsonOptions = JsonContextRegistry CreateCombinedOptions();\n    var logger = new NullLogger<KafkaTransport>();\n    var transport = new KafkaTransport(producerConfig, consumerConfig, jsonOptions, logger);\n    // Act\n    await transport InitializeAsync();\n    // Assert\n    await Assert That(transport IsInitialized) IsTrue();\n  }\n  [Test]\n  public async Task InitializeAsync_InvalidBroker_ThrowsAsync() {\n    // Arrange\n    var producerConfig = new ProducerConfig { BootstrapServers = \"invalid:9092\" };\n    var consumerConfig = new ConsumerConfig { BootstrapServers = \"invalid:9092\", GroupId = \"test\" };\n    var jsonOptions = JsonContextRegistry",
        "startIndex": 20922,
        "preview": "_innerTransport InitializeAsync(ct); public async Task PublishAsync( IMessageEnvelope envelope, TransportDestination destination, CancellationToken ct..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-10",
        "text": "jsonOptions, logger); // Act await transport InitializeAsync(); // Assert await Assert That(transport IsInitialized) IsTrue(); } [Test] public async Task InitializeAsync_InvalidBroker_ThrowsAsync() { // Arrange var producerConfig = new ProducerConfig { BootstrapServers = \"invalid:9092\" }; var consumerConfig = new ConsumerConfig { BootstrapServers = \"invalid:9092\", GroupId = \"test\" }; var jsonOptions = JsonContextRegistry CreateCombinedOptions();\n    var logger = new NullLogger<KafkaTransport>();\n    var transport = new KafkaTransport(producerConfig, consumerConfig, jsonOptions, logger);\n    // Act & Assert\n    await Assert That(async () => await transport InitializeAsync()) ThrowsException<InvalidOperationException>() WithMessage(\"Kafka transport initialization failed\");\n  }\n}\n`\nTesting Publish/Subscribe\n`csharp\npublic class KafkaTransportIntegrationTests {\n  [Test]\n  public async Task PublishAndSubscribe_MessageReceivedAsync() {\n    // Arrange\n    var transport = CreateKafkaTransport();\n    await transport InitializeAsync();\n    var receivedEnvelope = default(IMessageEnvelope);\n    var messageReceived = new TaskCompletionSource<bool>();\n    var destination = new TransportDestination(Address: \"test-topic\");\n    // Subscribe\n    await transport SubscribeAsync(\n      handler: async (envelope, ct) => {\n        receivedEnvelope = envelope;\n        messageReceived SetResult(true);\n      },\n      destination: destination\n    );\n    // Act - Publish\n    var envelope = MessageEnvelope Create(\n      messageId: MessageId New(),\n      correlationId: CorrelationId New(),\n      causationId: null,\n      payload: new TestMessage(\"Hello Kafka \")\n    );\n    await transport PublishAsync(envelope, destination);\n    // Assert - Wait for message\n    var received = await messageReceived Task WaitAsync(TimeSpan FromSeconds(10));\n    await Assert That(received) IsTrue();\n    await Assert That(receivedEnvelope) IsNotNull();\n    await Assert That(receivedEnvelope MessageId) IsEqualTo(envelope MessageId);\n  }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Implement InitializeAsync for connectivity verification\n‚úÖ Declare accurate Capabilities flags\n‚úÖ Use AOT-compatible serialization (JsonTypeInfo)\n‚úÖ Handle errors gracefully with retry logic\n‚úÖ Log all operations for observability\n‚úÖ Support cancellation via CancellationToken\n‚úÖ Add health checks for transport status\n‚úÖ Test with real backends (Docker containers)\nDON'T ‚ùå\n‚ùå Block async operations with Result or Wait()\n‚ùå Skip initialization verification (fail fast )\n‚ùå Ignore Capabilities (declare what you support)\n‚ùå Forget to dispose subscriptions (memory leaks)\n‚ùå Use reflection for serialization (breaks AOT)\n‚ùå Swallow exceptions silently (log errors",
        "startIndex": 23313,
        "preview": "jsonOptions, logger); // Act await transport InitializeAsync(); // Assert await Assert That(transport IsInitialized) IsTrue(); } [Test] public async T..."
      },
      {
        "id": "v0.1.0/extensibility/custom-transports-chunk-11",
        "text": "Test with real backends (Docker containers) DON'T ‚ùå ‚ùå Block async operations with Result or Wait() ‚ùå Skip initialization verification (fail fast ) ‚ùå Ignore Capabilities (declare what you support) ‚ùå Forget to dispose subscriptions (memory leaks) ‚ùå Use reflection for serialization (breaks AOT) ‚ùå Swallow exceptions silently (log errors )\n‚ùå Hardcode configuration (use options pattern)\n---\nFurther Reading\nTransports:\nAzure Service Bus - Built-in Service Bus transport\nIn-Memory - Testing transport\nMessaging:\nOutbox Pattern - Reliable event publishing\nWork Coordination - Lease-based processing\nSource Generators:\nJSON Contexts - AOT-compatible serialization\nInfrastructure:\nHealth Checks - Transport health monitoring\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 25603,
        "preview": "Test with real backends (Docker containers) DON'T ‚ùå ‚ùå Block async operations with Result or Wait() ‚ùå Skip initialization verification (fail fast ) ‚ùå I..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/custom-work-coordinators",
    "title": "Custom Work Coordinators",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/custom-work-coordinators",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/custom-work-coordinators-chunk-0",
        "text": "Custom Work Coordinators\nCustom work coordinators enable alternative work distribution strategies beyond PostgreSQL-based leasing Implement Redis-based queues, distributed locks, or custom lease management :::note\nWhizbang uses PostgreSQL stored procedures for work coordination by default Custom coordinators are for specialized scenarios :::\n---\nWhy Custom Work Coordinators | Strategy | Use Case | Benefits |\n|----------|----------|----------|\n| PostgreSQL (default) | Standard apps | ACID, atomic batches |\n| Redis | High-throughput | In-memory, fast locks |\n| Distributed Locks | Multi-region | Consensus-based |\n| Kafka | Event streaming | Offset-based tracking |\nWhen to use custom coordinators:\n‚úÖ Extreme throughput (> 100K msg/sec)\n‚úÖ Multi-region deployments\n‚úÖ Existing infrastructure\n‚úÖ Custom lease strategies\n---\nIWorkCoordinator Interface\n`csharp\npublic interface IWorkCoordinator {\n  Task<WorkBatch> ProcessWorkBatchAsync(\n    Guid instanceId,\n    string serviceName,\n    // parameters\n    CancellationToken ct = default\n  );\n}\n`\n---\nRedis Work Coordinator\nPattern 1: Redis Queue-Based Coordination\n`csharp\nusing StackExchange Redis;\npublic class RedisWorkCoordinator : IWorkCoordinator {\n  private readonly IConnectionMultiplexer _redis;\n  private readonly ILogger<RedisWorkCoordinator> _logger;\n  public RedisWorkCoordinator(\n    IConnectionMultiplexer redis,\n    ILogger<RedisWorkCoordinator> logger\n  ) {\n    _redis = redis;\n    _logger = logger;\n  }\n  public async Task<WorkBatch> ProcessWorkBatchAsync(\n    Guid instanceId,\n    string serviceName,\n    string hostName,\n    int processId,\n    Dictionary<string, JsonElement> metadata,\n    MessageCompletion[] outboxCompletions,\n    MessageFailure[] outboxFailures,\n    // other parameters\n    CancellationToken ct = default\n  ) {\n    var db = _redis GetDatabase();\n    // 1 Process completions (remove from Redis)\n    foreach (var completion in outboxCompletions) {\n      await db ListRemoveAsync(\n        \"outbox:pending\",\n        JsonSerializer Serialize(completion MessageId),\n        ct\n      );\n    }\n    // 2 Process failures (update retry count)\n    foreach (var failure in outboxFailures) {\n      // Increment retry count, re-queue if needed\n      // }\n    // 3 Claim new work (atomic LPOP)\n    var claimedWork = new List<OutboxMessage>();\n    for (int i = 0; i < 100; i++) {\n      var workItem = await db ListLeftPopAsync(\"outbox:pending\", ct);\n      if (workItem IsNullOrEmpty) break;\n      var message = JsonSerializer Deserialize<OutboxMessage>(workItem );\n      claimedWork Add(message",
        "startIndex": 0,
        "preview": "Custom Work Coordinators\nCustom work coordinators enable alternative work distribution strategies beyond PostgreSQL-based leasing Implement Redis-base..."
      },
      {
        "id": "v0.1.0/extensibility/custom-work-coordinators-chunk-1",
        "text": "// Increment retry count, re-queue if needed // } // 3 Claim new work (atomic LPOP) var claimedWork = new List<OutboxMessage>(); for (int i = 0; i < 100; i++) { var workItem = await db ListLeftPopAsync(\"outbox:pending\", ct); if (workItem IsNullOrEmpty) break; var message = JsonSerializer Deserialize<OutboxMessage>(workItem ); claimedWork Add(message );\n    }\n    return new WorkBatch {\n      ClaimedOutboxMessages = claimedWork ToArray()\n    };\n  }\n}\n`\n---\nFurther Reading\nMessaging:\nWork Coordination - PostgreSQL work coordination\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 2592,
        "preview": "// Increment retry count, re-queue if needed // } // 3 Claim new work (atomic LPOP) var claimedWork = new List<OutboxMessage>(); for (int i = 0; i < 1..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/hooks-and-middleware",
    "title": "Hooks and Middleware",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/hooks-and-middleware",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-0",
        "text": "Hooks and Middleware\nPipeline behaviors enable cross-cutting concerns without modifying business logic Behaviors intercept messages before/after receptor execution, allowing logging, validation, retry logic, caching, and other concerns to be injected declaratively Why Pipeline Behaviors Separate cross-cutting concerns from business logic:\n| Without Behaviors | With Behaviors | Benefit |\n|-------------------|----------------|---------|\n| Logging in every receptor | Single logging behavior | DRY principle |\n| Validation scattered | Centralized validation behavior | Consistency |\n| Retry logic duplicated | Reusable retry behavior | Maintainability |\n| Caching per-handler | Generic caching behavior | Reduced complexity |\n| Timing/metrics manual | Automatic timing behavior | Complete coverage |\nUse Cases:\n‚úÖ Logging - Structured logging for all messages\n‚úÖ Validation - Input validation before processing\n‚úÖ Retry Logic - Automatic retry on transient failures\n‚úÖ Caching - Response caching for idempotent queries\n‚úÖ Performance Metrics - Timing and throughput tracking\n‚úÖ Authorization - Permission checks\n‚úÖ Transaction Management - Automatic transaction boundaries\n‚úÖ Error Handling - Centralized exception handling\n---\nArchitecture\nPipeline Execution Flow\n`\nIDispatcher SendAsync(command)\n  ‚îÇ\n  ‚îÇ 1",
        "startIndex": 0,
        "preview": "Hooks and Middleware\nPipeline behaviors enable cross-cutting concerns without modifying business logic Behaviors intercept messages before/after recep..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-1",
        "text": "retry on transient failures ‚úÖ Caching - Response caching for idempotent queries ‚úÖ Performance Metrics - Timing and throughput tracking ‚úÖ Authorization - Permission checks ‚úÖ Transaction Management - Automatic transaction boundaries ‚úÖ Error Handling - Centralized exception handling --- Architecture Pipeline Execution Flow ` IDispatcher SendAsync(command) ‚îÇ ‚îÇ 1 Create pipeline\n  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Pipeline Chain (behaviors + receptor)                 ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  LoggingBehavior                                 ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Before: Log request                          ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Call next() ‚Üí ValidationBehavior             ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ After: Log response                          ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ                  ‚îÇ                                      ‚îÇ\n‚îÇ                  ‚ñº                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  ValidationBehavior                              ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Before: Validate request                     ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Call next() ‚Üí RetryBehavior                  ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ After: No post-processing                    ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ                  ‚îÇ                                      ‚îÇ\n‚îÇ                  ‚ñº                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  RetryBehavior                                   ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Before: No pre-processing                    ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Call next() ‚Üí OrderReceptor (with retry)     ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ After: No post-processing                    ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ                  ‚îÇ                                      ‚îÇ\n‚îÇ                  ‚ñº                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  OrderReceptor HandleAsync()                     ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ Business logic execution                     ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ\n  ‚îÇ 2",
        "startIndex": 1305,
        "preview": "retry on transient failures ‚úÖ Caching - Response caching for idempotent queries ‚úÖ Performance Metrics - Timing and throughput tracking ‚úÖ Authorization..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-2",
        "text": "‚îú‚îÄ Call next() ‚Üí OrderReceptor (with retry) ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ After: No post-processing ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚ñº ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ OrderReceptor HandleAsync() ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ Business logic execution ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 2 Return result\n  ‚ñº\nResponse\n`\n---\nIPipelineBehavior Interface\nDefinition\n`csharp\npublic interface IPipelineBehavior<in TRequest, TResponse> {\n  Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken = default\n  );\n}\n`\nParameters:\nrequest - The message being processed (command or query)\nnext - Delegate to invoke next behavior or receptor\ncancellationToken - Cancellation token\nReturn: Response from receptor (potentially modified by behavior)\nBase Class\n`csharp\npublic abstract class PipelineBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse> {\n  public abstract Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken = default\n  );\n  protected async Task<TResponse> ExecuteNextAsync(Func<Task<TResponse>> next) {\n    return await next();\n  }\n}\n`\n---\nBuilt-In Behaviors\nLogging Behavior\n`csharp\nusing Microsoft Extensions Logging;\nusing Whizbang Core Pipeline;\npublic class LoggingBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse> {\n  private readonly ILogger<LoggingBehavior<TRequest, TResponse>> _logger;\n  public LoggingBehavior(ILogger<LoggingBehavior<TRequest, TResponse>> logger) {\n    _logger = logger;\n  }\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    var requestName = typeof(TRequest) Name;\n    var requestId = Guid NewGuid();\n    // Before: Log request\n    _logger LogInformation(\n      \"Processing {RequestName} ({RequestId}): {@Request}\",\n      requestName,\n      requestId,\n      request\n    );\n    try {\n      // Execute next behavior or receptor\n      var response = await next();\n      // After: Log success\n      _logger LogInformation(\n        \"Completed {RequestName} ({RequestId}): {@Response}\",\n        requestName,\n        requestId,\n        response\n      );\n      return response;\n    } catch (Exception ex) {\n      // After: Log failure\n      _logger LogError(\n        ex,\n        \"Failed {RequestName} ({RequestId}): {Error}\",\n        requestName,\n        requestId,\n        ex Message\n      );\n      throw;\n    }\n  }\n}\n`\nRegistration:\n`csharp\nbuilder Services AddTransient(\n  typeof(IPipelineBehavior<,>),\n  typeof(LoggingBehavior<,>)\n);\n`\nValidation Behavior\n`csharp\nusing FluentValidation;\nusing Whizbang Core",
        "startIndex": 3209,
        "preview": "‚îú‚îÄ Call next() ‚Üí OrderReceptor (with retry) ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ After: No post-processing ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-3",
        "text": "{@Response}\", requestName, requestId, response ); return response; } catch (Exception ex) { // After: Log failure _logger LogError( ex, \"Failed {RequestName} ({RequestId}): {Error}\", requestName, requestId, ex Message ); throw; } } } ` Registration: `csharp builder Services AddTransient( typeof(IPipelineBehavior<,>), typeof(LoggingBehavior<,>) ); ` Validation Behavior `csharp using FluentValidation; using Whizbang Core Pipeline;\npublic class ValidationBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse> {\n  private readonly IEnumerable<IValidator<TRequest>> _validators;\n  public ValidationBehavior(IEnumerable<IValidator<TRequest>> validators) {\n    _validators = validators;\n  }\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    // No validators registered - skip validation\n    if ( _validators Any()) {\n      return await next();\n    }\n    // Validate request\n    var context = new ValidationContext<TRequest>(request);\n    var validationResults = await Task WhenAll(\n      _validators Select(v => v ValidateAsync(context, cancellationToken))\n    );\n    var failures = validationResults SelectMany(r => r Errors) Where(f => f = null) ToList();\n    if (failures Any()) {\n      throw new ValidationException(failures);\n    }\n    // Validation passed - continue\n    return await next();\n  }\n}\n`\nRegistration:\n`csharp\n// Register validators\nbuilder Services AddValidatorsFromAssemblyContaining<CreateOrderValidator>();\n// Register behavior\nbuilder Services AddTransient(\n  typeof(IPipelineBehavior<,>),\n  typeof(ValidationBehavior<,>)\n);\n`\nRetry Behavior\n`csharp\nusing Polly;\nusing Whizbang Core Pipeline;\npublic class RetryBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse> {\n  private readonly ILogger<RetryBehavior<TRequest, TResponse>> _logger;\n  public RetryBehavior(ILogger<RetryBehavior<TRequest, TResponse>> logger) {\n    _logger = logger;\n  }\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    // Define retry policy\n    var retryPolicy = Policy Handle<DbException>()  // Transient database failures Or<HttpRequestException>()  // Transient HTTP failures WaitAndRetryAsync(\n        retryCount: 3,\n        sleepDurationProvider: retryAttempt =>\n          TimeSpan FromSeconds(Math Pow(2, retryAttempt)),  // Exponential backoff\n        onRetry: (exception, timeSpan, retryCount, context) => {\n          _logger LogWarning(\n            exception,\n            \"Retry {RetryCount} for {RequestName} after {Delay}s\",\n            retryCount,\n            typeof(TRequest) Name,\n            timeSpan TotalSeconds\n          );\n        }\n      );\n    // Execute with retry\n    return await retryPolicy ExecuteAsync(async () => await next());\n  }\n}\n`\nCaching Behavior\n`csharp\nusing Microsoft Extensions Caching Memory;\nusing Whizbang Core",
        "startIndex": 5617,
        "preview": "{@Response}\", requestName, requestId, response ); return response; } catch (Exception ex) { // After: Log failure _logger LogError( ex, \"Failed {Reque..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-4",
        "text": "onRetry: (exception, timeSpan, retryCount, context) => { _logger LogWarning( exception, \"Retry {RetryCount} for {RequestName} after {Delay}s\", retryCount, typeof(TRequest) Name, timeSpan TotalSeconds ); } ); // Execute with retry return await retryPolicy ExecuteAsync(async () => await next()); } } ` Caching Behavior `csharp using Microsoft Extensions Caching Memory; using Whizbang Core Pipeline;\npublic class CachingBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse>\n  where TRequest : ICacheableQuery {  // Marker interface\n  private readonly IMemoryCache _cache;\n  private readonly ILogger<CachingBehavior<TRequest, TResponse>> _logger;\n  public CachingBehavior(\n    IMemoryCache cache,\n    ILogger<CachingBehavior<TRequest, TResponse>> logger\n  ) {\n    _cache = cache;\n    _logger = logger;\n  }\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    var cacheKey = $\"{typeof(TRequest) Name}:{request GetCacheKey()}\";\n    // Check cache\n    if (_cache TryGetValue<TResponse>(cacheKey, out var cachedResponse)) {\n      _logger LogDebug(\"Cache hit for {CacheKey}\", cacheKey);\n      return cachedResponse ;\n    }\n    // Cache miss - execute handler\n    _logger LogDebug(\"Cache miss for {CacheKey}\", cacheKey);\n    var response = await next();\n    // Store in cache\n    var cacheOptions = new MemoryCacheEntryOptions {\n      AbsoluteExpirationRelativeToNow = request GetCacheDuration()\n    };\n    _cache Set(cacheKey, response, cacheOptions);\n    return response;\n  }\n}\n// Marker interface for cacheable queries\npublic interface ICacheableQuery {\n  string GetCacheKey();\n  TimeSpan GetCacheDuration();\n}\n`\nPerformance Timing Behavior\n`csharp\nusing System Diagnostics;\nusing Whizbang Core Pipeline;\npublic class PerformanceBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse> {\n  private readonly ILogger<PerformanceBehavior<TRequest, TResponse>> _logger;\n  public PerformanceBehavior(ILogger<PerformanceBehavior<TRequest, TResponse>> logger) {\n    _logger = logger;\n  }\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    var stopwatch = Stopwatch StartNew();\n    try {\n      var response = await next();\n      stopwatch Stop();\n      var elapsedMs = stopwatch ElapsedMilliseconds;\n      var requestName = typeof(TRequest) Name;\n      if (elapsedMs > 500) {\n        // Slow request warning\n        _logger LogWarning(\n          \"Slow request: {RequestName} took {ElapsedMs}ms\",\n          requestName,\n          elapsedMs\n        );\n      } else {\n        _logger LogInformation(\n          \"{RequestName} completed in {ElapsedMs}ms\",\n          requestName,\n          elapsedMs\n        );\n      }\n      return response;\n    } catch {\n      stopwatch",
        "startIndex": 8207,
        "preview": "onRetry: (exception, timeSpan, retryCount, context) => { _logger LogWarning( exception, \"Retry {RetryCount} for {RequestName} after {Delay}s\", retryCo..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-5",
        "text": "stopwatch Stop(); var elapsedMs = stopwatch ElapsedMilliseconds; var requestName = typeof(TRequest) Name; if (elapsedMs > 500) { // Slow request warning _logger LogWarning( \"Slow request: {RequestName} took {ElapsedMs}ms\", requestName, elapsedMs ); } else { _logger LogInformation( \"{RequestName} completed in {ElapsedMs}ms\", requestName, elapsedMs ); } return response; } catch { stopwatch Stop();\n      throw;\n    }\n  }\n}\n`\n---\nRegistration and Ordering\nRegistration\n`csharp\nusing Microsoft Extensions DependencyInjection;\nvar builder = WebApplication CreateBuilder(args);\n// Behaviors execute in registration order\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(LoggingBehavior<,>));       // 1st\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(ValidationBehavior<,>));   // 2nd\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(RetryBehavior<,>));        // 3rd\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(PerformanceBehavior<,>));  // 4th\nvar app = builder Build();\n`\nExecution Order:\nLoggingBehavior - Logs request\nValidationBehavior - Validates request\nRetryBehavior - Wraps execution with retry\nPerformanceBehavior - Measures timing\nReceptor - Business logic\nConditional Registration\n`csharp\n// Only register in development\nif (builder Environment IsDevelopment()) {\n  builder Services AddTransient(\n    typeof(IPipelineBehavior<,>),\n    typeof(DebugBehavior<,>)\n  );\n}\n// Only register for specific message types\nbuilder Services AddTransient<IPipelineBehavior<CreateOrder, OrderCreated>,\n  OrderValidationBehavior>();\n`\n---\nAdvanced Patterns\nShort-Circuiting\n`csharp\npublic class AuthorizationBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse>\n  where TRequest : IAuthorizedRequest {\n  private readonly IAuthorizationService _authService;\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    // Check authorization\n    var isAuthorized = await _authService IsAuthorizedAsync(\n      request UserId,\n      request RequiredPermission\n    );\n    if ( isAuthorized) {\n      // Short-circuit - do NOT call next()\n      throw new UnauthorizedAccessException(\n        $\"User {request UserId} lacks permission {request RequiredPermission}\"\n      );\n    }\n    // Authorized - continue\n    return await next();\n  }\n}\n`\nResponse Modification\n`csharp\npublic class EnrichmentBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse>\n  where TResponse : IEnrichableResponse {\n  private readonly IUserContextService _userContext;\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    // Execute handler\n    var response = await next();\n    // Modify response\n    response UserId = _userContext GetCurrentUserId();\n    response Timestamp = DateTimeOffset",
        "startIndex": 10688,
        "preview": "stopwatch Stop(); var elapsedMs = stopwatch ElapsedMilliseconds; var requestName = typeof(TRequest) Name; if (elapsedMs > 500) { // Slow request warni..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-6",
        "text": "Modification `csharp public class EnrichmentBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> where TResponse : IEnrichableResponse { private readonly IUserContextService _userContext; public async Task<TResponse> Handle( TRequest request, Func<Task<TResponse>> next, CancellationToken cancellationToken ) { // Execute handler var response = await next(); // Modify response response UserId = _userContext GetCurrentUserId(); response Timestamp = DateTimeOffset UtcNow;\n    return response;\n  }\n}\n`\nTransaction Management\n`csharp\npublic class TransactionBehavior<TRequest, TResponse>\n  : IPipelineBehavior<TRequest, TResponse>\n  where TRequest : ITransactionalCommand {\n  private readonly IDbConnectionFactory _connectionFactory;\n  public async Task<TResponse> Handle(\n    TRequest request,\n    Func<Task<TResponse>> next,\n    CancellationToken cancellationToken\n  ) {\n    using var connection = await _connectionFactory CreateConnectionAsync(cancellationToken);\n    using var transaction = await connection BeginTransactionAsync(cancellationToken);\n    try {\n      // Execute within transaction\n      var response = await next();\n      // Commit on success\n      await transaction CommitAsync(cancellationToken);\n      return response;\n    } catch {\n      // Rollback on failure\n      await transaction RollbackAsync(cancellationToken);\n      throw;\n    }\n  }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Keep behaviors small and focused - Single responsibility\n‚úÖ Register in logical order (logging ‚Üí validation ‚Üí retry ‚Üí handler)\n‚úÖ Use marker interfaces for conditional behaviors (ICacheableQuery)\n‚úÖ Always call next() unless intentionally short-circuiting\n‚úÖ Handle exceptions appropriately (log, wrap, or propagate)\n‚úÖ Use async/await consistently - Don't block\n‚úÖ Make behaviors reusable - Generic across message types\nDON'T ‚ùå\n‚ùå Put business logic in behaviors (keep in receptors)\n‚ùå Mutate request in behaviors (immutable messages)\n‚ùå Forget to call next() (pipeline will hang)\n‚ùå Swallow exceptions silently (breaks error handling)\n‚ùå Register too many behaviors (keep pipeline lean)\n‚ùå Use behaviors for message routing (use policies instead)\n---\nTroubleshooting\nProblem: Behavior Not Executing\nSymptoms: Behavior code never runs Causes:\nNot registered in DI\nWrong generic type registration\nSolution:\n`csharp\n// ‚ùå WRONG: Concrete type registration\nbuilder Services AddTransient<LoggingBehavior<CreateOrder, OrderCreated>>();\n// ‚úÖ CORRECT: Open generic registration\nbuilder Services",
        "startIndex": 13240,
        "preview": "Modification `csharp public class EnrichmentBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> where TResponse : IEnrichableRespon..."
      },
      {
        "id": "v0.1.0/extensibility/hooks-and-middleware-chunk-7",
        "text": "lean) ‚ùå Use behaviors for message routing (use policies instead) --- Troubleshooting Problem: Behavior Not Executing Symptoms: Behavior code never runs Causes: Not registered in DI Wrong generic type registration Solution: `csharp // ‚ùå WRONG: Concrete type registration builder Services AddTransient<LoggingBehavior<CreateOrder, OrderCreated>>(); // ‚úÖ CORRECT: Open generic registration builder Services AddTransient(\n  typeof(IPipelineBehavior<,>),\n  typeof(LoggingBehavior<,>)\n);\n`\nProblem: Pipeline Hangs\nSymptoms: Request never completes Cause: Behavior doesn't call next() Solution:\n`csharp\n// ‚ùå WRONG: Forgot to call next()\npublic async Task<TResponse> Handle(TRequest request, Func<Task<TResponse>> next, ) {\n  _logger LogInformation(\"Processing \");\n  // Missing: await next()\n  return default ;  // Never executes handler }\n// ‚úÖ CORRECT: Always call next()\npublic async Task<TResponse> Handle(TRequest request, Func<Task<TResponse>> next, ) {\n  _logger LogInformation(\"Processing \");\n  return await next();  // ‚≠ê Essential\n}\n`\nProblem: Wrong Execution Order\nSymptoms: Behaviors run in unexpected order Cause: Registration order determines execution order Solution:\n`csharp\n// Execution order = registration order\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(FirstBehavior<,>));   // Runs 1st\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(SecondBehavior<,>));  // Runs 2nd\nbuilder Services AddTransient(typeof(IPipelineBehavior<,>), typeof(ThirdBehavior<,>));   // Runs 3rd\n`\n---\nFurther Reading\nExtensibility:\nCustom Receptors - Advanced receptor patterns\nCustom Policies - Dynamic routing logic\nCore Concepts:\nReceptors - Message handlers\nDispatcher - Message routing\nInfrastructure:\nPolicies - Policy-based routing\nExternal Resources:\nMediatR Pipeline Behaviors\nASP NET Core Middleware\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15246,
        "preview": "lean) ‚ùå Use behaviors for message routing (use policies instead) --- Troubleshooting Problem: Behavior Not Executing Symptoms: Behavior code never run..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/extensibility/plugin-architecture",
    "title": "Plugin Architecture",
    "category": "Extensibility",
    "url": "/docs/v0.1.0/extensibility/plugin-architecture",
    "chunks": [
      {
        "id": "v0.1.0/extensibility/plugin-architecture-chunk-0",
        "text": "Plugin Architecture\nPlugin architectures enable dynamic extensibility through loadable assemblies, hot-reload capabilities, and well-defined extension points :::note\nThis is an advanced topic for building extensible systems on top of Whizbang Most applications don't need plugin capabilities :::\n---\nWhy Plugin Architecture | Scenario | Static Assembly | Plugin System |\n|----------|----------------|---------------|\n| Fixed Features | ‚úÖ Simple | No need |\n| Dynamic Extensions | ‚ùå Recompile required | ‚úÖ Load at runtime |\n| Hot-Reload | ‚ùå Restart required | ‚úÖ Update without restart |\n| 3rd-Party Extensions | ‚ùå Code access needed | ‚úÖ Interface-based |\nWhen to use plugins:\n‚úÖ Extensible platforms (like VS Code)\n‚úÖ Multi-tenant customizations\n‚úÖ Hot-reloadable features\n‚úÖ 3rd-party integrations\n---\nPlugin Interface Pattern\nPattern 1: IPlugin Contract\n`csharp\npublic interface IWhizbangPlugin {\n  string Name { get; }\n  Version Version { get; }\n  void Initialize(IServiceCollection services);\n  void Configure(IApplicationBuilder app);\n}\n`\nPattern 2: Plugin Loader\n`csharp\nusing System Reflection;\nusing System Runtime Loader;\npublic class PluginLoader {\n  public IEnumerable<IWhizbangPlugin> LoadPlugins(string pluginDirectory) {\n    var plugins = new List<IWhizbangPlugin>();\n    foreach (var dllPath in Directory GetFiles(pluginDirectory, \"* dll\")) {\n      var context = new AssemblyLoadContext(Path GetFileName(dllPath), isCollectible: true);\n      var assembly = context LoadFromAssemblyPath(dllPath);\n      foreach (var type in assembly GetTypes()) {\n        if (typeof(IWhizbangPlugin) IsAssignableFrom(type) && type IsInterface) {\n          var plugin = (IWhizbangPlugin)Activator CreateInstance(type) ;\n          plugins Add(plugin);\n        }\n      }\n    }\n    return plugins;\n  }\n}\n`\n---\nExtension Points\nPattern 3: Receptor Plugin\n`csharp\n// Plugin assembly\npublic class CustomReceptorPlugin : IWhizbangPlugin {\n  public string Name => \"CustomReceptors\";\n  public Version Version => new(1, 0, 0);\n  public void Initialize(IServiceCollection services) {\n    services AddTransient<IReceptor<CustomCommand, CustomEvent>, CustomReceptor>();\n  }\n  public void Configure(IApplicationBuilder app) {\n    // No app configuration needed\n  }\n}\n`\n---\nHot-Reload Support\nPattern 4: Reloadable Plugins\n`csharp\npublic class HotReloadPluginManager {\n  private readonly Dictionary<string, AssemblyLoadContext> _contexts = [];\n  private FileSystemWatcher",
        "startIndex": 0,
        "preview": "Plugin Architecture\nPlugin architectures enable dynamic extensibility through loadable assemblies, hot-reload capabilities, and well-defined extension..."
      },
      {
        "id": "v0.1.0/extensibility/plugin-architecture-chunk-1",
        "text": "Version Version => new(1, 0, 0); public void Initialize(IServiceCollection services) { services AddTransient<IReceptor<CustomCommand, CustomEvent>, CustomReceptor>(); } public void Configure(IApplicationBuilder app) { // No app configuration needed } } ` --- Hot-Reload Support Pattern 4: Reloadable Plugins `csharp public class HotReloadPluginManager { private readonly Dictionary<string, AssemblyLoadContext> _contexts = []; private FileSystemWatcher _watcher;\n  public void EnableHotReload(string pluginDirectory) {\n    _watcher = new FileSystemWatcher(pluginDirectory, \"* dll\");\n    _watcher Changed += (s, e) => ReloadPlugin(e FullPath);\n    _watcher EnableRaisingEvents = true;\n  }\n  private void ReloadPlugin(string path) {\n    var name = Path GetFileName(path);\n    // Unload existing\n    if (_contexts TryGetValue(name, out var oldContext)) {\n      oldContext Unload();\n      _contexts Remove(name);\n    }\n    // Load new version\n    var newContext = new AssemblyLoadContext(name, isCollectible: true);\n    newContext LoadFromAssemblyPath(path);\n    _contexts[name] = newContext;\n  }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Define clear interfaces for plugins\n‚úÖ Use AssemblyLoadContext for isolation\n‚úÖ Version plugin APIs carefully\n‚úÖ Validate plugins before loading\n‚úÖ Handle load failures gracefully\nDON'T ‚ùå\n‚ùå Share state between plugins (isolation)\n‚ùå Allow reflection-heavy plugins (breaks AOT)\n‚ùå Skip versioning (compatibility issues)\n‚ùå Load untrusted plugins (security risk)\n---\nFurther Reading\nExtensibility:\nCustom Receptors - Receptor extension patterns\nCustom Transports - Transport plugins\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 2454,
        "preview": "Version Version => new(1, 0, 0); public void Initialize(IServiceCollection services) { services AddTransient<IReceptor<CustomCommand, CustomEvent>, Cu..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/getting-started/installation",
    "title": "Installation Guide",
    "category": "Getting Started",
    "url": "/docs/v0.1.0/getting-started/installation",
    "chunks": [
      {
        "id": "v0.1.0/getting-started/installation-chunk-0",
        "text": "Installation Guide\nThis guide walks you through installing Whizbang and setting up your first project Prerequisites\nBefore installing Whizbang, ensure you have:\nRequired NET 10 0 SDK (RC2 or later)\n  `bash\n  dotnet --version\n  Should show 10 0 0 or later\n  `\nC13 language support (included with NET 10 SDK)\nRecommended\nVisual Studio 2024 (17 12+) or Visual Studio Code with CDev Kit\nDocker Desktop (for PostgreSQL and Azure Service Bus Emulator) NET Aspire Workload (for orchestration):\n  `bash\n  dotnet workload install aspire\n  `\nInstallation Options\nOption 1: NuGet Packages (Recommended)\nInstall Whizbang packages for your specific needs:\nCore Package\n`bash\ndotnet add package Whizbang Core\n`\nIncludes:\nCore interfaces (IDispatcher, IReceptor, IPerspectiveOf)\nMessage envelope and observability\nObject pooling for performance\nPolicy engine foundation\nData Access Packages\nDapper + PostgreSQL (lightweight, fast):\n`bash\ndotnet add package Whizbang Data Dapper Postgres\n`\nEF Core + PostgreSQL (full-featured):\n`bash\ndotnet add package Whizbang Data EFCore Postgres\ndotnet add package Whizbang Data EFCore Postgres Generators\n`\nSQLite (development/testing):\n`bash\ndotnet add package Whizbang Data Dapper Sqlite\n`\nTransport Packages\nAzure Service Bus:\n`bash\ndotnet add package Whizbang Transports AzureServiceBus\ndotnet add package Whizbang Hosting Azure ServiceBus\n`\nSource Generators\nAutomatic Discovery:\n`bash\ndotnet add package Whizbang Generators\n`\nIncludes:\nReceptor discovery and registration\nPerspective discovery\nMessage registry generation (VSCode extension)\nAggregate ID generation\nAOT-compatible JSON contexts\nOption 2: Package Bundle\nFor complete functionality, add all packages:\n`xml\n< -- YourProject csproj -->\n<ItemGroup>\n  <PackageReference Include=\"Whizbang Core\" Version=\"0 1 0\" />\n  <PackageReference Include=\"Whizbang Generators\" Version=\"0 1 0\" />\n  <PackageReference Include=\"Whizbang Data Dapper Postgres\" Version=\"0 1 0\" />\n  <PackageReference Include=\"Whizbang Transports AzureServiceBus\" Version=\"0 1 0\" />\n  <PackageReference Include=\"Whizbang Hosting Azure ServiceBus\" Version=\"0 1 0\" />\n</ItemGroup>\n`\nOption 3: Central Package Management (Recommended for Solutions)\nUse Directory Packages props for version management:\n`xml\n< -- Directory Packages",
        "startIndex": 0,
        "preview": "Installation Guide\nThis guide walks you through installing Whizbang and setting up your first project Prerequisites\nBefore installing Whizbang, ensure..."
      },
      {
        "id": "v0.1.0/getting-started/installation-chunk-1",
        "text": "0\" /> <PackageReference Include=\"Whizbang Data Dapper Postgres\" Version=\"0 1 0\" /> <PackageReference Include=\"Whizbang Transports AzureServiceBus\" Version=\"0 1 0\" /> <PackageReference Include=\"Whizbang Hosting Azure ServiceBus\" Version=\"0 1 0\" /> </ItemGroup> ` Option 3: Central Package Management (Recommended for Solutions) Use Directory Packages props for version management: `xml < -- Directory Packages props -->\n<Project>\n  <PropertyGroup>\n    <ManagePackageVersionsCentrally>true</ManagePackageVersionsCentrally>\n  </PropertyGroup>\n  <ItemGroup>\n    < -- Whizbang Packages -->\n    <PackageVersion Include=\"Whizbang Core\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Generators\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Data Dapper Postgres\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Data EFCore Postgres\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Data EFCore Postgres Generators\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Transports AzureServiceBus\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Hosting Azure ServiceBus\" Version=\"0 1 0\" />\n  </ItemGroup>\n</Project>\n`\nThen in project files:\n`xml\n< -- YourProject csproj -->\n<ItemGroup>\n  <PackageReference Include=\"Whizbang Core\" />\n  <PackageReference Include=\"Whizbang Generators\" />\n  < -- Versions come from Directory Packages props -->\n</ItemGroup>\n`\nProject Setup\nCreate New Project\n`bash\nCreate solution\ndotnet new sln -n MyWhizbangApp\nCreate ASP NET Core Web API project\ndotnet new webapi -n MyWhizbangApp API\ndotnet sln add MyWhizbangApp API\nAdd Whizbang packages\ncd MyWhizbangApp API\ndotnet add package Whizbang Core\ndotnet add package Whizbang Generators\ndotnet add package Whizbang Data Dapper Postgres\n`\nConfigure Target Framework\nEnsure your project targets NET 10:\n`xml\n< -- MyWhizbangApp API csproj -->\n<Project Sdk=\"Microsoft NET Sdk Web\">\n  <PropertyGroup>\n    <TargetFramework>net10 0</TargetFramework>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <LangVersion>13</LangVersion> < -- C13 for latest features -->\n  </PropertyGroup>\n</Project>\n`\nAdd Directory Build props (Optional but Recommended)\nCreate solution-level build configuration:\n`xml\n< -- Directory Build props -->\n<Project>\n  <PropertyGroup>\n    <TargetFramework>net10 0</TargetFramework>\n    <LangVersion>13</LangVersion>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>\n  </PropertyGroup>\n  <PropertyGroup>\n    < -- Source Generator Settings -->\n    <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n    <CompilerGeneratedFilesOutputPath>$(MSBuildProjectDirectory)/ whizbang-generated</CompilerGeneratedFilesOutputPath>\n  </PropertyGroup>\n</Project>\n`\nConfigure editorconfig (K&R/Egyptian Braces)\nWhizbang follows K&R/Egyptian braces style:\n`ini",
        "startIndex": 2283,
        "preview": "0\" /> <PackageReference Include=\"Whizbang Data Dapper Postgres\" Version=\"0 1 0\" /> <PackageReference Include=\"Whizbang Transports AzureServiceBus\" Ver..."
      },
      {
        "id": "v0.1.0/getting-started/installation-chunk-2",
        "text": "Add Directory Build props (Optional but Recommended) Create solution-level build configuration: `xml < -- Directory Build props --> <Project> <PropertyGroup> <TargetFramework>net10 0</TargetFramework> <LangVersion>13</LangVersion> <Nullable>enable</Nullable> <ImplicitUsings>enable</ImplicitUsings> <TreatWarningsAsErrors>true</TreatWarningsAsErrors> </PropertyGroup> <PropertyGroup> < -- Source Generator Settings --> <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles> <CompilerGeneratedFilesOutputPath>$(MSBuildProjectDirectory)/ whizbang-generated</CompilerGeneratedFilesOutputPath> </PropertyGroup> </Project> ` Configure editorconfig (K&R/Egyptian Braces) Whizbang follows K&R/Egyptian braces style: `ini editorconfig\nroot = true\n[* cs]\nBrace style - K&R/Egyptian (opening brace on same line)\ncsharp_new_line_before_open_brace = none\ncsharp_new_line_before_else = false\ncsharp_new_line_before_catch = false\ncsharp_new_line_before_finally = false\nIndentation\nindent_style = space\nindent_size = 4\nNaming conventions\ndotnet_naming_rule async_methods_end_in_async severity = warning\ndotnet_naming_rule async_methods_end_in_async symbols = async_methods\ndotnet_naming_rule async_methods_end_in_async style = end_in_async\ndotnet_naming_symbols async_methods applicable_kinds = method\ndotnet_naming_symbols async_methods required_modifiers = async\ndotnet_naming_style end_in_async required_suffix = Async\ndotnet_naming_style end_in_async capitalization = pascal_case\n`\nDatabase Setup\nPostgreSQL (Recommended for Production)\nOption A: Docker (Easiest)\n`bash\ndocker run -d \\\n  --name whizbang-postgres \\\n  -e POSTGRES_PASSWORD=your_password \\\n  -e POSTGRES_USER=whizbang \\\n  -e POSTGRES_DB=whizbang \\\n  -p 5432:5432 \\\n  postgres:16\n`\nOption B: NET Aspire (Automatic)\nWith Aspire, PostgreSQL starts automatically:\n`csharp\n// AppHost/Program cs\nvar builder = DistributedApplication CreateBuilder(args);\nvar postgres = builder AddPostgres(\"postgres\") WithPgAdmin() AddDatabase(\"whizbangdb\");\nvar api = builder AddProject<Projects MyWhizbangApp_API>(\"api\") WithReference(postgres);\nbuilder Build() Run();\n`\nConnection String Configuration\nappsettings Development json:\n`json\n{\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"Host=localhost;Database=whizbang;Username=whizbang;Password=your_password\"\n  }\n}\n`\nIDE Configuration\nVisual Studio 2024\nInstall NET 10 SDK (included with VS 2024 17 12+)\nEnable Source Generators:\nTools ‚Üí Options ‚Üí Text Editor ‚Üí C‚Üí Advanced\nCheck \"Enable source generators\"\nView Generated Files:\nSolution Explorer ‚Üí Show All Files\nExpand whizbang-generated/ folder\nVisual Studio Code\nInstall Extensions:\n   `bash\n   code --install-extension ms-dotnettools csdevkit\n   code --install-extension ms-dotnettools csharp\n   `\nConfigure settings json:\n   `json\n   {\n     \"dotnet testWindow useTestingPlatformProtocol\": true,\n     \"omnisharp enableRoslynAnalyzers\": true,\n     \"omnisharp",
        "startIndex": 4778,
        "preview": "Add Directory Build props (Optional but Recommended) Create solution-level build configuration: `xml < -- Directory Build props --> <Project> <Propert..."
      },
      {
        "id": "v0.1.0/getting-started/installation-chunk-3",
        "text": "‚Üí Text Editor ‚Üí C‚Üí Advanced Check \"Enable source generators\" View Generated Files: Solution Explorer ‚Üí Show All Files Expand whizbang-generated/ folder Visual Studio Code Install Extensions: `bash code --install-extension ms-dotnettools csdevkit code --install-extension ms-dotnettools csharp ` Configure settings json: `json { \"dotnet testWindow useTestingPlatformProtocol\": true, \"omnisharp enableRoslynAnalyzers\": true, \"omnisharp enableEditorConfigSupport\": true\n   }\n   `\nInstall Whizbang VSCode Extension (Optional):\nProvides CodeLens annotations\nMessage flow visualization\nJump-to-definition for handlers\nJetBrains Rider\nEnable Source Generators:\nSettings ‚Üí Build, Execution, Deployment ‚Üí Toolset and Build\nCheck \"Enable source generators\"\nConfigure NuGet Sources:\nSettings ‚Üí NuGet ‚Üí Sources\nAdd nuget org if not present\nVerify Installation\nBuild Project\n`bash\ndotnet build\n`\nExpected output:\n`\nBuild succeeded 0 Warning(s)\n    0 Error(s)\n`\nCheck Source Generators\n`bash\nls whizbang-generated/\n`\nExpected files (after adding receptors):\n`\nWhizbang Generators/\n‚îú‚îÄ‚îÄ ReceptorDiscoveryGenerator/\n‚îÇ   ‚îî‚îÄ‚îÄ ReceptorRegistrations g cs\n‚îú‚îÄ‚îÄ PerspectiveDiscoveryGenerator/\n‚îÇ   ‚îî‚îÄ‚îÄ PerspectiveRegistrations g cs\n‚îî‚îÄ‚îÄ MessageRegistryGenerator/\n    ‚îî‚îÄ‚îÄ MessageRegistry g cs\n`\nRun Tests (if added)\n`bash\ndotnet test\n`\nTroubleshooting\nIssue: Source Generators Not Running\nSymptoms: No files in whizbang-generated/\nSolutions:\nRebuild solution: dotnet clean && dotnet build\nCheck generator package is referenced:\n   `bash\n   dotnet list package | grep Whizbang Generators\n   `\nEnable verbose MSBuild output:\n   `bash\n   dotnet build -v:detailed | grep Whizbang\n   `\nIssue: \"Type 'IReceptor' Not Found\"\nSymptoms: Cannot resolve Whizbang types\nSolutions:\nVerify package installation:\n   `bash\n   dotnet restore\n   dotnet list package\n   `\nCheck target framework is net10 0\nAdd using directive:\n   `csharp\n   using Whizbang Core;\n   `\nIssue: PostgreSQL Connection Fails\nSymptoms: \"Connection refused\" or timeout errors\nSolutions:\nCheck PostgreSQL is running:\n   `bash\n   docker ps | grep postgres\n   `\nTest connection:\n   `bash\n   psql -h localhost -U whizbang -d whizbang\n   `\nVerify connection string in appsettings",
        "startIndex": 6985,
        "preview": "‚Üí Text Editor ‚Üí C‚Üí Advanced Check \"Enable source generators\" View Generated Files: Solution Explorer ‚Üí Show All Files Expand whizbang-generated/ folde..."
      },
      {
        "id": "v0.1.0/getting-started/installation-chunk-4",
        "text": "framework is net10 0 Add using directive: `csharp using Whizbang Core; ` Issue: PostgreSQL Connection Fails Symptoms: \"Connection refused\" or timeout errors Solutions: Check PostgreSQL is running: `bash docker ps | grep postgres ` Test connection: `bash psql -h localhost -U whizbang -d whizbang ` Verify connection string in appsettings json\nIssue: Native AOT Warnings\nSymptoms: Trimming warnings during publish\nSolutions:\nWhizbang is trimming-safe by design\nEnsure all JSON contexts are generated:\n   `csharp\n   [JsonSerializable(typeof(YourMessage))]\n   partial class YourJsonContext : JsonSerializerContext { }\n   `\nUse Whizbang Generators to auto-generate contexts\nNext Steps\n‚úÖ Installation Complete What's Next Quick Start Tutorial - Build your first Whizbang app\nProject Structure Guide - Organize your application\nCore Concepts: Receptors - Understand message handling\nAdditional Resources\nSample Projects: /samples/ECommerce in the Whizbang repository\nPackage Documentation: https://nuget org/packages/Whizbang Core\nGitHub Issues: https://github com/whizbang/whizbang/issues\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 8761,
        "preview": "framework is net10 0 Add using directive: `csharp using Whizbang Core; ` Issue: PostgreSQL Connection Fails Symptoms: \"Connection refused\" or timeout ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/getting-started/introduction",
    "title": "Introduction to Whizbang",
    "category": "Getting Started",
    "url": "/docs/v0.1.0/getting-started/introduction",
    "chunks": [
      {
        "id": "v0.1.0/getting-started/introduction-chunk-0",
        "text": "Introduction to Whizbang\nWhizbang is a comprehensive NET library for building event-driven, CQRS, and event-sourced applications with zero reflection and native AOT compatibility from day one What is Whizbang Whizbang provides a complete foundation for building modern, scalable applications using message-driven architecture patterns Unlike traditional frameworks that rely on runtime reflection, Whizbang uses source generators to discover and wire up your application components at compile time, resulting in:\nBlazing Performance: < 20ns in-process message dispatch with zero allocations\nAOT Ready: Full Native AOT support with no runtime surprises\nType Safety: Compile-time verification of message handlers and routing\nDeveloper Experience: Rich IDE support with code navigation and discovery\nPhilosophy\nZero Reflection\nEvery feature in Whizbang is built without runtime reflection:\n`csharp\n// Source generators discover this at compile time\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken cancellationToken = default) {\n        // Business logic here\n        return new OrderCreated(OrderId: Guid CreateVersion7(), / /);\n    }\n}\n// Generated dispatcher code - no reflection // Routes messages at compile time with optimal performance\n`\nBenefits:\nNative AOT deployment out of the box\nPredictable performance (no reflection overhead)\nCompile-time safety (broken handlers = compiler errors)\nFaster startup times\nType-Safe Messaging\nWhizbang enforces type safety at compile time:\n`csharp\n// Compiler knows CreateOrder ‚Üí OrderCreated\nvar result = await dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n// Type mismatch Compiler error // var wrong = await dispatcher",
        "startIndex": 0,
        "preview": "Introduction to Whizbang\nWhizbang is a comprehensive NET library for building event-driven, CQRS, and event-sourced applications with zero reflection ..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-1",
        "text": "box Predictable performance (no reflection overhead) Compile-time safety (broken handlers = compiler errors) Faster startup times Type-Safe Messaging Whizbang enforces type safety at compile time: `csharp // Compiler knows CreateOrder ‚Üí OrderCreated var result = await dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command); // Type mismatch Compiler error // var wrong = await dispatcher LocalInvokeAsync<CreateOrder, PaymentProcessed>(command); // ‚ùå\n`\nEvent-Driven Architecture\nBuilt around three core patterns:\nReceptors: Stateless message handlers that make decisions\nPerspectives: Event listeners that maintain read models\nLenses: Query interfaces for optimized data access\n`csharp\n// Receptor: Receives command, produces event\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> { }\n// Perspective: Listens to events, updates read model\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> { }\n// Lens: Query interface for read model\npublic class OrderLens : ILensQuery { }\n`\nCore Concepts (Quick Overview)\nDispatcher\nCentral message router with three dispatch patterns:\n`csharp\n// SendAsync: Command dispatch with delivery receipt (can work over wire)\nvar receipt = await dispatcher SendAsync(new CreateOrder(/ /));\n// LocalInvokeAsync: In-process RPC with typed result (< 20ns, zero allocation)\nvar result = await dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n// PublishAsync: Event broadcasting (fire-and-forget)\nawait dispatcher PublishAsync(@event);\n`\nReceptors\nStateless message handlers:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken cancellationToken = default) {\n        // Validate\n        if (message Items Count == 0) {\n            throw new InvalidOperationException(\"Order must have items\");\n        }\n        // Make decision, return event\n        return new OrderCreated(\n            OrderId: Guid CreateVersion7(),\n            CustomerId: message CustomerId,\n            Items: message Items,\n            Total: message Items Sum(i => i Quantity * i Price),\n            CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nPerspectives\nEvent-driven read model updates:\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task Update(OrderCreated @event, CancellationToken ct = default) {\n        // Update denormalized read model\n        await using var conn = _db CreateConnection();\n        await conn",
        "startIndex": 1828,
        "preview": "box Predictable performance (no reflection overhead) Compile-time safety (broken handlers = compiler errors) Faster startup times Type-Safe Messaging ..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-2",
        "text": "* i Price), CreatedAt: DateTimeOffset UtcNow ); } } ` Perspectives Event-driven read model updates: `csharp public class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> { private readonly IDbConnectionFactory _db; public async Task Update(OrderCreated @event, CancellationToken ct = default) { // Update denormalized read model await using var conn = _db CreateConnection(); await conn ExecuteAsync(\n            \"INSERT INTO order_summaries (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\",\n            new {\n                @event OrderId,\n                @event CustomerId,\n                @event Total,\n                Status = \"Created\",\n                @event CreatedAt\n            }\n        );\n    }\n}\n`\nLenses\nQuery-optimized read repositories:\n`csharp\npublic class OrderLens : ILensQuery {\n    private readonly IDbConnectionFactory _db;\n    public async Task<OrderSummary > GetOrderAsync(Guid orderId) {\n        await using var conn = _db CreateConnection();\n        return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { OrderId = orderId }\n        );\n    }\n}\n`\nTechnology Stack (v0 1 0)\nWhizbang is built on modern NET:\n| Technology | Version | Purpose |\n|------------|---------|---------|\n| NET | 10 0 | Target framework (RC2+) |\n| Source Generators | Roslyn 4 8+ | Compile-time discovery |\n| Vogen | 8 0+ | Strongly-typed IDs |\n| Dapper | Latest | Lightweight data access |\n| EF Core | 10 0 | Full-featured ORM option |\n| Azure Service Bus | Latest | Message transport |\n| PostgreSQL | 16+ | Primary database |\n| NET Aspire | Latest | Orchestration & observability |\nProject Structure (15 Library Projects)\n`\nwhizbang/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Core/                          Core interfaces, dispatcher, pooling\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Generators/                    Source generators (discovery)\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Generators Shared/             Shared generator utilities\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data Dapper Postgres/          Dapper + PostgreSQL\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data Dapper Sqlite/            Dapper + SQLite\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data Dapper Custom/            Dapper base classes\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data EFCore",
        "startIndex": 4054,
        "preview": "* i Price), CreatedAt: DateTimeOffset UtcNow ); } } ` Perspectives Event-driven read model updates: `csharp public class OrderSummaryPerspective : IPe..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-3",
        "text": "interfaces, dispatcher, pooling ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Generators/ Source generators (discovery) ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Generators Shared/ Shared generator utilities ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Data Dapper Postgres/ Dapper + PostgreSQL ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Data Dapper Sqlite/ Dapper + SQLite ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Data Dapper Custom/ Dapper base classes ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Data EFCore Postgres/          EF Core + PostgreSQL\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data EFCore Postgres Generators/ EF Core generators\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data EFCore Custom/            EF Core attributes\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data Postgres/                 PostgreSQL utilities\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Data Schema/                   Schema definition\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Transports AzureServiceBus/    Azure Service Bus transport\n‚îÇ   ‚îú‚îÄ‚îÄ Whizbang Hosting Azure ServiceBus/      Hosting extensions\n‚îÇ   ‚îî‚îÄ‚îÄ Whizbang Testing/                       Testing utilities\n‚îî‚îÄ‚îÄ samples/\n    ‚îî‚îÄ‚îÄ ECommerce/                               12-project production sample\n`\nKey Features (v0 1 0)\nMessaging Patterns\n‚úÖ Outbox Pattern: Reliable cross-service event publishing\n‚úÖ Inbox Pattern: Exactly-once message processing with deduplication\n‚úÖ Work Coordination: Atomic batch processing with lease-based distribution\n‚úÖ Message Envelopes: Hop-based observability for distributed tracing\nData Access\n‚úÖ Dapper Integration: Lightweight, high-performance SQL\n‚úÖ EF Core Integration: Full-featured ORM with code-first migrations\n‚úÖ Perspective Storage: Optimized read model management\n‚úÖ Event Store: Append-only event storage with PostgreSQL\nSource Generators\n‚úÖ Receptor Discovery: Automatic handler registration\n‚úÖ Perspective Discovery: Event listener wiring\n‚úÖ Message Registry: VSCode extension integration\n‚úÖ Aggregate IDs: Strongly-typed identity generation\n‚úÖ JSON Contexts: AOT-compatible serialization\nInfrastructure\n‚úÖ",
        "startIndex": 5934,
        "preview": "interfaces, dispatcher, pooling ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Generators/ Source generators (discovery) ‚îÇ ‚îú‚îÄ‚îÄ Whizbang Generators Shared/ Shared generator utilities ..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-4",
        "text": "code-first migrations ‚úÖ Perspective Storage: Optimized read model management ‚úÖ Event Store: Append-only event storage with PostgreSQL Source Generators ‚úÖ Receptor Discovery: Automatic handler registration ‚úÖ Perspective Discovery: Event listener wiring ‚úÖ Message Registry: VSCode extension integration ‚úÖ Aggregate IDs: Strongly-typed identity generation ‚úÖ JSON Contexts: AOT-compatible serialization Infrastructure ‚úÖ NET Aspire: Automatic orchestration and service discovery\n‚úÖ Health Checks: Database and message transport readiness\n‚úÖ Object Pooling: Zero-allocation performance patterns\n‚úÖ Policy Engine: Decision trails and cross-cutting concerns\nTransports\n‚úÖ Azure Service Bus: Production-ready message transport\n‚úÖ In-Memory: Fast testing and development\nReal-World Example: ECommerce Sample\nWhizbang includes a complete 12-project production sample demonstrating:\nBackend for Frontend (BFF) with SignalR real-time updates\nMicroservices (Order, Inventory, Payment, Shipping, Notification)\nAngular 20 UI with NgRx state management\nEvent-driven workflows with Outbox/Inbox patterns NET Aspire orchestration for local development\nIntegration testing with TUnit\nServices:\nECommerce BFF API - Backend for Frontend (perspectives + lenses + SignalR)\nECommerce OrderService API - REST + GraphQL order management\nECommerce InventoryWorker - Inventory reservation\nECommerce PaymentWorker - Payment processing\nECommerce ShippingWorker - Fulfillment coordination\nECommerce NotificationWorker - Cross-cutting notifications\nECommerce UI - Angular 20 application\nSee ECommerce Tutorial for complete walkthrough",
        "startIndex": 7389,
        "preview": "code-first migrations ‚úÖ Perspective Storage: Optimized read model management ‚úÖ Event Store: Append-only event storage with PostgreSQL Source Generator..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-5",
        "text": "- Backend for Frontend (perspectives + lenses + SignalR) ECommerce OrderService API - REST + GraphQL order management ECommerce InventoryWorker - Inventory reservation ECommerce PaymentWorker - Payment processing ECommerce ShippingWorker - Fulfillment coordination ECommerce NotificationWorker - Cross-cutting notifications ECommerce UI - Angular 20 application See ECommerce Tutorial for complete walkthrough When to Use Whizbang\nPerfect For\n‚úÖ Event-Driven Applications: Microservices, event sourcing, CQRS\n‚úÖ High-Performance Systems: Need < 20ns in-process dispatch\n‚úÖ Native AOT Deployment: Cloud-native, serverless, edge computing\n‚úÖ Type-Safe Messaging: Compile-time verification required\n‚úÖ Complex Workflows: Order processing, sagas, distributed transactions\n‚úÖ Real-Time Systems: SignalR integration for live updates\nConsider Alternatives If\n‚ùå Simple CRUD: Whizbang is overkill for basic data entry apps\n‚ùå No Messaging Needs: Traditional MVC/Razor Pages may be simpler\n‚ùå Learning Curve: Team unfamiliar with event-driven patterns\n‚ùå Rapid Prototyping: Source generators add compile-time overhead\nPerformance Characteristics\n| Operation | Target | Description |\n|-----------|--------|-------------|\n| LocalInvoke | < 20ns | In-process receptor invocation (zero allocation) |\n| SendAsync | < 100Œºs | Outbox write + receipt generation |\n| Perspective Update | < 50Œºs | Read model update via Dapper |\n| Lens Query | < 10Œºs | Dapper query execution |\n| Source Generation | < 500ms | Full rebuild with all generators |\nLearning Path\nBeginner\nInstallation - Set up your first project\nQuick Start - Hello World with Receptors + Dispatcher\nProject Structure - Organize your application\nCore Concepts: Receptors - Understand message handling\nCore Concepts: Dispatcher - Master message routing\nIntermediate\nPerspectives - Build read models\nLenses - Query optimization\nOutbox Pattern - Reliable messaging\nInbox Pattern - Exactly-once processing\nECommerce Sample - Production patterns\nAdvanced\nSource Generators - Understand code generation\nExtensibility - Custom implementations\nPerformance Tuning - Optimize for scale\nDeployment - Production deployment\nNext Steps\nReady to get started",
        "startIndex": 8572,
        "preview": "- Backend for Frontend (perspectives + lenses + SignalR) ECommerce OrderService API - REST + GraphQL order management ECommerce InventoryWorker - Inve..."
      },
      {
        "id": "v0.1.0/getting-started/introduction-chunk-6",
        "text": "- Build read models Lenses - Query optimization Outbox Pattern - Reliable messaging Inbox Pattern - Exactly-once processing ECommerce Sample - Production patterns Advanced Source Generators - Understand code generation Extensibility - Custom implementations Performance Tuning - Optimize for scale Deployment - Production deployment Next Steps Ready to get started ‚Üí Installation Guide - Install Whizbang and create your first project\n‚Üí Quick Start Tutorial - Build a working app in 10 minutes\n‚Üí ECommerce Sample - Explore a production-ready example\nCommunity & Support\nDocumentation: https://whizbang-lib github io\nSource Code: https://github com/whizbang/whizbang\nIssues: https://github com/whizbang/whizbang/issues\nSamples: https://github com/whizbang/whizbang/tree/main/samples\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 10340,
        "preview": "- Build read models Lenses - Query optimization Outbox Pattern - Reliable messaging Inbox Pattern - Exactly-once processing ECommerce Sample - Product..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/getting-started/project-structure",
    "title": "Project Structure Guide",
    "category": "Getting Started",
    "url": "/docs/v0.1.0/getting-started/project-structure",
    "chunks": [
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-0",
        "text": "Project Structure Guide\nThis guide shows recommended project structures for Whizbang applications, from simple single-project apps to complex multi-service architectures Quick Reference\n| Architecture | When to Use | Example |\n|--------------|-------------|---------|\n| Single Project | Simple apps, prototypes, learning | Todo app, simple API |\n| Clean Architecture | Medium apps, clear boundaries | E-commerce site, CRM |\n| Microservices | Distributed systems, team scaling | Multi-tenant SaaS, complex domains |\nCore Principles\nRegardless of project size, follow these principles:\nSeparate Messages from Logic - Commands/Events in dedicated projects\nStateless Receptors - No state in message handlers\nRead Model Isolation - Perspectives maintain their own data\nExplicit Dependencies - Clear project references, no circular dependencies\nConfiguration by Environment - appsettings {Environment} json pattern\n---\nSingle Project Structure\nBest for: Learning, prototypes, simple APIs (< 10 message types)\n`\nMyApp/\n‚îú‚îÄ‚îÄ MyApp API/                          Single ASP NET Core project\n‚îÇ   ‚îú‚îÄ‚îÄ Program cs                      DI configuration + app setup\n‚îÇ   ‚îú‚îÄ‚îÄ appsettings json\n‚îÇ   ‚îú‚îÄ‚îÄ appsettings Development json\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Messages/                       Commands and Events\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Commands/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrder cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrder cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Events/\n‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ OrderCreated cs\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ OrderCancelled cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Receptors/                      Message handlers\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrderReceptor cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Perspectives/                   Read model updaters\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrderSummaryPerspective cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Lenses/                         Query interfaces\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrderLens cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Endpoints/                      HTTP endpoints\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrdersController cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ Models/                         Read models / DTOs\n‚îÇ       ‚îî‚îÄ‚îÄ OrderSummary cs\n‚îÇ\n‚îî‚îÄ‚îÄ MyApp API Tests/                    Tests\n    ‚îú‚îÄ‚îÄ Receptors/\n    ‚îÇ   ‚îî‚îÄ‚îÄ CreateOrderReceptorTests cs\n    ‚îî‚îÄ‚îÄ Perspectives/\n        ‚îî‚îÄ‚îÄ OrderSummaryPerspectiveTests cs\n`\nProgram cs Setup\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Dapper",
        "startIndex": 0,
        "preview": "Project Structure Guide\nThis guide shows recommended project structures for Whizbang applications, from simple single-project apps to complex multi-se..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-1",
        "text": "Endpoints/ HTTP endpoints ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ OrdersController cs ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ Models/ Read models / DTOs ‚îÇ ‚îî‚îÄ‚îÄ OrderSummary cs ‚îÇ ‚îî‚îÄ‚îÄ MyApp API Tests/ Tests ‚îú‚îÄ‚îÄ Receptors/ ‚îÇ ‚îî‚îÄ‚îÄ CreateOrderReceptorTests cs ‚îî‚îÄ‚îÄ Perspectives/ ‚îî‚îÄ‚îÄ OrderSummaryPerspectiveTests cs ` Program cs Setup `csharp using Whizbang Core; using Whizbang Data Dapper Postgres;\nvar builder = WebApplication CreateBuilder(args);\n// Whizbang Core\nbuilder Services AddWhizbangCore();\n// Auto-discovery (with Whizbang Generators)\nbuilder Services AddDiscoveredReceptors();\nbuilder Services AddDiscoveredPerspectives();\n// Data access\nvar connectionString = builder Configuration GetConnectionString(\"DefaultConnection\") ;\nbuilder Services AddWhizbangDapper(connectionString);\n// Controllers\nbuilder Services AddControllers();\nbuilder Services AddEndpointsApiExplorer();\nbuilder Services AddSwaggerGen();\nvar app = builder Build();\nif (app Environment IsDevelopment()) {\n    app UseSwagger();\n    app UseSwaggerUI();\n}\napp UseHttpsRedirection();\napp UseAuthorization();\napp MapControllers();\napp Run();\n`\nMessage Organization\nCommands (imperative - intent to change state):\n`csharp\n// Messages/Commands/CreateOrder cs\nnamespace MyApp API Messages Commands;\npublic record CreateOrder(\n    Guid CustomerId,\n    OrderLineItem[] Items\n);\npublic record OrderLineItem(\n    Guid ProductId,\n    int Quantity,\n    decimal UnitPrice\n);\n`\nEvents (past tense - fact of what happened):\n`csharp\n// Messages/Events/OrderCreated cs\nnamespace MyApp API Messages Events;\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    OrderLineItem[] Items,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\n`\nPros and Cons\nPros:\n‚úÖ Simple to understand and navigate\n‚úÖ Fast to set up and iterate\n‚úÖ Single deployment unit\n‚úÖ Easy debugging (single process)\nCons:\n‚ùå Limited scalability (single service)\n‚ùå Can become cluttered as app grows\n‚ùå All logic in one deployable\n‚ùå Hard to scale specific components independently\n---\nClean Architecture Structure\nBest for: Medium-sized applications with clear domain boundaries\n`\nMyApp/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ MyApp Messages/                 Shared message contracts\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Commands/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrder cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrder cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Events/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderCreated cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrderCancelled",
        "startIndex": 2208,
        "preview": "Endpoints/ HTTP endpoints ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ OrdersController cs ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ Models/ Read models / DTOs ‚îÇ ‚îî‚îÄ‚îÄ OrderSummary cs ‚îÇ ‚îî‚îÄ‚îÄ MyApp API Tests/ Tests ‚îú‚îÄ‚îÄ Rece..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-2",
        "text": "Best for: Medium-sized applications with clear domain boundaries ` MyApp/ ‚îú‚îÄ‚îÄ src/ ‚îÇ ‚îú‚îÄ‚îÄ MyApp Messages/ Shared message contracts ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Commands/ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ CreateOrder cs ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ CancelOrder cs ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Events/ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ OrderCreated cs ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ OrderCancelled cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MyApp Messages csproj\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ MyApp Domain/                   Business logic (receptors)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MyApp Domain csproj         References: Messages, Whizbang Core\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ MyApp ReadModels/               Perspectives and Lenses\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Perspectives/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderSummaryPerspective cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InventoryPerspective cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Lenses/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderLens cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InventoryLens cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Models/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderSummary cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InventoryLevel cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MyApp ReadModels csproj     References: Messages, Whizbang Core\n‚îÇ   ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ MyApp API/                      HTTP API\n‚îÇ       ‚îú‚îÄ‚îÄ Program cs\n‚îÇ       ‚îú‚îÄ‚îÄ Endpoints/\n‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ OrderEndpoints cs\n‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ InventoryEndpoints cs\n‚îÇ       ‚îî‚îÄ‚îÄ MyApp API csproj            References: Domain, ReadModels\n‚îÇ\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ MyApp Domain Tests/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ CreateOrderReceptorTests cs\n‚îÇ   ‚îú‚îÄ‚îÄ MyApp ReadModels Tests/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Perspectives/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ OrderSummaryPerspectiveTests cs\n‚îÇ   ‚îî‚îÄ‚îÄ MyApp Integration Tests/\n‚îÇ       ‚îî‚îÄ‚îÄ OrderWorkflowTests cs\n‚îÇ\n‚îî‚îÄ‚îÄ MyApp sln\n`\nProject Dependencies\n`\nMyApp API\n  ‚îú‚îÄ> MyApp Domain\n  ‚îú‚îÄ> MyApp ReadModels\n  ‚îî‚îÄ> Whizbang Core\nMyApp Domain\n  ‚îú‚îÄ> MyApp Messages\n  ‚îî‚îÄ> Whizbang Core\nMyApp ReadModels\n  ‚îú‚îÄ> MyApp Messages\n  ‚îú‚îÄ> Whizbang Core\n  ‚îî‚îÄ> Whizbang Data Dapper Postgres\nMyApp Messages\n  ‚îî‚îÄ> (no dependencies - pure DTOs)\n`\nKey Point: Messages project has no dependencies - makes it easy to share across services",
        "startIndex": 4188,
        "preview": "Best for: Medium-sized applications with clear domain boundaries ` MyApp/ ‚îú‚îÄ‚îÄ src/ ‚îÇ ‚îú‚îÄ‚îÄ MyApp Messages/ Shared message contracts ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Commands/ ‚îÇ ..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-3",
        "text": "MyApp ReadModels ‚îî‚îÄ> Whizbang Core MyApp Domain ‚îú‚îÄ> MyApp Messages ‚îî‚îÄ> Whizbang Core MyApp ReadModels ‚îú‚îÄ> MyApp Messages ‚îú‚îÄ> Whizbang Core ‚îî‚îÄ> Whizbang Data Dapper Postgres MyApp Messages ‚îî‚îÄ> (no dependencies - pure DTOs) ` Key Point: Messages project has no dependencies - makes it easy to share across services Central Package Management\nUse Directory Packages props for version consistency:\n`xml\n< -- Directory Packages props (solution root) -->\n<Project>\n  <PropertyGroup>\n    <ManagePackageVersionsCentrally>true</ManagePackageVersionsCentrally>\n  </PropertyGroup>\n  <ItemGroup>\n    <PackageVersion Include=\"Whizbang Core\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Generators\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Data Dapper Postgres\" Version=\"0 1 0\" />\n    <PackageVersion Include=\"Whizbang Transports AzureServiceBus\" Version=\"0 1 0\" />\n  </ItemGroup>\n</Project>\n`\nThen in project files:\n`xml\n< -- MyApp API csproj -->\n<ItemGroup>\n  <PackageReference Include=\"Whizbang Core\" />  < -- Version comes from Directory Packages props -->\n  <PackageReference Include=\"Whizbang Generators\" />\n</ItemGroup>\n`\nShared Build Properties\nUse Directory Build props for consistent settings:\n`xml\n< -- Directory Build props (solution root) -->\n<Project>\n  <PropertyGroup>\n    <TargetFramework>net10 0</TargetFramework>\n    <LangVersion>13</LangVersion>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>\n  </PropertyGroup>\n  <PropertyGroup>\n    < -- Source Generator Settings -->\n    <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n    <CompilerGeneratedFilesOutputPath>$(MSBuildProjectDirectory)/ whizbang-generated</CompilerGeneratedFilesOutputPath>\n  </PropertyGroup>\n</Project>\n`\nPros and Cons\nPros:\n‚úÖ Clear separation of concerns\n‚úÖ Testable in isolation\n‚úÖ Reusable message contracts\n‚úÖ Easy to understand dependencies\n‚úÖ Can grow to microservices later\nCons:\n‚ùå More projects to manage\n‚ùå Still a single deployable\n‚ùå Some indirection (navigate across projects)\n---\nMicroservices Structure\nBest for: Distributed systems, team scaling, independent deployment needs\nThis is the structure used in the ECommerce sample (12 projects) `\nECommerce/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce Messages/             Shared contracts (commands + events)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Commands/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrder cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReserveInventory cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProcessPayment cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Events/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderCreated cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InventoryReserved",
        "startIndex": 5827,
        "preview": "MyApp ReadModels ‚îî‚îÄ> Whizbang Core MyApp Domain ‚îú‚îÄ> MyApp Messages ‚îî‚îÄ> Whizbang Core MyApp ReadModels ‚îú‚îÄ> MyApp Messages ‚îú‚îÄ> Whizbang Core ‚îî‚îÄ> Whizban..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-4",
        "text": "` ECommerce/ ‚îú‚îÄ‚îÄ src/ ‚îÇ ‚îú‚îÄ‚îÄ ECommerce Messages/ Shared contracts (commands + events) ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Commands/ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ CreateOrder cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ReserveInventory cs ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ProcessPayment cs ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Events/ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ OrderCreated cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ InventoryReserved cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PaymentProcessed cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ECommerce Messages csproj\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce BFF API/              Backend for Frontend (UI layer)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Perspectives/               Read models for UI\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderSummaryPerspective cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InventoryPerspective cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ShippingPerspective cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Lenses/                     Query interfaces\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderLens cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InventoryLens cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Hubs/                       SignalR real-time\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrderHub cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Endpoints/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ OrderEndpoints cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce OrderService API/     Order management service\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Endpoints/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ OrdersController cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce InventoryWorker/      Inventory reservation (background worker)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ReserveInventoryReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Workers/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ InventoryWorker cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce PaymentWorker/        Payment processing (background worker)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProcessPaymentReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Workers/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ PaymentWorker cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce ShippingWorker/       Fulfillment coordination (background worker)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ShipOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Workers/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ShippingWorker cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce",
        "startIndex": 8073,
        "preview": "` ECommerce/ ‚îú‚îÄ‚îÄ src/ ‚îÇ ‚îú‚îÄ‚îÄ ECommerce Messages/ Shared contracts (commands + events) ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Commands/ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ CreateOrder cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ReserveInven..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-5",
        "text": "ProcessPaymentReceptor cs ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ Workers/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PaymentWorker cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ECommerce ShippingWorker/ Fulfillment coordination (background worker) ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Program cs ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Receptors/ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ShipOrderReceptor cs ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ Workers/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ShippingWorker cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ECommerce NotificationWorker/   Cross-cutting notifications (background worker)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Perspectives/               Listens to ALL events\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NotificationPerspective cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Workers/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ NotificationWorker cs\n‚îÇ   ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ ECommerce UI/                   Angular 20 frontend\n‚îÇ       ‚îî‚îÄ‚îÄ (Angular project)\n‚îÇ\n‚îú‚îÄ‚îÄ ECommerce AppHost/ NET Aspire orchestration\n‚îÇ   ‚îî‚îÄ‚îÄ Program cs\n‚îÇ\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce OrderService Tests/\n‚îÇ   ‚îú‚îÄ‚îÄ ECommerce InventoryWorker Tests/\n‚îÇ   ‚îî‚îÄ‚îÄ ECommerce Integration Tests/\n‚îÇ\n‚îî‚îÄ‚îÄ ECommerce sln\n`\nService Responsibilities\n| Service | Type | Responsibilities |\n|---------|------|------------------|\n| BFF API | ASP NET Core API | UI aggregation, SignalR, read models, GraphQL |\n| OrderService API | ASP NET Core API | Order creation, REST + GraphQL |\n| InventoryWorker | Background Worker | Inventory reservation, stock management |\n| PaymentWorker | Background Worker | Payment processing, refunds |\n| ShippingWorker | Background Worker | Fulfillment coordination |\n| NotificationWorker | Background Worker | Email, SMS, push notifications |\nCommunication Pattern\n`\nUI ‚Üí BFF API\n   ‚îî‚îÄ> Send CreateOrder command (via HTTP POST)\nBFF API ‚Üí Dispatcher (local)\n   ‚îî‚îÄ> LocalInvokeAsync<CreateOrder, OrderCreated>()\nReceptor ‚Üí Outbox\n   ‚îî‚îÄ> Stores OrderCreated event in outbox\nWorkCoordinatorPublisher ‚Üí Azure Service Bus\n   ‚îî‚îÄ> Publishes OrderCreated to topic\nInventoryWorker subscribes to OrderCreated\n   ‚îî‚îÄ> Processes event, publishes InventoryReserved\nPaymentWorker subscribes to InventoryReserved\n   ‚îî‚îÄ> Processes event, publishes PaymentProcessed\nBFF Perspectives subscribe to all events\n   ‚îî‚îÄ> Update read models, trigger SignalR updates to UI\n` NET Aspire Orchestration\nECommerce AppHost/Program cs:\n`csharp\nvar builder = DistributedApplication",
        "startIndex": 9662,
        "preview": "ProcessPaymentReceptor cs ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ Workers/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PaymentWorker cs ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ECommerce ShippingWorker/ Fulfillment coordination (background worker) ‚îÇ..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-6",
        "text": "‚îî‚îÄ> Publishes OrderCreated to topic InventoryWorker subscribes to OrderCreated ‚îî‚îÄ> Processes event, publishes InventoryReserved PaymentWorker subscribes to InventoryReserved ‚îî‚îÄ> Processes event, publishes PaymentProcessed BFF Perspectives subscribe to all events ‚îî‚îÄ> Update read models, trigger SignalR updates to UI ` NET Aspire Orchestration ECommerce AppHost/Program cs: `csharp var builder = DistributedApplication CreateBuilder(args);\n// Infrastructure\nvar postgres = builder AddPostgres(\"postgres\") WithPgAdmin() AddDatabase(\"ecommerce\");\nvar serviceBus = builder AddAzureServiceBus(\"servicebus\") RunAsEmulator();\n// Services\nvar orderService = builder AddProject<Projects ECommerce_OrderService_API>(\"orderservice\") WithReference(postgres) WithReference(serviceBus);\nvar inventoryWorker = builder AddProject<Projects ECommerce_InventoryWorker>(\"inventoryworker\") WithReference(postgres) WithReference(serviceBus);\nvar paymentWorker = builder AddProject<Projects ECommerce_PaymentWorker>(\"paymentworker\") WithReference(postgres) WithReference(serviceBus);\nvar shippingWorker = builder AddProject<Projects ECommerce_ShippingWorker>(\"shippingworker\") WithReference(postgres) WithReference(serviceBus);\nvar notificationWorker = builder AddProject<Projects ECommerce_NotificationWorker>(\"notificationworker\") WithReference(postgres) WithReference(serviceBus);\nvar bff = builder AddProject<Projects ECommerce_BFF_API>(\"bff\") WithReference(postgres) WithReference(serviceBus) WithReference(orderService);\nvar ui = builder AddNpmApp(\"ui\", \" /ECommerce UI\") WithReference(bff) WithHttpEndpoint(env: \"PORT\") WithExternalHttpEndpoints();\nbuilder Build() Run();\n`\nBenefits:\nOne-command local development: dotnet run --project ECommerce AppHost\nAutomatic service discovery\nBuilt-in dashboard (http://localhost:15000)\nPostgreSQL and Service Bus emulators\nHealth checks and observability\nPros and Cons\nPros:\n‚úÖ Independent deployment per service\n‚úÖ Scalability (scale specific services)\n‚úÖ Team autonomy (own services)\n‚úÖ Technology diversity (different stacks per service if needed)\n‚úÖ Fault isolation\nCons:\n‚ùå Complexity (distributed system challenges)\n‚ùå Eventual consistency\n‚ùå Debugging across services\n‚ùå Infrastructure overhead\n---\nConfiguration Patterns\nappsettings json Structure\nDevelopment (appsettings Development json):\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Whizbang\": \"Debug\",\n      \"Microsoft AspNetCore\": \"Warning\"\n    }\n  },\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"Host=localhost;Database=myapp;Username=postgres;Password=dev_password\"\n  },\n  \"Whizbang\": {\n    \"Outbox\": {\n      \"PollingIntervalMilliseconds\": 1000,\n      \"LeaseSeconds\": 300\n    },\n    \"Inbox\": {\n      \"PollingIntervalMilliseconds\": 1000\n    }\n  },\n  \"AzureServiceBus\": {\n    \"ConnectionString\": \"Endpoint=sb://localhost; \"\n  }\n}\n`\nProduction (appsettings Production",
        "startIndex": 11503,
        "preview": "‚îî‚îÄ> Publishes OrderCreated to topic InventoryWorker subscribes to OrderCreated ‚îî‚îÄ> Processes event, publishes InventoryReserved PaymentWorker subscrib..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-7",
        "text": "Development (appsettings Development json): `json { \"Logging\": { \"LogLevel\": { \"Default\": \"Information\", \"Whizbang\": \"Debug\", \"Microsoft AspNetCore\": \"Warning\" } }, \"ConnectionStrings\": { \"DefaultConnection\": \"Host=localhost;Database=myapp;Username=postgres;Password=dev_password\" }, \"Whizbang\": { \"Outbox\": { \"PollingIntervalMilliseconds\": 1000, \"LeaseSeconds\": 300 }, \"Inbox\": { \"PollingIntervalMilliseconds\": 1000 } }, \"AzureServiceBus\": { \"ConnectionString\": \"Endpoint=sb://localhost; \" } } ` Production (appsettings Production json):\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Warning\",\n      \"Whizbang\": \"Information\"\n    }\n  },\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"${DATABASE_URL}\"  // Injected from environment\n  },\n  \"Whizbang\": {\n    \"Outbox\": {\n      \"PollingIntervalMilliseconds\": 5000,\n      \"LeaseSeconds\": 600\n    }\n  },\n  \"AzureServiceBus\": {\n    \"ConnectionString\": \"${SERVICE_BUS_CONNECTION_STRING}\"\n  }\n}\n`\nEnvironment Variables\nUse environment variables for secrets:\n`bash env (local development - NOT committed)\nDATABASE_URL=Host=localhost;Database=myapp;Username=postgres;Password=dev_password\nSERVICE_BUS_CONNECTION_STRING=Endpoint=sb://localhost; Kubernetes/Docker secrets\nkubectl create secret generic myapp-db --from-literal=connection-string=\"Host= \"\n`\n---\nDependency Injection Patterns\nService Registration Layers\nLayer 1: Whizbang Core:\n`csharp\nbuilder Services AddWhizbangCore();  // IDispatcher, MessageEnvelope, etc `\nLayer 2: Auto-Discovery (with Whizbang Generators):\n`csharp\nbuilder Services AddDiscoveredReceptors();      // All IReceptor implementations\nbuilder Services AddDiscoveredPerspectives();   // All IPerspectiveOf implementations\n`\nLayer 3: Data Access:\n`csharp\nbuilder Services AddWhizbangDapper(connectionString);        // Dapper + PostgreSQL\n// OR\nbuilder Services AddWhizbangEFCore(connectionString);        // EF Core + PostgreSQL\n`\nLayer 4: Transports:\n`csharp\nbuilder Services AddWhizbangAzureServiceBus(\n    builder Configuration GetSection(\"AzureServiceBus\")\n);\n`\nLayer 5: Application Services:\n`csharp\nbuilder Services AddTransient<IOrderLens, OrderLens>();\nbuilder Services AddSingleton<IEmailService, SendGridEmailService>();\n`\nLifetime Guidelines\n| Component | Lifetime | Reason |\n|-----------|----------|--------|\n| IDispatcher | Singleton | Shared router, no state |\n| IReceptor<,> | Transient | May inject scoped services (DbContext) |\n| IPerspectiveOf<> | Transient | May inject scoped services |\n| ILensQuery | Transient | Lightweight, may inject scoped services |\n| DbContext | Scoped | Per-request database context |\n| IDbConnectionFactory | Singleton | Connection factory (Dapper) |\n---\nTesting Structure\nUnit Tests\nTest receptors in isolation:\n`csharp\n// tests/MyApp Domain Tests/Receptors/CreateOrderReceptorTests",
        "startIndex": 14070,
        "preview": "Development (appsettings Development json): `json { \"Logging\": { \"LogLevel\": { \"Default\": \"Information\", \"Whizbang\": \"Debug\", \"Microsoft AspNetCore\": ..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-8",
        "text": "Transient | May inject scoped services | | ILensQuery | Transient | Lightweight, may inject scoped services | | DbContext | Scoped | Per-request database context | | IDbConnectionFactory | Singleton | Connection factory (Dapper) | --- Testing Structure Unit Tests Test receptors in isolation: `csharp // tests/MyApp Domain Tests/Receptors/CreateOrderReceptorTests cs\npublic class CreateOrderReceptorTests {\n    [Test]\n    public async Task HandleAsync_ValidOrder_ReturnsOrderCreatedAsync() {\n        // Arrange\n        var receptor = new CreateOrderReceptor(/ mock dependencies /);\n        var command = new CreateOrder(/ /);\n        // Act\n        var result = await receptor HandleAsync(command);\n        // Assert\n        await Assert That(result OrderId) IsNotEqualTo(Guid Empty);\n    }\n}\n`\nIntegration Tests\nTest full message flow:\n`csharp\n// tests/MyApp Integration Tests/OrderWorkflowTests cs\npublic class OrderWorkflowTests {\n    private WebApplicationFactory<Program> _factory;\n    private IDispatcher _dispatcher;\n    [Before(Test)]\n    public async Task SetupAsync() {\n        _factory = new WebApplicationFactory<Program>();\n        _dispatcher = _factory Services GetRequiredService<IDispatcher>();\n    }\n    [Test]\n    public async Task CreateOrder_FullWorkflow_UpdatesReadModelAsync() {\n        // Arrange\n        var command = new CreateOrder(/ /);\n        // Act - dispatch command\n        var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command);\n        // Publish event to perspectives\n        await _dispatcher PublishAsync(result);\n        // Assert - query read model\n        var lens = _factory Services GetRequiredService<IOrderLens>();\n        var order = await lens GetOrderAsync(result OrderId);\n        await Assert That(order) IsNotNull();\n        await Assert That(order Status) IsEqualTo(\"Created\");\n    }\n}\n`\n---\nMigration Paths\nSingle ‚Üí Clean Architecture\nCreate MyApp Messages project\nMove commands/events to Messages project\nCreate MyApp Domain project\nMove receptors to Domain project\nCreate MyApp ReadModels project\nMove perspectives/lenses to ReadModels project\nUpdate API project to reference Domain + ReadModels\nTimeline: 1-2 hours for small app\nClean Architecture ‚Üí Microservices\nIdentify service boundaries (order, inventory, payment, etc )\nCreate service projects (API or Worker)\nAdd transport (Azure Service Bus)\nImplement Outbox/Inbox patterns\nSplit receptors across services\nCreate BFF for UI aggregation\nAdd",
        "startIndex": 16360,
        "preview": "Transient | May inject scoped services | | ILensQuery | Transient | Lightweight, may inject scoped services | | DbContext | Scoped | Per-request datab..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-9",
        "text": "Update API project to reference Domain + ReadModels Timeline: 1-2 hours for small app Clean Architecture ‚Üí Microservices Identify service boundaries (order, inventory, payment, etc ) Create service projects (API or Worker) Add transport (Azure Service Bus) Implement Outbox/Inbox patterns Split receptors across services Create BFF for UI aggregation Add NET Aspire AppHost for orchestration\nTimeline: 1-2 weeks for initial split, iterative refinement\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use central package management (Directory Packages props)\n‚úÖ Use shared build properties (Directory Build props)\n‚úÖ Keep messages in separate project (no dependencies)\n‚úÖ Use auto-discovery for receptors/perspectives (Whizbang Generators)\n‚úÖ Follow namespace conventions (Messages Commands, Messages Events)\n‚úÖ Use environment-specific appsettings\n‚úÖ Keep receptors stateless\n‚úÖ Test receptors in isolation\nDON'T ‚ùå\n‚ùå Put business logic in controllers/endpoints\n‚ùå Create circular dependencies between projects\n‚ùå Reference domain projects from Messages project\n‚ùå Hard-code connection strings\n‚ùå Share database contexts across services\n‚ùå Use static state in receptors\n‚ùå Mix read and write logic in same class\n---\nExample: Adding a New Feature\nScenario: Add \"Cancel Order\" feature to Clean Architecture app\nStep 1: Define Message\n`csharp\n// MyApp Messages/Commands/CancelOrder cs\npublic record CancelOrder(\n    Guid OrderId,\n    string Reason\n);\n// MyApp Messages/Events/OrderCancelled cs\npublic record OrderCancelled(\n    Guid OrderId,\n    string Reason,\n    DateTimeOffset CancelledAt\n);\n`\nStep 2: Create Receptor\n`csharp\n// MyApp Domain/Receptors/CancelOrderReceptor cs\nusing Whizbang Core;\nusing MyApp Messages Commands;\nusing MyApp Messages Events;\npublic class CancelOrderReceptor : IReceptor<CancelOrder, OrderCancelled> {\n    private readonly IDbConnectionFactory _db;\n    public CancelOrderReceptor(IDbConnectionFactory db) {\n        _db = db;\n    }\n    public async ValueTask<OrderCancelled> HandleAsync(\n        CancelOrder message,\n        CancellationToken ct = default) {\n        // Validation\n        await using var conn = _db CreateConnection();\n        var order = await conn QuerySingleOrDefaultAsync<Order>(\n            \"SELECT * FROM orders WHERE order_id = @OrderId\",\n            new { message",
        "startIndex": 18489,
        "preview": "Update API project to reference Domain + ReadModels Timeline: 1-2 hours for small app Clean Architecture ‚Üí Microservices Identify service boundaries (..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-10",
        "text": "{ private readonly IDbConnectionFactory _db; public CancelOrderReceptor(IDbConnectionFactory db) { _db = db; } public async ValueTask<OrderCancelled> HandleAsync( CancelOrder message, CancellationToken ct = default) { // Validation await using var conn = _db CreateConnection(); var order = await conn QuerySingleOrDefaultAsync<Order>( \"SELECT * FROM orders WHERE order_id = @OrderId\", new { message OrderId }\n        );\n        if (order is null) {\n            throw new InvalidOperationException($\"Order {message OrderId} not found\");\n        }\n        if (order Status == \"Shipped\") {\n            throw new InvalidOperationException(\"Cannot cancel shipped order\");\n        }\n        // Return event\n        return new OrderCancelled(\n            OrderId: message OrderId,\n            Reason: message Reason,\n            CancelledAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nStep 3: Update Perspective\n`csharp\n// MyApp ReadModels/Perspectives/OrderSummaryPerspective cs\npublic class OrderSummaryPerspective :\n    IPerspectiveOf<OrderCreated>,\n    IPerspectiveOf<OrderCancelled> {  // Add new event\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        // Existing logic\n    }\n    public async Task UpdateAsync(OrderCancelled @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"UPDATE order_summaries SET status = 'Cancelled', cancelled_at = @CancelledAt WHERE order_id = @OrderId\",\n            new { @event OrderId, @event CancelledAt }\n        );\n    }\n}\n`\nStep 4: Add Endpoint\n`csharp\n// MyApp API/Endpoints/OrdersController cs\n[HttpPost(\"{orderId:guid}/cancel\")]\npublic async Task<ActionResult> CancelOrder(\n    Guid orderId,\n    [FromBody] CancelOrderRequest request,\n    CancellationToken ct) {\n    var command = new CancelOrder(orderId, request Reason);\n    var result = await _dispatcher LocalInvokeAsync<CancelOrder, OrderCancelled>(command, ct);\n    await _dispatcher PublishAsync(result, ct);\n    return Ok(result);\n}\n`\nStep 5: Test\n`csharp\n// MyApp Domain Tests/Receptors/CancelOrderReceptorTests cs\n[Test]\npublic async Task HandleAsync_ValidOrder_ReturnsOrderCancelledAsync() {\n    // Arrange\n    var receptor = new CancelOrderReceptor(mockDb);\n    var command = new CancelOrder(Guid NewGuid(), \"Customer request\");\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    await Assert That(result Reason) IsEqualTo(\"Customer request\");\n}\n`\nDone Auto-discovery registers the receptor automatically on next build",
        "startIndex": 20416,
        "preview": "{ private readonly IDbConnectionFactory _db; public CancelOrderReceptor(IDbConnectionFactory db) { _db = db; } public async ValueTask<OrderCancelled> ..."
      },
      {
        "id": "v0.1.0/getting-started/project-structure-chunk-11",
        "text": "Tests/Receptors/CancelOrderReceptorTests cs [Test] public async Task HandleAsync_ValidOrder_ReturnsOrderCancelledAsync() { // Arrange var receptor = new CancelOrderReceptor(mockDb); var command = new CancelOrder(Guid NewGuid(), \"Customer request\"); // Act var result = await receptor HandleAsync(command); // Assert await Assert That(result Reason) IsEqualTo(\"Customer request\"); } ` Done Auto-discovery registers the receptor automatically on next build ---\nFurther Reading\nArchitecture Patterns:\nCore Concepts: Dispatcher\nCore Concepts: Receptors\nCore Concepts: Perspectives\nMessaging:\nOutbox Pattern\nInbox Pattern\nWork Coordination\nExamples:\nECommerce Sample Overview\nBFF Pattern\n---\nNext: Dive into Core Concepts: Dispatcher to master message routing patterns ---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 22606,
        "preview": "Tests/Receptors/CancelOrderReceptorTests cs [Test] public async Task HandleAsync_ValidOrder_ReturnsOrderCancelledAsync() { // Arrange var receptor = n..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/getting-started/quick-start",
    "title": "Quick Start Tutorial",
    "category": "Getting Started",
    "url": "/docs/v0.1.0/getting-started/quick-start",
    "chunks": [
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-0",
        "text": "Quick Start Tutorial\nBuild your first Whizbang application in 10 minutes This tutorial walks you through creating a simple order management system using Whizbang's core patterns What You'll Build\nA minimal ASP NET Core API that:\nAccepts CreateOrder commands via HTTP endpoint\nProcesses orders using a Receptor (message handler)\nReturns OrderCreated events with validation\nUses Dispatcher for type-safe message routing\nPrerequisites: Complete the Installation Guide first Step 1: Create Project Structure\n`bash\nCreate solution and project\ndotnet new sln -n QuickStartApp\ndotnet new webapi -n QuickStartApp API\ndotnet sln add QuickStartApp API\ncd QuickStartApp API\nAdd Whizbang packages\ndotnet add package Whizbang Core\ndotnet add package Whizbang Generators\n`\nStep 2: Define Your Messages\nCreate a Messages folder and define your command and event:\nMessages/CreateOrder cs:\n`csharp\nnamespace QuickStartApp API Messages;\npublic record CreateOrder(\n    Guid CustomerId,\n    string ProductName,\n    int Quantity,\n    decimal UnitPrice\n);\n`\nMessages/OrderCreated cs:\n`csharp\nnamespace QuickStartApp API Messages;\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    string ProductName,\n    int Quantity,\n    decimal UnitPrice,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\n`\nKey Points:\nUse records for immutability and value semantics\nCommands are requests (CreateOrder)\nEvents are facts (OrderCreated - past tense)\nInclude all necessary data for downstream consumers\nStep 3: Create Your First Receptor\nReceptors are stateless message handlers that implement business logic Receptors/CreateOrderReceptor cs:\n`csharp\nusing Whizbang Core;\nusing QuickStartApp API Messages;\nnamespace QuickStartApp API Receptors;\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly ILogger<CreateOrderReceptor> _logger;\n    public CreateOrderReceptor(ILogger<CreateOrderReceptor> logger) {\n        _logger = logger;\n    }\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken cancellationToken = default) {\n        // Validation\n        if (message Quantity <= 0) {\n            throw new InvalidOperationException(\"Quantity must be greater than zero\");\n        }\n        if (message UnitPrice <= 0) {\n            throw new InvalidOperationException(\"Unit price must be greater than zero\");\n        }\n        if (string IsNullOrWhiteSpace(message",
        "startIndex": 0,
        "preview": "Quick Start Tutorial\nBuild your first Whizbang application in 10 minutes This tutorial walks you through creating a simple order management system usi..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-1",
        "text": "= logger; } public async ValueTask<OrderCreated> HandleAsync( CreateOrder message, CancellationToken cancellationToken = default) { // Validation if (message Quantity <= 0) { throw new InvalidOperationException(\"Quantity must be greater than zero\"); } if (message UnitPrice <= 0) { throw new InvalidOperationException(\"Unit price must be greater than zero\"); } if (string IsNullOrWhiteSpace(message ProductName)) {\n            throw new InvalidOperationException(\"Product name is required\");\n        }\n        // Business logic\n        var orderId = Guid CreateVersion7(); // Time-ordered GUID\n        var total = message Quantity * message UnitPrice;\n        _logger LogInformation(\n            \"Creating order {OrderId} for customer {CustomerId}: {Quantity}x {ProductName} = {Total:C}\",\n            orderId, message CustomerId, message Quantity, message ProductName, total\n        );\n        // Return event (fact of what happened)\n        return new OrderCreated(\n            OrderId: orderId,\n            CustomerId: message CustomerId,\n            ProductName: message ProductName,\n            Quantity: message Quantity,\n            UnitPrice: message UnitPrice,\n            Total: total,\n            CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nKey Patterns:\nImplement IReceptor<TMessage, TResponse>\nUse constructor injection for dependencies\nValidate inputs and throw exceptions for invalid requests\nReturn domain events (OrderCreated) describing what happened\nUse ValueTask<T> for performance (may be synchronous or async)\nStep 4: Register Whizbang Services\nConfigure dependency injection in Program cs:\n`csharp\nusing Whizbang Core;\nusing QuickStartApp API Messages;\nusing QuickStartApp API Receptors;\nvar builder = WebApplication CreateBuilder(args);\n// Add Whizbang Core\nbuilder Services AddWhizbangCore();\n// Register receptors manually (or use Whizbang Generators for auto-discovery)\nbuilder Services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n// Add controllers (if using MVC/API)\nbuilder Services AddControllers();\nbuilder Services AddEndpointsApiExplorer();\nbuilder Services AddSwaggerGen();\nvar app = builder Build();\nif (app Environment IsDevelopment()) {\n    app UseSwagger();\n    app UseSwaggerUI();\n}\napp UseHttpsRedirection();\napp UseAuthorization();\napp MapControllers();\napp Run();\n`\nImportant:\nAddWhizbangCore() registers the dispatcher and core services\nReceptors can be registered manually or auto-discovered (with Whizbang Generators)\nReceptors are typically transient (new instance per request)\nStep 5: Create API Endpoint\nCreate a minimal API endpoint to dispatch your command:\nEndpoints/OrderEndpoints cs:\n`csharp\nusing Microsoft",
        "startIndex": 2447,
        "preview": "= logger; } public async ValueTask<OrderCreated> HandleAsync( CreateOrder message, CancellationToken cancellationToken = default) { // Validation if (..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-2",
        "text": "app MapControllers(); app Run(); ` Important: AddWhizbangCore() registers the dispatcher and core services Receptors can be registered manually or auto-discovered (with Whizbang Generators) Receptors are typically transient (new instance per request) Step 5: Create API Endpoint Create a minimal API endpoint to dispatch your command: Endpoints/OrderEndpoints cs: `csharp using Microsoft AspNetCore Mvc;\nusing Whizbang Core;\nusing QuickStartApp API Messages;\nnamespace QuickStartApp API Endpoints;\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class OrdersController : ControllerBase {\n    private readonly IDispatcher _dispatcher;\n    private readonly ILogger<OrdersController> _logger;\n    public OrdersController(IDispatcher dispatcher, ILogger<OrdersController> logger) {\n        _dispatcher = dispatcher;\n        _logger = logger;\n    }\n    [HttpPost]\n    public async Task<ActionResult<OrderCreated>> CreateOrder(\n        [FromBody] CreateOrderRequest request,\n        CancellationToken cancellationToken) {\n        try {\n            var command = new CreateOrder(\n                CustomerId: request CustomerId,\n                ProductName: request ProductName,\n                Quantity: request Quantity,\n                UnitPrice: request UnitPrice\n            );\n            // Dispatch command and get typed result (< 20ns, zero allocation)\n            var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n                command,\n                cancellationToken\n            );\n            _logger LogInformation(\"Order {OrderId} created successfully\", result OrderId);\n            return CreatedAtAction(\n                nameof(GetOrder),\n                new { orderId = result OrderId },\n                result\n            );\n        } catch (InvalidOperationException ex) {\n            _logger LogWarning(ex, \"Invalid order request\");\n            return BadRequest(new { error = ex Message });\n        } catch (Exception ex) {\n            _logger",
        "startIndex": 4750,
        "preview": "app MapControllers(); app Run(); ` Important: AddWhizbangCore() registers the dispatcher and core services Receptors can be registered manually or aut..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-3",
        "text": "await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>( command, cancellationToken ); _logger LogInformation(\"Order {OrderId} created successfully\", result OrderId); return CreatedAtAction( nameof(GetOrder), new { orderId = result OrderId }, result ); } catch (InvalidOperationException ex) { _logger LogWarning(ex, \"Invalid order request\"); return BadRequest(new { error = ex Message }); } catch (Exception ex) { _logger LogError(ex, \"Failed to create order\");\n            return StatusCode(500, new { error = \"An unexpected error occurred\" });\n        }\n    }\n    [HttpGet(\"{orderId:guid}\")]\n    public ActionResult<OrderCreated> GetOrder(Guid orderId) {\n        // Placeholder - in real app, query from read model via Lens\n        return NotFound(new { error = \"Order retrieval not implemented in quick start\" });\n    }\n}\n// Request DTO for API\npublic record CreateOrderRequest(\n    Guid CustomerId,\n    string ProductName,\n    int Quantity,\n    decimal UnitPrice\n);\n`\nKey Patterns:\nInject IDispatcher into your controller/endpoint\nUse LocalInvokeAsync<TMessage, TResponse> for in-process dispatch with typed result\nHandle exceptions from receptors (validation errors, business rule violations)\nReturn appropriate HTTP status codes (201 Created, 400 Bad Request, 500 Internal Server Error)\nStep 6: Run and Test\nStart the Application\n`bash\ndotnet run\n`\nExpected output:\n`\ninfo: Microsoft Hosting Lifetime[14]\n      Now listening on: https://localhost:7001\ninfo: Microsoft Hosting Lifetime[14]\n      Now listening on: http://localhost:5001\n`\nTest with curl\nValid request:\n`bash\ncurl -X POST https://localhost:7001/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"productName\": \"Laptop\",\n    \"quantity\": 2,\n    \"unitPrice\": 999 99\n  }'\n`\nExpected response (201 Created):\n`json\n{\n  \"orderId\": \"018d8f8e-1234-7890-abcd-ef1234567890\",\n  \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"productName\": \"Laptop\",\n  \"quantity\": 2,\n  \"unitPrice\": 999 99,\n  \"total\": 1999 98,\n  \"createdAt\": \"2024-12-12T10:30:00Z\"\n}\n`\nInvalid request (negative quantity):\n`bash\ncurl -X POST https://localhost:7001/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"productName\": \"Laptop\",\n    \"quantity\": -5,\n    \"unitPrice\": 999",
        "startIndex": 6353,
        "preview": "await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>( command, cancellationToken ); _logger LogInformation(\"Order {OrderId} created successfu..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-4",
        "text": "}' ` Expected response (201 Created): `json { \"orderId\": \"018d8f8e-1234-7890-abcd-ef1234567890\", \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\", \"productName\": \"Laptop\", \"quantity\": 2, \"unitPrice\": 999 99, \"total\": 1999 98, \"createdAt\": \"2024-12-12T10:30:00Z\" } ` Invalid request (negative quantity): `bash curl -X POST https://localhost:7001/api/orders \\ -H \"Content-Type: application/json\" \\ -d '{ \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\", \"productName\": \"Laptop\", \"quantity\": -5, \"unitPrice\": 999 99\n  }'\n`\nExpected response (400 Bad Request):\n`json\n{\n  \"error\": \"Quantity must be greater than zero\"\n}\n`\nTest with Swagger\nNavigate to https://localhost:7001/swagger\nExpand POST /api/orders\nClick Try it out\nEnter request body:\n   `json\n   {\n     \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\",\n     \"productName\": \"Mechanical Keyboard\",\n     \"quantity\": 1,\n     \"unitPrice\": 149 99\n   }\n   `\nClick Execute\nVerify 201 Created response\nWhat You Just Built\nCongratulations You've created a working Whizbang application with:\n‚úÖ Type-safe messaging - Compiler enforces CreateOrder ‚Üí OrderCreated\n‚úÖ Zero reflection - All routing happens at compile time\n‚úÖ Clean architecture - Commands, events, and handlers are separated\n‚úÖ Business logic isolation - Validation and rules in receptor, not controller\n‚úÖ Performance - < 20ns dispatch with zero allocations\nUnderstanding the Flow\n`\nHTTP POST /api/orders\n    ‚Üì\nOrdersController CreateOrder()\n    ‚Üì\ndispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command)\n    ‚Üì\nCreateOrderReceptor HandleAsync(command)\n    ‚Üì\nValidation ‚Üí Business Logic ‚Üí Return OrderCreated event\n    ‚Üì\nReturn 201 Created with OrderCreated response\n`\nNext Steps\nAdd Source Generators (Auto-Discovery)\nCurrently, you're registering receptors manually:\n`csharp\nbuilder Services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n`\nWith Whizbang Generators, receptors are discovered automatically:\nEnsure Whizbang Generators package is referenced\nRemove manual receptor registrations\nAdd auto-discovery:\n   `csharp\n   builder Services AddWhizbangCore();\n   builder Services AddDiscoveredReceptors(); // Auto-registers all IReceptor implementations\n   `\nRebuild: dotnet build\nCheck whizbang-generated/ReceptorRegistrations g cs for generated code\nBenefits:\nNo manual registration needed\nCompile-time verification\nAOT-compatible\nZero reflection\nAdd Perspectives (Read Models)\nPerspectives listen to events and update read models:\nPerspectives/OrderSummaryPerspective cs:\n`csharp\nusing Whizbang Core;\nusing QuickStartApp API",
        "startIndex": 8291,
        "preview": "}' ` Expected response (201 Created): `json { \"orderId\": \"018d8f8e-1234-7890-abcd-ef1234567890\", \"customerId\": \"550e8400-e29b-41d4-a716-446655440000\",..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-5",
        "text": "builder Services AddDiscoveredReceptors(); // Auto-registers all IReceptor implementations ` Rebuild: dotnet build Check whizbang-generated/ReceptorRegistrations g cs for generated code Benefits: No manual registration needed Compile-time verification AOT-compatible Zero reflection Add Perspectives (Read Models) Perspectives listen to events and update read models: Perspectives/OrderSummaryPerspective cs: `csharp using Whizbang Core; using QuickStartApp API Messages;\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly ILogger<OrderSummaryPerspective> _logger;\n    // In real app: inject IDbConnectionFactory or DbContext\n    public OrderSummaryPerspective(ILogger<OrderSummaryPerspective> logger) {\n        _logger = logger;\n    }\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        _logger LogInformation(\n            \"Updating order summary for {OrderId} - Total: {Total:C}\",\n            @event OrderId, @event Total\n        );\n        // In real app: update denormalized read model in database\n        // await _db ExecuteAsync(\"INSERT INTO order_summaries ( ) VALUES ( )\", @event);\n    }\n}\n`\nRegister perspective:\n`csharp\nbuilder Services AddTransient<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\n// Or use AddDiscoveredPerspectives() with Whizbang Generators\n`\nPublish events after receptor completes:\n`csharp\nvar result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(command, ct);\n// Publish event to all perspectives\nawait _dispatcher PublishAsync(result, ct);\n`\nAdd Data Persistence\nInstall Dapper + PostgreSQL:\n`bash\ndotnet add package Whizbang Data Dapper Postgres\n`\nConfigure connection string in appsettings Development json:\n`json\n{\n  \"ConnectionStrings\": {\n    \"DefaultConnection\": \"Host=localhost;Database=quickstart;Username=postgres;Password=your_password\"\n  }\n}\n`\nRegister database:\n`csharp\nbuilder Services AddWhizbangDapper(\n    builder Configuration GetConnectionString(\"DefaultConnection\") );\n`\nUse in receptor:\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public CreateOrderReceptor(IDbConnectionFactory db) {\n        _db = db;\n    }\n    public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct = default) {\n        // Save to database\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO orders (order_id, customer_id, product_name, quantity, unit_price, total, created_at) VALUES (@OrderId, @CustomerId, @ProductName, @Quantity, @UnitPrice, @Total, @CreatedAt)\",\n            new {\n                OrderId = orderId,\n                message CustomerId,\n                message ProductName,\n                message Quantity,\n                message UnitPrice,\n                Total = total,\n                CreatedAt = DateTimeOffset UtcNow\n            }\n        );\n        return new OrderCreated(/",
        "startIndex": 10357,
        "preview": "builder Services AddDiscoveredReceptors(); // Auto-registers all IReceptor implementations ` Rebuild: dotnet build Check whizbang-generated/ReceptorRe..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-6",
        "text": "conn = _db CreateConnection(); await conn ExecuteAsync( \"INSERT INTO orders (order_id, customer_id, product_name, quantity, unit_price, total, created_at) VALUES (@OrderId, @CustomerId, @ProductName, @Quantity, @UnitPrice, @Total, @CreatedAt)\", new { OrderId = orderId, message CustomerId, message ProductName, message Quantity, message UnitPrice, Total = total, CreatedAt = DateTimeOffset UtcNow } ); return new OrderCreated(/ /);\n    }\n}\n`\nAdd Tests\nInstall testing packages:\n`bash\ndotnet new tunit -n QuickStartApp API Tests\ncd QuickStartApp API Tests\ndotnet add package Whizbang Testing\ndotnet add package TUnit Assertions\ndotnet add reference /QuickStartApp API\n`\nTest your receptor:\n`csharp\nusing TUnit Assertions;\nusing QuickStartApp API Messages;\nusing QuickStartApp API Receptors;\npublic class CreateOrderReceptorTests {\n    [Test]\n    public async Task HandleAsync_ValidOrder_ReturnsOrderCreated() {\n        // Arrange\n        var logger = new NullLogger<CreateOrderReceptor>();\n        var receptor = new CreateOrderReceptor(logger);\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            ProductName: \"Test Product\",\n            Quantity: 5,\n            UnitPrice: 19 99m\n        );\n        // Act\n        var result = await receptor HandleAsync(command);\n        // Assert\n        await Assert That(result OrderId) IsNotEqualTo(Guid Empty);\n        await Assert That(result CustomerId) IsEqualTo(command CustomerId);\n        await Assert That(result ProductName) IsEqualTo(\"Test Product\");\n        await Assert That(result Quantity) IsEqualTo(5);\n        await Assert That(result UnitPrice) IsEqualTo(19 99m);\n        await Assert That(result Total) IsEqualTo(99 95m);\n    }\n    [Test]\n    public async Task HandleAsync_InvalidQuantity_ThrowsException() {\n        // Arrange\n        var logger = new NullLogger<CreateOrderReceptor>();\n        var receptor = new CreateOrderReceptor(logger);\n        var command = new CreateOrder(\n            CustomerId: Guid NewGuid(),\n            ProductName: \"Test Product\",\n            Quantity: -1, // Invalid\n            UnitPrice: 19 99m\n        );\n        // Act & Assert\n        await Assert That(async () => await receptor HandleAsync(command)) ThrowsException<InvalidOperationException>() WithMessage(\"Quantity must be greater than zero\");\n    }\n}\n`\nRun tests:\n`bash\ndotnet test\n`\nExplore the ECommerce Sample\nThe complete ECommerce sample demonstrates:\nBackend for Frontend (BFF) with SignalR real-time updates\nMicroservices architecture (Order, Inventory, Payment, Shipping, Notification)\nEvent-driven workflows with Outbox/Inbox patterns",
        "startIndex": 12929,
        "preview": "conn = _db CreateConnection(); await conn ExecuteAsync( \"INSERT INTO orders (order_id, customer_id, product_name, quantity, unit_price, total, created..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-7",
        "text": "() => await receptor HandleAsync(command)) ThrowsException<InvalidOperationException>() WithMessage(\"Quantity must be greater than zero\"); } } ` Run tests: `bash dotnet test ` Explore the ECommerce Sample The complete ECommerce sample demonstrates: Backend for Frontend (BFF) with SignalR real-time updates Microservices architecture (Order, Inventory, Payment, Shipping, Notification) Event-driven workflows with Outbox/Inbox patterns NET Aspire orchestration for local development\nAngular 20 UI with NgRx state management\nIntegration testing with TUnit\nSee ECommerce Tutorial for complete walkthrough Common Patterns\nPattern 1: Command ‚Üí Event\n`csharp\nCreateOrder (command) ‚Üí CreateOrderReceptor ‚Üí OrderCreated (event)\n`\nCommands express intent (imperative: \"create order\")\nEvents express facts (past tense: \"order created\")\nReceptors make decisions and return events\nPattern 2: Event ‚Üí Perspectives\n`csharp\nOrderCreated (event) ‚Üí OrderSummaryPerspective ‚Üí Update read model\n                     ‚Üí InventoryPerspective ‚Üí Update stock levels\n                     ‚Üí AnalyticsPerspective ‚Üí Update dashboards\n`\nOne event can trigger multiple perspectives\nPerspectives are eventually consistent\nEach perspective maintains its own optimized read model\nPattern 3: Query via Lenses\n`csharp\nGET /api/orders/{id} ‚Üí OrderLens ‚Üí Query read model ‚Üí Return DTO\n`\nLenses are query-optimized repositories\nRead from perspectives' denormalized tables\nFast, simple SQL queries (no joins)\nTroubleshooting\nIssue: \"No receptor registered for CreateOrder\"\nSymptom: Runtime exception when calling LocalInvokeAsync\nSolution:\nVerify receptor is registered in Program cs:\n   `csharp\n   builder Services AddTransient<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();\n   `\nOr use auto-discovery:\n   `csharp\n   builder Services AddDiscoveredReceptors();\n   `\nRebuild: dotnet clean && dotnet build\nIssue: \"Type 'IDispatcher' not found\"\nSymptom: Compiler error when injecting IDispatcher\nSolution:\nAdd using directive:\n   `csharp\n   using Whizbang Core;\n   `\nVerify package reference:\n   `bash\n   dotnet list package | grep Whizbang Core\n   `\nRestore if missing:\n   `bash\n   dotnet restore\n   `\nIssue: Generated files not appearing\nSymptom: Source generators not creating files in whizbang-generated/\nSolution:\nEnsure Whizbang Generators package is referenced\nCheck MSBuild properties in csproj:\n   `xml\n   <PropertyGroup>\n     <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n     <CompilerGeneratedFilesOutputPath>$(MSBuildProjectDirectory)/",
        "startIndex": 15164,
        "preview": "() => await receptor HandleAsync(command)) ThrowsException<InvalidOperationException>() WithMessage(\"Quantity must be greater than zero\"); } } ` Run t..."
      },
      {
        "id": "v0.1.0/getting-started/quick-start-chunk-8",
        "text": "Core; ` Verify package reference: `bash dotnet list package | grep Whizbang Core ` Restore if missing: `bash dotnet restore ` Issue: Generated files not appearing Symptom: Source generators not creating files in whizbang-generated/ Solution: Ensure Whizbang Generators package is referenced Check MSBuild properties in csproj: `xml <PropertyGroup> <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles> <CompilerGeneratedFilesOutputPath>$(MSBuildProjectDirectory)/ whizbang-generated</CompilerGeneratedFilesOutputPath>\n   </PropertyGroup>\n   `\nRebuild:\n   `bash\n   dotnet clean && dotnet build\n   `\nKey Takeaways\nüéØ Receptors handle commands and return events\nüéØ Dispatcher routes messages with compile-time type safety\nüéØ Zero Reflection - all wiring happens via source generators\nüéØ Type Safety - compiler enforces message ‚Üí response relationships\nüéØ Performance - < 20ns in-process dispatch with zero allocations\nFurther Reading\nCore Concepts:\nDispatcher Deep Dive - Three dispatch patterns explained\nReceptors Guide - Advanced receptor patterns\nPerspectives Guide - Building read models\nLenses Guide - Query optimization\nMessaging Patterns:\nOutbox Pattern - Reliable cross-service messaging\nInbox Pattern - Exactly-once message processing\nWork Coordination - Distributed work coordination\nAdvanced Topics:\nSource Generators - Auto-discovery internals\nPerformance Tuning - Optimize for scale\nTesting Strategies - Comprehensive testing guide\n---\nNext: Project Structure Guide - Organize your Whizbang application\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 17270,
        "preview": "Core; ` Verify package reference: `bash dotnet list package | grep Whizbang Core ` Restore if missing: `bash dotnet restore ` Issue: Generated files n..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/infrastructure/aspire-integration",
    "title": ".NET Aspire Integration",
    "category": "Infrastructure",
    "url": "/docs/v0.1.0/infrastructure/aspire-integration",
    "chunks": [
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-0",
        "text": "NET Aspire Integration NET Aspire is Microsoft's cloud-native application stack for building distributed applications with batteries-included infrastructure Whizbang integrates seamlessly with Aspire to provide automatic service discovery, infrastructure provisioning, and local development environments Why Aspire + Whizbang Aspire solves infrastructure complexity for Whizbang applications:\n| Challenge | Without Aspire | With Aspire |\n|-----------|---------------|-------------|\n| Service Bus Setup | Manual topic/subscription creation | Automatic provisioning from AppHost |\n| Connection Strings | Copy-paste from Azure Portal | Auto-injected via configuration |\n| Local Development | Install/configure Service Bus locally | Built-in emulator with zero config |\n| Service Discovery | Manual endpoint configuration | Automatic service-to-service discovery |\n| Health Checks | Manual endpoint setup | Built-in dashboards with live monitoring |\n| Observability | Configure OpenTelemetry manually | Auto-wired distributed tracing |\nWhizbang + Aspire Benefits:\n‚úÖ Zero Manual Infrastructure - Topics, subscriptions, filters provisioned automatically\n‚úÖ Emulator Support - Local Service Bus emulator for dev/test\n‚úÖ Configuration as Code - AppHost defines infrastructure declaratively\n‚úÖ Multi-Service Orchestration - Run distributed systems locally with dotnet run\n‚úÖ Production Parity - Same code runs locally (emulator) and in Azure\n---\nArchitecture\nAspire AppHost Pattern\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  AppHost (Program cs)                                  ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  Azure Service Bus Resource                      ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Topic: \"whizbang",
        "startIndex": 0,
        "preview": "NET Aspire Integration NET Aspire is Microsoft's cloud-native application stack for building distributed applications with batteries-included infrastr..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-1",
        "text": "- Run distributed systems locally with dotnet run ‚úÖ Production Parity - Same code runs locally (emulator) and in Azure --- Architecture Aspire AppHost Pattern ` ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ AppHost (Program cs) ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ Azure Service Bus Resource ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Topic: \"whizbang events\"                     ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ Subscription: \"inventory-service\"         ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Filter: Destination = \"inventory\"      ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ Subscription: \"notification-service\"      ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Filter: Destination = \"notifications\"  ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Subscription: \"analytics-service\"         ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ     ‚îî‚îÄ Filter: Destination = \"analytics\"      ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  Service Projects (with references)              ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Inventory Service ‚Üí inventory-service sub    ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Notification Service ‚Üí notification-service  ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ Analytics Service ‚Üí analytics-service sub    ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         ‚îÇ dotnet run (AppHost)\n         ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Aspire Runtime                                        ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  - Starts Service Bus emulator (or connects to Azure) ‚îÇ\n‚îÇ  - Provisions topics and subscriptions via Bicep/API  ‚îÇ\n‚îÇ  - Injects connection strings into services           ‚îÇ\n‚îÇ  - Starts all service projects                        ‚îÇ\n‚îÇ  - Exposes dashboard at http://localhost:15888        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nSetup\nCreate Aspire AppHost Project\n`bash\nCreate solution structure\ndotnet new sln -n MyDistributedApp\ndotnet new aspire-apphost -n MyDistributedApp AppHost\ndotnet sln add MyDistributedApp AppHost\nAdd service projects\ndotnet new webapi -n InventoryService\ndotnet new webapi -n NotificationService\ndotnet sln add InventoryService NotificationService\n`\nAdd Whizbang NuGet Packages\nAppHost Project:\n`bash\ncd MyDistributedApp AppHost\ndotnet add package Whizbang Hosting Azure ServiceBus\n`\nService Projects:\n`bash\ncd /InventoryService\ndotnet add package Whizbang\ndotnet add package Whizbang Transports AzureServiceBus\n`\nConfigure AppHost\nAppHost/Program",
        "startIndex": 1796,
        "preview": "- Run distributed systems locally with dotnet run ‚úÖ Production Parity - Same code runs locally (emulator) and in Azure --- Architecture Aspire AppHost..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-2",
        "text": "-n InventoryService dotnet new webapi -n NotificationService dotnet sln add InventoryService NotificationService ` Add Whizbang NuGet Packages AppHost Project: `bash cd MyDistributedApp AppHost dotnet add package Whizbang Hosting Azure ServiceBus ` Service Projects: `bash cd /InventoryService dotnet add package Whizbang dotnet add package Whizbang Transports AzureServiceBus ` Configure AppHost AppHost/Program cs:\n`csharp\nusing Whizbang Hosting Azure ServiceBus;\nvar builder = DistributedApplication CreateBuilder(args);\n// Add Service Bus resource (emulator for local dev)\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();  // Local development\n  // PublishAsAzureServiceBusNamespace();  // Production deployment\n// Create topic for all events\nvar topic = serviceBus AddTopic(\"whizbang-events\");\n// Add subscriptions with Whizbang correlation filters\nvar inventorySub = topic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");  // ‚≠ê Whizbang extension method\nvar notificationSub = topic AddSubscription(\"notification-service\") WithDestinationFilter(\"notifications\");\nvar analyticsSub = topic AddSubscription(\"analytics-service\") WithDestinationFilter(\"analytics\");\n// Add service projects with Service Bus references\nvar inventoryService = builder AddProject<Projects InventoryService>(\"inventory-service\") WithReference(serviceBus) WithReference(inventorySub);  // Grants read access to subscription\nvar notificationService = builder AddProject<Projects NotificationService>(\"notification-service\") WithReference(serviceBus) WithReference(notificationSub);\nvar analyticsService = builder AddProject<Projects AnalyticsService>(\"analytics-service\") WithReference(serviceBus) WithReference(analyticsSub);\nbuilder Build() Run();\n`\nWhat WithDestinationFilter() Does:\nProvisions Azure Service Bus Correlation Filter on the subscription\nFilters messages based on ApplicationProperties[\"Destination\"] value\nEnables multi-tenant and multi-service routing patterns\nWorks in both emulator and production\n---\nService Configuration\nAdd Aspire Service Defaults\nInventoryService/Program cs:\n`csharp\nvar builder = WebApplication CreateBuilder(args);\n// Add Aspire service defaults (health checks, telemetry, service discovery)\nbuilder AddServiceDefaults();  // ‚≠ê Essential for Aspire integration\n// Get Service Bus connection string injected by Aspire\nvar connectionString = builder Configuration GetConnectionString(\"messaging\") throw new InvalidOperationException(\"Service Bus connection not found\");\n// Register Whizbang transport\nbuilder Services AddAzureServiceBusTransport(connectionString);\n// Register receptors, perspectives, etc builder Services AddWhizbang();\nvar app = builder Build();\napp MapDefaultEndpoints();  // Health checks, metrics\napp",
        "startIndex": 3939,
        "preview": "-n InventoryService dotnet new webapi -n NotificationService dotnet sln add InventoryService NotificationService ` Add Whizbang NuGet Packages AppHost..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-3",
        "text": "integration // Get Service Bus connection string injected by Aspire var connectionString = builder Configuration GetConnectionString(\"messaging\") throw new InvalidOperationException(\"Service Bus connection not found\"); // Register Whizbang transport builder Services AddAzureServiceBusTransport(connectionString); // Register receptors, perspectives, etc builder Services AddWhizbang(); var app = builder Build(); app MapDefaultEndpoints(); // Health checks, metrics app Run();\n`\nHow It Works:\nAspire injects ConnectionStrings:messaging into app configuration\nService reads connection string and registers transport\nTransport auto-detects emulator vs production connection\nAspire dashboard shows service health and telemetry\nVerify Aspire Integration\n`bash\nRun AppHost\ncd MyDistributedApp AppHost\ndotnet run\nAspire dashboard opens at http://localhost:15888\nView:\nResources (Service Bus, services)\nService health status\nDistributed traces\nLogs (structured and correlated)\n`\n---\nCorrelation Filters\nWithDestinationFilter Extension\nPurpose: Route messages to specific services based on Destination property Implementation:\n`csharp\npublic static IResourceBuilder<AzureServiceBusSubscriptionResource> WithDestinationFilter(\n  this IResourceBuilder<AzureServiceBusSubscriptionResource> subscription,\n  string destination\n) {\n  return subscription WithProperties(sub => {\n    sub Rules Add(new AzureServiceBusRule(\"DestinationFilter\") {\n      CorrelationFilter = new() {\n        Properties = { [\"Destination\"] = destination }\n      }\n    });\n  });\n}\n`\nUsage Pattern:\n`csharp\n// AppHost - provision filters\nvar inventorySub = topic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");  // Only messages with Destination = \"inventory\"\n// Publisher - set Destination property\nvar destination = new TransportDestination(\n  Address: \"whizbang-events\",\n  RoutingKey: \"inventory-service\",\n  Metadata: new Dictionary<string, JsonElement> {\n    [\"Destination\"] = JsonSerializer SerializeToElement(\"inventory\")  // ‚≠ê Filter value\n  }\n);\nawait transport PublishAsync(envelope, destination);\n`\nResult: Only messages with Destination = \"inventory\" routed to inventory-service subscription ---\nEmulator vs Production\nDevelopment (Emulator)\n`csharp\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();  // Starts container with Service Bus emulator\n`\nCharacteristics:\nRuns in Docker container\nAccessed via localhost:5672 (AMQP)\nNo Admin API (port 443 not supported)\nFilters provisioned by Aspire at startup\nZero Azure credentials required\nConnection String:\n`\nEndpoint=sb://localhost;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=SAS_KEY_VALUE;UseDevelopmentEmulator=true\n`\nProduction (Azure)\n`csharp\nvar serviceBus = builder AddAzureServiceBus(\"messaging\")",
        "startIndex": 6355,
        "preview": "integration // Get Service Bus connection string injected by Aspire var connectionString = builder Configuration GetConnectionString(\"messaging\") thro..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-4",
        "text": "builder AddAzureServiceBus(\"messaging\") RunAsEmulator(); // Starts container with Service Bus emulator ` Characteristics: Runs in Docker container Accessed via localhost:5672 (AMQP) No Admin API (port 443 not supported) Filters provisioned by Aspire at startup Zero Azure credentials required Connection String: ` Endpoint=sb://localhost;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=SAS_KEY_VALUE;UseDevelopmentEmulator=true ` Production (Azure) `csharp var serviceBus = builder AddAzureServiceBus(\"messaging\") PublishAsAzureServiceBusNamespace();  // Generates Bicep for Azure deployment\n`\nCharacteristics:\nProvisions Azure Service Bus Namespace\nGenerates Bicep infrastructure-as-code\nUses Azure identity for authentication\nFull Admin API support for filter management\nConnection String (injected by Azure):\n`\nEndpoint=sb://my-namespace servicebus windows net/; `\n---\nConfiguration Generation\nAspireConfigurationGenerator\nPurpose: Generate Ccode for AppHost based on service requirements Use Case: Services define their messaging requirements programmatically, generator creates AppHost config Example:\n`csharp\nusing Whizbang Core Transports AzureServiceBus;\n// Service defines requirements\nvar requirements = new[] {\n  new TopicRequirement(\"whizbang-events\", \"inventory-service\"),\n  new TopicRequirement(\"whizbang-events\", \"notification-service\"),\n  new TopicRequirement(\"order-events\", \"shipping-service\")\n};\n// Generate AppHost code\nvar code = AspireConfigurationGenerator GenerateAppHostCode(\n  requirements,\n  serviceName: \"OrderService\"\n);\nConsole WriteLine(code);\n`\nGenerated Output:\n`csharp\n// === Whizbang Service Bus Configuration ===\n// Service Bus topics for OrderService service\nvar orderEventsTopic = serviceBus AddServiceBusTopic(\"order-events\");\norderEventsTopic AddServiceBusSubscription(\"shipping-service\");\nvar whizbangEventsTopic = serviceBus AddServiceBusTopic(\"whizbang-events\");\nwhizbangEventsTopic AddServiceBusSubscription(\"inventory-service\");\nwhizbangEventsTopic AddServiceBusSubscription(\"notification-service\");\n// ==========================================\n`\nUse Case: Copy-paste into AppHost to provision topics/subscriptions ---\nReadiness Checks\nServiceBusReadinessCheck\nPurpose: Verify Service Bus connectivity before accepting traffic Pattern:\n`csharp\nusing Whizbang Hosting Azure ServiceBus;\nbuilder Services AddSingleton<ITransportReadinessCheck, ServiceBusReadinessCheck>();\n`\nHow It Works:\n`csharp\npublic async Task<bool> IsReadyAsync(CancellationToken ct) {\n  // 1 Check if transport initialized\n  if ( _transport IsInitialized) {\n    return false;\n  }\n  // 2 Check cache (30-second TTL)\n  if (_lastSuccessfulCheck HasValue &&\n      DateTimeOffset UtcNow - _lastSuccessfulCheck Value < _cacheDuration) {\n    return true;  // Cached result\n  }\n  // 3 Verify ServiceBusClient is open\n  if (_client IsClosed) {\n    return false;\n  }\n  // 4 Cache successful check\n  _lastSuccessfulCheck = DateTimeOffset",
        "startIndex": 8689,
        "preview": "builder AddAzureServiceBus(\"messaging\") RunAsEmulator(); // Starts container with Service Bus emulator ` Characteristics: Runs in Docker container Acc..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-5",
        "text": "IsInitialized) { return false; } // 2 Check cache (30-second TTL) if (_lastSuccessfulCheck HasValue && DateTimeOffset UtcNow - _lastSuccessfulCheck Value < _cacheDuration) { return true; // Cached result } // 3 Verify ServiceBusClient is open if (_client IsClosed) { return false; } // 4 Cache successful check _lastSuccessfulCheck = DateTimeOffset UtcNow;\n  return true;\n}\n`\nBenefits:\nPrevents accepting requests before Service Bus connection is ready\nCached checks avoid excessive health check overhead\nIntegrates with Aspire dashboard for real-time status\n---\nMulti-Service Patterns\nFan-Out Events\n`csharp\n// AppHost - multiple services subscribe to same topic\nvar topic = serviceBus AddTopic(\"order-events\");\ntopic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");\ntopic AddSubscription(\"notification-service\") WithDestinationFilter(\"notifications\");\ntopic AddSubscription(\"analytics-service\") WithDestinationFilter(\"analytics\");\ntopic AddSubscription(\"audit-service\") WithDestinationFilter(\"audit\");\n// Publisher - send to multiple destinations\nawait transport PublishAsync(envelope, new TransportDestination(\"order-events\", Metadata: CreateDestination(\"inventory\")));\nawait transport PublishAsync(envelope, new TransportDestination(\"order-events\", Metadata: CreateDestination(\"notifications\")));\nawait transport PublishAsync(envelope, new TransportDestination(\"order-events\", Metadata: CreateDestination(\"audit\")));\n`\nResult: Single event published to multiple services via correlation filters Service-to-Service Communication\n`csharp\n// AppHost - inventory service references notification service\nvar notificationService = builder AddProject<Projects NotificationService>(\"notification-service\") WithReference(serviceBus);\nvar inventoryService = builder AddProject<Projects InventoryService>(\"inventory-service\") WithReference(serviceBus) WithReference(notificationService);  // Service discovery\n// InventoryService - call NotificationService\nvar notificationEndpoint = builder Configuration[\"services:notification-service:https:0\"];\nvar httpClient = new HttpClient { BaseAddress = new Uri(notificationEndpoint) };\nawait httpClient PostAsync(\"/notify\", content);  // Service-to-service HTTP\n`\nAspire provides:\nAutomatic service endpoint discovery\nLoad balancing across instances\nHealth-based routing\n---\nDashboard and Observability\nAspire Dashboard\nRun AppHost and open http://localhost:15888 Features:\nResources Tab: View Service Bus, services, dependencies\nConsole Logs Tab: Structured logs with correlation IDs\nTraces Tab: Distributed tracing across services\nMetrics Tab: Service health, request rates, latencies\nWhizbang Integration\nAutomatic Tracing:\nAll IDispatcher SendAsync calls create spans\nTransport PublishAsync and SubscribeAsync tracked\nCorrelation IDs propagated across services\nExample Trace:\n`\nOrderService DispatcherInvokeReceptor (50ms)\n  ‚îú‚îÄ OrderReceptor HandleAsync (45ms)\n  ‚îÇ  ‚îú‚îÄ Database Insert (10ms)\n  ‚îÇ  ‚îî‚îÄ Transport",
        "startIndex": 11129,
        "preview": "IsInitialized) { return false; } // 2 Check cache (30-second TTL) if (_lastSuccessfulCheck HasValue && DateTimeOffset UtcNow - _lastSuccessfulCheck Va..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-6",
        "text": "Tab: Distributed tracing across services Metrics Tab: Service health, request rates, latencies Whizbang Integration Automatic Tracing: All IDispatcher SendAsync calls create spans Transport PublishAsync and SubscribeAsync tracked Correlation IDs propagated across services Example Trace: ` OrderService DispatcherInvokeReceptor (50ms) ‚îú‚îÄ OrderReceptor HandleAsync (45ms) ‚îÇ ‚îú‚îÄ Database Insert (10ms) ‚îÇ ‚îî‚îÄ Transport PublishAsync (5ms)\n  ‚îÇ\n  ‚îî‚îÄ InventoryService ReceiveMessage (20ms)\n     ‚îî‚îÄ InventoryReceptor HandleAsync (18ms)\n        ‚îî‚îÄ Database Update (15ms)\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use WithDestinationFilter() for multi-service routing\n‚úÖ Run emulator for local development (zero Azure costs)\n‚úÖ Add AddServiceDefaults() to all service projects\n‚úÖ Reference subscriptions via WithReference() (grants access)\n‚úÖ Use PublishAsAzureServiceBusNamespace() for production Bicep generation\n‚úÖ Monitor Aspire dashboard during development\n‚úÖ Test locally with emulator before deploying to Azure\nDON'T ‚ùå\n‚ùå Hardcode connection strings (use Aspire configuration)\n‚ùå Skip AddServiceDefaults() (breaks health checks and telemetry)\n‚ùå Create topics/subscriptions manually (let Aspire provision)\n‚ùå Use Admin API with emulator (not supported)\n‚ùå Ignore readiness checks (services may accept traffic before ready)\n‚ùå Deploy to production without testing emulator first\n---\nTroubleshooting\nProblem: \"Connection string 'messaging' not found\"\nSymptoms: Service fails to start with missing connection string error Cause: Service not referenced in AppHost or missing WithReference(serviceBus) Solution:\n`csharp\n// AppHost - add reference to Service Bus\nvar inventoryService = builder AddProject<Projects InventoryService>(\"inventory-service\") WithReference(serviceBus);  // ‚≠ê Required for connection string injection\n// Service - verify configuration key\nvar connectionString = builder Configuration GetConnectionString(\"messaging\");\n// Key must match resource name in AppHost (\"messaging\")\n`\nProblem: Messages Not Filtered Correctly\nSymptoms: Subscriber receives all messages, not just filtered ones Causes:\nFilter not provisioned (missing WithDestinationFilter())\nPublisher not setting Destination property\nFilter value mismatch\nSolution:\n`csharp\n// AppHost - verify filter provisioning\nvar inventorySub = topic AddSubscription(\"inventory-service\")",
        "startIndex": 13777,
        "preview": "Tab: Distributed tracing across services Metrics Tab: Service health, request rates, latencies Whizbang Integration Automatic Tracing: All IDispatcher..."
      },
      {
        "id": "v0.1.0/infrastructure/aspire-integration-chunk-7",
        "text": "Key must match resource name in AppHost (\"messaging\") ` Problem: Messages Not Filtered Correctly Symptoms: Subscriber receives all messages, not just filtered ones Causes: Filter not provisioned (missing WithDestinationFilter()) Publisher not setting Destination property Filter value mismatch Solution: `csharp // AppHost - verify filter provisioning var inventorySub = topic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");  // Filter value: \"inventory\"\n// Publisher - set matching Destination property\nvar metadata = new Dictionary<string, JsonElement> {\n  [\"Destination\"] = JsonSerializer SerializeToElement(\"inventory\")  // Must match filter\n};\nvar destination = new TransportDestination(\"whizbang-events\", \"inventory-service\", metadata);\nawait transport PublishAsync(envelope, destination);\n// Verify in Azure Portal:\n// Service Bus Namespace ‚Üí Topics ‚Üí whizbang-events ‚Üí Subscriptions ‚Üí inventory-service ‚Üí Rules\n// Expected: DestinationFilter with Destination = \"inventory\"\n`\nProblem: Emulator Fails to Start\nSymptoms: AppHost throws error starting Service Bus emulator Causes:\nDocker not running\nPort 5672 already in use\nEmulator image not pulled\nSolution:\n`bash\nVerify Docker is running\ndocker ps\nPull Service Bus emulator image\ndocker pull mcr microsoft com/azure-messaging/servicebus-emulator:latest\nCheck port availability\nlsof -i :5672  Should be empty\nRun AppHost again\ndotnet run\n`\nProblem: Service Not Appearing in Dashboard\nSymptoms: Aspire dashboard shows Service Bus but not service projects Cause: Missing AddServiceDefaults() in service Program cs Solution:\n`csharp\n// Service Program cs - add service defaults\nvar builder = WebApplication CreateBuilder(args);\nbuilder AddServiceDefaults();  // ‚≠ê Required for dashboard integration\nvar app = builder Build();\napp MapDefaultEndpoints();  // Exposes health/metrics endpoints\napp Run();\n`\n---\nFurther Reading\nTransports:\nAzure Service Bus Transport - Service Bus integration details\nInfrastructure:\nHealth Checks - Application health monitoring\nPolicies - Policy-based routing\nMessaging:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nExternal Resources: NET Aspire Documentation\nAzure Service Bus Emulator\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 15702,
        "preview": "Key must match resource name in AppHost (\"messaging\") ` Problem: Messages Not Filtered Correctly Symptoms: Subscriber receives all messages, not just ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/infrastructure/health-checks",
    "title": "Health Checks",
    "category": "Infrastructure",
    "url": "/docs/v0.1.0/infrastructure/health-checks",
    "chunks": [
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-0",
        "text": "Health Checks\nHealth checks provide real-time monitoring of application health and dependency availability Whizbang includes built-in health checks for transports, databases, and infrastructure components with seamless integration into NET Aspire dashboards and Kubernetes readiness probes Why Health Checks Health checks prevent cascading failures in distributed systems:\n| Use Case | Description | Benefit |\n|----------|-------------|---------|\n| Kubernetes Readiness | Prevent routing traffic to unhealthy instances | Zero-downtime deployments |\n| Load Balancer Health | Remove unhealthy instances from pool | High availability |\n| Circuit Breakers | Detect downstream failures early | Fault isolation |\n| Aspire Dashboard | Real-time health visualization | Faster troubleshooting |\n| Startup Validation | Verify dependencies before accepting traffic | Fail-fast on misconfiguration |\n| Monitoring Alerts | Trigger alerts when dependencies fail | Proactive incident response |\nWhizbang Health Checks:\n‚úÖ Transport Connectivity - Azure Service Bus, In-Memory\n‚úÖ Database Connectivity - PostgreSQL, SQL Server\n‚úÖ Custom Checks - Extensible IHealthCheck pattern\n‚úÖ Caching - Avoid excessive health check overhead\n‚úÖ Aspire Integration - Auto-wired dashboard monitoring\n---\nArchitecture\nHealth Check Flow\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Health Check Endpoint: /health                        ‚îÇ\n‚îÇ  (Kubernetes readiness, load balancer, monitoring)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚îÇ HTTP GET /health\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Microsoft Extensions Diagnostics HealthChecks         ‚îÇ\n‚îÇ  (Built into ASP NET Core)                             ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  Executes all registered health checks in parallel:    ‚îÇ\n‚îÇ  ‚îú‚îÄ AzureServiceBusHealthCheck                         ‚îÇ\n‚îÇ  ‚îú‚îÄ PostgresHealthCheck                                ‚îÇ\n‚îÇ  ‚îú‚îÄ CustomHealthCheck                                  ‚îÇ\n‚îÇ  ‚îî‚îÄ",
        "startIndex": 0,
        "preview": "Health Checks\nHealth checks provide real-time monitoring of application health and dependency availability Whizbang includes built-in health checks fo..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-1",
        "text": "load balancer, monitoring) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ HTTP GET /health ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Microsoft Extensions Diagnostics HealthChecks ‚îÇ ‚îÇ (Built into ASP NET Core) ‚îÇ ‚îÇ ‚îÇ ‚îÇ Executes all registered health checks in parallel: ‚îÇ ‚îÇ ‚îú‚îÄ AzureServiceBusHealthCheck ‚îÇ ‚îÇ ‚îú‚îÄ PostgresHealthCheck ‚îÇ ‚îÇ ‚îú‚îÄ CustomHealthCheck ‚îÇ ‚îÇ ‚îî‚îÄ ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚îÇ Aggregate results\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Health Check Response                                 ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  {                                                      ‚îÇ\n‚îÇ    \"status\": \"Healthy\",           // or Degraded, Unhealthy\n‚îÇ    \"results\": {                                         ‚îÇ\n‚îÇ      \"azure_servicebus\": {                              ‚îÇ\n‚îÇ        \"status\": \"Healthy\",                             ‚îÇ\n‚îÇ        \"description\": \"Transport is available\"          ‚îÇ\n‚îÇ      },                                                 ‚îÇ\n‚îÇ      \"postgres\": {                                      ‚îÇ\n‚îÇ        \"status\": \"Healthy\",                             ‚îÇ\n‚îÇ        \"description\": \"Database is accessible\"          ‚îÇ\n‚îÇ      }                                                  ‚îÇ\n‚îÇ    }                                                    ‚îÇ\n‚îÇ  }                                                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nBuilt-In Health Checks\nAzure Service Bus Health Check\nPurpose: Verify transport is available and connected Usage:\n`csharp\nusing Whizbang Transports AzureServiceBus;\nbuilder Services AddAzureServiceBusTransport(connectionString);\nbuilder Services AddAzureServiceBusHealthChecks();  // ‚≠ê Register health check\n// Expose health endpoint\napp MapHealthChecks(\"/health\");\n`\nImplementation:\n`csharp\npublic class AzureServiceBusHealthCheck(ITransport transport) : IHealthCheck {\n  public Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken\n  ) {\n    // Verify transport is Azure Service Bus\n    if (transport is not AzureServiceBusTransport) {\n      return Task FromResult(\n        HealthCheckResult Degraded(\"Transport is not Azure Service Bus\")\n      );\n    }\n    // Transport is instantiated and not disposed\n    return Task FromResult(\n      HealthCheckResult Healthy(\"Azure Service Bus transport is available\")\n    );\n  }\n}\n`\nStatus Levels:\nHealthy: Transport instantiated and available\nDegraded: Wrong transport type registered\nUnhealthy: Transport disposed or unavailable\nPostgreSQL Health Check\nPurpose: Verify database connectivity and query execution Usage:\n`csharp\nusing Whizbang Data Dapper Postgres;\nbuilder Services AddPostgresConnection(connectionString);\nbuilder Services AddPostgresHealthChecks();  // ‚≠ê Register health check\napp MapHealthChecks(\"/health\");\n`\nImplementation:\n`csharp\npublic class PostgresHealthCheck(IDbConnectionFactory connectionFactory) : IHealthCheck {\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken\n  ) {\n    try {\n      using var connection = await connectionFactory",
        "startIndex": 2146,
        "preview": "load balancer, monitoring) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ HTTP GET /health ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-2",
        "text": "query execution Usage: `csharp using Whizbang Data Dapper Postgres; builder Services AddPostgresConnection(connectionString); builder Services AddPostgresHealthChecks(); // ‚≠ê Register health check app MapHealthChecks(\"/health\"); ` Implementation: `csharp public class PostgresHealthCheck(IDbConnectionFactory connectionFactory) : IHealthCheck { public async Task<HealthCheckResult> CheckHealthAsync( HealthCheckContext context, CancellationToken cancellationToken ) { try { using var connection = await connectionFactory CreateConnectionAsync(cancellationToken);\n      // Execute simple query to verify database is accessible\n      _ = await connection ExecuteScalarAsync(\"SELECT 1\");\n      return HealthCheckResult Healthy(\"PostgreSQL database is accessible\");\n    } catch (Exception ex) {\n      return HealthCheckResult Unhealthy(\"PostgreSQL database is not accessible\", ex);\n    }\n  }\n}\n`\nWhat It Checks:\n‚úÖ Connection factory can create connections\n‚úÖ Database accepts queries\n‚úÖ Network connectivity to database\nStatus Levels:\nHealthy: Database accessible and responsive\nUnhealthy: Connection failed or query timed out\nService Bus Readiness Check\nPurpose: Cached transport readiness check with initialization verification Usage:\n`csharp\nusing Whizbang Hosting Azure ServiceBus;\nbuilder Services AddSingleton<ITransportReadinessCheck, ServiceBusReadinessCheck>();\n// Use in startup validation\nvar readinessCheck = app Services GetRequiredService<ITransportReadinessCheck>();\nif ( await readinessCheck IsReadyAsync()) {\n  throw new InvalidOperationException(\"Service Bus is not ready\");\n}\n`\nImplementation:\n`csharp\npublic class ServiceBusReadinessCheck : ITransportReadinessCheck {\n  private DateTimeOffset _lastSuccessfulCheck;\n  private readonly TimeSpan _cacheDuration = TimeSpan FromSeconds(30);\n  public async Task<bool> IsReadyAsync(CancellationToken cancellationToken) {\n    // 1 Check if transport initialized\n    if ( _transport IsInitialized) {\n      return false;\n    }\n    // 2 Check cache (30-second TTL)\n    if (_lastSuccessfulCheck HasValue &&\n        DateTimeOffset UtcNow - _lastSuccessfulCheck Value < _cacheDuration) {\n      return true;  // Cached result\n    }\n    // 3 Verify ServiceBusClient is open\n    if (_client IsClosed) {\n      return false;\n    }\n    // 4 Cache successful check\n    _lastSuccessfulCheck = DateTimeOffset UtcNow;\n    return true;\n  }\n}\n`\nBenefits:\n30-second cache reduces health check overhead\nVerifies transport initialization (not just registration)\nThread-safe with double-checked locking\n---\nRegistration Patterns\nBasic Registration\n`csharp\nbuilder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\"azure_servicebus\") AddCheck<PostgresHealthCheck>(\"postgres\");\napp",
        "startIndex": 5052,
        "preview": "query execution Usage: `csharp using Whizbang Data Dapper Postgres; builder Services AddPostgresConnection(connectionString); builder Services AddPost..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-3",
        "text": "if (_client IsClosed) { return false; } // 4 Cache successful check _lastSuccessfulCheck = DateTimeOffset UtcNow; return true; } } ` Benefits: 30-second cache reduces health check overhead Verifies transport initialization (not just registration) Thread-safe with double-checked locking --- Registration Patterns Basic Registration `csharp builder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\"azure_servicebus\") AddCheck<PostgresHealthCheck>(\"postgres\"); app MapHealthChecks(\"/health\");\n`\nEndpoint Output:\n`json\n{\n  \"status\": \"Healthy\",\n  \"results\": {\n    \"azure_servicebus\": {\n      \"status\": \"Healthy\",\n      \"description\": \"Azure Service Bus transport is available\"\n    },\n    \"postgres\": {\n      \"status\": \"Healthy\",\n      \"description\": \"PostgreSQL database is accessible\"\n    }\n  }\n}\n`\nDetailed Health Checks\n`csharp\nbuilder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\n    name: \"azure_servicebus\",\n    failureStatus: HealthStatus Degraded,  // Degraded instead of Unhealthy\n    tags: [\"ready\", \"live\"]  // Kubernetes readiness and liveness\n  ) AddCheck<PostgresHealthCheck>(\n    name: \"postgres\",\n    failureStatus: HealthStatus Unhealthy,\n    tags: [\"ready\"]  // Required for readiness, not liveness\n  );\n// Readiness endpoint (includes postgres)\napp MapHealthChecks(\"/health/ready\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"ready\")\n});\n// Liveness endpoint (excludes postgres)\napp MapHealthChecks(\"/health/live\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"live\")\n});\n`\nKubernetes Usage:\n`yaml\ndeployment yaml\nlivenessProbe:\n  httpGet:\n    path: /health/live\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 10\nreadinessProbe:\n  httpGet:\n    path: /health/ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 5\n`\n---\nCustom Health Checks\nImplementing IHealthCheck\n`csharp\nusing Microsoft Extensions Diagnostics HealthChecks;\npublic class RedisHealthCheck : IHealthCheck {\n  private readonly IConnectionMultiplexer _redis;\n  public RedisHealthCheck(IConnectionMultiplexer redis) {\n    _redis = redis;\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken = default\n  ) {\n    try {\n      // Check Redis connectivity\n      var db = _redis GetDatabase();\n      await db PingAsync();\n      // Check specific keys if needed\n      var keyExists = await db KeyExistsAsync(\"health-check-key\");\n      var data = new Dictionary<string, object> {\n        { \"connected\", true },\n        { \"endpoints\", _redis GetEndPoints() Length }\n      };\n      return HealthCheckResult Healthy(\n        \"Redis is accessible\",\n        data: data\n      );\n    } catch (Exception ex) {\n      return HealthCheckResult",
        "startIndex": 7272,
        "preview": "if (_client IsClosed) { return false; } // 4 Cache successful check _lastSuccessfulCheck = DateTimeOffset UtcNow; return true; } } ` Benefits: 30-seco..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-4",
        "text": "GetDatabase(); await db PingAsync(); // Check specific keys if needed var keyExists = await db KeyExistsAsync(\"health-check-key\"); var data = new Dictionary<string, object> { { \"connected\", true }, { \"endpoints\", _redis GetEndPoints() Length } }; return HealthCheckResult Healthy( \"Redis is accessible\", data: data ); } catch (Exception ex) { return HealthCheckResult Unhealthy(\n        \"Redis is not accessible\",\n        exception: ex\n      );\n    }\n  }\n}\n`\nRegistration:\n`csharp\nbuilder Services AddSingleton<IConnectionMultiplexer>(/ Redis connection /);\nbuilder Services AddHealthChecks() AddCheck<RedisHealthCheck>(\"redis\");\n`\nTimeout and Failure Handling\n`csharp\npublic class ExternalApiHealthCheck : IHealthCheck {\n  private readonly HttpClient _httpClient;\n  private readonly TimeSpan _timeout = TimeSpan FromSeconds(5);\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken\n  ) {\n    using var cts = CancellationTokenSource CreateLinkedTokenSource(cancellationToken);\n    cts CancelAfter(_timeout);\n    try {\n      var response = await _httpClient GetAsync(\"/health\", cts Token);\n      if (response IsSuccessStatusCode) {\n        return HealthCheckResult Healthy(\"External API is responsive\");\n      }\n      return HealthCheckResult Degraded(\n        $\"External API returned {response StatusCode}\"\n      );\n    } catch (OperationCanceledException) {\n      return HealthCheckResult Degraded(\"External API timed out after 5 seconds\");\n    } catch (Exception ex) {\n      return HealthCheckResult Unhealthy(\"External API is not accessible\", ex);\n    }\n  }\n}\n`\n---\nAspire Dashboard Integration\nAutomatic Health Monitoring\nWhen using NET Aspire, health checks are automatically wired to the dashboard:\n`csharp\n// Service Program cs\nbuilder AddServiceDefaults();  // ‚≠ê Enables Aspire integration\nbuilder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\"azure_servicebus\") AddCheck<PostgresHealthCheck>(\"postgres\");\nvar app = builder Build();\napp MapDefaultEndpoints();  // ‚≠ê Exposes /health endpoint\napp Run();\n`\nAspire Dashboard (http://localhost:15888):\nResources Tab: Shows service health status (üü¢ Healthy, üü° Degraded, üî¥ Unhealthy)\nHealth History: Track health over time\nFailure Alerts: Visual indicators for unhealthy services\n---\nAdvanced Patterns\nStartup Health Check\n`csharp\nvar builder = WebApplication CreateBuilder(args);\n// Register services and health checks\nbuilder Services AddAzureServiceBusTransport(connectionString);\nbuilder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\"azure_servicebus\");\nvar app = builder Build();\n// Validate health BEFORE accepting traffic\nvar healthCheckService = app Services",
        "startIndex": 9588,
        "preview": "GetDatabase(); await db PingAsync(); // Check specific keys if needed var keyExists = await db KeyExistsAsync(\"health-check-key\"); var data = new Dict..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-5",
        "text": "over time Failure Alerts: Visual indicators for unhealthy services --- Advanced Patterns Startup Health Check `csharp var builder = WebApplication CreateBuilder(args); // Register services and health checks builder Services AddAzureServiceBusTransport(connectionString); builder Services AddHealthChecks() AddCheck<AzureServiceBusHealthCheck>(\"azure_servicebus\"); var app = builder Build(); // Validate health BEFORE accepting traffic var healthCheckService = app Services GetRequiredService<HealthCheckService>();\nvar healthReport = await healthCheckService CheckHealthAsync();\nif (healthReport Status = HealthStatus Healthy) {\n  Console WriteLine(\"‚ùå Application is not healthy - failing startup\");\n  Console WriteLine($\"Status: {healthReport Status}\");\n  foreach (var (key, entry) in healthReport Entries) {\n    if (entry Status = HealthStatus Healthy) {\n      Console WriteLine($\"  - {key}: {entry Status} - {entry Description}\");\n    }\n  }\n  Environment Exit(1);  // Fail fast\n}\nConsole WriteLine(\"‚úÖ All health checks passed - starting application\");\napp Run();\n`\nBenefit: Prevent application from starting if dependencies are unavailable Cached Health Checks\n`csharp\npublic class CachedDatabaseHealthCheck : IHealthCheck {\n  private readonly IDbConnectionFactory _connectionFactory;\n  private DateTimeOffset _lastCheck;\n  private HealthCheckResult _cachedResult;\n  private readonly TimeSpan _cacheDuration = TimeSpan FromMinutes(1);\n  private readonly SemaphoreSlim _lock = new(1, 1);\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken\n  ) {\n    // Return cached result if available and fresh\n    if (_cachedResult = null &&\n        _lastCheck HasValue &&\n        DateTimeOffset UtcNow - _lastCheck Value < _cacheDuration) {\n      return _cachedResult;\n    }\n    await _lock WaitAsync(cancellationToken);\n    try {\n      // Double-check cache after acquiring lock\n      if (_cachedResult = null &&\n          _lastCheck HasValue &&\n          DateTimeOffset UtcNow - _lastCheck Value < _cacheDuration) {\n        return _cachedResult;\n      }\n      // Perform actual health check\n      using var connection = await _connectionFactory CreateConnectionAsync(cancellationToken);\n      _ = await connection ExecuteScalarAsync(\"SELECT 1\");\n      _cachedResult = HealthCheckResult Healthy(\"Database is accessible\");\n      _lastCheck = DateTimeOffset UtcNow;\n      return _cachedResult;\n    } catch (Exception ex) {\n      _cachedResult = HealthCheckResult Unhealthy(\"Database is not accessible\", ex);\n      _lastCheck = DateTimeOffset UtcNow;\n      return _cachedResult;\n    } finally {\n      _lock",
        "startIndex": 11967,
        "preview": "over time Failure Alerts: Visual indicators for unhealthy services --- Advanced Patterns Startup Health Check `csharp var builder = WebApplication Cre..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-6",
        "text": "health check using var connection = await _connectionFactory CreateConnectionAsync(cancellationToken); _ = await connection ExecuteScalarAsync(\"SELECT 1\"); _cachedResult = HealthCheckResult Healthy(\"Database is accessible\"); _lastCheck = DateTimeOffset UtcNow; return _cachedResult; } catch (Exception ex) { _cachedResult = HealthCheckResult Unhealthy(\"Database is not accessible\", ex); _lastCheck = DateTimeOffset UtcNow; return _cachedResult; } finally { _lock Release();\n    }\n  }\n}\n`\nUse Case: Reduce database load from frequent health checks (Kubernetes polls every 5-10 seconds) Composite Health Checks\n`csharp\npublic class ApplicationHealthCheck : IHealthCheck {\n  private readonly IHealthCheck[] _checks;\n  public ApplicationHealthCheck(\n    AzureServiceBusHealthCheck transportCheck,\n    PostgresHealthCheck databaseCheck,\n    RedisHealthCheck cacheCheck\n  ) {\n    _checks = new IHealthCheck[] { transportCheck, databaseCheck, cacheCheck };\n  }\n  public async Task<HealthCheckResult> CheckHealthAsync(\n    HealthCheckContext context,\n    CancellationToken cancellationToken\n  ) {\n    var tasks = _checks Select(check =>\n      check CheckHealthAsync(context, cancellationToken)\n    );\n    var results = await Task WhenAll(tasks);\n    var unhealthyResults = results Where(r => r Status == HealthStatus Unhealthy) ToList();\n    var degradedResults = results Where(r => r Status == HealthStatus Degraded) ToList();\n    if (unhealthyResults Any()) {\n      return HealthCheckResult Unhealthy(\n        $\"{unhealthyResults Count} component(s) unhealthy\"\n      );\n    }\n    if (degradedResults Any()) {\n      return HealthCheckResult Degraded(\n        $\"{degradedResults Count} component(s) degraded\"\n      );\n    }\n    return HealthCheckResult",
        "startIndex": 14173,
        "preview": "health check using var connection = await _connectionFactory CreateConnectionAsync(cancellationToken); _ = await connection ExecuteScalarAsync(\"SELECT..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-7",
        "text": "= results Where(r => r Status == HealthStatus Unhealthy) ToList(); var degradedResults = results Where(r => r Status == HealthStatus Degraded) ToList(); if (unhealthyResults Any()) { return HealthCheckResult Unhealthy( $\"{unhealthyResults Count} component(s) unhealthy\" ); } if (degradedResults Any()) { return HealthCheckResult Degraded( $\"{degradedResults Count} component(s) degraded\" ); } return HealthCheckResult Healthy(\"All components healthy\");\n  }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Register health checks for all dependencies (database, cache, transport)\n‚úÖ Use tags for readiness vs liveness (readiness includes dependencies, liveness doesn't)\n‚úÖ Cache expensive checks (database queries, external API calls)\n‚úÖ Use timeouts to prevent health checks from blocking\n‚úÖ Validate health on startup (fail fast if misconfigured)\n‚úÖ Monitor health in Aspire dashboard during development\n‚úÖ Return detailed status (Healthy, Degraded, Unhealthy with descriptions)\nDON'T ‚ùå\n‚ùå Perform expensive operations in health checks (use caching)\n‚ùå Include authentication in liveness checks (should always succeed if app is running)\n‚ùå Ignore health check failures in logs (investigate and fix)\n‚ùå Use default /healthz endpoint (configure specific paths like /health/ready)\n‚ùå Skip health checks for \"optional\" dependencies (mark as Degraded instead)\n‚ùå Block application startup on non-critical dependencies\n---\nTroubleshooting\nProblem: Health Check Always Returns Unhealthy\nSymptoms: Health endpoint returns 503 Service Unavailable Causes:\nDependency actually unavailable (database down, Service Bus unreachable)\nHealth check timeout too short\nCaching not working (re-checking every request)\nSolution:\n`csharp\n// 1 Check logs for actual failure reason\nvar healthReport = await healthCheckService CheckHealthAsync();\nforeach (var (key, entry) in healthReport Entries) {\n  logger LogError(\"Health check {Name}: {Status} - {Description} - {Exception}\",\n    key, entry Status, entry Description, entry Exception);\n}\n// 2 Increase timeout\nbuilder Services AddHealthChecks() AddCheck<PostgresHealthCheck>(\"postgres\", timeout: TimeSpan FromSeconds(30));\n// 3 Verify caching logic\nif (_lastCheck HasValue) {\n  var age = DateTimeOffset UtcNow - _lastCheck Value;\n  logger",
        "startIndex": 15456,
        "preview": "= results Where(r => r Status == HealthStatus Unhealthy) ToList(); var degradedResults = results Where(r => r Status == HealthStatus Degraded) ToList(..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-8",
        "text": "in healthReport Entries) { logger LogError(\"Health check {Name}: {Status} - {Description} - {Exception}\", key, entry Status, entry Description, entry Exception); } // 2 Increase timeout builder Services AddHealthChecks() AddCheck<PostgresHealthCheck>(\"postgres\", timeout: TimeSpan FromSeconds(30)); // 3 Verify caching logic if (_lastCheck HasValue) { var age = DateTimeOffset UtcNow - _lastCheck Value; logger LogDebug(\"Cache age: {Age}, Duration: {Duration}\", age, _cacheDuration);\n}\n`\nProblem: Kubernetes Keeps Restarting Pod\nSymptoms: Pod repeatedly restarted with \"Liveness probe failed\" in events Cause: Liveness check includes database or external dependencies (shouldn't) Solution:\n`csharp\n// Liveness should only check app is running (no external dependencies)\nbuilder Services AddHealthChecks() AddCheck(\"self\", () => HealthCheckResult Healthy(\"App is running\"), tags: [\"live\"]) AddCheck<PostgresHealthCheck>(\"postgres\", tags: [\"ready\"]);  // Readiness only\n// Separate endpoints\napp MapHealthChecks(\"/health/live\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"live\")\n});\napp MapHealthChecks(\"/health/ready\", new HealthCheckOptions {\n  Predicate = check => check Tags Contains(\"ready\")\n});\n`\nProblem: Health Checks Cause Database Overload\nSymptoms: Database CPU spikes from health check queries Cause: Kubernetes polling every 5 seconds across 100 pods = 20 queries/second Solution:\n`csharp\n// Add caching to reduce database load\npublic class CachedPostgresHealthCheck : PostgresHealthCheck {\n  private DateTimeOffset _lastCheck;\n  private HealthCheckResult _cachedResult;\n  private readonly TimeSpan _cacheDuration = TimeSpan FromSeconds(30);  // ‚≠ê Cache for 30 seconds\n  public override async Task<HealthCheckResult> CheckHealthAsync( ) {\n    if (_cachedResult = null &&\n        _lastCheck HasValue &&\n        DateTimeOffset UtcNow - _lastCheck Value < _cacheDuration) {\n      return _cachedResult;  // Return cached result\n    }\n    _cachedResult = await base CheckHealthAsync(context, cancellationToken);\n    _lastCheck = DateTimeOffset UtcNow;\n    return _cachedResult;\n  }\n}\n`\n---\nFurther Reading\nInfrastructure:\nAspire Integration - NET Aspire orchestration and dashboard\nPolicies - Policy-based routing and decisions\nTransports:\nAzure Service Bus Transport - Transport health checks\nData Access:\nDapper + PostgreSQL - Database health checks\nExternal Resources:\nASP NET Core Health Checks\nKubernetes Liveness and Readiness Probes\n---\nVersion 0",
        "startIndex": 17284,
        "preview": "in healthReport Entries) { logger LogError(\"Health check {Name}: {Status} - {Description} - {Exception}\", key, entry Status, entry Description, entry ..."
      },
      {
        "id": "v0.1.0/infrastructure/health-checks-chunk-9",
        "text": "Further Reading Infrastructure: Aspire Integration - NET Aspire orchestration and dashboard Policies - Policy-based routing and decisions Transports: Azure Service Bus Transport - Transport health checks Data Access: Dapper + PostgreSQL - Database health checks External Resources: ASP NET Core Health Checks Kubernetes Liveness and Readiness Probes --- Version 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 5211,
        "preview": "Further Reading Infrastructure: Aspire Integration - NET Aspire orchestration and dashboard Policies - Policy-based routing and decisions Transports: ..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/infrastructure/policies",
    "title": "Policy-Based Routing",
    "category": "Infrastructure",
    "url": "/docs/v0.1.0/infrastructure/policies",
    "chunks": [
      {
        "id": "v0.1.0/infrastructure/policies-chunk-0",
        "text": "Policy-Based Routing\nPolicy-based routing enables dynamic message configuration based on runtime conditions Policies evaluate message context (type, aggregate ID, tenant, environment) and return routing configuration (topics, execution strategies, partitioning) without hardcoding business logic into handlers Why Policies Policies decouple routing decisions from business logic:\n| Without Policies | With Policies | Benefit |\n|------------------|---------------|---------|\n| Hardcoded Routes | Dynamic predicates | Flexible configuration |\n| If/Else Chains | First-match evaluation | Clean code |\n| Per-Handler Config | Centralized policy engine | Single source of truth |\n| No Audit Trail | PolicyDecisionTrail | Full observability |\n| Multi-Tenant Logic Scattered | Tenant-based policies | Centralized multi-tenancy |\nUse Cases:\n‚úÖ Multi-Tenancy - Route messages to tenant-specific topics/databases\n‚úÖ Environment-Based Routing - Different config for dev/staging/prod\n‚úÖ Aggregate-Based Partitioning - Route by OrderId, CustomerId, etc ‚úÖ Execution Strategies - Serial vs parallel based on message type\n‚úÖ Feature Flags - Enable/disable routing based on tags/metadata\n---\nArchitecture\nPolicy Evaluation Flow\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Message Processing                                    ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  1 Rent PolicyContext from pool                       ‚îÇ\n‚îÇ     context = PolicyContextPool Rent(message, )     ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  2 Evaluate policies                                  ‚îÇ\n‚îÇ     config = await policyEngine MatchAsync(context)    ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  3 Use configuration                                  ‚îÇ\n‚îÇ     - Topic routing                                    ‚îÇ\n‚îÇ     - Execution strategy                               ‚îÇ\n‚îÇ     - Partitioning                                     ‚îÇ\n‚îÇ     - Concurrency                                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nPolicyEngine Evaluation:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  PolicyEngine MatchAsync(context)                      ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  Policies evaluated in order (first match wins):       ‚îÇ\n‚îÇ  ‚îú‚îÄ Policy 1: TenantRouting                            ‚îÇ\n‚îÇ  ‚îÇ  ‚îú‚îÄ Predicate: context",
        "startIndex": 0,
        "preview": "Policy-Based Routing\nPolicy-based routing enables dynamic message configuration based on runtime conditions Policies evaluate message context (type, a..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-1",
        "text": "configuration ‚îÇ ‚îÇ - Topic routing ‚îÇ ‚îÇ - Execution strategy ‚îÇ ‚îÇ - Partitioning ‚îÇ ‚îÇ - Concurrency ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò PolicyEngine Evaluation: ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ PolicyEngine MatchAsync(context) ‚îÇ ‚îÇ ‚îÇ ‚îÇ Policies evaluated in order (first match wins): ‚îÇ ‚îÇ ‚îú‚îÄ Policy 1: TenantRouting ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Predicate: context GetMetadata(\"tenantId\") == \"tenant-a\"\n‚îÇ  ‚îÇ  ‚îú‚îÄ Matched: ‚úÖ                                     ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ Configuration: Topic = \"tenant-a-events\"        ‚îÇ\n‚îÇ  ‚îÇ                                                      ‚îÇ\n‚îÇ  ‚îÇ  ‚≠ê RETURN (first match - skip remaining policies)  ‚îÇ\n‚îÇ  ‚îÇ                                                      ‚îÇ\n‚îÇ  ‚îú‚îÄ Policy 2: EnvironmentRouting (skipped)             ‚îÇ\n‚îÇ  ‚îî‚îÄ Policy 3: DefaultRouting (skipped)                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nPolicyDecisionTrail (Observability):\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  context Trail Decisions                               ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  [0] PolicyName: \"TenantRouting\"                       ‚îÇ\n‚îÇ      Rule: \"tenantId == tenant-a\"                      ‚îÇ\n‚îÇ      Matched: ‚úÖ                                       ‚îÇ\n‚îÇ      Configuration: { Topic: \"tenant-a-events\" }       ‚îÇ\n‚îÇ      Reason: \"Tenant-based routing matched\"            ‚îÇ\n‚îÇ      Timestamp: 2024-12-12T10:30:45Z                   ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  [1] PolicyName: \"EnvironmentRouting\"                  ‚îÇ\n‚îÇ      Rule: \"environment == production\"                 ‚îÇ\n‚îÇ      Matched: ‚ùå                                       ‚îÇ\n‚îÇ      Reason: \"Environment is development\"              ‚îÇ\n‚îÇ      Timestamp: 2024-12-12T10:30:45Z                   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nCore Components\nPolicyEngine\nPurpose: Evaluates policies in order, returns first match Registration:\n`csharp\nbuilder Services AddSingleton<IPolicyEngine, PolicyEngine>();\n`\nUsage:\n`csharp\nvar policyEngine = new PolicyEngine();\n// Add policies (evaluated in order)\npolicyEngine AddPolicy(\n  name: \"TenantRouting\",\n  predicate: context =>\n    context GetMetadata(\"tenantId\") ToString() == \"tenant-a\",\n  configure: config =>\n    config PublishToServiceBus(\"tenant-a-events\")\n);\npolicyEngine AddPolicy(\n  name: \"DefaultRouting\",\n  predicate: context => true,  // Always matches (fallback)\n  configure: config =>\n    config PublishToServiceBus(\"default-events\")\n);\n// Evaluate policies\nvar config = await policyEngine MatchAsync(context);\n`\nEvaluation Rules:\nPolicies evaluated in registration order\nFirst matched policy returns configuration\nSubsequent policies skipped\nIf no policies match, returns null\nPolicyContext\nPurpose: Universal context with message, envelope, services, environment",
        "startIndex": 2449,
        "preview": "configuration ‚îÇ ‚îÇ - Topic routing ‚îÇ ‚îÇ - Execution strategy ‚îÇ ‚îÇ - Partitioning ‚îÇ ‚îÇ - Concurrency ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-2",
        "text": "// Always matches (fallback) configure: config => config PublishToServiceBus(\"default-events\") ); // Evaluate policies var config = await policyEngine MatchAsync(context); ` Evaluation Rules: Policies evaluated in registration order First matched policy returns configuration Subsequent policies skipped If no policies match, returns null PolicyContext Purpose: Universal context with message, envelope, services, environment Properties:\n`csharp\npublic class PolicyContext {\n  public object Message { get; }              // The message being processed\n  public Type MessageType { get; }            // Runtime type of message\n  public IMessageEnvelope Envelope { get; }  // Envelope with metadata\n  public IServiceProvider Services { get; }  // DI container\n  public string Environment { get; }          // \"development\", \"production\", etc public DateTimeOffset ExecutionTime { get; } // When processing started\n  public PolicyDecisionTrail Trail { get; }   // Decision audit trail\n}\n`\nHelper Methods:\n`csharp\n// Service resolution\nvar repository = context GetService<IOrderRepository>();\n// Metadata access\nvar tenantId = context GetMetadata(\"tenantId\");\nvar hasHighPriority = context HasTag(\"high-priority\");\nvar isUrgent = context HasFlag(MessageFlags Urgent);\n// Aggregate matching\nbool isOrderMessage = context MatchesAggregate<Order>();\n// Aggregate ID extraction (zero reflection)\nvar orderId = context GetAggregateId();  // Requires [AggregateId] attribute\n`\nPooling:\n`csharp\n// Rent from pool\nvar context = PolicyContextPool Rent(message, envelope, services, \"production\");\ntry {\n  var config = await policyEngine MatchAsync(context);\n  // Use config } finally {\n  // Always return to pool\n  PolicyContextPool Return(context);\n}\n`\nPolicyDecisionTrail\nPurpose: Records all policy decisions for debugging and time-travel Usage:\n`csharp\n// Automatic recording by PolicyEngine\ncontext Trail RecordDecision(\n  policyName: \"TenantRouting\",\n  rule: \"tenantId == tenant-a\",\n  matched: true,\n  configuration: config,\n  reason: \"Tenant-based routing matched\"\n);\n// Query trail\nvar matchedPolicies = context Trail GetMatchedRules();\nvar unmatchedPolicies = context Trail GetUnmatchedRules();\nforeach (var decision in context Trail Decisions) {\n  Console WriteLine($\"{decision PolicyName}: {decision Matched} - {decision",
        "startIndex": 4937,
        "preview": "// Always matches (fallback) configure: config => config PublishToServiceBus(\"default-events\") ); // Evaluate policies var config = await policyEngine..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-3",
        "text": "by PolicyEngine context Trail RecordDecision( policyName: \"TenantRouting\", rule: \"tenantId == tenant-a\", matched: true, configuration: config, reason: \"Tenant-based routing matched\" ); // Query trail var matchedPolicies = context Trail GetMatchedRules(); var unmatchedPolicies = context Trail GetUnmatchedRules(); foreach (var decision in context Trail Decisions) { Console WriteLine($\"{decision PolicyName}: {decision Matched} - {decision Reason}\");\n}\n`\nBenefits:\nDebugging: See why specific configuration was applied\nAuditing: Track policy decisions over time\nTime-Travel: Replay message processing with decision history\nPolicyConfiguration\nPurpose: Routing and execution configuration returned by matched policy Properties:\n`csharp\npublic class PolicyConfiguration {\n  // Publishing (outbound)\n  public List<PublishTarget> PublishTargets { get; }\n  // Subscribing (inbound)\n  public List<SubscriptionTarget> SubscriptionTargets { get; }\n  // Stream configuration\n  public string Topic { get; }\n  public string StreamKey { get; }\n  // Execution strategy\n  public Type ExecutionStrategyType { get; }\n  public Type PartitionRouterType { get; }\n  public int PartitionCount { get; }\n  public int MaxConcurrency { get; }\n  // Persistence size limits\n  public int MaxDataSizeBytes { get; }\n  public bool SuppressSizeWarnings { get; }\n  public bool ThrowOnSizeExceeded { get; }\n}\n`\nFluent API:\n`csharp\nconfigure: config => config PublishToServiceBus(\"order-events\") UseStreamKey(\"order-{aggregateId}\") UseExecutionStrategy<SerialExecutor>() UsePartitionRouter<HashPartitionRouter>() WithPartitions(count: 100) WithConcurrency(maxConcurrency: 10) WithPersistenceSize(maxDataSizeBytes: 7000, throwOnExceeded: true)\n`\n---\nCommon Policies\nMulti-Tenant Routing\n`csharp\npolicyEngine AddPolicy(\n  name: \"TenantARouting\",\n  predicate: context =>\n    context GetMetadata(\"tenantId\") ToString() == \"tenant-a\",\n  configure: config => config PublishToServiceBus(\"tenant-a-events\") UseStreamKey(\"tenant-a-{aggregateId}\")\n);\npolicyEngine AddPolicy(\n  name: \"TenantBRouting\",\n  predicate: context =>\n    context GetMetadata(\"tenantId\") ToString() == \"tenant-b\",\n  configure: config => config PublishToServiceBus(\"tenant-b-events\") UseStreamKey(\"tenant-b-{aggregateId}\")\n);\n// Fallback for unknown tenants\npolicyEngine AddPolicy(\n  name: \"DefaultTenantRouting\",\n  predicate: context => true,\n  configure: config => config PublishToServiceBus(\"default-events\")\n);\n`\nEnvironment-Based Routing\n`csharp\npolicyEngine AddPolicy(\n  name: \"ProductionRouting\",\n  predicate: context => context Environment == \"production\",\n  configure: config => config PublishToServiceBus(\"prod-events\") WithConcurrency(maxConcurrency: 50)\n);\npolicyEngine AddPolicy(\n  name: \"StagingRouting\",\n  predicate: context => context Environment == \"staging\",\n  configure: config => config PublishToServiceBus(\"staging-events\") WithConcurrency(maxConcurrency: 10)\n);\npolicyEngine",
        "startIndex": 6837,
        "preview": "by PolicyEngine context Trail RecordDecision( policyName: \"TenantRouting\", rule: \"tenantId == tenant-a\", matched: true, configuration: config, reason:..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-4",
        "text": "true, configure: config => config PublishToServiceBus(\"default-events\") ); ` Environment-Based Routing `csharp policyEngine AddPolicy( name: \"ProductionRouting\", predicate: context => context Environment == \"production\", configure: config => config PublishToServiceBus(\"prod-events\") WithConcurrency(maxConcurrency: 50) ); policyEngine AddPolicy( name: \"StagingRouting\", predicate: context => context Environment == \"staging\", configure: config => config PublishToServiceBus(\"staging-events\") WithConcurrency(maxConcurrency: 10) ); policyEngine AddPolicy(\n  name: \"DevelopmentRouting\",\n  predicate: context => context Environment == \"development\",\n  configure: config => config PublishToServiceBus(\"dev-events\") WithConcurrency(maxConcurrency: 1)  // Serial processing in dev\n);\n`\nAggregate-Based Partitioning\n`csharp\npolicyEngine AddPolicy(\n  name: \"OrderPartitioning\",\n  predicate: context => context MatchesAggregate<Order>(),\n  configure: config => config UseStreamKey(\"order-{aggregateId}\") UsePartitionRouter<HashPartitionRouter>() WithPartitions(count: 100)\n);\npolicyEngine AddPolicy(\n  name: \"CustomerPartitioning\",\n  predicate: context => context MatchesAggregate<Customer>(),\n  configure: config => config UseStreamKey(\"customer-{aggregateId}\") UsePartitionRouter<HashPartitionRouter>() WithPartitions(count: 50)\n);\n`\nMessage Type-Based Execution\n`csharp\npolicyEngine AddPolicy(\n  name: \"BulkImportExecutionStrategy\",\n  predicate: context => context MessageType Name Contains(\"BulkImport\"),\n  configure: config => config UseExecutionStrategy<ParallelExecutor>() WithConcurrency(maxConcurrency: 100)\n);\npolicyEngine AddPolicy(\n  name: \"OrderExecutionStrategy\",\n  predicate: context => context MessageType Name Contains(\"Order\"),\n  configure: config => config UseExecutionStrategy<SerialExecutor>()  // Strict ordering for orders\n);\n`\nTag-Based Routing\n`csharp\npolicyEngine AddPolicy(\n  name: \"HighPriorityRouting\",\n  predicate: context => context HasTag(\"high-priority\"),\n  configure: config => config PublishToServiceBus(\"priority-events\") WithConcurrency(maxConcurrency: 100)\n);\npolicyEngine AddPolicy(\n  name: \"ArchivalRouting\",\n  predicate: context => context HasTag(\"archival\"),\n  configure: config => config PublishToServiceBus(\"archive-events\") WithConcurrency(maxConcurrency: 1)  // Low priority\n);\n`\n---\nAdvanced Patterns\nComposite Policies\n`csharp\npolicyEngine AddPolicy(\n  name: \"HighValueOrderRouting\",\n  predicate: context => {\n    // Complex predicate with multiple conditions\n    bool isOrder = context MatchesAggregate<Order>();\n    bool isHighValue = context GetMetadata(\"totalAmount\") is decimal amount && amount > 10000;\n    bool isProduction = context Environment == \"production\";\n    return isOrder && isHighValue && isProduction;\n  },\n  configure: config => config PublishToServiceBus(\"high-value-orders\") UseExecutionStrategy<SerialExecutor>() WithConcurrency(maxConcurrency: 1)\n);\n`\nService-Injected Policies\n`csharp\npolicyEngine AddPolicy(\n  name: \"FeatureFlagRouting\",\n  predicate: context => {\n    // Resolve service from context\n    var featureFlags = context GetService<IFeatureFlagService>();\n    // Check feature flag\n    return featureFlags IsEnabled(\"new-event-routing\");\n  },\n  configure: config => config",
        "startIndex": 9397,
        "preview": "true, configure: config => config PublishToServiceBus(\"default-events\") ); ` Environment-Based Routing `csharp policyEngine AddPolicy( name: \"Producti..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-5",
        "text": "return isOrder && isHighValue && isProduction; }, configure: config => config PublishToServiceBus(\"high-value-orders\") UseExecutionStrategy<SerialExecutor>() WithConcurrency(maxConcurrency: 1) ); ` Service-Injected Policies `csharp policyEngine AddPolicy( name: \"FeatureFlagRouting\", predicate: context => { // Resolve service from context var featureFlags = context GetService<IFeatureFlagService>(); // Check feature flag return featureFlags IsEnabled(\"new-event-routing\"); }, configure: config => config PublishToServiceBus(\"new-events-topic\")\n);\n`\nTime-Based Policies\n`csharp\npolicyEngine AddPolicy(\n  name: \"PeakHoursRouting\",\n  predicate: context => {\n    var hour = context ExecutionTime Hour;\n    bool isPeakHours = hour >= 9 && hour <= 17;  // 9 AM - 5 PM\n    return isPeakHours;\n  },\n  configure: config => config WithConcurrency(maxConcurrency: 100)  // High concurrency during peak\n);\npolicyEngine AddPolicy(\n  name: \"OffHoursRouting\",\n  predicate: context => true,  // Fallback\n  configure: config => config WithConcurrency(maxConcurrency: 10)  // Lower concurrency off-peak\n);\n`\n---\nTesting Policies\nUnit Testing Predicates\n`csharp\n[Test]\npublic async Task TenantARouting_WithTenantA_MatchesAsync() {\n  // Arrange\n  var context = new PolicyContext(\n    message: new CreateOrder(),\n    envelope: CreateEnvelope(metadata: new Dictionary<string, object> {\n      [\"tenantId\"] = \"tenant-a\"\n    }),\n    services: null,\n    environment: \"production\"\n  );\n  var policyEngine = new PolicyEngine();\n  policyEngine AddPolicy(\n    name: \"TenantARouting\",\n    predicate: ctx => ctx GetMetadata(\"tenantId\") ToString() == \"tenant-a\",\n    configure: config => config PublishToServiceBus(\"tenant-a-events\")\n  );\n  // Act\n  var result = await policyEngine MatchAsync(context);\n  // Assert\n  await Assert That(result) IsNotNull();\n  await Assert That(result PublishTargets) HasCount() EqualTo(1);\n  await Assert That(result PublishTargets[0] Destination) IsEqualTo(\"tenant-a-events\");\n}\n`\nTesting Policy Order\n`csharp\n[Test]\npublic async Task PolicyEngine_FirstMatchWins_SkipsSubsequentPoliciesAsync() {\n  // Arrange\n  var context = new PolicyContext(new CreateOrder(), null, null, \"production\");\n  var policyEngine = new PolicyEngine();\n  policyEngine AddPolicy(\"FirstPolicy\",\n    predicate: ctx => true,  // Always matches\n    configure: config => config PublishToServiceBus(\"first-topic\")\n  );\n  policyEngine AddPolicy(\"SecondPolicy\",\n    predicate: ctx => true,  // Would match, but skipped\n    configure: config => config PublishToServiceBus(\"second-topic\")\n  );\n  // Act\n  var result = await policyEngine MatchAsync(context);\n  // Assert\n  await Assert That(result PublishTargets[0] Destination) IsEqualTo(\"first-topic\");\n  // Verify decision trail\n  var matched = context Trail GetMatchedRules() ToList();\n  await Assert That(matched)",
        "startIndex": 12196,
        "preview": "return isOrder && isHighValue && isProduction; }, configure: config => config PublishToServiceBus(\"high-value-orders\") UseExecutionStrategy<SerialExec..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-6",
        "text": "config PublishToServiceBus(\"first-topic\") ); policyEngine AddPolicy(\"SecondPolicy\", predicate: ctx => true, // Would match, but skipped configure: config => config PublishToServiceBus(\"second-topic\") ); // Act var result = await policyEngine MatchAsync(context); // Assert await Assert That(result PublishTargets[0] Destination) IsEqualTo(\"first-topic\"); // Verify decision trail var matched = context Trail GetMatchedRules() ToList(); await Assert That(matched) HasCount() EqualTo(1);\n  await Assert That(matched[0] PolicyName) IsEqualTo(\"FirstPolicy\");\n}\n`\nTesting PolicyDecisionTrail\n`csharp\n[Test]\npublic async Task PolicyEngine_RecordsDecisionTrail_ForAllPoliciesAsync() {\n  // Arrange\n  var context = new PolicyContext(new CreateOrder(), null, null, \"production\");\n  var policyEngine = new PolicyEngine();\n  policyEngine AddPolicy(\"Policy1\", ctx => false, config => { });\n  policyEngine AddPolicy(\"Policy2\", ctx => true, config => { });\n  // Act\n  await policyEngine MatchAsync(context);\n  // Assert\n  var decisions = context Trail Decisions ToList();\n  await Assert That(decisions) HasCount() EqualTo(2);\n  // First policy did not match\n  await Assert That(decisions[0] PolicyName) IsEqualTo(\"Policy1\");\n  await Assert That(decisions[0] Matched) IsFalse();\n  // Second policy matched\n  await Assert That(decisions[1] PolicyName) IsEqualTo(\"Policy2\");\n  await Assert That(decisions[1] Matched) IsTrue();\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Register policies in order of specificity (most specific first, fallback last)\n‚úÖ Use descriptive policy names for clarity in decision trails\n‚úÖ Return contexts to pool after policy evaluation\n‚úÖ Test policies with various inputs (unit test predicates)\n‚úÖ Use service injection for complex predicates (feature flags, config)\n‚úÖ Add fallback policy with predicate: ctx => true at end\n‚úÖ Monitor PolicyDecisionTrail in logs for debugging\nDON'T ‚ùå\n‚ùå Perform expensive operations in predicates (database queries, API calls)\n‚ùå Mutate context in predicates (side effects)\n‚ùå Throw exceptions in predicates (they're caught and logged as failures)\n‚ùå Skip returning contexts to pool (memory leak)\n‚ùå Hardcode business logic in predicates (use services instead)\n‚ùå Use policies for non-routing concerns (keep focused on configuration)\n---\nTroubleshooting\nProblem: No Policy Matches, Null Configuration\nSymptoms: MatchAsync() returns null, no configuration applied",
        "startIndex": 13570,
        "preview": "config PublishToServiceBus(\"first-topic\") ); policyEngine AddPolicy(\"SecondPolicy\", predicate: ctx => true, // Would match, but skipped configure: con..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-7",
        "text": "in predicates (they're caught and logged as failures) ‚ùå Skip returning contexts to pool (memory leak) ‚ùå Hardcode business logic in predicates (use services instead) ‚ùå Use policies for non-routing concerns (keep focused on configuration) --- Troubleshooting Problem: No Policy Matches, Null Configuration Symptoms: MatchAsync() returns null, no configuration applied Cause: No policies registered or all predicates return false Solution:\n`csharp\n// Add fallback policy\npolicyEngine AddPolicy(\n  name: \"DefaultPolicy\",\n  predicate: context => true,  // Always matches (last resort)\n  configure: config => config PublishToServiceBus(\"default-events\")\n);\n// Verify policies registered\nvar config = await policyEngine MatchAsync(context);\nif (config is null) {\n  logger LogWarning(\"No policy matched for message {MessageType}\", context MessageType Name);\n  // Check decision trail\n  foreach (var decision in context Trail Decisions) {\n    logger LogDebug(\"Policy {PolicyName}: {Matched} - {Reason}\",\n      decision PolicyName, decision Matched, decision Reason);\n  }\n}\n`\nProblem: Wrong Policy Matched\nSymptoms: Unexpected configuration returned Cause: Policy order incorrect (fallback registered before specific policies) Solution:\n`csharp\n// ‚ùå WRONG: Fallback first (always matches)\npolicyEngine AddPolicy(\"Fallback\", ctx => true, config => config PublishToServiceBus(\"default\"));\npolicyEngine AddPolicy(\"Specific\", ctx => ctx HasTag(\"high-priority\"), config => config PublishToServiceBus(\"priority\"));\n// ‚úÖ CORRECT: Specific first, fallback last\npolicyEngine AddPolicy(\"Specific\", ctx => ctx HasTag(\"high-priority\"), config => config PublishToServiceBus(\"priority\"));\npolicyEngine AddPolicy(\"Fallback\", ctx => true, config => config PublishToServiceBus(\"default\"));\n`\nProblem: Predicate Throws Exception\nSymptoms: Policy skipped with error in decision trail Cause: Exception thrown in predicate Solution:\n`csharp\n// Predicate exception is caught and logged\npolicyEngine AddPolicy(\n  name: \"FaultyPolicy\",\n  predicate: context => {\n    var metadata = context GetMetadata(\"value\");\n    return (int)metadata > 100;  // NullReferenceException if missing\n  },\n  configure: config => { }\n);\n// Decision trail shows failure\n// PolicyName: \"FaultyPolicy\"\n// Matched: false\n// Reason: \"Evaluation failed: Object reference not set to an instance of an object\"\n// FIX: Null-safe predicate\npolicyEngine",
        "startIndex": 16461,
        "preview": "in predicates (they're caught and logged as failures) ‚ùå Skip returning contexts to pool (memory leak) ‚ùå Hardcode business logic in predicates (use ser..."
      },
      {
        "id": "v0.1.0/infrastructure/policies-chunk-8",
        "text": "var metadata = context GetMetadata(\"value\"); return (int)metadata > 100; // NullReferenceException if missing }, configure: config => { } ); // Decision trail shows failure // PolicyName: \"FaultyPolicy\" // Matched: false // Reason: \"Evaluation failed: Object reference not set to an instance of an object\" // FIX: Null-safe predicate policyEngine AddPolicy(\n  name: \"SafePolicy\",\n  predicate: context => {\n    var metadata = context GetMetadata(\"value\");\n    return metadata is int value && value > 100;  // ‚úÖ Null-safe\n  },\n  configure: config => { }\n);\n`\n---\nFurther Reading\nInfrastructure:\nObject Pooling - PolicyContext pooling for performance\nAspire Integration - Service configuration injection\nCore Concepts:\nMessage Context - MessageId, CorrelationId, CausationId\nObservability - Distributed tracing with hops\nSource Generators:\nAggregate IDs - Zero-reflection aggregate ID extraction\nAdvanced:\nMulti-Tenancy - Tenant isolation patterns\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 18494,
        "preview": "var metadata = context GetMetadata(\"value\"); return (int)metadata > 100; // NullReferenceException if missing }, configure: config => { } ); // Decisi..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/infrastructure/pooling",
    "title": "Object Pooling",
    "category": "Infrastructure",
    "url": "/docs/v0.1.0/infrastructure/pooling",
    "chunks": [
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-0",
        "text": "Object Pooling\nObject pooling reduces heap allocations by reusing objects instead of creating new ones Whizbang uses pooling for frequently-allocated objects like PolicyContext to minimize garbage collection pressure and improve throughput in high-performance scenarios Why Object Pooling Pooling reduces GC overhead for frequently-created objects:\n| Without Pooling | With Pooling | Improvement |\n|-----------------|--------------|-------------|\n| 1M PolicyContext created | 1,024 PolicyContext created (max pool size) | ~999x fewer allocations |\n| Gen 0 GC: Every 5,000 messages | Gen 0 GC: Every 500,000 messages | ~100x less frequent |\n| Heap Pressure: 160MB | Heap Pressure: ~1 6MB | ~100x reduction |\n| Throughput: 50K msg/sec | Throughput: 150K msg/sec | 3x faster |\nWhen to Use Pooling:\n‚úÖ High-Throughput Scenarios - Processing 10K+ messages/second\n‚úÖ Frequently-Allocated Objects - Created and discarded per message\n‚úÖ Short-Lived Objects - Used briefly then returned to pool\n‚úÖ Fixed-Size Objects - Predictable memory usage\nWhizbang Pooled Objects:\nPolicyContext - Message processing context (100-200 bytes)\nExecutionState - Execution pipeline state (50-100 bytes)\n---\nArchitecture\nPolicyContextPool Design\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  PolicyContextPool (Static)                            ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ  ConcurrentBag<PolicyContext>                    ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  (Thread-safe, lock-free pool)                   ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ                                                   ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  [Context1] [Context2] [Context3] [Context1024]  ‚îÇ\n‚îÇ  ‚îÇ                                                   ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  Max Size: 1024 (overflow discarded)             ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nMessage Processing Lifecycle:\nRent from Pool\n   ‚Üì\n   context = PolicyContextPool Rent(message, envelope, services, environment);\n   ‚Üì\nInitialize with Message\n   ‚Üì\n   context Initialize(message, envelope, services, environment);\n   ‚Üì\nUse Context in Processing\n   ‚Üì\n   var config = await policyEngine MatchAsync(context);\n   await HandleMessageAsync(message, context);\n   ‚Üì\nReturn to Pool\n   ‚Üì\n   PolicyContextPool Return(context);\n   ‚Üì\n   context Reset() ‚Üí clears references\n   ‚Üì\n   Added to pool (if not full) or GC'd (if full)\n`\n---\nPolicyContextPool\nImplementation\n`csharp\nusing Whizbang Core",
        "startIndex": 0,
        "preview": "Object Pooling\nObject pooling reduces heap allocations by reusing objects instead of creating new ones Whizbang uses pooling for frequently-allocated ..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-1",
        "text": "envelope, services, environment); ‚Üì Use Context in Processing ‚Üì var config = await policyEngine MatchAsync(context); await HandleMessageAsync(message, context); ‚Üì Return to Pool ‚Üì PolicyContextPool Return(context); ‚Üì context Reset() ‚Üí clears references ‚Üì Added to pool (if not full) or GC'd (if full) ` --- PolicyContextPool Implementation `csharp using Whizbang Core Pooling;\npublic static class PolicyContextPool {\n  private static readonly ConcurrentBag<PolicyContext> _pool = [];\n  private static int _poolSize = 0;\n  private const int MaxPoolSize = 1024;\n  /// <summary>\n  /// Rents a PolicyContext from the pool and initializes it /// If pool is empty, creates a new instance /// </summary>\n  public static PolicyContext Rent(\n    object message,\n    IMessageEnvelope envelope,\n    IServiceProvider services,\n    string environment\n  ) {\n    if (_pool TryTake(out var context)) {\n      Interlocked Decrement(ref _poolSize);\n    } else {\n      context = new PolicyContext();\n    }\n    context Initialize(message, envelope, services, environment);\n    return context;\n  }\n  /// <summary>\n  /// Returns a PolicyContext to the pool after resetting it /// If pool is full, context is discarded and GC'd /// </summary>\n  public static void Return(PolicyContext context) {\n    if (context is null) {\n      return;\n    }\n    // Reset to clear references (prevent memory leaks)\n    context Reset();\n    // Only add back if pool not full\n    if (_poolSize < MaxPoolSize) {\n      _pool Add(context);\n      Interlocked Increment(ref _poolSize);\n    }\n    // If full, let context be GC'd\n  }\n}\n`\nKey Features:\nThread-Safe: ConcurrentBag provides lock-free concurrency\nMax Size Limit: Prevents unbounded growth (1,024 contexts = ~100KB max)\nOverflow Handling: Discards contexts when full (GC collects them)\nReset Before Return: Clears references to prevent memory leaks\n---\nUsage Patterns\nBasic Rent/Return\n`csharp\nusing Whizbang Core Pooling;\nusing Whizbang Core Policies;\npublic class MessageHandler {\n  private readonly IPolicyEngine _policyEngine;\n  private readonly IServiceProvider _services;\n  public async Task HandleAsync(\n    object message,\n    IMessageEnvelope envelope,\n    CancellationToken ct\n  ) {\n    // Rent context from pool\n    var context = PolicyContextPool",
        "startIndex": 2519,
        "preview": "envelope, services, environment); ‚Üì Use Context in Processing ‚Üì var config = await policyEngine MatchAsync(context); await HandleMessageAsync(message,..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-2",
        "text": "prevent memory leaks --- Usage Patterns Basic Rent/Return `csharp using Whizbang Core Pooling; using Whizbang Core Policies; public class MessageHandler { private readonly IPolicyEngine _policyEngine; private readonly IServiceProvider _services; public async Task HandleAsync( object message, IMessageEnvelope envelope, CancellationToken ct ) { // Rent context from pool var context = PolicyContextPool Rent(\n      message,\n      envelope,\n      _services,\n      environment: \"production\"\n    );\n    try {\n      // Use context for policy evaluation\n      var config = await _policyEngine MatchAsync(context);\n      // Process message with context\n      await ProcessMessageAsync(message, config, context, ct);\n    } finally {\n      // ALWAYS return to pool (even on exception)\n      PolicyContextPool Return(context);\n    }\n  }\n}\n`\nCritical: Always return contexts in finally block to prevent pool depletion Automatic Return with Using\n`csharp\n// Helper class for IDisposable pattern\npublic class PooledPolicyContext : IDisposable {\n  public PolicyContext Context { get; }\n  public PooledPolicyContext(\n    object message,\n    IMessageEnvelope envelope,\n    IServiceProvider services,\n    string environment\n  ) {\n    Context = PolicyContextPool Rent(message, envelope, services, environment);\n  }\n  public void Dispose() {\n    PolicyContextPool Return(Context);\n  }\n}\n// Usage\nusing var pooled = new PooledPolicyContext(message, envelope, services, \"production\");\nvar config = await policyEngine MatchAsync(pooled Context);\n// Automatic return when 'using' block exits\n`\nAsync Method Pattern\n`csharp\npublic async Task ProcessMessageAsync(\n  CreateOrder command,\n  IMessageEnvelope envelope,\n  CancellationToken ct\n) {\n  var context = PolicyContextPool Rent(command, envelope, _services, \"production\");\n  try {\n    // Async policy evaluation\n    var config = await _policyEngine MatchAsync(context);\n    // Async message processing\n    await _receptor HandleAsync(command, ct);\n    // Async event publishing\n    var @event = new OrderCreated(command OrderId);\n    await PublishEventAsync(@event, config, ct);\n  } finally {\n    // Return even if async operation cancelled\n    PolicyContextPool Return(context);\n  }\n}\n`\n---\nPolicyContext Lifecycle\nRent (Create or Reuse)\n`csharp\nvar context = PolicyContextPool",
        "startIndex": 4438,
        "preview": "prevent memory leaks --- Usage Patterns Basic Rent/Return `csharp using Whizbang Core Pooling; using Whizbang Core Policies; public class MessageHandl..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-3",
        "text": "MatchAsync(context); // Async message processing await _receptor HandleAsync(command, ct); // Async event publishing var @event = new OrderCreated(command OrderId); await PublishEventAsync(@event, config, ct); } finally { // Return even if async operation cancelled PolicyContextPool Return(context); } } ` --- PolicyContext Lifecycle Rent (Create or Reuse) `csharp var context = PolicyContextPool Rent(message, envelope, services, \"production\");\n`\nWhat Happens:\nPool checked for available context\nIf found ‚Üí reused (zero allocation)\nIf empty ‚Üí new context created (rare)\nContext initialized with message data\nInitialize\n`csharp\ncontext Initialize(message, envelope, services, environment);\n`\nWhat's Set:\nMessage = message object\nMessageType = message GetType()\nEnvelope = envelope with metadata\nServices = DI container\nEnvironment = \"production\"\nExecutionTime = DateTimeOffset UtcNow\nTrail = new PolicyDecisionTrail()\nUse\n`csharp\nvar config = await policyEngine MatchAsync(context);\nvar aggregateId = context GetAggregateId();\nvar service = context GetService<IOrderRepository>();\n`\nAvailable Operations:\nPolicy evaluation\nAggregate ID extraction (zero reflection)\nService resolution\nMetadata access\nTag/flag checking\nReset\n`csharp\ncontext Reset();\n`\nWhat's Cleared:\nMessage = null (release reference)\nMessageType = null\nEnvelope = null (prevent memory leak)\nServices = null\nEnvironment = \"development\" (default)\nTrail = new PolicyDecisionTrail() (clear decisions)\nWhy Reset Prevents holding references to disposed objects (memory leaks) Return\n`csharp\nPolicyContextPool",
        "startIndex": 6347,
        "preview": "MatchAsync(context); // Async message processing await _receptor HandleAsync(command, ct); // Async event publishing var @event = new OrderCreated(com..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-4",
        "text": "access Tag/flag checking Reset `csharp context Reset(); ` What's Cleared: Message = null (release reference) MessageType = null Envelope = null (prevent memory leak) Services = null Environment = \"development\" (default) Trail = new PolicyDecisionTrail() (clear decisions) Why Reset Prevents holding references to disposed objects (memory leaks) Return `csharp PolicyContextPool Return(context);\n`\nWhat Happens:\nContext reset (step 4)\nIf pool < 1,024 ‚Üí added to pool\nIf pool >= 1,024 ‚Üí discarded, GC'd\n---\nPerformance Characteristics\nAllocation Benchmarks\n| Scenario | Without Pooling | With Pooling | Improvement |\n|----------|----------------|--------------|-------------|\n| 1M Messages | 160MB allocated | ~160KB allocated | 1000x reduction |\n| Gen 0 Collections | ~200 | ~2 | 100x fewer |\n| Gen 1 Collections | ~20 | ~0 | Eliminated |\n| Gen 2 Collections | ~2 | ~0 | Eliminated |\n| Throughput | 50K msg/sec | 150K msg/sec | 3x faster |\nLatency Impact\n| Operation | Without Pooling | With Pooling | Improvement |\n|-----------|----------------|--------------|-------------|\n| Context Creation | ~500ns (alloc + init) | ~50ns (reuse) | 10x faster |\n| GC Pause | ~10-50ms | ~1-5ms | 10x shorter |\n| 99th Percentile | ~15ms | ~2ms | 7 5x better |\nMemory Usage\n`\nPool Size: 1,024 contexts\nContext Size: ~160 bytes\nTotal Pool Memory: ~160KB (negligible)\nPeak Pool Memory: 1,024 √ó 160 bytes = ~160KB\nHeap Savings: 1M √ó 160 bytes - 160KB = 159",
        "startIndex": 7523,
        "preview": "access Tag/flag checking Reset `csharp context Reset(); ` What's Cleared: Message = null (release reference) MessageType = null Envelope = null (preve..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-5",
        "text": "10x shorter | | 99th Percentile | ~15ms | ~2ms | 7 5x better | Memory Usage ` Pool Size: 1,024 contexts Context Size: ~160 bytes Total Pool Memory: ~160KB (negligible) Peak Pool Memory: 1,024 √ó 160 bytes = ~160KB Heap Savings: 1M √ó 160 bytes - 160KB = 159 84MB saved\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Always return in finally block - Prevents pool depletion\n‚úÖ Use pooling for high-throughput scenarios - 10K+ msg/sec\n‚úÖ Reset before return - Prevent memory leaks\n‚úÖ Monitor pool size - Track _poolSize in metrics\n‚úÖ Use IDisposable wrapper for automatic return\n‚úÖ Profile before optimizing - Measure allocations first\nDON'T ‚ùå\n‚ùå Hold context references after return (use-after-return bug)\n‚ùå Return context twice (double-free bug)\n‚ùå Skip returning contexts (pool depletion)\n‚ùå Pool large objects (> 1KB) - GC is fine for large objects\n‚ùå Use pooling for infrequent operations (< 100 msg/sec)\n‚ùå Forget to reset before return (memory leaks)\n---\nAdvanced Patterns\nCustom Pool Size\n`csharp\n// For very high throughput (100K+ msg/sec), increase max size\nprivate const int MaxPoolSize = 4096;  // 4x default\n// For memory-constrained environments, decrease\nprivate const int MaxPoolSize = 256;  // 1/4 default\n`\nGuideline: Set MaxPoolSize to 2x concurrent message processing capacity Pool Monitoring\n`csharp\npublic static class PolicyContextPool {\n  // Metrics for monitoring\n  private static long _totalRented = 0;\n  private static long _totalReturned = 0;\n  private static long _totalAllocated = 0;  // Rent when pool empty\n  public static PolicyContext Rent( ) {\n    Interlocked Increment(ref _totalRented);\n    if (_pool TryTake(out var context)) {\n      // Reused from pool\n    } else {\n      // Pool empty - allocate new\n      Interlocked Increment(ref _totalAllocated);\n      context = new PolicyContext();\n    }\n    // }\n  public static void Return(PolicyContext context) {\n    if (context is null) return;\n    Interlocked Increment(ref _totalReturned);\n    //",
        "startIndex": 8583,
        "preview": "10x shorter | | 99th Percentile | ~15ms | ~2ms | 7 5x better | Memory Usage ` Pool Size: 1,024 contexts Context Size: ~160 bytes Total Pool Memory: ~1..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-6",
        "text": "Rent( ) { Interlocked Increment(ref _totalRented); if (_pool TryTake(out var context)) { // Reused from pool } else { // Pool empty - allocate new Interlocked Increment(ref _totalAllocated); context = new PolicyContext(); } // } public static void Return(PolicyContext context) { if (context is null) return; Interlocked Increment(ref _totalReturned); // }\n  // Metrics endpoints\n  public static int GetPoolSize() => _poolSize;\n  public static long GetTotalRented() => _totalRented;\n  public static long GetTotalReturned() => _totalReturned;\n  public static long GetTotalAllocated() => _totalAllocated;\n  public static double GetHitRate() =>\n    _totalRented > 0 (double)(_totalRented - _totalAllocated) / _totalRented : 0;\n}\n`\nMonitoring:\nPool Size: Should stabilize near max concurrent processing\nHit Rate: Should be > 99% (reusing from pool)\nAllocations: Should plateau after warmup\nPre-Warming Pool\n`csharp\n// Warm pool on application startup\npublic static class PolicyContextPool {\n  public static void WarmPool(int targetSize = MaxPoolSize) {\n    for (int i = 0; i < targetSize; i++) {\n      var context = new PolicyContext();\n      context Reset();\n      _pool Add(context);\n      Interlocked Increment(ref _poolSize);\n    }\n  }\n}\n// Usage in Startup\npublic class Program {\n  public static void Main(string[] args) {\n    // Warm pool before accepting traffic\n    PolicyContextPool WarmPool(targetSize: 1024);\n    var app = WebApplication Create(args);\n    app Run();\n  }\n}\n`\nBenefit: Eliminates allocations during first 1,024 messages (faster startup) ---\nTroubleshooting\nProblem: Pool Never Reuses Contexts\nSymptoms: GetHitRate() returns 0%, all messages allocate new contexts Causes:\nContexts not returned to pool\nReturned contexts not added (pool full on every return)\nPool cleared between rent/return\nSolution:\n`csharp\n// 1 Verify return in finally\ntry {\n  var context = PolicyContextPool Rent( );\n  // Use context\n} finally {\n  PolicyContextPool Return(context);  // ‚≠ê Must execute\n}\n// 2 Check pool size metrics\nvar poolSize = PolicyContextPool GetPoolSize();\nvar returned = PolicyContextPool GetTotalReturned();\nvar rented = PolicyContextPool GetTotalRented();\nConsole",
        "startIndex": 10292,
        "preview": "Rent( ) { Interlocked Increment(ref _totalRented); if (_pool TryTake(out var context)) { // Reused from pool } else { // Pool empty - allocate new Int..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-7",
        "text": "`csharp // 1 Verify return in finally try { var context = PolicyContextPool Rent( ); // Use context } finally { PolicyContextPool Return(context); // ‚≠ê Must execute } // 2 Check pool size metrics var poolSize = PolicyContextPool GetPoolSize(); var returned = PolicyContextPool GetTotalReturned(); var rented = PolicyContextPool GetTotalRented(); Console WriteLine($\"Pool Size: {poolSize}, Returned: {returned}, Rented: {rented}\");\n// Expected: returned ‚âà rented, poolSize > 0\n`\nProblem: Memory Leak Despite Pooling\nSymptoms: Heap grows over time even with pooling Cause: Context references not cleared in Reset() Solution:\n`csharp\n// Verify Reset() clears ALL references\ninternal void Reset() {\n  Message = null ;          // ‚≠ê Clear\n  MessageType = null ;      // ‚≠ê Clear\n  Envelope = null;          // ‚≠ê Clear (prevent leak)\n  Services = null;          // ‚≠ê Clear (prevent leak)\n  Environment = \"development\";\n  Trail = new PolicyDecisionTrail();  // New instance\n}\n// Verify no lingering references\ncontext Reset();\nAssert That(context Envelope) IsNull();\nAssert That(context Services) IsNull();\n`\nProblem: Pool Depletion Under Load\nSymptoms: GetPoolSize() drops to 0 under high load, allocations spike Causes:\nContexts not returned (leaked)\nMax pool size too small\nConcurrent processing exceeds pool capacity\nSolution:\n`csharp\n// 1 Audit return paths\npublic async Task HandleAsync(message) {\n  var context = PolicyContextPool Rent( );\n  try {\n    await ProcessAsync(message, context);\n  } catch {\n    // Exception path - still return\n    throw;\n  } finally {\n    PolicyContextPool Return(context);  // ‚≠ê All paths return\n  }\n}\n// 2 Increase max pool size\nprivate const int MaxPoolSize = 4096;  // 4x concurrent capacity\n// 3 Monitor concurrent usage\nvar concurrentMessages = GetConcurrentMessageCount();\nvar poolSize = PolicyContextPool GetPoolSize();\nif (concurrentMessages > poolSize) {\n  // Pool too small - increase MaxPoolSize\n  Console",
        "startIndex": 12128,
        "preview": "`csharp // 1 Verify return in finally try { var context = PolicyContextPool Rent( ); // Use context } finally { PolicyContextPool Return(context); // ..."
      },
      {
        "id": "v0.1.0/infrastructure/pooling-chunk-8",
        "text": "// ‚≠ê All paths return } } // 2 Increase max pool size private const int MaxPoolSize = 4096; // 4x concurrent capacity // 3 Monitor concurrent usage var concurrentMessages = GetConcurrentMessageCount(); var poolSize = PolicyContextPool GetPoolSize(); if (concurrentMessages > poolSize) { // Pool too small - increase MaxPoolSize Console WriteLine($\"WARNING: Pool depleted - {concurrentMessages} concurrent > {poolSize} pool size\");\n}\n`\n---\nFurther Reading\nInfrastructure:\nPolicies - PolicyContext usage in policy evaluation\nHealth Checks - Monitoring pool health\nPerformance:\nPerformance Tuning - GC optimization strategies\nExternal Resources: NET Memory Management\nObjectPool<T>\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 13728,
        "preview": "// ‚≠ê All paths return } } // 2 Increase max pool size private const int MaxPoolSize = 4096; // 4x concurrent capacity // 3 Monitor concurrent usage va..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/messaging/commands-events",
    "title": "v0.1.0/messaging/commands-events",
    "category": "General",
    "url": "/docs/v0.1.0/messaging/commands-events",
    "chunks": [
      {
        "id": "v0.1.0/messaging/commands-events-chunk-0",
        "text": "Commands and Events\nCommands and Events are the core message types in Whizbang, representing intent (commands) and facts (events) in your domain Overview\nWhizbang uses marker interfaces to distinguish between different message types:\nCommands: Represent intent or requests for action (e g , CreateOrder, CancelOrder)\nEvents: Represent facts or things that have happened (e g , OrderCreated, OrderCancelled)\nBoth commands and events are wrapped in Message Envelopes for routing, tracing, and metadata ICommand Interface\nCommands express intent - a request to perform an action in the system Characteristics\nImperative naming: CreateOrder, UpdateInventory, ProcessPayment\nSingle handler: Typically processed by exactly one receptor\nCan fail: Commands can be rejected due to business rules or validation\nIdempotent: Should be safe to retry\nAuthorization: May require permissions or policies\nDefinition\n`csharp\n/// <summary>\n/// Marker interface for command messages\n/// </summary>\n/// <docs>messaging/commands-events</docs>\npublic interface ICommand {\n  // Marker interface - no members\n}\n`\nExample Commands\n`csharp\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n  public string CouponCode { get; init; }\n}\npublic record CancelOrder : ICommand {\n  public required Guid OrderId { get; init; }\n  public required string Reason { get; init; }\n}\npublic record UpdateInventory : ICommand {\n  public required string ProductId { get; init; }\n  public required int QuantityChange { get; init; }\n}\n`\nNaming Conventions\nCommands use imperative verbs:\n‚úÖ CreateOrder, UpdateProfile, ProcessPayment\n‚ùå OrderCreation, ProfileUpdate, PaymentProcessing\nCommands are specific:\n‚úÖ ApproveOrder, RejectOrder, CancelOrder\n‚ùå ModifyOrder, ChangeOrder, UpdateOrder (too generic)\nIEvent Interface\nEvents represent facts - things that have already happened in the system",
        "startIndex": 0,
        "preview": "Commands and Events\nCommands and Events are the core message types in Whizbang, representing intent (commands) and facts (events) in your domain Overv..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-1",
        "text": "required int QuantityChange { get; init; } } ` Naming Conventions Commands use imperative verbs: ‚úÖ CreateOrder, UpdateProfile, ProcessPayment ‚ùå OrderCreation, ProfileUpdate, PaymentProcessing Commands are specific: ‚úÖ ApproveOrder, RejectOrder, CancelOrder ‚ùå ModifyOrder, ChangeOrder, UpdateOrder (too generic) IEvent Interface Events represent facts - things that have already happened in the system Characteristics\nPast tense naming: OrderCreated, PaymentProcessed, InventoryUpdated\nMultiple handlers: Can be processed by many receptors and perspectives\nCannot fail: Events are facts - you can't \"reject\" something that already happened\nImmutable: Events should never be modified after creation\nSource of truth: Events drive perspectives (read models) and analytics\nDefinition\n`csharp\n/// <summary>\n/// Marker interface for event messages\n/// </summary>\n/// <docs>messaging/commands-events</docs>\npublic interface IEvent {\n  // Marker interface - no members\n}\n`\nExample Events\n`csharp\npublic record OrderCreated : IEvent {\n  public required Guid OrderId { get; init; }\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n  public required decimal TotalAmount { get; init; }\n  public required DateTimeOffset CreatedAt { get; init; }\n}\npublic record OrderCancelled : IEvent {\n  public required Guid OrderId { get; init; }\n  public required string Reason { get; init; }\n  public required DateTimeOffset CancelledAt { get; init; }\n}\npublic record InventoryUpdated : IEvent {\n  public required string ProductId { get; init; }\n  public required int OldQuantity { get; init; }\n  public required int NewQuantity { get; init; }\n  public required DateTimeOffset UpdatedAt { get; init; }\n}\n`\nNaming Conventions\nEvents use past tense:\n‚úÖ OrderCreated, PaymentProcessed, InventoryReserved\n‚ùå CreateOrder, ProcessPayment, ReserveInventory\nEvents capture state changes:\n‚úÖ ProductPriceChanged (includes old and new price)\n‚úÖ OrderStatusChanged (includes old and new status)\n‚ùå ProductUpdated (too generic, doesn't capture what changed)\nCommand ‚Üí Event Flow\nCommands trigger business logic that results in events:\n`csharp\n// Command: Request to create an order\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n}\n// Event: Order was created successfully\npublic record OrderCreated : IEvent {\n  public required Guid OrderId { get; init; }\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n  public required decimal TotalAmount { get; init; }\n  public required DateTimeOffset CreatedAt { get; init; }\n}\n// Receptor: Handles command, produces event\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    IMessageContext context,\n    CancellationToken cancellationToken = default\n  ) {\n    // Validate business rules\n    if (command",
        "startIndex": 1939,
        "preview": "required int QuantityChange { get; init; } } ` Naming Conventions Commands use imperative verbs: ‚úÖ CreateOrder, UpdateProfile, ProcessPayment ‚ùå OrderC..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-2",
        "text": "public required decimal TotalAmount { get; init; } public required DateTimeOffset CreatedAt { get; init; } } // Receptor: Handles command, produces event public class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> { public async Task<OrderCreated> HandleAsync( CreateOrder command, IMessageContext context, CancellationToken cancellationToken = default ) { // Validate business rules if (command Items Length == 0) {\n      throw new InvalidOperationException(\"Order must contain at least one item\");\n    }\n    // Create order\n    var orderId = Guid CreateVersion7();\n    var totalAmount = command Items Sum(i => i Price * i Quantity);\n    // Return event (fact)\n    return new OrderCreated {\n      OrderId = orderId,\n      CustomerId = command CustomerId,\n      Items = command Items,\n      TotalAmount = totalAmount,\n      CreatedAt = DateTimeOffset UtcNow\n    };\n  }\n}\n`\nMessage Envelopes\nBoth commands and events are wrapped in MessageEnvelope<T> for routing and tracing:\n`csharp\n// Dispatch a command\nvar createOrder = new CreateOrder {\n  CustomerId = \"cust-123\",\n  Items = [\n    new OrderItem { ProductId = \"prod-456\", Quantity = 2, Price = 29 99m }\n  ]\n};\nvar result = await dispatcher DispatchAsync<CreateOrder, OrderCreated>(createOrder);\n// The envelope provides:\n// - MessageId (UUIDv7)\n// - CorrelationId (for distributed tracing)\n// - CausationId (parent message)\n// - Hops (routing and metadata)\n// - SecurityContext (user, tenant)\n// - PolicyDecisionTrail (authorization audit)\n`\nSee Message Envelopes for details Event Sourcing\nEvents are the source of truth in event-sourced systems:\n`csharp\n// Event store tracks all events for an aggregate\npublic class Order {\n  public Guid Id { get; private set; }\n  public List<IEvent> Events { get; } = new();\n  public void Apply(OrderCreated e) {\n    Id = e OrderId;\n    // update state\n  }\n  public void Apply(OrderCancelled e) {\n    // update state\n  }\n  // Rebuild state from events\n  public static Order FromEvents(IEnumerable<IEvent> events) {\n    var order = new Order();\n    foreach (var e in events) {\n      order",
        "startIndex": 1236,
        "preview": "public required decimal TotalAmount { get; init; } public required DateTimeOffset CreatedAt { get; init; } } // Receptor: Handles command, produces ev..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-3",
        "text": "{ get; } = new(); public void Apply(OrderCreated e) { Id = e OrderId; // update state } public void Apply(OrderCancelled e) { // update state } // Rebuild state from events public static Order FromEvents(IEnumerable<IEvent> events) { var order = new Order(); foreach (var e in events) { order Apply((dynamic)e);\n    }\n    return order;\n  }\n}\n`\nSee Event Store for details Perspectives (Read Models)\nEvents drive perspectives - read models optimized for queries:\n`csharp\n// Perspective: Order summary read model\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderSummary> {\n  public async Task<OrderSummary> ProjectAsync(\n    IEvent @event,\n    OrderSummary current,\n    CancellationToken cancellationToken = default\n  ) {\n    return @event switch {\n      OrderCreated e => new OrderSummary {\n        OrderId = e OrderId,\n        CustomerId = e CustomerId,\n        TotalAmount = e TotalAmount,\n        Status = \"Created\",\n        CreatedAt = e CreatedAt\n      },\n      OrderCancelled e => current with {\n        Status = \"Cancelled\",\n        CancelledAt = e CancelledAt\n      },\n      _ => current throw new InvalidOperationException(\"Unknown event type\")\n    };\n  }\n}\n`\nSee Perspectives for details Best Practices\nCommand Design\nUse value objects for type safety:\n`csharp\n// ‚úÖ GOOD: Type-safe value objects\npublic record CreateOrder : ICommand {\n  public required CustomerId CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n}\n// ‚ùå BAD: Primitive obsession\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }  // What format Validated public required object[] Items { get; init; }      // What type }\n`\nMake commands self-contained:\n`csharp\n// ‚úÖ GOOD: Everything needed to process the command\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n  public required Address ShippingAddress { get; init; }\n  public string",
        "startIndex": 6227,
        "preview": "{ get; } = new(); public void Apply(OrderCreated e) { Id = e OrderId; // update state } public void Apply(OrderCancelled e) { // update state } // Reb..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-4",
        "text": "// What type } ` Make commands self-contained: `csharp // ‚úÖ GOOD: Everything needed to process the command public record CreateOrder : ICommand { public required string CustomerId { get; init; } public required OrderItem[] Items { get; init; } public required Address ShippingAddress { get; init; } public string CouponCode { get; init; }\n}\n// ‚ùå BAD: Requires external lookups\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }\n  // Missing: Items, shipping address - where do these come from }\n`\nUse records for immutability:\n`csharp\n// ‚úÖ GOOD: Immutable record with init-only properties\npublic record CreateOrder : ICommand {\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n}\n// ‚ùå BAD: Mutable class with setters\npublic class CreateOrder : ICommand {\n  public string CustomerId { get; set; }  // Can be modified after creation",
        "startIndex": 7926,
        "preview": "// What type } ` Make commands self-contained: `csharp // ‚úÖ GOOD: Everything needed to process the command public record CreateOrder : ICommand { publ..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-5",
        "text": "properties public record CreateOrder : ICommand { public required string CustomerId { get; init; } public required OrderItem[] Items { get; init; } } // ‚ùå BAD: Mutable class with setters public class CreateOrder : ICommand { public string CustomerId { get; set; } // Can be modified after creation public OrderItem[] Items { get; set; }\n}\n`\nEvent Design\nCapture all relevant state:\n`csharp\n// ‚úÖ GOOD: Complete snapshot of what changed\npublic record ProductPriceChanged : IEvent {\n  public required string ProductId { get; init; }\n  public required decimal OldPrice { get; init; }\n  public required decimal NewPrice { get; init; }\n  public required DateTimeOffset ChangedAt { get; init; }\n  public required string ChangedBy { get; init; }\n}\n// ‚ùå BAD: Incomplete - can't reconstruct history\npublic record ProductPriceChanged : IEvent {\n  public required string ProductId { get; init; }\n  public required decimal NewPrice { get; init; }\n  // Missing: old price, timestamp, who made the change\n}\n`\nMake events immutable and serializable:\n`csharp\n// ‚úÖ GOOD: All properties init-only, no methods\npublic record OrderCreated : IEvent {\n  public required Guid OrderId { get; init; }\n  public required string CustomerId { get; init; }\n  public required OrderItem[] Items { get; init; }\n}\n// ‚ùå BAD: Mutable properties, non-serializable state\npublic record OrderCreated : IEvent {\n  public Guid OrderId { get; set; }  // Mutable public Func<decimal> CalculateTotal { get; set; }  // Non-serializable }\n`\nUse UUIDv7 for time-ordered IDs:\n`csharp\n// ‚úÖ GOOD: UUIDv7 for database-friendly, time-ordered IDs\npublic record OrderCreated : IEvent {\n  public required Guid OrderId { get; init; }  // Generated via Guid",
        "startIndex": 8539,
        "preview": "properties public record CreateOrder : ICommand { public required string CustomerId { get; init; } public required OrderItem[] Items { get; init; } } ..."
      },
      {
        "id": "v0.1.0/messaging/commands-events-chunk-6",
        "text": "OrderId { get; set; } // Mutable public Func<decimal> CalculateTotal { get; set; } // Non-serializable } ` Use UUIDv7 for time-ordered IDs: `csharp // ‚úÖ GOOD: UUIDv7 for database-friendly, time-ordered IDs public record OrderCreated : IEvent { public required Guid OrderId { get; init; } // Generated via Guid CreateVersion7()\n  public required DateTimeOffset CreatedAt { get; init; }\n}\n// ‚ùå BAD: Random GUIDs cause index fragmentation\npublic record OrderCreated : IEvent {\n  public required Guid OrderId { get; init; }  // Guid NewGuid() - random }\n`\nRelated Topics\nMessage Envelopes - How commands and events are wrapped for routing\nReceptors - How commands are handled\nPerspectives - How events drive read models\nEvent Store - How events are persisted\nInbox Pattern - Guaranteed message delivery\nOutbox Pattern - Transactional message publishing\nSummary\nCommands = Intent (imperative verbs, can fail, single handler)\nEvents = Facts (past tense, cannot fail, multiple handlers)\nBoth wrapped in MessageEnvelope for routing and tracing\nCommands handled by Receptors which produce events\nEvents drive Perspectives (read models) and analytics\nUse records for immutability\nUse value objects for type safety\nUse UUIDv7 for time-ordered IDs",
        "startIndex": 9943,
        "preview": "OrderId { get; set; } // Mutable public Func<decimal> CalculateTotal { get; set; } // Non-serializable } ` Use UUIDv7 for time-ordered IDs: `csharp //..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/messaging/inbox-pattern",
    "title": "Inbox Pattern",
    "category": "Messaging",
    "url": "/docs/v0.1.0/messaging/inbox-pattern",
    "chunks": [
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-0",
        "text": "Inbox Pattern\nThe Inbox Pattern ensures exactly-once message processing by storing incoming messages in a database table (\"inbox\") before processing If a duplicate message arrives, it's detected and ignored Problem: Duplicate Messages\nThe Challenge: Message brokers provide at-least-once delivery, meaning messages may be delivered multiple times Sources of Duplicates\nOutbox retry: Publisher retries after partial failure\nNetwork timeout: Ack not received, broker resends\nConsumer restart: Message in-flight when consumer crashes\nBroker failover: Message replayed after broker failover\nNaive Approach (BROKEN)\n`csharp\npublic async Task ProcessMessageAsync(OrderCreated @event, CancellationToken ct) {\n    // ‚ùå No duplicate detection - processes every message await _db ExecuteAsync(\n        \"UPDATE inventory SET reserved = reserved + @Quantity WHERE product_id = @ProductId\",\n        new { @event ProductId, @event Quantity }\n    );\n}\n`\nWhat goes wrong with duplicates ‚ùå Inventory reserved twice (incorrect stock levels)\n‚ùå Payment charged twice (angry customers )\n‚ùå Email sent twice (spam)\n---\nSolution: Inbox Pattern\nThe Fix: Check inbox before processing, store message ID after processing `\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 1 Message arrives from Azure Service Bus      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 2 Check inbox for duplicate                    ‚îÇ\n‚îÇ    SELECT * FROM wh_inbox WHERE message_id = ‚îÇ\n‚îÇ                                                 ‚îÇ\n‚îÇ    If found: SKIP (already processed )         ‚îÇ  ‚Üê Exactly-once ‚îÇ    If not found: Continue ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 3 Process message (business logic)             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 4 Store message ID in inbox (atomic )          ‚îÇ\n‚îÇ    INSERT INTO wh_inbox (message_id,",
        "startIndex": 0,
        "preview": "Inbox Pattern\nThe Inbox Pattern ensures exactly-once message processing by storing incoming messages in a database table (\"inbox\") before processing I..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-1",
        "text": "WHERE message_id = ‚îÇ ‚îÇ ‚îÇ ‚îÇ If found: SKIP (already processed ) ‚îÇ ‚Üê Exactly-once ‚îÇ If not found: Continue ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ 3 Process message (business logic) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ 4 Store message ID in inbox (atomic ) ‚îÇ ‚îÇ INSERT INTO wh_inbox (message_id, )       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\n‚úÖ Exactly-once processing: Duplicates detected and skipped\n‚úÖ Idempotent: Safe to replay messages\n‚úÖ Automatic: Framework handles deduplication\n‚úÖ Auditability: Complete record of processed messages\n---\nWhizbang Implementation\nDatabase Schema\n`sql\nCREATE TABLE wh_inbox (\n    message_id UUID PRIMARY KEY,\n    correlation_id UUID NOT NULL,\n    causation_id UUID NULL,\n    message_type VARCHAR(500) NOT NULL,\n    payload JSONB NOT NULL,\n    source_topic VARCHAR(255) NOT NULL,\n    -- Metadata\n    metadata JSONB NULL,\n    -- Lease-based coordination\n    instance_id UUID NULL,\n    lease_expiry TIMESTAMPTZ NULL,\n    -- Status tracking\n    status VARCHAR(50) NOT NULL DEFAULT 'Received',\n    attempts INT NOT NULL DEFAULT 0,\n    last_error TEXT NULL,\n    -- Timestamps\n    received_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    processed_at TIMESTAMPTZ NULL,\n    completed_at TIMESTAMPTZ NULL,\n    -- Indexes\n    CONSTRAINT chk_inbox_status CHECK (status IN ('Received', 'Processing', 'Completed', 'Failed'))\n);\nCREATE INDEX idx_inbox_status ON wh_inbox(status, partition_number);\nCREATE INDEX idx_inbox_correlation ON wh_inbox(correlation_id);\nCREATE UNIQUE INDEX idx_inbox_message_id ON wh_inbox(message_id);  -- Enforces exactly-once `\nKey Fields:\nmessage_id: Unique message identifier (primary key, enforces uniqueness)\nstatus: Received ‚Üí Processing ‚Üí Completed | Failed\ninstance_id: Which worker is processing this message\nlease_expiry: When the lease expires\nCritical: UNIQUE INDEX on message_id prevents duplicate processing ---\nDetecting Duplicates\nCheck Before Processing\n`csharp\npublic async Task<bool> IsMessageProcessedAsync(\n    Guid messageId,\n    CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    var existing = await conn QuerySingleOrDefaultAsync<InboxRow>(\n        \"SELECT * FROM wh_inbox WHERE message_id = @MessageId\",\n        new { MessageId = messageId },\n        cancellationToken: ct\n    );\n    return existing is not null && existing Status == \"Completed\";\n}\n`\nUsage:\n`csharp\nif (await IsMessageProcessedAsync(message MessageId, ct)) {\n    _logger",
        "startIndex": 2103,
        "preview": "WHERE message_id = ‚îÇ ‚îÇ ‚îÇ ‚îÇ If found: SKIP (already processed ) ‚îÇ ‚Üê Exactly-once ‚îÇ If not found: Continue ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-2",
        "text": "using var conn = _db CreateConnection(); var existing = await conn QuerySingleOrDefaultAsync<InboxRow>( \"SELECT * FROM wh_inbox WHERE message_id = @MessageId\", new { MessageId = messageId }, cancellationToken: ct ); return existing is not null && existing Status == \"Completed\"; } ` Usage: `csharp if (await IsMessageProcessedAsync(message MessageId, ct)) { _logger LogWarning(\"Duplicate message {MessageId} detected, skipping\", message MessageId);\n    return;  // Skip processing }\n`\nAtomic Insert with Duplicate Check\n`csharp\ntry {\n    await conn ExecuteAsync(\n        \"\"\"\n        INSERT INTO wh_inbox (message_id, correlation_id, message_type, payload, source_topic, status, received_at)\n        VALUES (@MessageId, @CorrelationId, @MessageType, @Payload, @SourceTopic, 'Received', NOW())\n        \"\"\",\n        new {\n            MessageId = message MessageId,\n            CorrelationId = message CorrelationId,\n            MessageType = message GetType() FullName,\n            Payload = JsonSerializer Serialize(message),\n            SourceTopic = \"orders\"\n        },\n        cancellationToken: ct\n    );\n} catch (Npgsql PostgresException ex) when (ex SqlState == \"23505\") {  // Unique violation\n    _logger LogWarning(\"Duplicate message {MessageId} detected (unique constraint)\", message MessageId);\n    return;  // Skip processing }\n`\nPattern: Let database enforce uniqueness via unique constraint ---\nComplete Processing Example\nInventoryWorker\n`csharp\npublic class InventoryWorker : BackgroundService {\n    private readonly IWorkCoordinator _coordinator;\n    private readonly IMessageTransport _transport;\n    private readonly IDispatcher _dispatcher;\n    protected override async Task ExecuteAsync(CancellationToken ct) {\n        var instanceId = Guid NewGuid();\n        // Subscribe to topic\n        await _transport SubscribeAsync(\"orders\", async (msg, ct) => {\n            try {\n                // 1 Check for duplicate (via inbox)\n                var isDuplicate = await _coordinator IsMessageInInboxAsync(msg MessageId, ct);\n                if (isDuplicate) {\n                    _logger LogWarning(\n                        \"Duplicate message {MessageId} detected, skipping\",\n                        msg MessageId\n                    );\n                    return;  // Skip }\n                // 2 Store in inbox (atomic - prevents concurrent processing)\n                await _coordinator ProcessWorkBatchAsync(\n                    instanceId: instanceId,\n                    serviceName: \"InventoryWorker\",\n                    hostName: Environment MachineName,\n                    processId: Environment ProcessId,\n                    metadata: null,\n                    outboxCompletions: [],\n                    outboxFailures: [],\n                    inboxCompletions: [],\n                    inboxFailures: [],\n                    receptorCompletions: [],\n                    receptorFailures: [],\n                    perspectiveCompletions: [],\n                    perspectiveFailures: [],\n                    newOutboxMessages: [],\n                    newInboxMessages: [\n                        new InboxMessage(\n                            MessageId: msg MessageId,\n                            CorrelationId: msg CorrelationId,\n                            CausationId: msg CausationId,\n                            MessageType: msg MessageType,\n                            Payload: msg",
        "startIndex": 4282,
        "preview": "using var conn = _db CreateConnection(); var existing = await conn QuerySingleOrDefaultAsync<InboxRow>( \"SELECT * FROM wh_inbox WHERE message_id = @Me..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-3",
        "text": "_coordinator ProcessWorkBatchAsync( instanceId: instanceId, serviceName: \"InventoryWorker\", hostName: Environment MachineName, processId: Environment ProcessId, metadata: null, outboxCompletions: [], outboxFailures: [], inboxCompletions: [], inboxFailures: [], receptorCompletions: [], receptorFailures: [], perspectiveCompletions: [], perspectiveFailures: [], newOutboxMessages: [], newInboxMessages: [ new InboxMessage( MessageId: msg MessageId, CorrelationId: msg CorrelationId, CausationId: msg CausationId, MessageType: msg MessageType, Payload: msg Payload,\n                            SourceTopic: \"orders\"\n                        )\n                    ],\n                    renewOutboxLeaseIds: [],\n                    renewInboxLeaseIds: [],\n                    ct: ct\n                );\n                // 3 Process message (business logic)\n                var orderCreated = JsonSerializer Deserialize<OrderCreated>(msg Payload);\n                if (orderCreated is null) {\n                    throw new InvalidOperationException(\"Failed to deserialize OrderCreated\");\n                }\n                await ProcessOrderCreatedAsync(orderCreated, ct);\n                // 4 Mark as completed\n                await _coordinator ProcessWorkBatchAsync(\n                    instanceId: instanceId,\n                    serviceName: \"InventoryWorker\",\n                    hostName: Environment MachineName,\n                    processId: Environment ProcessId,\n                    metadata: null,\n                    outboxCompletions: [],\n                    outboxFailures: [],\n                    inboxCompletions: [\n                        new MessageCompletion(\n                            MessageId: msg MessageId,\n                            Status: MessageProcessingStatus Completed\n                        )\n                    ],\n                    inboxFailures: [],\n                    receptorCompletions: [],\n                    receptorFailures: [],\n                    perspectiveCompletions: [],\n                    perspectiveFailures: [],\n                    newOutboxMessages: [],\n                    newInboxMessages: [],\n                    renewOutboxLeaseIds: [],\n                    renewInboxLeaseIds: [],\n                    ct: ct\n                );\n                _logger LogInformation(\n                    \"Successfully processed message {MessageId}\",\n                    msg MessageId\n                );\n            } catch (Exception ex) {\n                _logger LogError(\n                    ex,\n                    \"Failed to process message {MessageId}\",\n                    msg MessageId\n                );\n                // Mark as failed\n                await _coordinator ProcessWorkBatchAsync(\n                    instanceId: instanceId,\n                    serviceName: \"InventoryWorker\",\n                    hostName: Environment MachineName,\n                    processId: Environment ProcessId,\n                    metadata: null,\n                    outboxCompletions: [],\n                    outboxFailures: [],\n                    inboxCompletions: [],\n                    inboxFailures: [\n                        new MessageFailure(\n                            MessageId: msg MessageId,\n                            Status: MessageProcessingStatus Failed,\n                            Error: ex Message,\n                            StackTrace: ex StackTrace\n                        )\n                    ],\n                    receptorCompletions: [],\n                    receptorFailures: [],\n                    perspectiveCompletions: [],\n                    perspectiveFailures: [],\n                    newOutboxMessages: [],\n                    newInboxMessages: [],\n                    renewOutboxLeaseIds: [],\n                    renewInboxLeaseIds: [],\n                    ct: ct\n                );\n            }\n        }, ct);\n        // Keep running\n        await Task Delay(Timeout Infinite, ct);\n    }\n    private async Task ProcessOrderCreatedAsync(OrderCreated @event, CancellationToken ct) {\n        // Business logic: Reserve inventory\n        foreach (var item in @event Items) {\n            var available = await _db QuerySingleAsync<int>(\n                \"SELECT available FROM inventory WHERE product_id = @ProductId\",\n                new { ProductId = item ProductId },\n                ct\n            );\n            if (available < item Quantity) {\n                throw new InsufficientInventoryException(\n                    $\"Product {item",
        "startIndex": 7345,
        "preview": "_coordinator ProcessWorkBatchAsync( instanceId: instanceId, serviceName: \"InventoryWorker\", hostName: Environment MachineName, processId: Environment ..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-4",
        "text": "@event, CancellationToken ct) { // Business logic: Reserve inventory foreach (var item in @event Items) { var available = await _db QuerySingleAsync<int>( \"SELECT available FROM inventory WHERE product_id = @ProductId\", new { ProductId = item ProductId }, ct ); if (available < item Quantity) { throw new InsufficientInventoryException( $\"Product {item ProductId} has only {available} units available, requested {item Quantity}\"\n                );\n            }\n            await _db ExecuteAsync(\n                \"UPDATE inventory SET reserved = reserved + @Quantity WHERE product_id = @ProductId\",\n                new { ProductId = item ProductId, Quantity = item Quantity },\n                ct\n            );\n        }\n        _logger LogInformation(\n            \"Reserved inventory for order {OrderId}\",\n            @event OrderId\n        );\n    }\n}\n`\nFlow:\nCheck inbox for duplicate ‚Üí Skip if found\nInsert into inbox (atomic) ‚Üí Prevents concurrent processing\nProcess message (business logic)\nMark as completed ‚Üí Won't process again\n---\nLease-Based Processing\nLike the Outbox Pattern, Inbox uses leases for coordinating work across multiple workers Claiming Messages\n`sql\n-- Claim inbox messages for processing\nUPDATE wh_inbox\nSET\n    instance_id = @InstanceId,\n    lease_expiry = NOW() + INTERVAL '5 minutes',\n    status = 'Processing'\nWHERE message_id IN (\n    SELECT message_id\n    FROM wh_inbox\n    WHERE\n        status = 'Received'\n        AND (instance_id IS NULL OR lease_expiry < NOW())\n        AND partition_number IN (SELECT * FROM assigned_partitions)\n    ORDER BY received_at\n    LIMIT 100\n)\nRETURNING *;\n`\nBenefits:\n‚úÖ Multiple workers can process different messages\n‚úÖ Crashed workers release leases automatically (via expiry)\n‚úÖ Work distributed evenly (partition-based)\n---\nExactly-Once Semantics\nHow Inbox Ensures Exactly-Once\n`\nMessage arrives with MessageId: msg-123\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Attempt 1 (Worker A)                     ‚îÇ\n‚îÇ                                          ‚îÇ\n‚îÇ 1 Check inbox for msg-123: NOT FOUND   ‚îÇ\n‚îÇ 2 Insert into inbox: SUCCESS           ‚îÇ  ‚Üê First to insert ‚îÇ 3 Process message: SUCCESS              ‚îÇ\n‚îÇ 4",
        "startIndex": 11314,
        "preview": "@event, CancellationToken ct) { // Business logic: Reserve inventory foreach (var item in @event Items) { var available = await _db QuerySingleAsync<i..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-5",
        "text": "--- Exactly-Once Semantics How Inbox Ensures Exactly-Once ` Message arrives with MessageId: msg-123 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Attempt 1 (Worker A) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 Check inbox for msg-123: NOT FOUND ‚îÇ ‚îÇ 2 Insert into inbox: SUCCESS ‚îÇ ‚Üê First to insert ‚îÇ 3 Process message: SUCCESS ‚îÇ ‚îÇ 4 Mark completed: SUCCESS               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nDuplicate arrives with MessageId: msg-123 (network retry)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Attempt 2 (Worker B)                     ‚îÇ\n‚îÇ                                          ‚îÇ\n‚îÇ 1 Check inbox for msg-123: FOUND ‚îÇ  ‚Üê Duplicate detected ‚îÇ 2 SKIP processing                       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey: UNIQUE INDEX on message_id prevents duplicate inserts Race Condition Handling\n`\nTwo workers receive same message simultaneously:\nWorker A                     Worker B\n  ‚Üì                           ‚Üì\nINSERT msg-123 ‚Üí SUCCESS     INSERT msg-123 ‚Üí DUPLICATE KEY ERROR ‚Üì                           ‚Üì\nProcess message              Skip (unique constraint violation)\n  ‚Üì\nMark completed\n`\nDatabase guarantees exactly-once via unique constraint ---\nIdempotency\nEven with inbox, business logic should be idempotent as a defense-in-depth strategy Idempotent Update\n`csharp\n// ‚úÖ Idempotent - safe to run multiple times\nawait _db ExecuteAsync(\n    \"UPDATE orders SET status = 'Shipped', shipped_at = @ShippedAt WHERE order_id = @OrderId AND status = 'Created'\",\n    new { @event OrderId, @event ShippedAt }\n);\n`\nKey: WHERE status = 'Created' ensures update only happens once (already shipped orders are skipped) Non-Idempotent Update (Avoid )\n`csharp\n// ‚ùå Not idempotent - running twice doubles inventory await _db ExecuteAsync(\n    \"UPDATE inventory SET reserved = reserved + @Quantity WHERE product_id = @ProductId\",\n    new { @event ProductId, @event Quantity }\n);\n`\nFix: Use inbox to prevent this, OR make logic idempotent:\n`csharp\n// ‚úÖ Idempotent - check if already reserved\nvar alreadyReserved = await _db QuerySingleAsync<bool>(\n    \"SELECT EXISTS(SELECT 1 FROM inventory_reservations WHERE order_id = @OrderId AND product_id = @ProductId)\",\n    new { @event OrderId, @event ProductId }\n);\nif (",
        "startIndex": 13142,
        "preview": "--- Exactly-Once Semantics How Inbox Ensures Exactly-Once ` Message arrives with MessageId: msg-123 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Att..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-6",
        "text": "); ` Fix: Use inbox to prevent this, OR make logic idempotent: `csharp // ‚úÖ Idempotent - check if already reserved var alreadyReserved = await _db QuerySingleAsync<bool>( \"SELECT EXISTS(SELECT 1 FROM inventory_reservations WHERE order_id = @OrderId AND product_id = @ProductId)\", new { @event OrderId, @event ProductId } ); if ( alreadyReserved) {\n    await _db ExecuteAsync(\n        \"UPDATE inventory SET reserved = reserved + @Quantity WHERE product_id = @ProductId\",\n        new { @event ProductId, @event Quantity }\n    );\n    await _db ExecuteAsync(\n        \"INSERT INTO inventory_reservations (order_id, product_id, quantity) VALUES (@OrderId, @ProductId, @Quantity)\",\n        new { @event OrderId, @event ProductId, @event Quantity }\n    );\n}\n`\n---\nRetry & Failure Handling\nRetry Logic\n`csharp\n// Failed messages: increment attempts, update status\nforeach (var failure in inboxFailures) {\n    await conn ExecuteAsync(\n        \"\"\"\n        UPDATE wh_inbox\n        SET\n            attempts = attempts + 1,\n            status = CASE\n                WHEN attempts + 1 >= 5 THEN 'Failed'  -- Max 5 attempts\n                ELSE 'Received'  -- Retry\n            END,\n            last_error = @Error,\n            instance_id = NULL,\n            lease_expiry = NULL\n        WHERE message_id = @MessageId\n        \"\"\",\n        new { failure MessageId, failure Error }\n    );\n}\n`\nRetry Strategy:\nAttempt 1-4: Retry (status = Received, available for next poll)\nAttempt 5+: Give up (status = Failed, needs manual intervention)\nDead Letter Queue\n`csharp\npublic async Task ReprocessFailedMessagesAsync(CancellationToken ct = default) {\n    var failedMessages = await _db QueryAsync<InboxRow>(\n        \"\"\"\n        SELECT * FROM wh_inbox\n        WHERE status = 'Failed'\n        ORDER BY received_at\n        LIMIT 100\n        \"\"\",\n        cancellationToken: ct\n    );\n    foreach (var msg in failedMessages) {\n        // Manual retry or move to dead letter queue\n        _logger LogWarning(\n            \"Failed message {MessageId} after {Attempts} attempts: {Error}\",\n            msg MessageId, msg Attempts, msg",
        "startIndex": 15080,
        "preview": "); ` Fix: Use inbox to prevent this, OR make logic idempotent: `csharp // ‚úÖ Idempotent - check if already reserved var alreadyReserved = await _db Que..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-7",
        "text": "await _db QueryAsync<InboxRow>( \"\"\" SELECT * FROM wh_inbox WHERE status = 'Failed' ORDER BY received_at LIMIT 100 \"\"\", cancellationToken: ct ); foreach (var msg in failedMessages) { // Manual retry or move to dead letter queue _logger LogWarning( \"Failed message {MessageId} after {Attempts} attempts: {Error}\", msg MessageId, msg Attempts, msg LastError\n        );\n    }\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Check inbox before processing (detect duplicates)\n‚úÖ Insert into inbox atomically (prevents concurrent processing)\n‚úÖ Use unique constraint on message_id (enforces exactly-once)\n‚úÖ Make business logic idempotent (defense-in-depth)\n‚úÖ Log all processing (correlation ID, message type)\n‚úÖ Monitor failed messages (alerts when attempts >= 5)\n‚úÖ Clean up old messages (archive Completed after 30 days)\n‚úÖ Use leases (enables parallel processing)\nDON'T ‚ùå\n‚ùå Skip duplicate detection (leads to duplicate processing)\n‚ùå Process before inserting into inbox (race condition)\n‚ùå Ignore failed messages (silent data loss)\n‚ùå Assume messages arrive in order (they don't )\n‚ùå Store large payloads in inbox (use size limits)\n‚ùå Process same message concurrently (use leases)\n‚ùå Skip monitoring (blind to failures)\n---\nMonitoring & Observability\nKey Metrics\n`csharp\npublic class InboxMetrics {\n    public int ReceivedCount { get; set; }     // Messages waiting to be processed\n    public int ProcessingCount { get; set; }   // Messages currently being processed\n    public int CompletedCount { get; set; }    // Messages successfully processed\n    public int FailedCount { get; set; }       // Messages that failed max retries\n    public double OldestMessageAge { get; set; }  // Age of oldest Received message (seconds)\n}\npublic async Task<InboxMetrics> GetMetricsAsync(CancellationToken ct = default) {\n    await using var conn = _db CreateConnection();\n    return await conn",
        "startIndex": 16852,
        "preview": "await _db QueryAsync<InboxRow>( \"\"\" SELECT * FROM wh_inbox WHERE status = 'Failed' ORDER BY received_at LIMIT 100 \"\"\", cancellationToken: ct ); foreac..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-8",
        "text": "// Messages successfully processed public int FailedCount { get; set; } // Messages that failed max retries public double OldestMessageAge { get; set; } // Age of oldest Received message (seconds) } public async Task<InboxMetrics> GetMetricsAsync(CancellationToken ct = default) { await using var conn = _db CreateConnection(); return await conn QuerySingleAsync<InboxMetrics>(\n        \"\"\"\n        SELECT\n            COUNT(*) FILTER (WHERE status = 'Received') AS ReceivedCount,\n            COUNT(*) FILTER (WHERE status = 'Processing') AS ProcessingCount,\n            COUNT(*) FILTER (WHERE status = 'Completed') AS CompletedCount,\n            COUNT(*) FILTER (WHERE status = 'Failed') AS FailedCount,\n            EXTRACT(EPOCH FROM (NOW() - MIN(received_at) FILTER (WHERE status = 'Received'))) AS OldestMessageAge\n        FROM wh_inbox\n        \"\"\",\n        cancellationToken: ct\n    );\n}\n`\nAlerts\nCritical Alerts:\nüö® OldestMessageAge > 600 (message stuck for 10+ minutes)\nüö® FailedCount > 0 (messages gave up after max retries)\nüö® ReceivedCount > 10000 (inbox backlog growing)\nWarning Alerts:\n‚ö†Ô∏è OldestMessageAge > 60 (message not processed within 1 minute)\n‚ö†Ô∏è ProcessingCount > 1000 (many messages being processed)\n---\nTesting\nUnit Tests\n`csharp\n[Test]\npublic async Task ProcessMessage_Duplicate_SkipsProcessingAsync() {\n    // Arrange\n    var messageId = Guid CreateVersion7();\n    // First processing\n    await _coordinator ProcessWorkBatchAsync(\n        / /,\n        newInboxMessages: [new InboxMessage(MessageId: messageId, / /)],\n        / /\n    );\n    await _coordinator ProcessWorkBatchAsync(\n        / /,\n        inboxCompletions: [new MessageCompletion(MessageId: messageId, Status: MessageProcessingStatus Completed)],\n        / /\n    );\n    // Act - attempt duplicate\n    var isDuplicate = await _coordinator IsMessageInInboxAsync(messageId);\n    // Assert\n    await Assert That(isDuplicate) IsTrue();\n}\n`\nIntegration Tests\n`csharp\n[Test]\npublic async Task InventoryWorker_DuplicateMessage_ProcessesOnceAsync() {\n    // Arrange\n    var message = new OrderCreated(/ /);\n    var messageId = message MessageId;\n    // Act - publish same message twice\n    await _transport PublishAsync(\"orders\", message);\n    await Task Delay(1000);  // Let worker process\n    await _transport PublishAsync(\"orders\", message);  // Duplicate await Task Delay(1000);  // Let worker process\n    // Assert - inventory reserved only once\n    var reserved = await _db",
        "startIndex": 18358,
        "preview": "// Messages successfully processed public int FailedCount { get; set; } // Messages that failed max retries public double OldestMessageAge { get; set;..."
      },
      {
        "id": "v0.1.0/messaging/inbox-pattern-chunk-9",
        "text": "OrderCreated(/ /); var messageId = message MessageId; // Act - publish same message twice await _transport PublishAsync(\"orders\", message); await Task Delay(1000); // Let worker process await _transport PublishAsync(\"orders\", message); // Duplicate await Task Delay(1000); // Let worker process // Assert - inventory reserved only once var reserved = await _db QuerySingleAsync<int>(\n        \"SELECT reserved FROM inventory WHERE product_id = @ProductId\",\n        new { ProductId = message Items[0] ProductId }\n    );\n    await Assert That(reserved) IsEqualTo(message Items[0] Quantity);  // Not doubled // Assert - inbox has one completed entry\n    var inboxCount = await _db ExecuteScalarAsync<int>(\n        \"SELECT COUNT(*) FROM wh_inbox WHERE message_id = @MessageId\",\n        new { MessageId = messageId }\n    );\n    await Assert That(inboxCount) IsEqualTo(1);\n}\n`\n---\nFurther Reading\nCore Concepts:\nDispatcher - Message routing\nReceptors - Message handlers\nMessaging Patterns:\nOutbox Pattern - Reliable event publishing\nWork Coordination - IWorkCoordinator deep dive\nMessage Envelopes - Hop-based observability\nExamples:\nECommerce: Inventory Worker - Real-world inbox usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20498,
        "preview": "OrderCreated(/ /); var messageId = message MessageId; // Act - publish same message twice await _transport PublishAsync(\"orders\", message); await Task..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/messaging/message-envelopes",
    "title": "Message Envelopes Deep Dive",
    "category": "Messaging",
    "url": "/docs/v0.1.0/messaging/message-envelopes",
    "chunks": [
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-0",
        "text": "Message Envelopes Deep Dive\nThis guide explores how MessageEnvelope enables hop-based distributed tracing across Outbox, Inbox, and message transports like Azure Service Bus See Observability & Message Hops for architectural overview This document focuses on practical messaging scenarios ---\nEnvelope Flow Across Services\nComplete Journey\n`\nService A (OrderService)\n  ‚îú‚îÄ> CreateOrder command arrives\n  ‚îú‚îÄ> Envelope created with Current hop\n  ‚îú‚îÄ> Receptor processes, creates OrderCreated event\n  ‚îú‚îÄ> Event stored in Outbox with inherited hops\n  ‚îú‚îÄ> Background worker publishes to Azure Service Bus\n  ‚îî‚îÄ> Envelope serialized with all hops\n      ‚Üì Azure Service Bus\nService B (InventoryWorker)\n  ‚îú‚îÄ> Message arrives from Azure Service Bus\n  ‚îú‚îÄ> Envelope deserialized (hops restored )\n  ‚îú‚îÄ> Stored in Inbox with all original hops\n  ‚îú‚îÄ> Receptor processes, adds new Current hop\n  ‚îú‚îÄ> InventoryReserved event created\n  ‚îî‚îÄ> Published to Azure Service Bus with accumulated hops\n      ‚Üì Azure Service Bus\nService C (PaymentWorker)\n  ‚îú‚îÄ> Message arrives with hops from A + B\n  ‚îî‚îÄ> Complete trace from HTTP request ‚Üí Payment `\nKey Insight: Hops accumulate across services, providing end-to-end trace ---\nOutbox Integration\nStoring Envelope in Outbox\n`csharp\npublic async ValueTask<OrderCreated> HandleAsync(\n    CreateOrder message,\n    CancellationToken ct = default) {\n    // Create event\n    var @event = new OrderCreated(/ /);\n    // Create envelope with hops\n    var envelope = MessageEnvelope Create(\n        messageId: MessageId New(),\n        correlationId: message CorrelationId,\n        causationId: CausationId From(message MessageId),\n        payload: @event,\n        currentHop: new MessageHop {\n            Type = MessageHopType Current,\n            Topic = \"orders\",\n            StreamKey: message CustomerId ToString(),\n            SecurityContext = GetSecurityContext(),\n            Metadata = new Dictionary<string, string> {\n                [\"ServiceName\"] = \"OrderService\",\n                [\"ReceptorName\"] = nameof(CreateOrderReceptor)\n            },\n            Timestamp = DateTimeOffset UtcNow\n        },\n        causationHops: message Envelope Hops  // Inherit parent hops );\n    // Store in outbox (serialize envelope)\n    await _coordinator ProcessWorkBatchAsync(\n        / /,\n        newOutboxMessages: [\n            new OutboxMessage(\n                MessageId: envelope MessageId Value,\n                CorrelationId: envelope CorrelationId Value,\n                CausationId: envelope CausationId Value,\n                MessageType: typeof(OrderCreated) FullName ,\n                Payload: JsonSerializer",
        "startIndex": 0,
        "preview": "Message Envelopes Deep Dive\nThis guide explores how MessageEnvelope enables hop-based distributed tracing across Outbox, Inbox, and message transports..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-1",
        "text": "= nameof(CreateOrderReceptor) }, Timestamp = DateTimeOffset UtcNow }, causationHops: message Envelope Hops // Inherit parent hops ); // Store in outbox (serialize envelope) await _coordinator ProcessWorkBatchAsync( / /, newOutboxMessages: [ new OutboxMessage( MessageId: envelope MessageId Value, CorrelationId: envelope CorrelationId Value, CausationId: envelope CausationId Value, MessageType: typeof(OrderCreated) FullName , Payload: JsonSerializer Serialize(envelope),  // ‚Üê Full envelope Topic: \"orders\",\n                StreamKey: message CustomerId ToString(),\n                PartitionKey: message CustomerId ToString()\n            )\n        ],\n        / /\n    );\n    return @event;\n}\n`\nKey Points:\nEnvelope includes all hops (current + causation)\nSerialized as JSON in Payload field\nHops persist in database for auditability\n---\nPublishing with Hops\nAzure Service Bus Integration\n`csharp\npublic class AzureServiceBusTransport : IMessageTransport {\n    public async Task PublishAsync(\n        string topic,\n        MessageEnvelope envelope,\n        CancellationToken ct = default) {\n        // Serialize envelope (includes all hops)\n        var json = JsonSerializer Serialize(envelope, _jsonOptions);\n        var message = new ServiceBusMessage(json) {\n            MessageId = envelope MessageId Value ToString(),\n            CorrelationId = envelope CorrelationId Value ToString(),\n            Subject = envelope Payload GetType() Name,\n            // Add custom properties for routing\n            ApplicationProperties = {\n                [\"MessageType\"] = envelope Payload GetType() FullName,\n                [\"CausationId\"] = envelope CausationId Value ToString() \"\",\n                [\"HopCount\"] = envelope Hops Count,  // For monitoring\n                [\"OriginatingService\"] = envelope Hops FirstOrDefault() Metadata [\"ServiceName\"] \"Unknown\"\n            }\n        };\n        var sender = _client CreateSender(topic);\n        await sender SendMessageAsync(message, ct);\n        _logger LogInformation(\n            \"Published message {MessageId} to topic {Topic} with {HopCount} hops\",\n            envelope MessageId, topic, envelope Hops Count\n        );\n    }\n}\n`\nResult: Envelope with all hops transmitted to Azure Service Bus ---\nReceiving with Hops\nInbox Deduplication + Hop Restoration\n`csharp\npublic async Task SubscribeAsync(\n    string topic,\n    Func<MessageEnvelope, CancellationToken, Task> handler,\n    CancellationToken ct = default) {\n    var processor = _client CreateProcessor(topic, new ServiceBusProcessorOptions());\n    processor ProcessMessageAsync += async args => {\n        try {\n            // 1 Deserialize envelope (hops restored )\n            var envelope = JsonSerializer Deserialize<MessageEnvelope>(\n                args Message Body",
        "startIndex": 2645,
        "preview": "= nameof(CreateOrderReceptor) }, Timestamp = DateTimeOffset UtcNow }, causationHops: message Envelope Hops // Inherit parent hops ); // Store in outbo..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-2",
        "text": "+ Hop Restoration `csharp public async Task SubscribeAsync( string topic, Func<MessageEnvelope, CancellationToken, Task> handler, CancellationToken ct = default) { var processor = _client CreateProcessor(topic, new ServiceBusProcessorOptions()); processor ProcessMessageAsync += async args => { try { // 1 Deserialize envelope (hops restored ) var envelope = JsonSerializer Deserialize<MessageEnvelope>( args Message Body ToString(),\n                _jsonOptions\n            );\n            if (envelope is null) {\n                _logger LogError(\"Failed to deserialize envelope\");\n                await args CompleteMessageAsync(args Message, ct);\n                return;\n            }\n            _logger LogInformation(\n                \"Received message {MessageId} with {HopCount} hops, CorrelationId {CorrelationId}\",\n                envelope MessageId, envelope Hops Count, envelope CorrelationId\n            );\n            // 2 Check inbox for duplicate\n            var isDuplicate = await _coordinator IsMessageInInboxAsync(\n                envelope MessageId Value,\n                ct\n            );\n            if (isDuplicate) {\n                _logger LogWarning(\n                    \"Duplicate message {MessageId} detected, skipping\",\n                    envelope MessageId\n                );\n                await args CompleteMessageAsync(args Message, ct);\n                return;\n            }\n            // 3 Store in inbox\n            await _coordinator ProcessWorkBatchAsync(\n                / /,\n                newInboxMessages: [\n                    new InboxMessage(\n                        MessageId: envelope MessageId Value,\n                        CorrelationId: envelope CorrelationId Value,\n                        CausationId: envelope CausationId Value,\n                        MessageType: envelope Payload GetType() FullName ,\n                        Payload: JsonSerializer Serialize(envelope),  // Store full envelope\n                        SourceTopic: topic\n                    )\n                ],\n                / /\n            );\n            // 4 Process message (handler receives envelope with hops )\n            await handler(envelope, ct);\n            // 5 Complete message\n            await args CompleteMessageAsync(args Message, ct);\n        } catch (Exception ex) {\n            _logger LogError(ex, \"Error processing message\");\n            await args AbandonMessageAsync(args Message);\n        }\n    };\n    await processor StartProcessingAsync(ct);\n}\n`\nKey Points:\nEnvelope deserialized with all hops intact\nHops stored in inbox for auditability\nHandler receives full envelope (not just payload)\n---\nAdding Hops in Workers\nInventoryWorker Example\n`csharp\npublic async Task ProcessOrderCreatedAsync(\n    MessageEnvelope envelope,\n    CancellationToken ct = default) {\n    var orderCreated = (OrderCreated)envelope Payload;\n    // Business logic: Reserve inventory\n    await ReserveInventoryAsync(orderCreated, ct);\n    // Create InventoryReserved event\n    var inventoryReserved = new InventoryReserved(\n        OrderId: orderCreated OrderId,\n        Reservations: / /,\n        ReservedAt: DateTimeOffset UtcNow\n    );\n    // Create envelope with NEW hop\n    var newEnvelope = MessageEnvelope Create(\n        messageId: MessageId",
        "startIndex": 5003,
        "preview": "+ Hop Restoration `csharp public async Task SubscribeAsync( string topic, Func<MessageEnvelope, CancellationToken, Task> handler, CancellationToken ct..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-3",
        "text": "CancellationToken ct = default) { var orderCreated = (OrderCreated)envelope Payload; // Business logic: Reserve inventory await ReserveInventoryAsync(orderCreated, ct); // Create InventoryReserved event var inventoryReserved = new InventoryReserved( OrderId: orderCreated OrderId, Reservations: / /, ReservedAt: DateTimeOffset UtcNow ); // Create envelope with NEW hop var newEnvelope = MessageEnvelope Create( messageId: MessageId New(),\n        correlationId: envelope CorrelationId,  // Inherit\n        causationId: CausationId From(envelope MessageId),  // Parent\n        payload: inventoryReserved,\n        currentHop: new MessageHop {\n            Type = MessageHopType Current,\n            Topic = \"inventory\",\n            StreamKey: orderCreated OrderId ToString(),\n            SecurityContext = envelope Hops FirstOrDefault() SecurityContext,  // Inherit security\n            Metadata = new Dictionary<string, string> {\n                [\"ServiceName\"] = \"InventoryWorker\",\n                [\"ReceptorName\"] = \"ReserveInventoryReceptor\",\n                [\"OriginalOrderId\"] = orderCreated OrderId ToString()\n            },\n            Timestamp = DateTimeOffset UtcNow\n        },\n        causationHops: envelope Hops  // ‚Üê INHERIT ALL PARENT HOPS );\n    // Store in outbox for publishing\n    await _coordinator ProcessWorkBatchAsync(\n        / /,\n        newOutboxMessages: [\n            new OutboxMessage(\n                MessageId: newEnvelope MessageId Value,\n                CorrelationId: newEnvelope CorrelationId Value,\n                CausationId: newEnvelope CausationId Value,\n                MessageType: typeof(InventoryReserved) FullName ,\n                Payload: JsonSerializer Serialize(newEnvelope),\n                Topic: \"inventory\",\n                StreamKey: orderCreated OrderId ToString(),\n                PartitionKey: orderCreated OrderId ToString()\n            )\n        ],\n        / /\n    );\n    _logger LogInformation(\n        \"Published InventoryReserved event with {HopCount} hops (inherited {InheritedHops})\",\n        newEnvelope Hops Count,\n        newEnvelope Hops Count(h => h Type == MessageHopType Causation)\n    );\n}\n`\nResult: InventoryReserved envelope contains:\nCurrent hop (InventoryWorker)\nAll causation hops from OrderCreated (OrderService, API Gateway, etc )\n---\nQuerying Hops Across Services\nFind Complete Workflow\n`sql\n-- Find all messages in a workflow (all services)\nSELECT\n    o message_id,\n    o message_type,\n    o topic,\n    o created_at,\n    (o payload::JSONB)->'Hops' AS hops\nFROM wh_outbox o\nWHERE (o payload::JSONB)->>'CorrelationId' = 'corr-abc'\nORDER BY o",
        "startIndex": 7878,
        "preview": "CancellationToken ct = default) { var orderCreated = (OrderCreated)envelope Payload; // Business logic: Reserve inventory await ReserveInventoryAsync(..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-4",
        "text": "hops from OrderCreated (OrderService, API Gateway, etc ) --- Querying Hops Across Services Find Complete Workflow `sql -- Find all messages in a workflow (all services) SELECT o message_id, o message_type, o topic, o created_at, (o payload::JSONB)->'Hops' AS hops FROM wh_outbox o WHERE (o payload::JSONB)->>'CorrelationId' = 'corr-abc' ORDER BY o created_at;\n`\nExample output:\n`\nmessage_id | message_type       | topic     | created_at          | hops\n-----------|--------------------|-----------|---------------------|------\nmsg-001    | OrderCreated       | orders    | 2024-12-12 10:00:00 | [API Gateway]\nmsg-002    | InventoryReserved  | inventory | 2024-12-12 10:00:01 | [API Gateway, OrderService]\nmsg-003    | PaymentProcessed   | payment   | 2024-12-12 10:00:02 | [API Gateway, OrderService, InventoryWorker]\n`\nVisualize Hop Accumulation\n`csharp\npublic void PrintHopAccumulation(Guid correlationId) {\n    var messages = GetMessagesByCorrelation(correlationId);\n    foreach (var msg in messages) {\n        Console WriteLine($\"{msg MessageType} ({msg Timestamp}):\");\n        for (int i = 0; i < msg Envelope Hops Count; i++) {\n            var hop = msg Envelope Hops[i];\n            var prefix = new string(' ', i * 2);\n            var type = hop Type == MessageHopType Current \"CURRENT\" : \"CAUSATION\";\n            Console WriteLine($\"{prefix}‚îú‚îÄ {type}: {hop Metadata [\"ServiceName\"]}\");\n        }\n        Console WriteLine();\n    }\n}\n`\nOutput:\n`\nOrderCreated (2024-12-12 10:00:00):\n‚îú‚îÄ CURRENT: OrderService\nInventoryReserved (2024-12-12 10:00:01):\n‚îú‚îÄ CAUSATION: OrderService\n  ‚îú‚îÄ CURRENT: InventoryWorker\nPaymentProcessed (2024-12-12 10:00:02):\n‚îú‚îÄ CAUSATION: OrderService\n  ‚îú‚îÄ CAUSATION: InventoryWorker\n    ‚îú‚îÄ CURRENT: PaymentWorker\n`\n---\nSecurity Context Propagation\nExtracting Security from Hops\n`csharp\npublic async Task<InventoryReserved> HandleAsync(\n    MessageEnvelope envelope,\n    CancellationToken ct = default) {\n    // Extract security context from first hop (originating service)\n    var securityContext = envelope Hops FirstOrDefault(h => h SecurityContext is not null) SecurityContext;\n    if (securityContext UserId is null) {\n        throw new UnauthorizedAccessException(\"No user context in hops\");\n    }\n    // Validate tenant isolation\n    if (securityContext TenantId = expectedTenantId) {\n        throw new ForbiddenException(\"Tenant mismatch\");\n    }\n    // Business logic with security context\n    await ReserveInventoryAsync(orderCreated, securityContext, ct);\n}\n`\nBenefit: Security context flows automatically via hops",
        "startIndex": 10080,
        "preview": "hops from OrderCreated (OrderService, API Gateway, etc ) --- Querying Hops Across Services Find Complete Workflow `sql -- Find all messages in a workf..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-5",
        "text": "null) SecurityContext; if (securityContext UserId is null) { throw new UnauthorizedAccessException(\"No user context in hops\"); } // Validate tenant isolation if (securityContext TenantId = expectedTenantId) { throw new ForbiddenException(\"Tenant mismatch\"); } // Business logic with security context await ReserveInventoryAsync(orderCreated, securityContext, ct); } ` Benefit: Security context flows automatically via hops ---\nBest Practices\nDO ‚úÖ\n‚úÖ Inherit causation hops when creating new messages\n‚úÖ Add current hop with service name, timestamp, metadata\n‚úÖ Propagate security context via hops\n‚úÖ Store envelopes in outbox/inbox (full auditability)\n‚úÖ Query by CorrelationId for end-to-end traces\n‚úÖ Monitor hop count (alert if > 10 hops indicates circular dependency)\n‚úÖ Include debug info (CallerMemberName, FilePath, LineNumber)\nDON'T ‚ùå\n‚ùå Discard causation hops (breaks tracing)\n‚ùå Modify inherited hops (immutable )\n‚ùå Skip adding current hop (incomplete trace)\n‚ùå Store sensitive data in metadata (use SecurityContext)\n‚ùå Ignore hop count limits (circular dependencies)\n‚ùå Forget to log hop information\n---\nTroubleshooting\nProblem: Missing Hops\nSymptom: Messages arrive with fewer hops than expected Causes:\nWorker not inheriting causation hops\nEnvelope not serialized/deserialized correctly\nHops not stored in outbox\nSolution:\n`csharp\n// Verify hops are inherited\nvar newEnvelope = MessageEnvelope Create(\n    / /,\n    causationHops: parentEnvelope Hops  // ‚Üê REQUIRED );\n// Verify serialization\nvar json = JsonSerializer Serialize(envelope);\nvar deserialized = JsonSerializer Deserialize<MessageEnvelope>(json);\nDebug Assert(deserialized Hops Count == envelope Hops Count);\n`\nProblem: Circular Dependencies\nSymptom: Hop count grows indefinitely Causes:\nService A publishes event that triggers Service B\nService B publishes event that triggers Service A\nLoop repeats forever\nSolution:\n`csharp\n// Detect circular dependency via hop count\nif (envelope Hops Count > 10) {\n    _logger LogError(\n        \"Circular dependency detected {HopCount} hops for {CorrelationId}\",\n        envelope Hops Count, envelope",
        "startIndex": 12310,
        "preview": "null) SecurityContext; if (securityContext UserId is null) { throw new UnauthorizedAccessException(\"No user context in hops\"); } // Validate tenant is..."
      },
      {
        "id": "v0.1.0/messaging/message-envelopes-chunk-6",
        "text": "indefinitely Causes: Service A publishes event that triggers Service B Service B publishes event that triggers Service A Loop repeats forever Solution: `csharp // Detect circular dependency via hop count if (envelope Hops Count > 10) { _logger LogError( \"Circular dependency detected {HopCount} hops for {CorrelationId}\", envelope Hops Count, envelope CorrelationId\n    );\n    // Break the loop\n    return;\n}\n`\n---\nPerformance Considerations\nHop Size\nTypical hop: ~500 bytes (JSON)\n10 hops: ~5KB total envelope size\nRecommendation: Limit hops to 10-20 max to prevent payload bloat Serialization Performance\n`csharp\n// ‚úÖ Efficient: Use JsonTypeInfo for AOT\nvar json = JsonSerializer Serialize(\n    envelope,\n    _jsonOptions GetTypeInfo(typeof(MessageEnvelope))\n);\n// ‚ùå Slow: Reflection-based serialization\nvar json = JsonSerializer Serialize(envelope);  // Not AOT-compatible\n`\n---\nFurther Reading\nCore Concepts:\nObservability & Message Hops - Architecture overview\nMessage Context - MessageId, CorrelationId, CausationId\nMessaging Patterns:\nOutbox Pattern - Reliable publishing with hops\nInbox Pattern - Exactly-once processing with hops\nWork Coordinator - Atomic batch processing\nTransports:\nAzure Service Bus - ASB integration with hops\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 13997,
        "preview": "indefinitely Causes: Service A publishes event that triggers Service B Service B publishes event that triggers Service A Loop repeats forever Solution..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/messaging/outbox-pattern",
    "title": "Outbox Pattern",
    "category": "Messaging",
    "url": "/docs/v0.1.0/messaging/outbox-pattern",
    "chunks": [
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-0",
        "text": "Outbox Pattern\nThe Outbox Pattern ensures reliable event publishing in distributed systems by storing events in a database table (\"outbox\") as part of the same transaction that modifies business data A background worker then publishes events from the outbox to the message transport Problem: Dual Writes\nThe Challenge: How do you atomically update a database AND publish an event to a message broker Naive Approach (BROKEN)\n`csharp\npublic async Task<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) {\n    // 1 Update database\n    await _db ExecuteAsync(\n        \"INSERT INTO orders (order_id, customer_id, total) VALUES (@OrderId, @CustomerId, @Total)\",\n        new { OrderId = orderId, message CustomerId, Total = total }\n    );\n    // 2 Publish event to Azure Service Bus\n    await _transport PublishAsync(orderCreatedEvent);  // ‚ùå NOT ATOMIC return orderCreatedEvent;\n}\n`\nWhat can go wrong ‚ùå Database commit succeeds, but publish fails ‚Üí Event lost ‚ùå Publish succeeds, but database commit fails ‚Üí Duplicate event ‚ùå Process crashes between the two operations ‚Üí Inconsistent state Root Cause: You cannot have a distributed transaction across database and message broker ---\nSolution: Outbox Pattern\nThe Fix: Store the event in the database (same transaction), then publish it later `\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Database Transaction                            ‚îÇ\n‚îÇ                                                 ‚îÇ\n‚îÇ 1 INSERT INTO orders ( ) VALUES ( )       ‚îÇ\n‚îÇ 2 INSERT INTO wh_outbox ( ) VALUES ( )    ‚îÇ  ‚Üê Event stored atomically ‚îÇ                                                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Background Worker (polls outbox)                ‚îÇ\n‚îÇ                                                 ‚îÇ\n‚îÇ 3 SELECT * FROM wh_outbox WHERE status = ‚îÇ\n‚îÇ 4 Publish to Azure Service Bus                ‚îÇ\n‚îÇ 5",
        "startIndex": 0,
        "preview": "Outbox Pattern\nThe Outbox Pattern ensures reliable event publishing in distributed systems by storing events in a database table (\"outbox\") as part of..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-1",
        "text": ") ‚îÇ ‚îÇ 2 INSERT INTO wh_outbox ( ) VALUES ( ) ‚îÇ ‚Üê Event stored atomically ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Background Worker (polls outbox) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 3 SELECT * FROM wh_outbox WHERE status = ‚îÇ ‚îÇ 4 Publish to Azure Service Bus ‚îÇ ‚îÇ 5 UPDATE wh_outbox SET status = 'Published'   ‚îÇ\n‚îÇ                                                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\n‚úÖ Atomicity: Event stored in same transaction as business data\n‚úÖ Guaranteed delivery: Event will be published eventually\n‚úÖ No data loss: If publish fails, event remains in outbox for retry\n‚úÖ Idempotency: Can safely retry publishing\n---\nWhizbang Implementation\nDatabase Schema\n`sql\nCREATE TABLE wh_outbox (\n    message_id UUID PRIMARY KEY,\n    correlation_id UUID NOT NULL,\n    causation_id UUID NULL,\n    message_type VARCHAR(500) NOT NULL,\n    payload JSONB NOT NULL,\n    topic VARCHAR(255) NOT NULL,\n    stream_key VARCHAR(255) NULL,\n    partition_number INT NOT NULL,\n    -- Metadata\n    metadata JSONB NULL,\n    -- Lease-based coordination\n    instance_id UUID NULL,\n    lease_expiry TIMESTAMPTZ NULL,\n    -- Status tracking\n    status VARCHAR(50) NOT NULL DEFAULT 'Stored',\n    attempts INT NOT NULL DEFAULT 0,\n    last_error TEXT NULL,\n    -- Timestamps\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    published_at TIMESTAMPTZ NULL,\n    -- Indexes for efficient querying\n    CONSTRAINT chk_outbox_status CHECK (status IN ('Stored', 'Published', 'Failed'))\n);\nCREATE INDEX idx_outbox_status ON wh_outbox(status, partition_number);\nCREATE INDEX idx_outbox_lease ON wh_outbox(instance_id, lease_expiry);\nCREATE INDEX idx_outbox_correlation ON wh_outbox(correlation_id);\n`\nKey Fields:\nmessage_id: Unique identifier (UUIDv7)\nstatus: Stored ‚Üí Published | Failed\ninstance_id: Which worker claimed this message (lease-based coordination)\nlease_expiry: When the lease expires (prevents stuck messages)\npartition_number: Consistent hashing for work distribution\nIWorkCoordinator Interface\n`csharp\npublic interface IWorkCoordinator {\n    Task<WorkBatch> ProcessWorkBatchAsync(\n        Guid instanceId,\n        string serviceName,\n        string hostName,\n        int processId,\n        Dictionary<string, JsonElement>",
        "startIndex": 1996,
        "preview": ") ‚îÇ ‚îÇ 2 INSERT INTO wh_outbox ( ) VALUES ( ) ‚îÇ ‚Üê Event stored atomically ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-2",
        "text": "Unique identifier (UUIDv7) status: Stored ‚Üí Published | Failed instance_id: Which worker claimed this message (lease-based coordination) lease_expiry: When the lease expires (prevents stuck messages) partition_number: Consistent hashing for work distribution IWorkCoordinator Interface `csharp public interface IWorkCoordinator { Task<WorkBatch> ProcessWorkBatchAsync( Guid instanceId, string serviceName, string hostName, int processId, Dictionary<string, JsonElement> metadata,\n        // Completions and failures\n        MessageCompletion[] outboxCompletions,\n        MessageFailure[] outboxFailures,\n        MessageCompletion[] inboxCompletions,\n        MessageFailure[] inboxFailures,\n        // Event store tracking\n        ReceptorProcessingCompletion[] receptorCompletions,\n        ReceptorProcessingFailure[] receptorFailures,\n        PerspectiveCheckpointCompletion[] perspectiveCompletions,\n        PerspectiveCheckpointFailure[] perspectiveFailures,\n        // New work to store\n        OutboxMessage[] newOutboxMessages,\n        InboxMessage[] newInboxMessages,\n        // Lease renewals\n        Guid[] renewOutboxLeaseIds,\n        Guid[] renewInboxLeaseIds,\n        // Configuration\n        WorkBatchFlags flags = WorkBatchFlags None,\n        int partitionCount = 10000,\n        int maxPartitionsPerInstance = 100,\n        int leaseSeconds = 300,\n        int staleThresholdSeconds = 600,\n        CancellationToken cancellationToken = default\n    );\n}\n`\nKey Method: ProcessWorkBatchAsync handles atomic operations:\nDelete completed messages\nUpdate failed messages\nInsert new outbox messages\nClaim new work (via leasing)\n---\nStoring Events in Outbox\nExample: CreateOrderReceptor\n`csharp\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IWorkCoordinator _coordinator;\n    private readonly IDbConnectionFactory _db;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Business logic\n        var orderId = Guid CreateVersion7();\n        var total = message Items Sum(i => i Quantity * i UnitPrice);\n        var @event = new OrderCreated(\n            OrderId: orderId,\n            CustomerId: message CustomerId,\n            Items: message Items,\n            Total: total,\n            CreatedAt: DateTimeOffset UtcNow\n        );\n        // Store event in outbox (atomic with business data)\n        await using var conn = _db CreateConnection();\n        await using var transaction = await conn BeginTransactionAsync(ct);\n        try {\n            // 1 Insert business data\n            await conn ExecuteAsync(\n                \"INSERT INTO orders (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\",\n                new {\n                    OrderId = orderId,\n                    message CustomerId,\n                    Total = total,\n                    Status = \"Created\",\n                    CreatedAt = @event CreatedAt\n                },\n                transaction: transaction,\n                cancellationToken: ct\n            );\n            // 2 Insert event into outbox (same transaction )\n            await _coordinator ProcessWorkBatchAsync(\n                instanceId: Guid",
        "startIndex": 3979,
        "preview": "Unique identifier (UUIDv7) status: Stored ‚Üí Published | Failed instance_id: Which worker claimed this message (lease-based coordination) lease_expiry:..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-3",
        "text": "INTO orders (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\", new { OrderId = orderId, message CustomerId, Total = total, Status = \"Created\", CreatedAt = @event CreatedAt }, transaction: transaction, cancellationToken: ct ); // 2 Insert event into outbox (same transaction ) await _coordinator ProcessWorkBatchAsync( instanceId: Guid NewGuid(),\n                serviceName: \"OrderService\",\n                hostName: Environment MachineName,\n                processId: Environment ProcessId,\n                metadata: null,\n                outboxCompletions: [],\n                outboxFailures: [],\n                inboxCompletions: [],\n                inboxFailures: [],\n                receptorCompletions: [],\n                receptorFailures: [],\n                perspectiveCompletions: [],\n                perspectiveFailures: [],\n                newOutboxMessages: [\n                    new OutboxMessage(\n                        MessageId: Guid CreateVersion7(),\n                        CorrelationId: message CorrelationId Value,\n                        CausationId: message MessageId Value,\n                        MessageType: typeof(OrderCreated) FullName ,\n                        Payload: JsonSerializer Serialize(@event, _jsonOptions),\n                        Topic: \"orders\",\n                        StreamKey: message CustomerId ToString(),\n                        PartitionKey: message CustomerId ToString()\n                    )\n                ],\n                newInboxMessages: [],\n                renewOutboxLeaseIds: [],\n                renewInboxLeaseIds: [],\n                ct: ct\n            );\n            await transaction CommitAsync(ct);\n        } catch {\n            await transaction RollbackAsync(ct);\n            throw;\n        }\n        return @event;\n    }\n}\n`\nKey Points:\n‚úÖ Business data and outbox insert in same transaction\n‚úÖ If transaction fails, nothing is committed (atomicity)\n‚úÖ Event is stored even if network to message broker is down\n---\nPublishing from Outbox\nWorkCoordinatorPublisher Worker\n`csharp\npublic class WorkCoordinatorPublisherWorker : BackgroundService {\n    private readonly IWorkCoordinator _coordinator;\n    private readonly IMessageTransport _transport;\n    private readonly IConfiguration _config;\n    private readonly ILogger<WorkCoordinatorPublisherWorker> _logger;\n    protected override async Task ExecuteAsync(CancellationToken ct) {\n        var instanceId = Guid NewGuid();\n        var pollingInterval = _config GetValue<int>(\"WorkCoordinatorPublisher:PollingIntervalMilliseconds\", 1000);\n        _logger LogInformation(\n            \"WorkCoordinatorPublisher starting with instance ID {InstanceId}\",\n            instanceId\n        );\n        while ( ct IsCancellationRequested) {\n            try {\n                // 1 Claim work from outbox\n                var batch = await _coordinator ProcessWorkBatchAsync(\n                    instanceId: instanceId,\n                    serviceName: \"OrderService\",\n                    hostName: Environment MachineName,\n                    processId: Environment ProcessId,\n                    metadata: null,\n                    outboxCompletions: [],\n                    outboxFailures: [],\n                    inboxCompletions: [],\n                    inboxFailures: [],\n                    receptorCompletions: [],\n                    receptorFailures: [],\n                    perspectiveCompletions: [],\n                    perspectiveFailures: [],\n                    newOutboxMessages: [],\n                    newInboxMessages: [],\n                    renewOutboxLeaseIds: [],\n                    renewInboxLeaseIds: [],\n                    ct: ct\n                );\n                // 2",
        "startIndex": 6796,
        "preview": "INTO orders (order_id, customer_id, total, status, created_at) VALUES (@OrderId, @CustomerId, @Total, @Status, @CreatedAt)\", new { OrderId = orderId, ..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-4",
        "text": "work from outbox var batch = await _coordinator ProcessWorkBatchAsync( instanceId: instanceId, serviceName: \"OrderService\", hostName: Environment MachineName, processId: Environment ProcessId, metadata: null, outboxCompletions: [], outboxFailures: [], inboxCompletions: [], inboxFailures: [], receptorCompletions: [], receptorFailures: [], perspectiveCompletions: [], perspectiveFailures: [], newOutboxMessages: [], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: ct ); // 2 Publish claimed messages\n                var completions = new List<MessageCompletion>();\n                var failures = new List<MessageFailure>();\n                foreach (var msg in batch ClaimedOutboxMessages) {\n                    try {\n                        await _transport PublishAsync(\n                            topic: msg Topic,\n                            messageId: msg MessageId,\n                            correlationId: msg CorrelationId,\n                            causationId: msg CausationId,\n                            messageType: msg MessageType,\n                            payload: msg Payload,\n                            ct: ct\n                        );\n                        completions Add(new MessageCompletion(\n                            MessageId: msg MessageId,\n                            Status: MessageProcessingStatus Published\n                        ));\n                        _logger LogInformation(\n                            \"Published message {MessageId} of type {MessageType} to topic {Topic}\",\n                            msg MessageId, msg MessageType, msg Topic\n                        );\n                    } catch (Exception ex) {\n                        _logger LogError(\n                            ex,\n                            \"Failed to publish message {MessageId} of type {MessageType}\",\n                            msg MessageId, msg MessageType\n                        );\n                        failures Add(new MessageFailure(\n                            MessageId: msg MessageId,\n                            Status: MessageProcessingStatus Failed,\n                            Error: ex Message,\n                            StackTrace: ex StackTrace\n                        ));\n                    }\n                }\n                // 3 Report completions/failures back to coordinator\n                if (completions Count > 0 || failures Count > 0) {\n                    await _coordinator ProcessWorkBatchAsync(\n                        instanceId: instanceId,\n                        serviceName: \"OrderService\",\n                        hostName: Environment MachineName,\n                        processId: Environment ProcessId,\n                        metadata: null,\n                        outboxCompletions: completions ToArray(),\n                        outboxFailures: failures ToArray(),\n                        inboxCompletions: [],\n                        inboxFailures: [],\n                        receptorCompletions: [],\n                        receptorFailures: [],\n                        perspectiveCompletions: [],\n                        perspectiveFailures: [],\n                        newOutboxMessages: [],\n                        newInboxMessages: [],\n                        renewOutboxLeaseIds: [],\n                        renewInboxLeaseIds: [],\n                        ct: ct\n                    );\n                }\n            } catch (Exception ex) {\n                _logger LogError(ex, \"Error in WorkCoordinatorPublisher\");\n            }\n            await Task",
        "startIndex": 10169,
        "preview": "work from outbox var batch = await _coordinator ProcessWorkBatchAsync( instanceId: instanceId, serviceName: \"OrderService\", hostName: Environment Mach..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-5",
        "text": "Environment MachineName, processId: Environment ProcessId, metadata: null, outboxCompletions: completions ToArray(), outboxFailures: failures ToArray(), inboxCompletions: [], inboxFailures: [], receptorCompletions: [], receptorFailures: [], perspectiveCompletions: [], perspectiveFailures: [], newOutboxMessages: [], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: ct ); } } catch (Exception ex) { _logger LogError(ex, \"Error in WorkCoordinatorPublisher\"); } await Task Delay(pollingInterval, ct);\n        }\n    }\n}\n`\nWorkflow:\nClaim work: Get messages from outbox (with lease)\nPublish: Send to Azure Service Bus\nReport: Mark as Published (success) or Failed (error)\nRetry: Failed messages remain in outbox for retry\n---\nLease-Based Coordination\nHow Leasing Works\n`sql\n-- Claim messages for this instance\nUPDATE wh_outbox\nSET\n    instance_id = @InstanceId,\n    lease_expiry = NOW() + INTERVAL '5 minutes'\nWHERE message_id IN (\n    SELECT message_id\n    FROM wh_outbox\n    WHERE\n        status = 'Stored'\n        AND (instance_id IS NULL OR lease_expiry < NOW())  -- Available or lease expired\n        AND partition_number IN (SELECT * FROM assigned_partitions)\n    ORDER BY created_at\n    LIMIT 100\n)\nRETURNING *;\n`\nBenefits:\n‚úÖ Parallel processing: Multiple workers can process different partitions\n‚úÖ Fault tolerance: If worker crashes, lease expires and message is reclaimed\n‚úÖ Load balancing: Work distributed via consistent hashing (partition_number)\nConfiguration\n`json\n{\n  \"WorkCoordinatorPublisher\": {\n    \"PollingIntervalMilliseconds\": 1000,\n    \"LeaseSeconds\": 300,\n    \"StaleThresholdSeconds\": 600,\n    \"PartitionCount\": 10000,\n    \"MaxPartitionsPerInstance\": 100\n  }\n}\n`\nParameters:\nPollingIntervalMilliseconds: How often to check for new work (1000ms = 1 second)\nLeaseSeconds: How long a lease lasts (300s = 5 minutes)\nStaleThresholdSeconds: When to consider a lease stale (600s = 10 minutes)\nPartitionCount: Total partitions for consistent hashing (10,000)\nMaxPartitionsPerInstance: Max partitions per worker (100)\n---\nGuaranteed Delivery\nAt-Least-Once Semantics\nThe Outbox Pattern provides at-least-once delivery:\n‚úÖ Event is guaranteed to be published (eventually)\n‚ö†Ô∏è Event may be published multiple times (rare, but possible)\nWhy duplicates",
        "startIndex": 13239,
        "preview": "Environment MachineName, processId: Environment ProcessId, metadata: null, outboxCompletions: completions ToArray(), outboxFailures: failures ToArray(..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-6",
        "text": "lease stale (600s = 10 minutes) PartitionCount: Total partitions for consistent hashing (10,000) MaxPartitionsPerInstance: Max partitions per worker (100) --- Guaranteed Delivery At-Least-Once Semantics The Outbox Pattern provides at-least-once delivery: ‚úÖ Event is guaranteed to be published (eventually) ‚ö†Ô∏è Event may be published multiple times (rare, but possible) Why duplicates `\nWorker publishes message to Azure Service Bus (success)\nWorker tries to mark message as Published in database (fails due to network blip)\nLease expires\nDifferent worker claims message\nWorker publishes message again (duplicate )\n`\nSolution: Use Inbox Pattern on receiving side to detect duplicates Retry Strategy\n`csharp\npublic async Task ProcessWorkBatchAsync( ) {\n    // Failed messages: increment attempt count, update status\n    foreach (var failure in outboxFailures) {\n        await conn ExecuteAsync(\n            \"\"\"\n            UPDATE wh_outbox\n            SET\n                attempts = attempts + 1,\n                status = CASE\n                    WHEN attempts + 1 >= 5 THEN 'Failed'  -- Max 5 attempts\n                    ELSE 'Stored'  -- Retry\n                END,\n                last_error = @Error,\n                instance_id = NULL,  -- Release lease\n                lease_expiry = NULL\n            WHERE message_id = @MessageId\n            \"\"\",\n            new { failure MessageId, failure",
        "startIndex": 15024,
        "preview": "lease stale (600s = 10 minutes) PartitionCount: Total partitions for consistent hashing (10,000) MaxPartitionsPerInstance: Max partitions per worker (..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-7",
        "text": "UPDATE wh_outbox SET attempts = attempts + 1, status = CASE WHEN attempts + 1 >= 5 THEN 'Failed' -- Max 5 attempts ELSE 'Stored' -- Retry END, last_error = @Error, instance_id = NULL, -- Release lease lease_expiry = NULL WHERE message_id = @MessageId \"\"\", new { failure MessageId, failure Error }\n        );\n    }\n}\n`\nRetry Logic:\nAttempt 1-4: Retry (status = Stored)\nAttempt 5+: Give up (status = Failed)\nMonitoring:\n`sql\n-- Find messages with multiple failures\nSELECT message_id, message_type, attempts, last_error, created_at\nFROM wh_outbox\nWHERE status = 'Failed'\nORDER BY created_at DESC;\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Store events in same transaction as business data\n‚úÖ Use UUIDv7 for MessageId (time-ordered, avoids index fragmentation)\n‚úÖ Set reasonable lease duration (5 minutes default)\n‚úÖ Monitor failed messages (alerts when attempts >= 5)\n‚úÖ Use consistent hashing (partition_number) for work distribution\n‚úÖ Log all publishes (correlation ID, message type, topic)\n‚úÖ Implement retry logic (exponential backoff, max attempts)\n‚úÖ Clean up old messages (archive Published messages after 30 days)\nDON'T ‚ùå\n‚ùå Publish directly to transport without outbox (breaks atomicity)\n‚ùå Use database locks instead of leases (doesn't scale)\n‚ùå Ignore failed messages (silent data loss)\n‚ùå Set lease duration too short (thrashing)\n‚ùå Set lease duration too long (slow recovery from crashes)\n‚ùå Store large payloads in outbox (use payload size limits)\n‚ùå Skip monitoring (blind to failures)\n---\nMonitoring & Observability\nKey Metrics\n`csharp\npublic class OutboxMetrics {\n    public int StoredCount { get; set; }      // Messages waiting to be published\n    public int PublishedCount { get; set; }   // Messages successfully published\n    public int FailedCount { get; set; }      // Messages that failed max retries\n    public double OldestMessageAge { get; set; }  // Age of oldest Stored message (seconds)\n    public int ActiveLeases { get; set; }     // Number of active leases\n}\npublic async Task<OutboxMetrics> GetMetricsAsync(CancellationToken ct = default) {\n    await using var conn = _db",
        "startIndex": 16040,
        "preview": "UPDATE wh_outbox SET attempts = attempts + 1, status = CASE WHEN attempts + 1 >= 5 THEN 'Failed' -- Max 5 attempts ELSE 'Stored' -- Retry END, last_er..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-8",
        "text": "get; set; } // Messages that failed max retries public double OldestMessageAge { get; set; } // Age of oldest Stored message (seconds) public int ActiveLeases { get; set; } // Number of active leases } public async Task<OutboxMetrics> GetMetricsAsync(CancellationToken ct = default) { await using var conn = _db CreateConnection();\n    var metrics = await conn QuerySingleAsync<OutboxMetrics>(\n        \"\"\"\n        SELECT\n            COUNT(*) FILTER (WHERE status = 'Stored') AS StoredCount,\n            COUNT(*) FILTER (WHERE status = 'Published') AS PublishedCount,\n            COUNT(*) FILTER (WHERE status = 'Failed') AS FailedCount,\n            EXTRACT(EPOCH FROM (NOW() - MIN(created_at) FILTER (WHERE status = 'Stored'))) AS OldestMessageAge,\n            COUNT(*) FILTER (WHERE instance_id IS NOT NULL AND lease_expiry > NOW()) AS ActiveLeases\n        FROM wh_outbox\n        \"\"\",\n        cancellationToken: ct\n    );\n    return metrics;\n}\n`\nAlerts\nCritical Alerts:\nüö® OldestMessageAge > 600 (message stuck for 10+ minutes)\nüö® FailedCount > 0 (messages gave up after max retries)\nüö® StoredCount > 10000 (outbox backlog growing)\nWarning Alerts:\n‚ö†Ô∏è OldestMessageAge > 60 (message not published within 1 minute)\n‚ö†Ô∏è StoredCount > 1000 (outbox filling up)\n---\nTesting\nUnit Tests\n`csharp\n[Test]\npublic async Task ProcessWorkBatchAsync_NewOutboxMessage_StoresInDatabaseAsync() {\n    // Arrange\n    var coordinator = CreateWorkCoordinator();\n    var outboxMsg = new OutboxMessage(\n        MessageId: Guid CreateVersion7(),\n        CorrelationId: Guid CreateVersion7(),\n        CausationId: Guid CreateVersion7(),\n        MessageType: \"OrderCreated\",\n        Payload: \"{\\\"orderId\\\":\\\"123\\\"}\",\n        Topic: \"orders\",\n        StreamKey: \"customer-456\",\n        PartitionKey: \"customer-456\"\n    );\n    // Act\n    await coordinator ProcessWorkBatchAsync(\n        instanceId: Guid NewGuid(),\n        serviceName: \"OrderService\",\n        hostName: \"localhost\",\n        processId: 1234,\n        metadata: null,\n        outboxCompletions: [],\n        outboxFailures: [],\n        inboxCompletions: [],\n        inboxFailures: [],\n        receptorCompletions: [],\n        receptorFailures: [],\n        perspectiveCompletions: [],\n        perspectiveFailures: [],\n        newOutboxMessages: [outboxMsg],\n        newInboxMessages: [],\n        renewOutboxLeaseIds: [],\n        renewInboxLeaseIds: [],\n        ct: CancellationToken None\n    );\n    // Assert\n    var stored = await _db QuerySingleOrDefaultAsync<OutboxRow>(\n        \"SELECT * FROM wh_outbox WHERE message_id = @MessageId\",\n        new { outboxMsg MessageId }\n    );\n    await Assert That(stored) IsNotNull();\n    await Assert That(stored Status) IsEqualTo(\"Stored\");\n    await Assert That(stored MessageType)",
        "startIndex": 17828,
        "preview": "get; set; } // Messages that failed max retries public double OldestMessageAge { get; set; } // Age of oldest Stored message (seconds) public int Acti..."
      },
      {
        "id": "v0.1.0/messaging/outbox-pattern-chunk-9",
        "text": "[], perspectiveFailures: [], newOutboxMessages: [outboxMsg], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: CancellationToken None ); // Assert var stored = await _db QuerySingleOrDefaultAsync<OutboxRow>( \"SELECT * FROM wh_outbox WHERE message_id = @MessageId\", new { outboxMsg MessageId } ); await Assert That(stored) IsNotNull(); await Assert That(stored Status) IsEqualTo(\"Stored\"); await Assert That(stored MessageType) IsEqualTo(\"OrderCreated\");\n}\n`\nIntegration Tests\n`csharp\n[Test]\npublic async Task WorkCoordinatorPublisher_PublishesFromOutboxAsync() {\n    // Arrange\n    var mockTransport = CreateMockTransport();\n    var worker = new WorkCoordinatorPublisherWorker(_coordinator, mockTransport, _config, _logger);\n    // Seed outbox with message\n    await SeedOutboxAsync(new OutboxMessage(/ /));\n    // Act\n    await worker StartAsync(CancellationToken None);\n    await Task Delay(2000);  // Let worker poll\n    await worker StopAsync(CancellationToken None);\n    // Assert\n    await Assert That(mockTransport PublishedMessages) HasCount() EqualTo(1);\n    var published = await _db QuerySingleOrDefaultAsync<OutboxRow>(\n        \"SELECT * FROM wh_outbox WHERE message_id = @MessageId\",\n        new { MessageId = outboxMsg MessageId }\n    );\n    await Assert That(published Status) IsEqualTo(\"Published\");\n}\n`\n---\nFurther Reading\nCore Concepts:\nDispatcher - How to publish events\nReceptors - Message handlers\nMessaging Patterns:\nInbox Pattern - Exactly-once message processing\nWork Coordination - IWorkCoordinator deep dive\nMessage Envelopes - Hop-based observability\nExamples:\nECommerce: Order Service - Real-world outbox usage\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20274,
        "preview": "[], perspectiveFailures: [], newOutboxMessages: [outboxMsg], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: CancellationTo..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/messaging/work-coordinator",
    "title": "Work Coordinator",
    "category": "Messaging",
    "url": "/docs/v0.1.0/messaging/work-coordinator",
    "chunks": [
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-0",
        "text": "Work Coordinator\nThe Work Coordinator (IWorkCoordinator) is Whizbang's atomic batch processing engine It handles Outbox, Inbox, and event store tracking in a single database transaction with lease-based coordination for distributed work Overview\nThe Work Coordinator solves a critical problem: How do you atomically coordinate multiple operations (mark messages complete, store new events, claim work) across distributed workers What It Coordinates\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Single Atomic Database Transaction                  ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îÇ 1 Delete completed outbox messages                ‚îÇ\n‚îÇ 2 Update failed outbox messages (retry counts)    ‚îÇ\n‚îÇ 3 Insert new outbox messages                      ‚îÇ\n‚îÇ 4 Delete completed inbox messages                 ‚îÇ\n‚îÇ 5 Update failed inbox messages                    ‚îÇ\n‚îÇ 6 Insert new inbox messages                       ‚îÇ\n‚îÇ 7 Update receptor processing records              ‚îÇ\n‚îÇ 8 Update perspective checkpoint records           ‚îÇ\n‚îÇ 9 Claim new outbox/inbox work (via leasing)       ‚îÇ\n‚îÇ 10 Return claimed work to caller                   ‚îÇ\n‚îÇ                                                     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey Insight: All operations succeed together or fail together (atomicity via database transaction) ---\nIWorkCoordinator Interface\n`csharp\npublic interface IWorkCoordinator {\n    Task<WorkBatch> ProcessWorkBatchAsync(\n        // Instance info\n        Guid instanceId,\n        string serviceName,\n        string hostName,\n        int processId,\n        Dictionary<string, JsonElement> metadata,\n        // Outbox completions and failures\n        MessageCompletion[] outboxCompletions,\n        MessageFailure[] outboxFailures,\n        // Inbox completions and failures\n        MessageCompletion[] inboxCompletions,\n        MessageFailure[] inboxFailures,\n        // Event store tracking - Receptors\n        ReceptorProcessingCompletion[] receptorCompletions,\n        ReceptorProcessingFailure[] receptorFailures,\n        // Event store tracking - Perspectives\n        PerspectiveCheckpointCompletion[] perspectiveCompletions,\n        PerspectiveCheckpointFailure[] perspectiveFailures,\n        // New work to store\n        OutboxMessage[] newOutboxMessages,\n        InboxMessage[] newInboxMessages,\n        // Lease renewals\n        Guid[] renewOutboxLeaseIds,\n        Guid[] renewInboxLeaseIds,\n        // Configuration\n        WorkBatchFlags flags = WorkBatchFlags None,\n        int partitionCount = 10000,\n        int maxPartitionsPerInstance = 100,\n        int leaseSeconds = 300,\n        int staleThresholdSeconds = 600,\n        CancellationToken cancellationToken = default\n    );\n}\n`\nReturns:\n`csharp\npublic record WorkBatch(\n    OutboxMessage[] ClaimedOutboxMessages,\n    InboxMessage[] ClaimedInboxMessages,\n    int[] AssignedPartitions\n);\n`\n---\nCore Concepts\nAtomic Batch Processing\nPattern: Submit all changes in one call, get all results atomically",
        "startIndex": 0,
        "preview": "Work Coordinator\nThe Work Coordinator (IWorkCoordinator) is Whizbang's atomic batch processing engine It handles Outbox, Inbox, and event store tracki..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-1",
        "text": "10000, int maxPartitionsPerInstance = 100, int leaseSeconds = 300, int staleThresholdSeconds = 600, CancellationToken cancellationToken = default ); } ` Returns: `csharp public record WorkBatch( OutboxMessage[] ClaimedOutboxMessages, InboxMessage[] ClaimedInboxMessages, int[] AssignedPartitions ); ` --- Core Concepts Atomic Batch Processing Pattern: Submit all changes in one call, get all results atomically `csharp\n// Example: Order created, publish event, claim new work\nvar batch = await _coordinator ProcessWorkBatchAsync(\n    instanceId: workerInstanceId,\n    serviceName: \"OrderService\",\n    hostName: Environment MachineName,\n    processId: Environment ProcessId,\n    metadata: null,\n    // No completions/failures this time\n    outboxCompletions: [],\n    outboxFailures: [],\n    inboxCompletions: [],\n    inboxFailures: [],\n    // Event store tracking\n    receptorCompletions: [],\n    receptorFailures: [],\n    perspectiveCompletions: [],\n    perspectiveFailures: [],\n    // Store new OrderCreated event in outbox\n    newOutboxMessages: [\n        new OutboxMessage(\n            MessageId: Guid CreateVersion7(),\n            CorrelationId: correlationId,\n            CausationId: causationId,\n            MessageType: \"OrderCreated\",\n            Payload: JsonSerializer Serialize(orderCreated),\n            Topic: \"orders\",\n            StreamKey: customerId ToString(),\n            PartitionKey: customerId ToString()\n        )\n    ],\n    newInboxMessages: [],\n    // No renewals\n    renewOutboxLeaseIds: [],\n    renewInboxLeaseIds: [],\n    ct: cancellationToken\n);\n// batch ClaimedOutboxMessages = newly claimed work ready to publish\n`\nResult:\nOrderCreated event stored in outbox\nNew outbox messages claimed for this worker\nAll atomic - if database commit fails, nothing happens\nLease-Based Coordination\nProblem: How do multiple workers process messages without conflicts Solution: Leasing - workers \"claim\" messages for a time period `sql\n-- Worker A claims messages\nUPDATE wh_outbox\nSET\n    instance_id = 'worker-a',\n    lease_expiry = NOW() + INTERVAL '5 minutes'\nWHERE message_id IN ( )\n`\nBenefits:\n‚úÖ Prevents duplicate processing: Only one worker holds lease\n‚úÖ Fault tolerance: Lease expires if worker crashes\n‚úÖ Scalability: Multiple workers process different partitions\nPartition-Based Distribution\nProblem: How do you distribute work evenly across workers Solution: Consistent hashing via partition_number `csharp\n// Each message gets a partition number (0-9999)\nvar partitionNumber = Math Abs(customerId",
        "startIndex": 3048,
        "preview": "10000, int maxPartitionsPerInstance = 100, int leaseSeconds = 300, int staleThresholdSeconds = 600, CancellationToken cancellationToken = default ); }..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-2",
        "text": "Only one worker holds lease ‚úÖ Fault tolerance: Lease expires if worker crashes ‚úÖ Scalability: Multiple workers process different partitions Partition-Based Distribution Problem: How do you distribute work evenly across workers Solution: Consistent hashing via partition_number `csharp // Each message gets a partition number (0-9999) var partitionNumber = Math Abs(customerId GetHashCode()) % 10000;\n// Worker A might handle partitions 0-999\n// Worker B might handle partitions 1000-1999\n// Worker C might handle partitions 2000-2999\n// etc `\nBenefits:\n‚úÖ Even distribution: Hash function spreads messages evenly\n‚úÖ Deterministic: Same customer always maps to same partition\n‚úÖ Scalable: Add more workers, redistribute partitions\n---\nParameters Explained\nInstance Information\n`csharp\nGuid instanceId,          // Unique ID for this worker instance\nstring serviceName,       // Name of service (\"OrderService\")\nstring hostName,          // Machine name (Environment MachineName)\nint processId,            // Process ID (Environment ProcessId)\nDictionary<string, JsonElement> metadata,  // Optional metadata\n`\nUsage: Identifies which worker is processing messages (for observability and debugging) Message Completions\n`csharp\nMessageCompletion[] outboxCompletions,\nMessageCompletion[] inboxCompletions,\npublic record MessageCompletion(\n    Guid MessageId,\n    MessageProcessingStatus Status\n);\npublic enum MessageProcessingStatus {\n    Stored = 1,\n    Published = 2,\n    Completed = 4,\n    Failed = 8\n}\n`\nUsage: Mark messages as successfully processed (delete from outbox/inbox) Message Failures\n`csharp\nMessageFailure[] outboxFailures,\nMessageFailure[] inboxFailures,\npublic record MessageFailure(\n    Guid MessageId,\n    MessageProcessingStatus Status,\n    string Error,\n    string StackTrace = null\n);\n`\nUsage: Mark messages as failed (increment retry count, update error) Event Store Tracking - Receptors\n`csharp\nReceptorProcessingCompletion[] receptorCompletions,\nReceptorProcessingFailure[] receptorFailures,\npublic record ReceptorProcessingCompletion(\n    Guid EventId,\n    string ReceptorName,\n    ReceptorProcessingStatus Status\n);\npublic record ReceptorProcessingFailure(\n    Guid EventId,\n    string ReceptorName,\n    ReceptorProcessingStatus Status,\n    string Error\n);\n`\nPurpose: Track which receptors have processed which events (log-style, many receptors per event)",
        "startIndex": 5166,
        "preview": "Only one worker holds lease ‚úÖ Fault tolerance: Lease expires if worker crashes ‚úÖ Scalability: Multiple workers process different partitions Partition-..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-3",
        "text": "retry count, update error) Event Store Tracking - Receptors `csharp ReceptorProcessingCompletion[] receptorCompletions, ReceptorProcessingFailure[] receptorFailures, public record ReceptorProcessingCompletion( Guid EventId, string ReceptorName, ReceptorProcessingStatus Status ); public record ReceptorProcessingFailure( Guid EventId, string ReceptorName, ReceptorProcessingStatus Status, string Error ); ` Purpose: Track which receptors have processed which events (log-style, many receptors per event) Use Cases:\nSide effects (sending emails, notifications)\nRead model updates (non-ordered)\nAnalytics/metrics collection\nEvent Store Tracking - Perspectives\n`csharp\nPerspectiveCheckpointCompletion[] perspectiveCompletions,\nPerspectiveCheckpointFailure[] perspectiveFailures,\npublic record PerspectiveCheckpointCompletion(\n    Guid StreamId,\n    string PerspectiveName,\n    Guid LastEventId,\n    PerspectiveProcessingStatus Status\n);\npublic record PerspectiveCheckpointFailure(\n    Guid StreamId,\n    string PerspectiveName,\n    Guid LastEventId,\n    PerspectiveProcessingStatus Status,\n    string Error\n);\n`\nPurpose: Track checkpoints for perspectives processing event streams (one checkpoint per stream/perspective pair) Use Cases:\nRead model projections (ordered events per stream)\nTemporal queries (state as of specific event)\nRebuilding projections from event history\nKey Difference from Receptors:\nReceptors: Many receptors can process same event independently\nPerspectives: One checkpoint per (stream_id, perspective_name) pair for ordered processing\nNew Messages\n`csharp\nOutboxMessage[] newOutboxMessages,\nInboxMessage[] newInboxMessages,\npublic record OutboxMessage(\n    Guid MessageId,\n    Guid CorrelationId,\n    Guid CausationId,\n    string MessageType,\n    string Payload,  // JSON\n    string Topic,\n    string StreamKey,\n    string PartitionKey\n);\npublic record InboxMessage(\n    Guid MessageId,\n    Guid CorrelationId,\n    Guid CausationId,\n    string MessageType,\n    string Payload,  // JSON\n    string SourceTopic\n);\n`\nUsage: Store new events in outbox (for publishing) or inbox (for deduplication) Lease Renewals\n`csharp\nGuid[] renewOutboxLeaseIds,\nGuid[] renewInboxLeaseIds,\n`\nUsage: Extend leases on messages being processed (prevents timeout during long operations) Configuration\n`csharp\nWorkBatchFlags flags = WorkBatchFlags",
        "startIndex": 7173,
        "preview": "retry count, update error) Event Store Tracking - Receptors `csharp ReceptorProcessingCompletion[] receptorCompletions, ReceptorProcessingFailure[] re..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-4",
        "text": "Guid CausationId, string MessageType, string Payload, // JSON string SourceTopic ); ` Usage: Store new events in outbox (for publishing) or inbox (for deduplication) Lease Renewals `csharp Guid[] renewOutboxLeaseIds, Guid[] renewInboxLeaseIds, ` Usage: Extend leases on messages being processed (prevents timeout during long operations) Configuration `csharp WorkBatchFlags flags = WorkBatchFlags None,\nint partitionCount = 10000,\nint maxPartitionsPerInstance = 100,\nint leaseSeconds = 300,\nint staleThresholdSeconds = 600,\n`\nFlags:\nNone: Normal operation\nSkipClaim: Don't claim new work (only process completions/failures)\nParameters:\npartitionCount: Total partitions (10,000 recommended)\nmaxPartitionsPerInstance: Max partitions per worker (100 recommended)\nleaseSeconds: Lease duration (300s = 5 minutes)\nstaleThresholdSeconds: Stale lease threshold (600s = 10 minutes)\n---\nCommon Usage Patterns\nPattern 1: Store Event in Outbox\n`csharp\n// Receptor creates event, stores in outbox\nawait _coordinator ProcessWorkBatchAsync(\n    instanceId: instanceId,\n    serviceName: \"OrderService\",\n    hostName: Environment MachineName,\n    processId: Environment ProcessId,\n    metadata: null,\n    outboxCompletions: [],\n    outboxFailures: [],\n    inboxCompletions: [],\n    inboxFailures: [],\n    receptorCompletions: [],\n    receptorFailures: [],\n    perspectiveCompletions: [],\n    perspectiveFailures: [],\n    newOutboxMessages: [\n        new OutboxMessage(\n            MessageId: Guid CreateVersion7(),\n            CorrelationId: command CorrelationId Value,\n            CausationId: command MessageId Value,\n            MessageType: typeof(OrderCreated) FullName ,\n            Payload: JsonSerializer Serialize(orderCreated),\n            Topic: \"orders\",\n            StreamKey: customerId ToString(),\n            PartitionKey: customerId ToString()\n        )\n    ],\n    newInboxMessages: [],\n    renewOutboxLeaseIds: [],\n    renewInboxLeaseIds: [],\n    ct: ct\n);\n`\nPattern 2: Claim and Publish Outbox Messages\n`csharp\n// Background worker claims work\nvar batch = await _coordinator ProcessWorkBatchAsync(\n    instanceId: workerInstanceId,\n    serviceName: \"OrderService\",\n    hostName: Environment MachineName,\n    processId: Environment ProcessId,\n    metadata: null,\n    outboxCompletions: [],\n    outboxFailures: [],\n    inboxCompletions: [],\n    inboxFailures: [],\n    receptorCompletions: [],\n    receptorFailures: [],\n    perspectiveCompletions: [],\n    perspectiveFailures: [],\n    newOutboxMessages: [],\n    newInboxMessages: [],\n    renewOutboxLeaseIds: [],\n    renewInboxLeaseIds: [],\n    ct: ct\n);\n// Publish claimed messages\nforeach (var msg in batch ClaimedOutboxMessages) {\n    await _transport PublishAsync(msg Topic, msg MessageId, msg Payload, ct);\n}\n`\nPattern 3: Report Completions After Publishing\n`csharp\nvar completions = new List<MessageCompletion>();\nforeach (var msg in batch",
        "startIndex": 9021,
        "preview": "Guid CausationId, string MessageType, string Payload, // JSON string SourceTopic ); ` Usage: Store new events in outbox (for publishing) or inbox (for..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-5",
        "text": "newOutboxMessages: [], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: ct ); // Publish claimed messages foreach (var msg in batch ClaimedOutboxMessages) { await _transport PublishAsync(msg Topic, msg MessageId, msg Payload, ct); } ` Pattern 3: Report Completions After Publishing `csharp var completions = new List<MessageCompletion>(); foreach (var msg in batch ClaimedOutboxMessages) {\n    try {\n        await _transport PublishAsync(msg Topic, msg MessageId, msg Payload, ct);\n        completions Add(new MessageCompletion(\n            MessageId: msg MessageId,\n            Status: MessageProcessingStatus Published\n        ));\n    } catch (Exception ex) {\n        failures Add(new MessageFailure(\n            MessageId: msg MessageId,\n            Status: MessageProcessingStatus Failed,\n            Error: ex Message,\n            StackTrace: ex StackTrace\n        ));\n    }\n}\n// Report back to coordinator\nawait _coordinator ProcessWorkBatchAsync(\n    instanceId: workerInstanceId,\n    serviceName: \"OrderService\",\n    hostName: Environment MachineName,\n    processId: Environment ProcessId,\n    metadata: null,\n    outboxCompletions: completions ToArray(),\n    outboxFailures: failures ToArray(),\n    / /,\n    ct: ct\n);\n`\nPattern 4: Store in Inbox (Deduplication)\n`csharp\n// Worker receives message from Azure Service Bus\ntry {\n    // Store in inbox (atomic - prevents duplicate processing)\n    await _coordinator ProcessWorkBatchAsync(\n        instanceId: workerInstanceId,\n        serviceName: \"InventoryWorker\",\n        hostName: Environment MachineName,\n        processId: Environment ProcessId,\n        metadata: null,\n        outboxCompletions: [],\n        outboxFailures: [],\n        inboxCompletions: [],\n        inboxFailures: [],\n        receptorCompletions: [],\n        receptorFailures: [],\n        perspectiveCompletions: [],\n        perspectiveFailures: [],\n        newOutboxMessages: [],\n        newInboxMessages: [\n            new InboxMessage(\n                MessageId: message MessageId,\n                CorrelationId: message CorrelationId,\n                CausationId: message CausationId,\n                MessageType: message MessageType,\n                Payload: message Payload,\n                SourceTopic: \"orders\"\n            )\n        ],\n        renewOutboxLeaseIds: [],\n        renewInboxLeaseIds: [],\n        ct: ct\n    );\n} catch (Npgsql PostgresException ex) when (ex SqlState == \"23505\") {\n    // Unique constraint violation = duplicate message\n    _logger LogWarning(\"Duplicate message {MessageId} detected\", message MessageId);\n    return;  // Skip processing\n}\n`\n---\nPostgreSQL Implementation\nThe Work Coordinator is implemented as a PostgreSQL stored procedure for optimal performance",
        "startIndex": 11520,
        "preview": "newOutboxMessages: [], newInboxMessages: [], renewOutboxLeaseIds: [], renewInboxLeaseIds: [], ct: ct ); // Publish claimed messages foreach (var msg i..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-6",
        "text": "ct: ct ); } catch (Npgsql PostgresException ex) when (ex SqlState == \"23505\") { // Unique constraint violation = duplicate message _logger LogWarning(\"Duplicate message {MessageId} detected\", message MessageId); return; // Skip processing } ` --- PostgreSQL Implementation The Work Coordinator is implemented as a PostgreSQL stored procedure for optimal performance Stored Procedure: process_work_batch\n`sql\nCREATE OR REPLACE FUNCTION process_work_batch(\n    p_instance_id UUID,\n    p_service_name VARCHAR(255),\n    p_host_name VARCHAR(255),\n    p_process_id INT,\n    p_metadata JSONB,\n    -- Completions and failures (JSON arrays)\n    p_outbox_completions JSONB,\n    p_outbox_failures JSONB,\n    p_inbox_completions JSONB,\n    p_inbox_failures JSONB,\n    -- Event store tracking\n    p_receptor_completions JSONB,\n    p_receptor_failures JSONB,\n    p_perspective_completions JSONB,\n    p_perspective_failures JSONB,\n    -- New messages\n    p_new_outbox_messages JSONB,\n    p_new_inbox_messages JSONB,\n    -- Lease renewals\n    p_renew_outbox_lease_ids JSONB,\n    p_renew_inbox_lease_ids JSONB,\n    -- Configuration\n    p_partition_count INT DEFAULT 10000,\n    p_max_partitions_per_instance INT DEFAULT 100,\n    p_lease_seconds INT DEFAULT 300,\n    p_stale_threshold_seconds INT DEFAULT 600\n)\nRETURNS TABLE (\n    claimed_outbox_messages JSONB,\n    claimed_inbox_messages JSONB,\n    assigned_partitions JSONB\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    -- 1 Delete completed outbox messages\n    DELETE FROM wh_outbox\n    WHERE message_id IN (\n        SELECT (value->>'MessageId')::UUID\n        FROM jsonb_array_elements(p_outbox_completions)\n    );\n    -- 2 Update failed outbox messages\n    -- (increment attempts, update error, release lease)\n    -- 3 Insert new outbox messages\n    -- (with partition_number for consistent hashing)\n    -- 4 Delete completed inbox messages\n    -- 5 Update failed inbox messages\n    -- 6 Insert new inbox messages\n    -- 7 Update receptor processing records\n    -- 8 Update perspective checkpoint records\n    -- 9 Claim new outbox work (with leasing)\n    -- 10 Claim new inbox work (with leasing)\n    -- Return claimed work\n    RETURN QUERY SELECT",
        "startIndex": 13889,
        "preview": "ct: ct ); } catch (Npgsql PostgresException ex) when (ex SqlState == \"23505\") { // Unique constraint violation = duplicate message _logger LogWarning(..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-7",
        "text": "completed inbox messages -- 5 Update failed inbox messages -- 6 Insert new inbox messages -- 7 Update receptor processing records -- 8 Update perspective checkpoint records -- 9 Claim new outbox work (with leasing) -- 10 Claim new inbox work (with leasing) -- Return claimed work RETURN QUERY SELECT ;\nEND;\n$$;\n`\nBenefits:\n‚úÖ Single database roundtrip: All operations in one call\n‚úÖ Atomic: Transaction semantics guarantee consistency\n‚úÖ Performance: Stored procedure is compiled, optimized by PostgreSQL\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use single transaction: All operations atomic\n‚úÖ Report completions promptly: Don't let leases expire\n‚úÖ Monitor stale leases: Alert when lease_expiry is old\n‚úÖ Use consistent hashing: Partition-based work distribution\n‚úÖ Log all operations: InstanceId, ServiceName, timestamps\n‚úÖ Handle failures gracefully: Increment retry counts, log errors\n‚úÖ Clean up old data: Archive completed messages periodically\n‚úÖ Configure lease duration: Balance fault tolerance vs recovery time\nDON'T ‚ùå\n‚ùå Skip reporting completions (leads to duplicate work)\n‚ùå Ignore failures (silent data loss)\n‚ùå Use locks instead of leases (doesn't scale)\n‚ùå Set lease duration too short (thrashing)\n‚ùå Set lease duration too long (slow recovery from crashes)\n‚ùå Process outside coordinator (breaks atomicity)\n‚ùå Skip monitoring (blind to failures)\n---\nMonitoring & Observability\nKey Metrics\n`csharp\npublic class WorkCoordinatorMetrics {\n    public int OutboxStoredCount { get; set; }\n    public int OutboxPublishedCount { get; set; }\n    public int OutboxFailedCount { get; set; }\n    public int InboxReceivedCount { get; set; }\n    public int InboxCompletedCount { get; set; }\n    public int InboxFailedCount { get; set; }\n    public int ActiveLeases { get; set; }\n    public int StaleLeases { get; set; }\n}\n`\nAlerts\nCritical:\nüö® StaleLeases > 0 (workers crashed or stuck)\nüö® OutboxFailedCount > 0 or InboxFailedCount > 0 (messages gave up)\nWarning:\n‚ö†Ô∏è OutboxStoredCount > 10000 (backlog growing)\n‚ö†Ô∏è ActiveLeases > workers * maxPartitionsPerInstance (too many leases)\n---\nFurther Reading\nCore Concepts:\nDispatcher - Message routing\nMessaging Patterns:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nMessage Envelopes - Hop-based observability\nData Access:\nEvent Store - Event storage and replay\n---\nVersion 0",
        "startIndex": 15708,
        "preview": "completed inbox messages -- 5 Update failed inbox messages -- 6 Insert new inbox messages -- 7 Update receptor processing records -- 8 Update perspect..."
      },
      {
        "id": "v0.1.0/messaging/work-coordinator-chunk-8",
        "text": "(backlog growing) ‚ö†Ô∏è ActiveLeases > workers * maxPartitionsPerInstance (too many leases) --- Further Reading Core Concepts: Dispatcher - Message routing Messaging Patterns: Outbox Pattern - Reliable event publishing Inbox Pattern - Exactly-once processing Message Envelopes - Hop-based observability Data Access: Event Store - Event storage and replay --- Version 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 624,
        "preview": "(backlog growing) ‚ö†Ô∏è ActiveLeases > workers * maxPartitionsPerInstance (too many leases) --- Further Reading Core Concepts: Dispatcher - Message routi..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/source-generators/aggregate-ids",
    "title": "Aggregate IDs",
    "category": "Source Generators",
    "url": "/docs/v0.1.0/source-generators/aggregate-ids",
    "chunks": [
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-0",
        "text": "Aggregate IDs\nThe AggregateIdGenerator discovers properties marked with [AggregateId] at compile-time and generates zero-reflection extractor methods This enables PolicyContext to extract aggregate IDs from messages for distributed tracing, tenant isolation, and policy decisions without runtime reflection Why Aggregate IDs Aggregate IDs are the primary identifiers for domain entities (Orders, Customers, Products) Whizbang uses them for:\n| Use Case | Description | Example |\n|----------|-------------|---------|\n| Distributed Tracing | Group all events for an aggregate | All events for Order #123 |\n| Tenant Isolation | Route messages to correct tenant database | Customer #456 ‚Üí Tenant A database |\n| Policy Decisions | Make routing decisions based on ID | High-value orders ‚Üí Priority queue |\n| Stream Keys | Organize events in Event Store | Stream: Order-abc123 |\n| Partitioning | Distribute work across instances | Order #789 ‚Üí Instance 2 |\nProblem: Extracting IDs at runtime requires reflection (slow, not AOT-compatible) Solution: Generator discovers IDs at compile-time, generates zero-reflection extractors ---\nHow It Works\nMark Properties with [AggregateId]\n`csharp\nusing Whizbang Core;\n// Command\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,  // ‚Üê Marked as aggregate ID\n    Guid CustomerId,\n    OrderItem[] Items\n) : ICommand;\n// Event\npublic record OrderCreated(\n    [property: AggregateId] Guid OrderId,  // ‚Üê Marked as aggregate ID\n    Guid CustomerId,\n    decimal Total,\n    DateTimeOffset CreatedAt\n) : IEvent;\n`\nConvention: One [AggregateId] per message type (typically the primary entity ID) ---\nCompile-Time Discovery\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  AggregateIdGenerator (Roslyn)                  ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 Scan syntax tree for records/classes        ‚îÇ\n‚îÇ  2 Check properties for [AggregateId] attribute‚îÇ\n‚îÇ  3 Extract: Message type, Property name        ‚îÇ\n‚îÇ  4 Validate: Must be Guid or Guid ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Generated: AggregateIdExtractors g",
        "startIndex": 0,
        "preview": "Aggregate IDs\nThe AggregateIdGenerator discovers properties marked with [AggregateId] at compile-time and generates zero-reflection extractor methods ..."
      },
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-1",
        "text": "Compile-Time Discovery ` ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ AggregateIdGenerator (Roslyn) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 Scan syntax tree for records/classes ‚îÇ ‚îÇ 2 Check properties for [AggregateId] attribute‚îÇ ‚îÇ 3 Extract: Message type, Property name ‚îÇ ‚îÇ 4 Validate: Must be Guid or Guid ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Generated: AggregateIdExtractors g cs           ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  - Static extractor methods (zero reflection)   ‚îÇ\n‚îÇ  - Type-safe property access                    ‚îÇ\n‚îÇ  - AOT-compatible                                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nGenerated Code\nAggregateIdExtractors g cs:\n`csharp\n// <auto-generated/>\nusing System;\nnamespace MyApp Generated;\npublic static class AggregateIdExtractors {\n    /// <summary>\n    /// Extracts aggregate ID from a message (zero reflection, AOT-compatible) /// Generated for 3 message types with [AggregateId] attributes /// </summary>\n    public static Guid ExtractAggregateId(object message, Type messageType) {\n        // CreateOrder\n        if (messageType == typeof(global::MyApp Commands CreateOrder)) {\n            return ((global::MyApp Commands CreateOrder)message) OrderId;\n        }\n        // OrderCreated\n        if (messageType == typeof(global::MyApp Events OrderCreated)) {\n            return ((global::MyApp Events OrderCreated)message) OrderId;\n        }\n        // ShipOrder\n        if (messageType == typeof(global::MyApp Commands ShipOrder)) {\n            return ((global::MyApp Commands ShipOrder)message) OrderId;\n        }\n        return null;  // No [AggregateId] found\n    }\n}\n`\nKey Features:\nZero Reflection: Direct type checks and casts\nType Safe: Compile-time property access\nAOT Compatible: No MakeGenericType or GetProperty calls\nFast: < 10ns per extraction (vs ~1,000ns with reflection)\n---\nUsage in PolicyContext\nPolicyContext Integration\n`csharp\nusing Whizbang Core Policies;\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    private readonly IPolicyEngine _policies;\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // PolicyContext automatically extracts OrderId via generated extractor\n        var context = new PolicyContext {\n            Message = message,\n            MessageType = typeof(CreateOrder),\n            AggregateId = AggregateIdExtractors ExtractAggregateId(message, typeof(CreateOrder)),  // ‚Üê Generated method\n            UserId = GetCurrentUserId(),\n            TenantId = GetCurrentTenantId()\n        };\n        // Policy decisions based on aggregate ID\n        var decision = await _policies EvaluateAsync(\"OrderRouting\", context, ct);\n        // Route based on aggregate ID\n        if (decision",
        "startIndex": 2224,
        "preview": "Compile-Time Discovery ` ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ AggregateIdGenerator (Roslyn) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 Scan syntax tree for records/c..."
      },
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-2",
        "text": "context = new PolicyContext { Message = message, MessageType = typeof(CreateOrder), AggregateId = AggregateIdExtractors ExtractAggregateId(message, typeof(CreateOrder)), // ‚Üê Generated method UserId = GetCurrentUserId(), TenantId = GetCurrentTenantId() }; // Policy decisions based on aggregate ID var decision = await _policies EvaluateAsync(\"OrderRouting\", context, ct); // Route based on aggregate ID if (decision IsAllowed) {\n            // Process order }\n        return new OrderCreated(/ /);\n    }\n}\n`\nAutomatic Extraction (via MessageEnvelope):\n`csharp\n// MessageEnvelope automatically extracts aggregate ID\nvar envelope = MessageEnvelope Create(\n    messageId: MessageId New(),\n    correlationId: CorrelationId New(),\n    causationId: null,\n    payload: message,\n    currentHop: new MessageHop {\n        // Aggregate ID extracted automatically via generator\n        StreamKey: AggregateIdExtractors ExtractAggregateId(message, message GetType()) ToString()\n    }\n);\n`\n---\nPatterns\nPattern 1: Simple Aggregate ID\n`csharp\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,  // ‚Üê Primary entity ID\n    Guid CustomerId,\n    OrderItem[] Items\n) : ICommand;\n`\nGenerated:\n`csharp\nif (messageType == typeof(CreateOrder)) {\n    return ((CreateOrder)message) OrderId;\n}\n`\n---\nPattern 2: Nullable Aggregate ID\n`csharp\npublic record GetOrders(\n    [property: AggregateId] Guid OrderId,  // ‚Üê Nullable (optional filter)\n    Guid CustomerId\n) : ICommand;\n`\nGenerated:\n`csharp\nif (messageType == typeof(GetOrders)) {\n    return ((GetOrders)message) OrderId;  // Returns Guid (nullable)\n}\n`\nUse Case: Query commands where aggregate ID is optional ---\nPattern 3: Inherited Aggregate ID\n`csharp\n// Base class\npublic abstract record OrderCommand {\n    [AggregateId]\n    public Guid OrderId { get; init; }\n}\n// Derived commands inherit [AggregateId]\npublic record ShipOrder(Guid OrderId, string TrackingNumber) : OrderCommand, ICommand;\npublic record CancelOrder(Guid OrderId, string Reason) : OrderCommand, ICommand;\n`\nGenerated (one extractor per type):\n`csharp\nif (messageType == typeof(ShipOrder)) {\n    return ((ShipOrder)message) OrderId;  // Inherited property\n}\nif (messageType == typeof(CancelOrder)) {\n    return ((CancelOrder)message) OrderId;  // Inherited property\n}\n`\n---\nDiagnostics\nWHIZ004: Aggregate ID Property Discovered\nSeverity: Info\nMessage: Found [AggregateId] on property '{0}",
        "startIndex": 4675,
        "preview": "context = new PolicyContext { Message = message, MessageType = typeof(CreateOrder), AggregateId = AggregateIdExtractors ExtractAggregateId(message, ty..."
      },
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-3",
        "text": ": OrderCommand, ICommand; ` Generated (one extractor per type): `csharp if (messageType == typeof(ShipOrder)) { return ((ShipOrder)message) OrderId; // Inherited property } if (messageType == typeof(CancelOrder)) { return ((CancelOrder)message) OrderId; // Inherited property } ` --- Diagnostics WHIZ004: Aggregate ID Property Discovered Severity: Info Message: Found [AggregateId] on property '{0} {1}'\nExample:\n`\ninfo WHIZ004: Found [AggregateId] on property 'CreateOrder OrderId'\ninfo WHIZ004: Found [AggregateId] on property 'OrderCreated OrderId'\n`\n---\nWHIZ005: Multiple [AggregateId] Attributes\nSeverity: Warning\nMessage: Type '{0}' has multiple [AggregateId] attributes Using first: '{1}'\nExample:\n`\nwarning WHIZ005: Type 'CreateOrder' has multiple [AggregateId] attributes Using first: 'OrderId'\n`\nCause:\n`csharp\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,  // ‚Üê First (used)\n    [property: AggregateId] Guid CustomerId  // ‚Üê Second (ignored)\n) : ICommand;\n`\nFix: Only mark one property per message type ---\nWHIZ006: Invalid Property Type\nSeverity: Error\nMessage: Property '{0} {1}' has [AggregateId] but is not Guid or Guid Example:\n`\nerror WHIZ006: Property 'CreateOrder OrderId' has [AggregateId] but is not Guid or Guid `\nCause:\n`csharp\npublic record CreateOrder(\n    [property: AggregateId] string OrderId,  // ‚ùå String, not Guid\n    Guid CustomerId\n) : ICommand;\n`\nFix: Use Guid or Guid :\n`csharp\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,  // ‚úÖ Guid\n    Guid CustomerId\n) : ICommand;\n`\n---\nPerformance\nBenchmark: Extraction Speed\n| Method | Overhead | Notes |\n|--------|----------|-------|\n| Generated Extractor | ~8ns | Direct cast + property access |\n| Reflection | ~1,000ns | GetProperty() + GetValue() |\n125x faster than reflection `csharp\n// ‚úÖ Generated (fast)\nvar id = AggregateIdExtractors ExtractAggregateId(message, typeof(CreateOrder));\n// ‚ùå Reflection (slow)\nvar property = typeof(CreateOrder) GetProperty(\"OrderId\");\nvar id = (Guid )property GetValue(message);\n`\nZero Allocations\nGenerated code produces zero allocations:\n`csharp\n// Generated code (no boxing/unboxing, no reflection overhead)\nif (messageType == typeof(CreateOrder)) {\n    return ((CreateOrder)message)",
        "startIndex": 6685,
        "preview": ": OrderCommand, ICommand; ` Generated (one extractor per type): `csharp if (messageType == typeof(ShipOrder)) { return ((ShipOrder)message) OrderId; /..."
      },
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-4",
        "text": "`csharp // ‚úÖ Generated (fast) var id = AggregateIdExtractors ExtractAggregateId(message, typeof(CreateOrder)); // ‚ùå Reflection (slow) var property = typeof(CreateOrder) GetProperty(\"OrderId\"); var id = (Guid )property GetValue(message); ` Zero Allocations Generated code produces zero allocations: `csharp // Generated code (no boxing/unboxing, no reflection overhead) if (messageType == typeof(CreateOrder)) { return ((CreateOrder)message) OrderId;  // Direct property access\n}\n`\nBenchmark:\n`\nMemory Diagnostics:\n  Gen 0: 0\n  Gen 1: 0\n  Gen 2: 0\n  Allocated: 0 bytes\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Mark primary entity ID with [AggregateId]\n‚úÖ Use Guid or Guid for ID properties\n‚úÖ Use UUIDv7 for time-ordered IDs (Guid CreateVersion7())\n‚úÖ One [AggregateId] per message (typically the main entity)\n‚úÖ Consistent naming (OrderId, CustomerId, ProductId)\n‚úÖ Apply to both commands and events for traceability\nDON'T ‚ùå\n‚ùå Mark multiple properties (only first is used)\n‚ùå Use non-Guid types (must be Guid or Guid )\n‚ùå Skip [AggregateId] on primary entities (breaks tracing)\n‚ùå Use random GUIDs (use UUIDv7 for time-ordering)\n---\nTroubleshooting\nProblem: Extractor Returns Null\nSymptoms: ExtractAggregateId() returns null for message Causes:\nProperty not marked with [AggregateId]\nWrong message type passed\nSolution:\n`csharp\n// ‚úÖ Mark property\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,  // Add attribute\n    Guid CustomerId\n) : ICommand;\n// ‚úÖ Pass correct type\nvar id = AggregateIdExtractors ExtractAggregateId(message, message GetType());\n`\nProblem: Property Ignored\nSymptoms: Warning WHIZ005, second property not used Cause: Multiple [AggregateId] attributes on same type",
        "startIndex": 8540,
        "preview": "`csharp // ‚úÖ Generated (fast) var id = AggregateIdExtractors ExtractAggregateId(message, typeof(CreateOrder)); // ‚ùå Reflection (slow) var property = t..."
      },
      {
        "id": "v0.1.0/source-generators/aggregate-ids-chunk-5",
        "text": "`csharp // ‚úÖ Mark property public record CreateOrder( [property: AggregateId] Guid OrderId, // Add attribute Guid CustomerId ) : ICommand; // ‚úÖ Pass correct type var id = AggregateIdExtractors ExtractAggregateId(message, message GetType()); ` Problem: Property Ignored Symptoms: Warning WHIZ005, second property not used Cause: Multiple [AggregateId] attributes on same type Solution: Remove duplicate:\n`csharp\n// ‚ùå Multiple attributes\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,\n    [property: AggregateId] Guid CustomerId  // ‚Üê Remove this\n) : ICommand;\n// ‚úÖ Single attribute\npublic record CreateOrder(\n    [property: AggregateId] Guid OrderId,\n    Guid CustomerId\n) : ICommand;\n`\n---\nIntegration with Event Store\nStream Key Generation\nAggregate IDs are used to generate Event Store stream keys:\n`csharp\n// Event Store automatically uses aggregate ID for stream key\nvar streamKey = AggregateIdExtractors ExtractAggregateId(@event, @event GetType()) ToString();\n// Stream: \"Order-abc123-def456- \"\n// All events for Order #abc123 in same stream\n`\nBenefits:\nConsistent Ordering: Events for same aggregate always ordered\nRebuild Capability: Replay events for specific aggregate\nQuery Efficiency: Read all events for aggregate in one query\n---\nFurther Reading\nSource Generators:\nReceptor Discovery - Compile-time receptor discovery\nPerspective Discovery - Compile-time perspective discovery\nMessage Registry - VSCode extension integration\nJSON Contexts - AOT-compatible JSON serialization\nCore Concepts:\nMessage Context - MessageId, CorrelationId, CausationId\nObservability - Distributed tracing with hops\nData Access:\nEvent Store - Event sourcing and stream storage\nInfrastructure:\nPolicies - Policy-based routing and decisions\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 9786,
        "preview": "`csharp // ‚úÖ Mark property public record CreateOrder( [property: AggregateId] Guid OrderId, // Add attribute Guid CustomerId ) : ICommand; // ‚úÖ Pass c..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/source-generators/json-contexts",
    "title": "JSON Contexts",
    "category": "Source Generators",
    "url": "/docs/v0.1.0/source-generators/json-contexts",
    "chunks": [
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-0",
        "text": "JSON Contexts\nThe MessageJsonContextGenerator discovers all message types (ICommand, IEvent) at compile-time and generates a JsonSerializerContext with JsonTypeInfo for AOT-compatible JSON serialization This enables Native AOT deployments with zero reflection overhead Why JSON Source Generation Problem: Traditional JsonSerializer uses reflection at runtime:\n`csharp\n// ‚ùå Reflection-based (not AOT-compatible)\nvar json = JsonSerializer Serialize(message);  // Scans type at runtime var deserialized = JsonSerializer Deserialize<CreateOrder>(json);  // Reflection `\nIssues with Reflection:\n‚ùå Not AOT Compatible: Native AOT trims reflection metadata\n‚ùå Slow First Call: ~50-100ms to scan type and build metadata\n‚ùå Runtime Overhead: Type analysis on every new type\n‚ùå Large Binary Size: Includes all reflection infrastructure\nSolution: Source-Generated JsonSerializerContext:\n`csharp\n// ‚úÖ AOT-compatible (compile-time metadata)\nvar options = new JsonSerializerOptions {\n    TypeInfoResolver = new WhizbangJsonContext()  // Generated at compile-time\n};\nvar json = JsonSerializer Serialize(message, options);  // Zero reflection var deserialized = JsonSerializer Deserialize<CreateOrder>(json, options);\n`\nBenefits:\n‚úÖ AOT Compatible: No reflection, full Native AOT support\n‚úÖ Fast: Zero runtime type analysis (~100x faster first call)\n‚úÖ Small Binary: No reflection infrastructure needed\n‚úÖ Explicit: All serialized types visible at compile-time\n---\nHow It Works\nCompile-Time Discovery\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  MessageJsonContextGenerator (Roslyn)            ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  Discovers:                                      ‚îÇ\n‚îÇ  1 Messages (ICommand, IEvent)                 ‚îÇ\n‚îÇ  2 Nested types (OrderItem in List<OrderItem>) ‚îÇ\n‚îÇ  3 Collection types (List<T>)                  ‚îÇ\n‚îÇ  4 WhizbangId types (MessageId, ProductId)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Generated Files                                 ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 MessageJsonContext g cs                      ‚îÇ\n‚îÇ     ‚îî‚îÄ JsonTypeInfo for all discovered types    ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  2 WhizbangJsonContext g cs (facade)            ‚îÇ\n‚îÇ     ‚îî‚îÄ Public API for JsonSerializerOptions     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nGenerated Code\nWhizbangJsonContext g cs (facade):\n`csharp\nusing System Text Json;\nusing System Text Json Serialization;\nnamespace MyApp Generated;\n/// <summary>\n/// Generated JSON context for WhizBang message serialization (AOT-compatible)",
        "startIndex": 0,
        "preview": "JSON Contexts\nThe MessageJsonContextGenerator discovers all message types (ICommand, IEvent) at compile-time and generates a JsonSerializerContext wit..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-1",
        "text": "‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 WhizbangJsonContext g cs (facade) ‚îÇ ‚îÇ ‚îî‚îÄ Public API for JsonSerializerOptions ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` --- Generated Code WhizbangJsonContext g cs (facade): `csharp using System Text Json; using System Text Json Serialization; namespace MyApp Generated; /// <summary> /// Generated JSON context for WhizBang message serialization (AOT-compatible) /// Discovered 5 message types, 3 nested types, 2 collection types /// </summary>\n[JsonSerializable(typeof(CreateOrder))]\n[JsonSerializable(typeof(OrderCreated))]\n[JsonSerializable(typeof(ShipOrder))]\n[JsonSerializable(typeof(OrderShipped))]\n[JsonSerializable(typeof(CancelOrder))]\npublic partial class WhizbangJsonContext : JsonSerializerContext {\n    /// <summary>\n    /// Creates JsonSerializerOptions with WhizbangJsonContext /// </summary>\n    public static JsonSerializerOptions CreateOptions() {\n        var options = new JsonSerializerOptions {\n            TypeInfoResolver = new WhizbangJsonContext(),\n            PropertyNamingPolicy = JsonNamingPolicy CamelCase,\n            DefaultIgnoreCondition = JsonIgnoreCondition WhenWritingNull\n        };\n        // Register WhizbangId converters (AOT-compatible)\n        options Converters Add(new ProductIdJsonConverter());\n        options Converters Add(new OrderIdJsonConverter());\n        return options;\n    }\n}\n`\nMessageJsonContext g cs (implementation):\n`csharp\nusing System;\nusing System Text Json;\nusing System Text Json Serialization;\nusing System Text Json Serialization Metadata;\nnamespace MyApp Generated;\ninternal partial class MessageJsonContext : JsonSerializerContext {\n    // Generated JsonTypeInfo for CreateOrder\n    private JsonTypeInfo<CreateOrder> Create_CreateOrder(JsonSerializerOptions options) {\n        var properties = new JsonPropertyInfo[3];\n        properties[0] = JsonMetadataServices CreatePropertyInfo<Guid>(\n            options,\n            propertyName: \"OrderId\",\n            getter: static obj => ((CreateOrder)obj) OrderId,\n            setter: null  // Init-only property\n        );\n        properties[1] = JsonMetadataServices CreatePropertyInfo<Guid>(\n            options,\n            propertyName: \"CustomerId\",\n            getter: static obj => ((CreateOrder)obj) CustomerId,\n            setter: null\n        );\n        properties[2] = JsonMetadataServices CreatePropertyInfo<List<OrderItem>>(\n            options,\n            propertyName: \"Items\",\n            getter: static obj => ((CreateOrder)obj)",
        "startIndex": 2720,
        "preview": "‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 WhizbangJsonContext g cs (facade) ‚îÇ ‚îÇ ‚îî‚îÄ Public API for JsonSerializerOptions ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` --- G..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-2",
        "text": "= new JsonPropertyInfo[3]; properties[0] = JsonMetadataServices CreatePropertyInfo<Guid>( options, propertyName: \"OrderId\", getter: static obj => ((CreateOrder)obj) OrderId, setter: null // Init-only property ); properties[1] = JsonMetadataServices CreatePropertyInfo<Guid>( options, propertyName: \"CustomerId\", getter: static obj => ((CreateOrder)obj) CustomerId, setter: null ); properties[2] = JsonMetadataServices CreatePropertyInfo<List<OrderItem>>( options, propertyName: \"Items\", getter: static obj => ((CreateOrder)obj) Items,\n            setter: null\n        );\n        // Constructor parameters for record with primary constructor\n        var ctorParams = new JsonParameterInfoValues[3];\n        ctorParams[0] = new JsonParameterInfoValues { Name = \"OrderId\", ParameterType = typeof(Guid) };\n        ctorParams[1] = new JsonParameterInfoValues { Name = \"CustomerId\", ParameterType = typeof(Guid) };\n        ctorParams[2] = new JsonParameterInfoValues { Name = \"Items\", ParameterType = typeof(List<OrderItem>) };\n        var objectInfo = new JsonObjectInfoValues<CreateOrder> {\n            ObjectWithParameterizedConstructorCreator = static args => new CreateOrder(\n                (Guid)args[0],\n                (Guid)args[1],\n                (List<OrderItem>)args[2]\n            ),\n            PropertyMetadataInitializer = _ => properties,\n            ConstructorParameterMetadataInitializer = () => ctorParams\n        };\n        var jsonTypeInfo = JsonMetadataServices CreateObjectInfo(options, objectInfo);\n        jsonTypeInfo OriginatingResolver = this;\n        return jsonTypeInfo;\n    }\n    // Type resolver - matches type to JsonTypeInfo\n    public override JsonTypeInfo GetTypeInfo(Type type) {\n        if (type == typeof(CreateOrder)) {\n            return Create_CreateOrder(Options);\n        }\n        if (type == typeof(OrderCreated)) {\n            return Create_OrderCreated(Options);\n        }\n        // more types\n        return null;  // Not handled by this context\n    }\n}\n`\n---\nDiscovery Patterns\nPattern 1: Command/Event Discovery\n`csharp\n// Commands and events are auto-discovered\npublic record CreateOrder(\n    Guid OrderId,\n    Guid CustomerId,\n    List<OrderItem> Items\n) : ICommand;  // ‚Üê Discovered\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    decimal Total,\n    DateTimeOffset CreatedAt\n) : IEvent;  // ‚Üê Discovered\n`\nResult: JsonTypeInfo<CreateOrder> and JsonTypeInfo<OrderCreated> generated ---\nPattern 2: Nested Type Discovery\n`csharp\n// Command uses OrderItem (nested type)\npublic record CreateOrder(\n    Guid OrderId,\n    Guid CustomerId,\n    List<OrderItem> Items  // ‚Üê OrderItem discovered automatically\n) : ICommand;\n// Nested type (not ICommand or IEvent)\npublic record OrderItem(\n    Guid ProductId,\n    int Quantity,\n    decimal UnitPrice\n);\n`\nResult: JsonTypeInfo<OrderItem> also generated (needed for List<OrderItem>)",
        "startIndex": 4827,
        "preview": "= new JsonPropertyInfo[3]; properties[0] = JsonMetadataServices CreatePropertyInfo<Guid>( options, propertyName: \"OrderId\", getter: static obj => ((Cr..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-3",
        "text": "Discovery `csharp // Command uses OrderItem (nested type) public record CreateOrder( Guid OrderId, Guid CustomerId, List<OrderItem> Items // ‚Üê OrderItem discovered automatically ) : ICommand; // Nested type (not ICommand or IEvent) public record OrderItem( Guid ProductId, int Quantity, decimal UnitPrice ); ` Result: JsonTypeInfo<OrderItem> also generated (needed for List<OrderItem>) ---\nPattern 3: Collection Type Discovery\n`csharp\n// List<T> types discovered from properties\npublic record CreateOrder(\n    Guid OrderId,\n    List<OrderItem> Items  // ‚Üê List<OrderItem> discovered\n) : ICommand;\n`\nResult: JsonTypeInfo<List<OrderItem>> generated for AOT compatibility ---\nPattern 4: WhizbangId Converter Discovery\n`csharp\n// Generator infers converters for *Id types\npublic record CreateOrder(\n    ProductId ProductId,  // ‚Üê Infers ProductIdJsonConverter\n    CustomerId CustomerId  // ‚Üê Infers CustomerIdJsonConverter\n) : ICommand;\n`\nResult: Converters automatically registered in CreateOptions():\n`csharp\noptions Converters Add(new ProductIdJsonConverter());\noptions Converters Add(new CustomerIdJsonConverter());\n`\n---\nUsage\nBasic Serialization\n`csharp\nusing MyApp Generated;\n// Create options with generated context\nvar options = WhizbangJsonContext CreateOptions();\n// Serialize (AOT-compatible, zero reflection)\nvar command = new CreateOrder(orderId, customerId, items);\nvar json = JsonSerializer Serialize(command, options);\n// Deserialize (AOT-compatible)\nvar deserialized = JsonSerializer Deserialize<CreateOrder>(json, options);\n`\n---\nDependency Injection\n`csharp\n// Program cs\nusing MyApp Generated;\nvar builder = WebApplication CreateBuilder(args);\n// Register JsonSerializerOptions with generated context\nbuilder Services AddSingleton(WhizbangJsonContext CreateOptions());\n// Or configure JsonOptions for ASP NET Core\nbuilder Services Configure<JsonOptions>(options => {\n    options JsonSerializerOptions TypeInfoResolver = new WhizbangJsonContext();\n    options JsonSerializerOptions PropertyNamingPolicy = JsonNamingPolicy CamelCase;\n});\n`\n---\nOutbox/Inbox Serialization\n`csharp\npublic class OutboxPublisher {\n    private readonly JsonSerializerOptions _jsonOptions;\n    public OutboxPublisher() {\n        _jsonOptions = WhizbangJsonContext CreateOptions();\n    }\n    public async Task PublishAsync(object message, CancellationToken ct = default) {\n        // Serialize with AOT-compatible context\n        var json = JsonSerializer Serialize(message, _jsonOptions);\n        await _db ExecuteAsync(\n            \"INSERT INTO wh_outbox (message_id, payload, ) VALUES (@MessageId, @Payload::jsonb, )\",\n            new { MessageId = Guid",
        "startIndex": 7201,
        "preview": "Discovery `csharp // Command uses OrderItem (nested type) public record CreateOrder( Guid OrderId, Guid CustomerId, List<OrderItem> Items // ‚Üê OrderIt..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-4",
        "text": "readonly JsonSerializerOptions _jsonOptions; public OutboxPublisher() { _jsonOptions = WhizbangJsonContext CreateOptions(); } public async Task PublishAsync(object message, CancellationToken ct = default) { // Serialize with AOT-compatible context var json = JsonSerializer Serialize(message, _jsonOptions); await _db ExecuteAsync( \"INSERT INTO wh_outbox (message_id, payload, ) VALUES (@MessageId, @Payload::jsonb, )\", new { MessageId = Guid NewGuid(), Payload = json },\n            cancellationToken: ct\n        );\n    }\n}\n`\n---\nPerformance\nBenchmark: First Serialization\n| Method | Overhead | Notes |\n|--------|----------|-------|\n| Generated Context | ~5ms | Compile-time metadata |\n| Reflection | ~100ms | Runtime type analysis |\n20x faster on first call Subsequent Calls\n| Method | Overhead | Notes |\n|--------|----------|-------|\n| Generated Context | ~100ns | Direct property access |\n| Reflection | ~150ns | Cached reflection metadata |\n1 5x faster on subsequent calls (minimal difference after warm-up) ---\nNative AOT Compatibility\nPublish Native AOT\n`xml\n< -- MyApp csproj -->\n<PropertyGroup>\n  <PublishAot>true</PublishAot>\n</PropertyGroup>\n`\nBuild:\n`bash\ndotnet publish -c Release\nOutput:\nGenerating native code MyApp dll -> MyApp exe (Native AOT)\n  Binary size: 12 5 MB (includes JSON context)\n  Startup time: < 10ms\n`\nVerification:\n`bash\nCheck binary doesn't use reflection\nnm MyApp exe | grep -i \"reflection\"\nNo results = success `\n---\nDiagnostics\nWHIZ099: Generator Running\nSeverity: Info\nMessage: MessageJsonContextGenerator invoked for assembly '{0}' with {1} message type(s)\nExample:\n`\ninfo WHIZ099: MessageJsonContextGenerator invoked for assembly 'MyApp' with 5 message type(s)\n`\n---\nWHIZ007: JSON Serializable Type Discovered\nSeverity: Info\nMessage: Found JSON-serializable type '{0}' ({1})\nExample:\n`\ninfo WHIZ007: Found JSON-serializable type 'CreateOrder' (command)\ninfo WHIZ007: Found JSON-serializable type 'OrderItem' (nested type)\ninfo WHIZ007: Found JSON-serializable type 'List<OrderItem>' (collection type)\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use WhizbangJsonContext",
        "startIndex": 9470,
        "preview": "readonly JsonSerializerOptions _jsonOptions; public OutboxPublisher() { _jsonOptions = WhizbangJsonContext CreateOptions(); } public async Task Publis..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-5",
        "text": "type(s) ` --- WHIZ007: JSON Serializable Type Discovered Severity: Info Message: Found JSON-serializable type '{0}' ({1}) Example: ` info WHIZ007: Found JSON-serializable type 'CreateOrder' (command) info WHIZ007: Found JSON-serializable type 'OrderItem' (nested type) info WHIZ007: Found JSON-serializable type 'List<OrderItem>' (collection type) ` --- Best Practices DO ‚úÖ ‚úÖ Use WhizbangJsonContext CreateOptions() for all JSON serialization\n‚úÖ Mark all messages as public (generator only processes public types)\n‚úÖ Use records with primary constructors for best JSON support\n‚úÖ Test Native AOT deployment early (catches issues sooner)\n‚úÖ Include nested types in same assembly as messages\nDON'T ‚ùå\n‚ùå Use reflection-based JsonSerializer (defeats AOT)\n‚ùå Mark messages as internal (won't be discovered)\n‚ùå Use complex custom converters (may not be AOT-compatible)\n‚ùå Serialize types from other assemblies without their context\n‚ùå Skip testing with PublishAot=true\n---\nTroubleshooting\nProblem: Type Not Serializable in Native AOT\nSymptoms: Serialization throws NotSupportedException in AOT build Cause: Type not included in generated context Solution:\nVerify type is public\nVerify type implements ICommand or IEvent\nRebuild project to regenerate context\n`csharp\n// ‚ùå Internal type (not discovered)\ninternal record CreateOrder( ) : ICommand;\n// ‚úÖ Public type (discovered)\npublic record CreateOrder( ) : ICommand;\n`\nProblem: Nested Type Not Found\nSymptoms: List<OrderItem> fails to serialize Cause: OrderItem not public or in different assembly Solution: Make nested types public in same assembly:\n`csharp\n// ‚úÖ Public nested type\npublic record OrderItem(Guid ProductId, int Quantity);\n`\nProblem: WhizbangId Converter Not Registered\nSymptoms: ProductId serializes as {} instead of GUID value Cause: Converter not auto-discovered (name doesn't match convention) Solution: Ensure converter follows naming convention:\n`csharp\n// Type: ProductId\n// Converter: ProductIdJsonConverter (must match )\npublic class ProductIdJsonConverter : JsonConverter<ProductId> {\n    // Implementation",
        "startIndex": 11127,
        "preview": "type(s) ` --- WHIZ007: JSON Serializable Type Discovered Severity: Info Message: Found JSON-serializable type '{0}' ({1}) Example: ` info WHIZ007: Fou..."
      },
      {
        "id": "v0.1.0/source-generators/json-contexts-chunk-6",
        "text": "ProductId, int Quantity); ` Problem: WhizbangId Converter Not Registered Symptoms: ProductId serializes as {} instead of GUID value Cause: Converter not auto-discovered (name doesn't match convention) Solution: Ensure converter follows naming convention: `csharp // Type: ProductId // Converter: ProductIdJsonConverter (must match ) public class ProductIdJsonConverter : JsonConverter<ProductId> { // Implementation }\n`\n---\nFurther Reading\nSource Generators:\nReceptor Discovery - Compile-time receptor discovery\nPerspective Discovery - Compile-time perspective discovery\nMessage Registry - VSCode extension integration\nAggregate IDs - UUIDv7 generation for identity value objects\nCore Concepts:\nMessage Context - MessageId, CorrelationId, CausationId\nMessaging:\nOutbox Pattern - Reliable event publishing\nInbox Pattern - Exactly-once processing\nAdvanced:\nNative AOT Deployment - Full AOT deployment guide\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 12806,
        "preview": "ProductId, int Quantity); ` Problem: WhizbangId Converter Not Registered Symptoms: ProductId serializes as {} instead of GUID value Cause: Converter n..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/source-generators/message-registry",
    "title": "Message Registry",
    "category": "Source Generators",
    "url": "/docs/v0.1.0/source-generators/message-registry",
    "chunks": [
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-0",
        "text": "Message Registry\nThe MessageRegistryGenerator discovers all messages, dispatchers, receptors, and perspectives at compile-time and generates a JSON registry file for the Whizbang VSCode Extension This enables rich IDE features like CodeLens annotations, hover tooltips, and \"Go to Handler\" navigation VSCode Extension Integration\nIDE Features Enabled\n| Feature | Description | Example |\n|---------|-------------|---------|\n| CodeLens | Inline annotations showing handler counts | CreateOrder ‚Üí 3 dispatchers, 1 receptor |\n| Hover Tooltip | Rich markdown with handler locations | Mouse over message ‚Üí see all handlers |\n| Go to Handler | Navigate from message to implementation | Click CodeLens ‚Üí jump to receptor |\n| Find References | List all dispatchers for a message | Right-click ‚Üí Find dispatchers |\nVisual Example:\n`csharp\n// In your code editor:\npublic record CreateOrder(Guid CustomerId, OrderItem[] Items) : ICommand;\n             ‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë\n             [3 dispatchers] [1 receptor] [0 perspectives]  ‚Üê CodeLens\n// Click [1 receptor] ‚Üí Jump to OrderReceptor HandleAsync()\n`\n---\nHow It Works\nCompile-Time Discovery\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  MessageRegistryGenerator (Roslyn)              ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  Discovers 4 types of constructs:               ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 Messages (ICommand, IEvent)                 ‚îÇ\n‚îÇ  2 Dispatchers (SendAsync, PublishAsync calls) ‚îÇ\n‚îÇ  3 Receptors (IReceptor implementations)       ‚îÇ\n‚îÇ  4 Perspectives (IPerspectiveOf implementations)‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Generated: MessageRegistry g cs                 ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  Contains:                                       ‚îÇ\n‚îÇ  - Embedded JSON with message-to-handler mapping‚îÇ\n‚îÇ  - File paths and line numbers for navigation   ‚îÇ\n‚îÇ  - Message type metadata (command vs event)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Build Process: Copy to whizbang/               ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  message-registry json                           ‚îÇ\n‚îÇ  ‚îî‚îÄ Used by VSCode extension for tooling        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nGenerated File\nMessageRegistry g cs (simplified):\n`csharp\n// <auto-generated/>\n// This file is generated by MessageRegistryGenerator\n// DO NOT EDIT - Changes will be overwritten\nnamespace MyApp",
        "startIndex": 0,
        "preview": "Message Registry\nThe MessageRegistryGenerator discovers all messages, dispatchers, receptors, and perspectives at compile-time and generates a JSON re..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-1",
        "text": "Build Process: Copy to whizbang/ ‚îÇ ‚îÇ ‚îÇ ‚îÇ message-registry json ‚îÇ ‚îÇ ‚îî‚îÄ Used by VSCode extension for tooling ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Generated File MessageRegistry g cs (simplified): `csharp // <auto-generated/> // This file is generated by MessageRegistryGenerator // DO NOT EDIT - Changes will be overwritten namespace MyApp Generated;\ninternal static class MessageRegistry {\n    public static string Json = @\"{\n  \"\"messages\"\": [\n    {\n      \"\"type\"\": \"\"MyApp Commands CreateOrder\"\",\n      \"\"isCommand\"\": true,\n      \"\"isEvent\"\": false,\n      \"\"filePath\"\": \"\"src/Commands/CreateOrder cs\"\",\n      \"\"lineNumber\"\": 5,\n      \"\"dispatchers\"\": [\n        {\n          \"\"className\"\": \"\"MyApp Controllers OrderController\"\",\n          \"\"methodName\"\": \"\"CreateAsync\"\",\n          \"\"filePath\"\": \"\"src/Controllers/OrderController cs\"\",\n          \"\"lineNumber\"\": 42\n        },\n        {\n          \"\"className\"\": \"\"MyApp Sagas OrderSaga\"\",\n          \"\"methodName\"\": \"\"ProcessAsync\"\",\n          \"\"filePath\"\": \"\"src/Sagas/OrderSaga cs\"\",\n          \"\"lineNumber\"\": 18\n        }\n      ],\n      \"\"receptors\"\": [\n        {\n          \"\"className\"\": \"\"MyApp Receptors OrderReceptor\"\",\n          \"\"methodName\"\": \"\"HandleAsync\"\",\n          \"\"filePath\"\": \"\"src/Receptors/OrderReceptor cs\"\",\n          \"\"lineNumber\"\": 12\n        }\n      ],\n      \"\"perspectives\"\": []\n    },\n    {\n      \"\"type\"\": \"\"MyApp Events OrderCreated\"\",\n      \"\"isCommand\"\": false,\n      \"\"isEvent\"\": true,\n      \"\"filePath\"\": \"\"src/Events/OrderCreated cs\"\",\n      \"\"lineNumber\"\": 3,\n      \"\"dispatchers\"\": [\n        {\n          \"\"className\"\": \"\"MyApp Receptors OrderReceptor\"\",\n          \"\"methodName\"\": \"\"HandleAsync\"\",\n          \"\"filePath\"\": \"\"src/Receptors/OrderReceptor cs\"\",\n          \"\"lineNumber\"\": 25\n        }\n      ],\n      \"\"receptors\"\": [],\n      \"\"perspectives\"\": [\n        {\n          \"\"className\"\": \"\"MyApp Perspectives OrderSummaryPerspective\"\",\n          \"\"filePath\"\": \"\"src/Perspectives/OrderSummaryPerspective cs\"\",\n          \"\"lineNumber\"\": 8\n        },\n        {\n          \"\"className\"\": \"\"MyApp Perspectives CustomerStatisticsPerspective\"\",\n          \"\"filePath\"\": \"\"src/Perspectives/CustomerStatisticsPerspective cs\"\",\n          \"\"lineNumber\"\": 15\n        }\n      ]\n    }\n  ]\n}\";\n}\n`\nKey Information:\nMessage type (fully qualified name)\nMessage kind (command vs event)\nDefinition location (file path + line number)\nAll dispatchers calling this message\nAll receptors handling this message\nAll perspectives listening to this event\n---\nDiscovery Patterns\nPattern 1: Message Discovery\nDiscovers ICommand and IEvent implementations:\n`csharp\n// Command\npublic record CreateOrder(\n    Guid CustomerId,\n    OrderItem[] Items\n) : ICommand;  // ‚Üê Discovered\n// Event\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    decimal Total,\n    DateTimeOffset CreatedAt\n) : IEvent;  // ‚Üê Discovered\n`\nGenerator finds:\nType name: MyApp Commands CreateOrder\nFile: src/Commands/CreateOrder",
        "startIndex": 2668,
        "preview": "Build Process: Copy to whizbang/ ‚îÇ ‚îÇ ‚îÇ ‚îÇ message-registry json ‚îÇ ‚îÇ ‚îî‚îÄ Used by VSCode extension for tooling ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-2",
        "text": "Discovers ICommand and IEvent implementations: `csharp // Command public record CreateOrder( Guid CustomerId, OrderItem[] Items ) : ICommand; // ‚Üê Discovered // Event public record OrderCreated( Guid OrderId, Guid CustomerId, decimal Total, DateTimeOffset CreatedAt ) : IEvent; // ‚Üê Discovered ` Generator finds: Type name: MyApp Commands CreateOrder File: src/Commands/CreateOrder cs\nLine: 5\nIsCommand: true\nIsEvent: false\n---\nPattern 2: Dispatcher Discovery\nDiscovers SendAsync and PublishAsync call sites:\n`csharp\npublic class OrderController : ControllerBase {\n    private readonly IDispatcher _dispatcher;\n    public async Task<IActionResult> CreateAsync(CreateOrderRequest request) {\n        var command = new CreateOrder(request CustomerId, request Items);\n        // ‚Üê Dispatcher call discovered\n        var @event = await _dispatcher SendAsync(command);\n        return Ok(@event);\n    }\n}\n`\nGenerator finds:\nMessage type: CreateOrder\nClass: OrderController\nMethod: CreateAsync\nFile: src/Controllers/OrderController cs\nLine: 42\nAlso discovers PublishAsync:\n`csharp\n// Inside OrderReceptor\nvar @event = new OrderCreated(/ /);\nawait _dispatcher PublishAsync(@event);  // ‚Üê Discovered\n`\n---\nPattern 3: Receptor Discovery\nDiscovers IReceptor<TMessage, TResponse> implementations:\n`csharp\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(  // ‚Üê Method discovered\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Business logic return new OrderCreated(/ /);\n    }\n}\n`\nGenerator finds:\nMessage type: CreateOrder\nClass: OrderReceptor\nMethod: HandleAsync\nFile: src/Receptors/OrderReceptor cs\nLine: 12 (HandleAsync method location)\n---\nPattern 4: Perspective Discovery\nDiscovers IPerspectiveOf<TEvent> implementations:\n`csharp\npublic class OrderSummaryPerspective :\n    IPerspectiveOf<OrderCreated>,  // ‚Üê Discovered\n    IPerspectiveOf<OrderShipped>,  // ‚Üê Discovered\n    IPerspectiveOf<OrderCancelled> {  // ‚Üê Discovered\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct) {\n        // Update order_summaries table\n    }\n    public async Task UpdateAsync(OrderShipped @event, CancellationToken ct) {\n        // Update order_summaries table\n    }\n    public async Task UpdateAsync(OrderCancelled @event, CancellationToken ct) {\n        // Update order_summaries table\n    }\n}\n`\nGenerator finds:\nEvent types: OrderCreated, OrderShipped, OrderCancelled\nClass: OrderSummaryPerspective\nFile: src/Perspectives/OrderSummaryPerspective cs\nLine: 8 (class declaration)\nResult: One perspective, three event type mappings",
        "startIndex": 5301,
        "preview": "Discovers ICommand and IEvent implementations: `csharp // Command public record CreateOrder( Guid CustomerId, OrderItem[] Items ) : ICommand; // ‚Üê Dis..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-3",
        "text": "async Task UpdateAsync(OrderShipped @event, CancellationToken ct) { // Update order_summaries table } public async Task UpdateAsync(OrderCancelled @event, CancellationToken ct) { // Update order_summaries table } } ` Generator finds: Event types: OrderCreated, OrderShipped, OrderCancelled Class: OrderSummaryPerspective File: src/Perspectives/OrderSummaryPerspective cs Line: 8 (class declaration) Result: One perspective, three event type mappings ---\nJSON Structure\nComplete Example\n`json\n{\n  \"messages\": [\n    {\n      \"type\": \"MyApp Commands CreateOrder\",\n      \"isCommand\": true,\n      \"isEvent\": false,\n      \"filePath\": \"src/Commands/CreateOrder cs\",\n      \"lineNumber\": 5,\n      \"dispatchers\": [\n        {\n          \"className\": \"MyApp Controllers OrderController\",\n          \"methodName\": \"CreateAsync\",\n          \"filePath\": \"src/Controllers/OrderController cs\",\n          \"lineNumber\": 42\n        }\n      ],\n      \"receptors\": [\n        {\n          \"className\": \"MyApp Receptors OrderReceptor\",\n          \"methodName\": \"HandleAsync\",\n          \"filePath\": \"src/Receptors/OrderReceptor cs\",\n          \"lineNumber\": 12\n        }\n      ],\n      \"perspectives\": []\n    },\n    {\n      \"type\": \"MyApp Events OrderCreated\",\n      \"isCommand\": false,\n      \"isEvent\": true,\n      \"filePath\": \"src/Events/OrderCreated cs\",\n      \"lineNumber\": 3,\n      \"dispatchers\": [\n        {\n          \"className\": \"MyApp Receptors OrderReceptor\",\n          \"methodName\": \"HandleAsync\",\n          \"filePath\": \"src/Receptors/OrderReceptor cs\",\n          \"lineNumber\": 25\n        }\n      ],\n      \"receptors\": [],\n      \"perspectives\": [\n        {\n          \"className\": \"MyApp Perspectives OrderSummaryPerspective\",\n          \"filePath\": \"src/Perspectives/OrderSummaryPerspective cs\",\n          \"lineNumber\": 8\n        }\n      ]\n    }\n  ]\n}\n`\nField Descriptions\n| Field | Type | Description |\n|-------|------|-------------|\n| type | string | Fully qualified message type name |\n| isCommand | boolean | True if implements ICommand |\n| isEvent | boolean | True if implements IEvent |\n| filePath | string | Relative path from workspace root |\n| lineNumber | number | Line number (1-based) |\n| dispatchers | array | All SendAsync/PublishAsync calls |\n| receptors | array | All IReceptor implementations |\n| perspectives | array | All IPerspectiveOf implementations |\n---\nVSCode Extension Usage\nInstalling the Extension\n`bash\nFrom VSCode Extensions panel:\nSearch: \"Whizbang\"\nInstall: Whizbang Message Flow Visualizer\nOr from command line:\ncode --install-extension whizbang",
        "startIndex": 7578,
        "preview": "async Task UpdateAsync(OrderShipped @event, CancellationToken ct) { // Update order_summaries table } public async Task UpdateAsync(OrderCancelled @ev..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-4",
        "text": "array | All SendAsync/PublishAsync calls | | receptors | array | All IReceptor implementations | | perspectives | array | All IPerspectiveOf implementations | --- VSCode Extension Usage Installing the Extension `bash From VSCode Extensions panel: Search: \"Whizbang\" Install: Whizbang Message Flow Visualizer Or from command line: code --install-extension whizbang whizbang-vscode\n`\nExtension Features\nCodeLens Annotations\nInline annotations above message types:\n`csharp\n// [3 dispatchers] [1 receptor] [0 perspectives]\npublic record CreateOrder(Guid CustomerId, OrderItem[] Items) : ICommand;\n`\nClick counts to navigate:\n[3 dispatchers] ‚Üí List of dispatcher locations\n[1 receptor] ‚Üí Jump to receptor HandleAsync\n[0 perspectives] ‚Üí No perspectives for this command\nHover Tooltips\nRich markdown tooltips on hover:\n`\nCreateOrder\nType: Command\nHandlers: 1 receptor\nDispatchers (3):\n  ‚Ä¢ OrderController CreateAsync (Controllers/OrderController cs:42)\n  ‚Ä¢ OrderSaga ProcessAsync (Sagas/OrderSaga cs:18)\n  ‚Ä¢ OrderScheduler ScheduleAsync (Schedulers/OrderScheduler cs:105)\nReceptors (1):\n  ‚Ä¢ OrderReceptor HandleAsync (Receptors/OrderReceptor cs:12)\n    Returns: OrderCreated\n`\nGo to Handler Command\nRight-click message ‚Üí \"Go to Whizbang Handler\":\n`\nJump to:\n  ‚Ä¢ OrderReceptor HandleAsync (Receptors/OrderReceptor cs:12)\n`\nMessage Flow Visualization\nCommand palette ‚Üí \"Whizbang: Show Message Flow\":\n`\nCreateOrder\n  ‚îú‚îÄ Dispatcher: OrderController CreateAsync\n  ‚îÇ   ‚îî‚îÄ Receptor: OrderReceptor HandleAsync\n  ‚îÇ       ‚îî‚îÄ Publishes: OrderCreated\n  ‚îÇ           ‚îú‚îÄ Perspective: OrderSummaryPerspective\n  ‚îÇ           ‚îî‚îÄ Perspective: CustomerStatisticsPerspective\n  ‚îî‚îÄ Dispatcher: OrderSaga ProcessAsync\n      ‚îî‚îÄ (Remote via Outbox)\n`\n---\nBuild Integration\nMSBuild Target\nGenerator runs automatically during build Optional: Copy JSON to whizbang/ folder for extension:\n`xml\n< -- MyApp csproj -->\n<Target Name=\"CopyMessageRegistry\" AfterTargets=\"Build\">\n  <ItemGroup>\n    <MessageRegistryFiles Include=\"$(IntermediateOutputPath)generated//*MessageRegistry g cs\" />\n  </ItemGroup>\n  < -- Extract JSON from generated Cfile and write to whizbang/message-registry json -->\n  <Exec Command=\"dotnet run --project tools/extract-message-registry csproj\" />\n</Target>\n`\nExtract JSON Script\n`csharp\n// tools/extract-message-registry/Program cs\nusing System Text RegularExpressions;\nvar generatedFile = args[0];  // Path to MessageRegistry g cs\nvar outputFile = \" whizbang/message-registry json\";\nvar content = File",
        "startIndex": 9684,
        "preview": "array | All SendAsync/PublishAsync calls | | receptors | array | All IReceptor implementations | | perspectives | array | All IPerspectiveOf implement..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-5",
        "text": "JSON from generated Cfile and write to whizbang/message-registry json --> <Exec Command=\"dotnet run --project tools/extract-message-registry csproj\" /> </Target> ` Extract JSON Script `csharp // tools/extract-message-registry/Program cs using System Text RegularExpressions; var generatedFile = args[0]; // Path to MessageRegistry g cs var outputFile = \" whizbang/message-registry json\"; var content = File ReadAllText(generatedFile);\n// Extract JSON from embedded string\nvar match = Regex Match(content, @\"public static string Json = @\"\"( + )\"\";\", RegexOptions Singleline);\nif (match Success) {\n    var json = match Groups[1] Value Replace(\"\\\"\\\"\", \"\\\"\");  // Unescape\n    Directory CreateDirectory(\" whizbang\");\n    File WriteAllText(outputFile, json);\n    Console WriteLine($\"Wrote message registry to {outputFile}\");\n}\n`\nRun after build:\n`bash\ndotnet build\nWrites whizbang/message-registry json\n`\n---\nGenerator Performance\nMulti-Pipeline Architecture\nGenerator uses 4 independent pipelines for optimal caching:\n`csharp\n// Pipeline 1: Messages\nvar messageTypes = context SyntaxProvider CreateSyntaxProvider(\n    predicate: static (node, _) => node is RecordDeclarationSyntax { BaseList Types Count: > 0 },\n    transform: static (ctx, ct) => ExtractMessageType(ctx, ct)\n);\n// Pipeline 2: Dispatchers\nvar dispatchers = context SyntaxProvider CreateSyntaxProvider(\n    predicate: static (node, _) => node is InvocationExpressionSyntax { },\n    transform: static (ctx, ct) => ExtractDispatcher(ctx, ct)\n);\n// Pipeline 3: Receptors\nvar receptors = context SyntaxProvider CreateSyntaxProvider(\n    predicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types Count: > 0 },\n    transform: static (ctx, ct) => ExtractReceptor(ctx, ct)\n);\n// Pipeline 4: Perspectives\nvar perspectives = context SyntaxProvider CreateSyntaxProvider(\n    predicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types Count: > 0 },\n    transform: static (ctx, ct) => ExtractPerspective(ctx, ct)\n);\n// Combine at the end\nvar allData = messageTypes Collect() Combine(dispatchers Collect()) Combine(receptors Collect()) Combine(perspectives Collect());\n`\nWhy 4 pipelines",
        "startIndex": 11809,
        "preview": "JSON from generated Cfile and write to whizbang/message-registry json --> <Exec Command=\"dotnet run --project tools/extract-message-registry csproj\" /..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-6",
        "text": "Perspectives var perspectives = context SyntaxProvider CreateSyntaxProvider( predicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types Count: > 0 }, transform: static (ctx, ct) => ExtractPerspective(ctx, ct) ); // Combine at the end var allData = messageTypes Collect() Combine(dispatchers Collect()) Combine(receptors Collect()) Combine(perspectives Collect()); ` Why 4 pipelines Independent caching: Changing a dispatcher doesn't invalidate message cache\nOptimized predicates: Each pipeline filters for its specific construct\nParallel execution: Roslyn runs pipelines concurrently\nPerformance Characteristics\n`\nFirst compilation (100 messages, 200 handlers):\n‚îú‚îÄ Message discovery: 30ms\n‚îú‚îÄ Dispatcher discovery: 40ms\n‚îú‚îÄ Receptor discovery: 20ms\n‚îú‚îÄ Perspective discovery: 15ms\n‚îú‚îÄ JSON generation: 5ms\n‚îî‚îÄ Total: 110ms\nIncremental compilation (change 1 receptor):\n‚îú‚îÄ Message cache: 0ms (unchanged)\n‚îú‚îÄ Dispatcher cache: 0ms (unchanged)\n‚îú‚îÄ Receptor discovery: 20ms (changed)\n‚îú‚îÄ Perspective cache: 0ms (unchanged)\n‚îú‚îÄ JSON generation: 5ms\n‚îî‚îÄ Total: 25ms (85ms saved )\n`\n---\nCross-Assembly Messages\nGenerator handles messages from referenced assemblies:\n`csharp\n// In Whizbang Core (referenced assembly)\npublic interface ICommand { }\n// In MyApp (your project)\npublic record CreateOrder(Guid CustomerId) : ICommand;  // ‚Üê Discovered\n// Also in MyApp\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    // ‚Üê Receptor discovered, links to CreateOrder\n}\n`\nResult: CreateOrder appears in registry even though ICommand is external External Messages:\n`csharp\n// In SharedMessages (referenced assembly)\npublic record CustomerCreated(Guid CustomerId) : IEvent;\n// In MyApp\npublic class CustomerStatsPerspective : IPerspectiveOf<CustomerCreated> {\n    // ‚Üê Perspective discovered, links to CustomerCreated\n}\n`\nJSON output:\n`json\n{\n  \"type\": \"SharedMessages CustomerCreated\",\n  \"isCommand\": false,\n  \"isEvent\": true,\n  \"filePath\": \"\",  // Empty - not defined in this project\n  \"lineNumber\": 0,\n  \"dispatchers\": [],\n  \"receptors\": [],\n  \"perspectives\": [\n    {\n      \"className\": \"MyApp Perspectives CustomerStatsPerspective\",\n      \"filePath\": \"src/Perspectives/CustomerStatsPerspective cs\",\n      \"lineNumber\": 8\n    }\n  ]\n}\n`\nBenefit: Complete message flow visualization across assemblies ---\nDebugging\nView Generated File\n`\nobj/Debug/net10 0/generated/Whizbang Generators/MessageRegistryGenerator/\n‚îî‚îÄ‚îÄ MessageRegistry",
        "startIndex": 13598,
        "preview": "Perspectives var perspectives = context SyntaxProvider CreateSyntaxProvider( predicate: static (node, _) => node is ClassDeclarationSyntax { BaseList ..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-7",
        "text": "\"filePath\": \"\", // Empty - not defined in this project \"lineNumber\": 0, \"dispatchers\": [], \"receptors\": [], \"perspectives\": [ { \"className\": \"MyApp Perspectives CustomerStatsPerspective\", \"filePath\": \"src/Perspectives/CustomerStatsPerspective cs\", \"lineNumber\": 8 } ] } ` Benefit: Complete message flow visualization across assemblies --- Debugging View Generated File ` obj/Debug/net10 0/generated/Whizbang Generators/MessageRegistryGenerator/ ‚îî‚îÄ‚îÄ MessageRegistry g cs\n`\nOr configured output:\n`xml\n<PropertyGroup>\n  <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n  <CompilerGeneratedFilesOutputPath> whizbang-generated</CompilerGeneratedFilesOutputPath>\n</PropertyGroup>\n`\nValidate JSON\n`bash\nExtract JSON from generated file\ndotnet run --project tools/extract-message-registry csproj\nValidate JSON\ncat whizbang/message-registry json | jq Output:\n{\n  \"messages\": [\n    {\n      \"type\": \"MyApp Commands CreateOrder\",\n      \"isCommand\": true, }\n  ]\n}\n`\nVSCode Extension Logs\nView extension logs:\nView ‚Üí Output\nSelect \"Whizbang\" from dropdown\nSee message registry loading and parsing\n`\n[Whizbang] Loading message registry from whizbang/message-registry json\n[Whizbang] Found 15 messages\n[Whizbang] Registered 42 CodeLens providers\n[Whizbang] Registry loaded successfully\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use ICommand and IEvent markers for all messages\n‚úÖ Keep messages in dedicated folders (Commands/, Events/)\n‚úÖ Use descriptive names (CreateOrder, not Order1)\n‚úÖ Commit whizbang/message-registry json to source control (helps team)\n‚úÖ Rebuild after adding new messages (F5 in VSCode to reload extension)\nDON'T ‚ùå\n‚ùå Modify MessageRegistry g cs manually (regenerated on build)\n‚ùå Use abstract message types (can't be instantiated)\n‚ùå Mix commands and events (implement one interface only)\n‚ùå Delete whizbang/ folder (VSCode extension needs it)\n---\nTroubleshooting\nProblem: CodeLens Not Showing\nSymptoms: No [X dispatchers] annotations above messages Causes:\nExtension not installed\nMessage registry not generated\nExtension not loaded\nSolution:\n`bash\nVerify extension installed\ncode --list-extensions | grep whizbang\nRebuild project (generates registry)\ndotnet build\nCheck whizbang/message-registry json exists\nls -la whizbang/\nReload VSCode window\nCtrl+Shift+P ‚Üí \"Developer: Reload Window\"\n`\nProblem: Wrong Handler Count\nSymptoms: CodeLens shows [1 receptor] but you have 2 receptors Causes:\nStale message-registry",
        "startIndex": 5,
        "preview": "\"filePath\": \"\", // Empty - not defined in this project \"lineNumber\": 0, \"dispatchers\": [], \"receptors\": [], \"perspectives\": [ { \"className\": \"MyApp Pe..."
      },
      {
        "id": "v0.1.0/source-generators/message-registry-chunk-8",
        "text": "loaded Solution: `bash Verify extension installed code --list-extensions | grep whizbang Rebuild project (generates registry) dotnet build Check whizbang/message-registry json exists ls -la whizbang/ Reload VSCode window Ctrl+Shift+P ‚Üí \"Developer: Reload Window\" ` Problem: Wrong Handler Count Symptoms: CodeLens shows [1 receptor] but you have 2 receptors Causes: Stale message-registry json\nReceptor not discovered (missing IReceptor interface)\nSolution:\n`bash\nClean and rebuild\ndotnet clean && dotnet build\nCheck generated file\ncat whizbang/message-registry json | jq ' messages[] | select( type == \"MyApp Commands CreateOrder\")'\nVerify receptor implements interface correctly\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    // Must have HandleAsync method\n}\n`\nProblem: External Messages Not Found\nSymptoms: Messages from referenced assemblies don't appear in registry Causes:\nMessage not used in any dispatcher/receptor/perspective\nAssembly reference missing\nSolution: Generator only includes messages that are actually used in the project If you want external messages in registry, add at least one handler:\n`csharp\n// Add a perspective for external event\npublic class ExternalEventPerspective : IPerspectiveOf<SharedMessages CustomerCreated> {\n    public async Task UpdateAsync(CustomerCreated @event, CancellationToken ct) {\n        // Now CustomerCreated appears in registry }\n}\n`\n---\nFurther Reading\nSource Generators:\nReceptor Discovery - Compile-time receptor discovery\nPerspective Discovery - Compile-time perspective discovery\nAggregate IDs - UUIDv7 generation for identity value objects\nJSON Contexts - AOT-compatible JSON serialization\nCore Concepts:\nDispatcher - Message routing patterns\nReceptors - Message handlers\nPerspectives - Event-driven read models\nTools:\nVSCode Extension - IDE integration features\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 17617,
        "preview": "loaded Solution: `bash Verify extension installed code --list-extensions | grep whizbang Rebuild project (generates registry) dotnet build Check whizb..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/source-generators/perspective-discovery",
    "title": "Perspective Discovery",
    "category": "Source Generators",
    "url": "/docs/v0.1.0/source-generators/perspective-discovery",
    "chunks": [
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-0",
        "text": "Perspective Discovery\nThe PerspectiveDiscoveryGenerator discovers all IPerspectiveOf<TEvent> implementations at compile-time and generates zero-reflection DI registration code Perspectives are event-driven read models that update denormalized views in response to domain events Perspectives vs Receptors\n| Aspect | Perspectives | Receptors |\n|--------|-------------|----------|\n| Purpose | Update read models | Handle commands/queries |\n| Trigger | Domain events | Commands/queries |\n| Return | void (async Task) | Typed response |\n| Pattern | Event-driven denormalization | Command/query handling |\n| Invocation | Via Event Store coordinator | Via Dispatcher |\n| Use Case | Build query-optimized views | Implement business logic |\nWhizbang Pattern: Commands ‚Üí Receptors ‚Üí Events ‚Üí Perspectives ‚Üí Read Models\n---\nEvent-Driven Read Models\nTraditional Approach (Direct Updates)\n`csharp\n// ‚ùå Tight coupling between command and query models\npublic class OrderService {\n    public async Task<OrderCreated> CreateOrderAsync(CreateOrder command) {\n        // 1 Update write model\n        var order = new Order(command CustomerId, command Items);\n        await _context Orders AddAsync(order);\n        // 2 Update read model (tightly coupled )\n        var summary = new OrderSummary {\n            OrderId = order Id,\n            CustomerId = order CustomerId,\n            Total = order Total,\n            Status = \"Created\"\n        };\n        await _context OrderSummaries AddAsync(summary);\n        await _context SaveChangesAsync();\n        return new OrderCreated(/ /);\n    }\n}\n`\nWhizbang Approach (Event-Driven)\n`csharp\n// ‚úÖ Decoupled: Command handler publishes event, perspective updates read model\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) {\n        // 1 Business logic (write model)\n        var order = new Order(message CustomerId, message Items);\n        // 2 Return event (no direct coupling to read model )\n        return new OrderCreated(\n            OrderId: order Id,\n            CustomerId: message CustomerId,\n            Total: order Total,\n            CreatedAt: DateTimeOffset",
        "startIndex": 0,
        "preview": "Perspective Discovery\nThe PerspectiveDiscoveryGenerator discovers all IPerspectiveOf<TEvent> implementations at compile-time and generates zero-reflec..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-1",
        "text": "IReceptor<CreateOrder, OrderCreated> { public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) { // 1 Business logic (write model) var order = new Order(message CustomerId, message Items); // 2 Return event (no direct coupling to read model ) return new OrderCreated( OrderId: order Id, CustomerId: message CustomerId, Total: order Total, CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n// ‚úÖ Perspective updates read model independently\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (order_id, customer_id, total, status, created_at)\n            VALUES (@OrderId, @CustomerId, @Total, 'Created', @CreatedAt)\n            \"\"\",\n            @event,\n            cancellationToken: ct\n        );\n    }\n}\n`\nBenefits:\n‚úÖ Decoupling: Command handler doesn't know about read models\n‚úÖ Multiple Perspectives: Many read models from same event\n‚úÖ Independent Evolution: Change read models without touching commands\n‚úÖ Rebuild Capability: Replay events to rebuild read models\n---\nHow It Works\nCompile-Time Discovery\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Your Code                                       ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  public class OrderSummaryPerspective           ‚îÇ\n‚îÇ      : IPerspectiveOf<OrderCreated> {           ‚îÇ\n‚îÇ    public async Task UpdateAsync(               ‚îÇ\n‚îÇ        OrderCreated @event,                     ‚îÇ\n‚îÇ        CancellationToken ct) { }            ‚îÇ\n‚îÇ  }                                               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  PerspectiveDiscoveryGenerator (Roslyn)         ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 Scan syntax tree for classes                ‚îÇ\n‚îÇ  2 Filter classes with base types              ‚îÇ\n‚îÇ  3 Check for IPerspectiveOf<TEvent>            ‚îÇ\n‚îÇ  4 Extract: Class, Event types (can be many )  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Generated Code                                  ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  PerspectiveRegistrations g cs                  ‚îÇ\n‚îÇ  ‚îî‚îÄ services AddScoped<IPerspectiveOf< >>()  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nGenerated File\nPerspectiveRegistrations g cs:\n`csharp\nusing Microsoft Extensions DependencyInjection;\nusing Whizbang Core;\nnamespace MyApp Generated;\npublic static class PerspectiveRegistrations {\n    /// <summary>\n    /// Registers all discovered perspectives (5 perspective classes, 8 event handlers) /// Generated at compile-time by PerspectiveDiscoveryGenerator",
        "startIndex": 2226,
        "preview": "IReceptor<CreateOrder, OrderCreated> { public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) { // 1 Business log..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-2",
        "text": "cs ‚îÇ ‚îÇ ‚îî‚îÄ services AddScoped<IPerspectiveOf< >>() ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Generated File PerspectiveRegistrations g cs: `csharp using Microsoft Extensions DependencyInjection; using Whizbang Core; namespace MyApp Generated; public static class PerspectiveRegistrations { /// <summary> /// Registers all discovered perspectives (5 perspective classes, 8 event handlers) /// Generated at compile-time by PerspectiveDiscoveryGenerator /// </summary>\n    public static IServiceCollection AddWhizbangPerspectives(\n        this IServiceCollection services) {\n        // OrderSummaryPerspective handles 3 events\n        services AddScoped<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\n        services AddScoped<IPerspectiveOf<OrderShipped>, OrderSummaryPerspective>();\n        services AddScoped<IPerspectiveOf<OrderCancelled>, OrderSummaryPerspective>();\n        // CustomerStatisticsPerspective handles 2 events\n        services AddScoped<IPerspectiveOf<OrderCreated>, CustomerStatisticsPerspective>();\n        services AddScoped<IPerspectiveOf<OrderShipped>, CustomerStatisticsPerspective>();\n        // InventoryPerspective handles 3 events\n        services AddScoped<IPerspectiveOf<OrderCreated>, InventoryPerspective>();\n        services AddScoped<IPerspectiveOf<OrderShipped>, InventoryPerspective>();\n        services AddScoped<IPerspectiveOf<OrderCancelled>, InventoryPerspective>();\n        return services;\n    }\n}\n`\nKey Observations:\nOne perspective class can handle multiple events (e g , OrderSummaryPerspective handles 3 events)\nMultiple perspectives can handle the same event (e g , OrderCreated handled by 3 perspectives)\nRegistered as Scoped (new instance per request/worker batch)\n---\nUsing Generated Registration\nRegistration in Program cs\n`csharp\n// Program cs\nusing MyApp Generated;\nvar builder = WebApplication CreateBuilder(args);\n// Register perspectives (generated method)\nbuilder Services AddWhizbangPerspectives();\n// Register Event Store coordinator (triggers perspectives)\nbuilder Services AddWhizbangEventStore(/ config /);\nvar app = builder Build();\napp Run();\n`\nThat's it No manual registration, no reflection, no assembly scanning ---\nPerspective Patterns\nPattern 1: Single Event Handler\n`csharp\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO order_summaries (\n                order_id, customer_id, total, status, created_at\n            ) VALUES (\n                @OrderId, @CustomerId, @Total, 'Created', @CreatedAt\n            )\n            \"\"\",\n            @event,\n            cancellationToken: ct\n        );\n    }\n}\n`\nGenerated registration (1 event):\n`csharp\nservices",
        "startIndex": 4886,
        "preview": "cs ‚îÇ ‚îÇ ‚îî‚îÄ services AddScoped<IPerspectiveOf< >>() ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Generated File PerspectiveRegistrations g c..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-3",
        "text": "UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"\"\" INSERT INTO order_summaries ( order_id, customer_id, total, status, created_at ) VALUES ( @OrderId, @CustomerId, @Total, 'Created', @CreatedAt ) \"\"\", @event, cancellationToken: ct ); } } ` Generated registration (1 event): `csharp services AddScoped<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\n`\n---\nPattern 2: Multiple Event Handlers\n`csharp\npublic class OrderSummaryPerspective :\n    IPerspectiveOf<OrderCreated>,\n    IPerspectiveOf<OrderShipped>,\n    IPerspectiveOf<OrderCancelled> {\n    private readonly IDbConnectionFactory _db;\n    // Handle OrderCreated\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"INSERT INTO order_summaries ( ) VALUES ( )\",\n            @event,\n            cancellationToken: ct\n        );\n    }\n    // Handle OrderShipped\n    public async Task UpdateAsync(OrderShipped @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"UPDATE order_summaries SET status = 'Shipped', shipped_at = @ShippedAt WHERE order_id = @OrderId\",\n            @event,\n            cancellationToken: ct\n        );\n    }\n    // Handle OrderCancelled\n    public async Task UpdateAsync(OrderCancelled @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        await conn ExecuteAsync(\n            \"UPDATE order_summaries SET status = 'Cancelled', cancelled_at = @CancelledAt WHERE order_id = @OrderId\",\n            @event,\n            cancellationToken: ct\n        );\n    }\n}\n`\nGenerated registration (3 events):\n`csharp\nservices AddScoped<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\nservices AddScoped<IPerspectiveOf<OrderShipped>, OrderSummaryPerspective>();\nservices AddScoped<IPerspectiveOf<OrderCancelled>, OrderSummaryPerspective>();\n`\nBenefits:\nSingle perspective class for related updates\nMaintains cohesion (all order summary logic in one place)\nGenerator handles multiple interface implementations automatically\n---\nPattern 3: Aggregated Statistics\n`csharp\npublic class CustomerStatisticsPerspective :\n    IPerspectiveOf<OrderCreated>,\n    IPerspectiveOf<OrderShipped> {\n    private readonly IDbConnectionFactory _db;\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Increment order count and total spent\n        await conn ExecuteAsync(\n            \"\"\"\n            INSERT INTO customer_statistics (customer_id, total_orders, total_spent, last_order_at)\n            VALUES (@CustomerId, 1, @Total, @CreatedAt)\n            ON CONFLICT (customer_id) DO UPDATE SET\n                total_orders = customer_statistics",
        "startIndex": 7358,
        "preview": "UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); await conn ExecuteAsync( \"\"\" INSERT ..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-4",
        "text": "_db; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Increment order count and total spent await conn ExecuteAsync( \"\"\" INSERT INTO customer_statistics (customer_id, total_orders, total_spent, last_order_at) VALUES (@CustomerId, 1, @Total, @CreatedAt) ON CONFLICT (customer_id) DO UPDATE SET total_orders = customer_statistics total_orders + 1,\n                total_spent = customer_statistics total_spent + @Total,\n                last_order_at = @CreatedAt\n            \"\"\",\n            new { @event CustomerId, @event Total, @event CreatedAt },\n            cancellationToken: ct\n        );\n    }\n    public async Task UpdateAsync(OrderShipped @event, CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        // Update last shipped date\n        await conn ExecuteAsync(\n            \"\"\"\n            UPDATE customer_statistics\n            SET last_shipped_at = @ShippedAt\n            WHERE customer_id = @CustomerId\n            \"\"\",\n            new { @event CustomerId, @event ShippedAt },\n            cancellationToken: ct\n        );\n    }\n}\n`\nUse Case: Pre-compute aggregations for analytics dashboards ---\nEvent Store Integration\nPerspective Invocation Flow\n`\nReceptor handles command, returns event\n   ‚îî‚îÄ> OrderCreated event\nEvent published to Event Store\n   ‚îî‚îÄ> Stored in wh_events table\nEvent Store Coordinator processes event\n   ‚îî‚îÄ> Resolves IPerspectiveOf<OrderCreated> implementations\nPerspectives invoked (parallel)\n   ‚îú‚îÄ> OrderSummaryPerspective UpdateAsync(OrderCreated)\n   ‚îú‚îÄ> CustomerStatisticsPerspective UpdateAsync(OrderCreated)\n   ‚îî‚îÄ> InventoryPerspective UpdateAsync(OrderCreated)\nCheckpoints updated\n   ‚îî‚îÄ> wh_perspective_checkpoints table\n`\nCheckpoint-Based Processing\nEach perspective tracks last processed event per stream:\n`sql\n-- wh_perspective_checkpoints table\nCREATE TABLE wh_perspective_checkpoints (\n    stream_id UUID NOT NULL,\n    perspective_name VARCHAR(200) NOT NULL,\n    last_event_id UUID NOT NULL,\n    last_sequence_number BIGINT NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    PRIMARY KEY (stream_id, perspective_name)\n);\n`\nExample:\n`\nstream_id                           | perspective_name           | last_event_id | last_sequence_number\n------------------------------------|----------------------------|---------------|---------------------\norder-abc-123                       | OrderSummaryPerspective    | event-001     | 5\norder-abc-123                       | CustomerStatistics         | event-001     | 5\norder-abc-123                       | InventoryPerspective       | event-001     | 5\n`\nBenefit: Can rebuild perspectives from any checkpoint (time-travel )",
        "startIndex": 9956,
        "preview": "_db; public async Task UpdateAsync(OrderCreated @event, CancellationToken ct = default) { await using var conn = _db CreateConnection(); // Increment ..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-5",
        "text": "NULL DEFAULT NOW(), PRIMARY KEY (stream_id, perspective_name) ); ` Example: ` stream_id | perspective_name | last_event_id | last_sequence_number ------------------------------------|----------------------------|---------------|--------------------- order-abc-123 | OrderSummaryPerspective | event-001 | 5 order-abc-123 | CustomerStatistics | event-001 | 5 order-abc-123 | InventoryPerspective | event-001 | 5 ` Benefit: Can rebuild perspectives from any checkpoint (time-travel ) ---\nRebuilding Perspectives\nFull Rebuild\n`csharp\npublic class PerspectiveRebuilder {\n    private readonly IEventStore _eventStore;\n    private readonly IServiceProvider _services;\n    public async Task RebuildAllPerspectivesAsync(CancellationToken ct = default) {\n        // 1 Truncate all perspective tables\n        await TruncatePerspectiveTables();\n        // 2 Reset checkpoints\n        await ResetCheckpoints();\n        // 3 Read all events from Event Store\n        var events = await _eventStore ReadAllEventsAsync(fromSequence: 0);\n        // 4 Resolve all perspectives\n        var perspectives = GetAllPerspectives();\n        // 5 Replay events through perspectives\n        foreach (var @event in events) {\n            foreach (var perspective in perspectives) {\n                if (CanHandle(perspective, @event)) {\n                    await perspective UpdateAsync(@event, ct);\n                }\n            }\n        }\n    }\n    private IEnumerable<IPerspectiveOf<object>> GetAllPerspectives() {\n        // Generator registers all perspectives, we can resolve them here\n        return _services GetServices<IPerspectiveOf<OrderCreated>>() Concat(_services GetServices<IPerspectiveOf<OrderShipped>>()) Concat(_services GetServices<IPerspectiveOf<OrderCancelled>>()) Cast<IPerspectiveOf<object>>();\n    }\n}\n`\nUse Cases:\nAdd new perspective to existing system\nFix bug in perspective logic\nSchema migration (add new columns)\nAnalytics: \"What would customer stats look like without refunds \"\n---\nGenerator Performance\nIncremental Caching\nLike ReceptorDiscoveryGenerator, uses value-based caching:\n`csharp\ninternal sealed record PerspectiveInfo(\n    string ClassName,\n    string[] EventTypes  // Arrays support value equality in records );\n`\nPerformance:\n`\nFirst compilation:\n‚îú‚îÄ Scan syntax tree: 50ms\n‚îú‚îÄ Extract perspective info: 20ms\n‚îú‚îÄ Generate registration file: 5ms\n‚îî‚îÄ Total: 75ms\nSubsequent compilation (no changes):\n‚îú‚îÄ Check cache: 1ms (inputs unchanged)\n‚îú‚îÄ Skip generation: 0ms\n‚îî‚îÄ Total: 1ms (74ms saved )\n`\nSyntactic Filtering\n`csharp\n// Fast syntactic check (no semantic model access)\npredicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types",
        "startIndex": 12329,
        "preview": "NULL DEFAULT NOW(), PRIMARY KEY (stream_id, perspective_name) ); ` Example: ` stream_id | perspective_name | last_event_id | last_sequence_number ----..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-6",
        "text": "Generate registration file: 5ms ‚îî‚îÄ Total: 75ms Subsequent compilation (no changes): ‚îú‚îÄ Check cache: 1ms (inputs unchanged) ‚îú‚îÄ Skip generation: 0ms ‚îî‚îÄ Total: 1ms (74ms saved ) ` Syntactic Filtering `csharp // Fast syntactic check (no semantic model access) predicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types Count: > 0 },\n// Only runs on ~5% of nodes (those with base types)\ntransform: static (ctx, ct) => ExtractPerspectiveInfo(ctx, ct)\n`\nResult: 100x faster than analyzing every node ---\nDebugging Generated Code\nView Generated File\nGenerated file written to:\n`\nobj/Debug/net10 0/generated/Whizbang Generators/PerspectiveDiscoveryGenerator/\n‚îî‚îÄ‚îÄ PerspectiveRegistrations g cs\n`\nOr configured output:\n`xml\n<PropertyGroup>\n  <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n  <CompilerGeneratedFilesOutputPath> whizbang-generated</CompilerGeneratedFilesOutputPath>\n</PropertyGroup>\n`\nBuild Diagnostics\nGenerator reports discoveries:\n`\nBuild started info WHIZ003: Found perspective 'OrderSummaryPerspective' handling OrderCreated, OrderShipped, OrderCancelled\ninfo WHIZ003: Found perspective 'CustomerStatisticsPerspective' handling OrderCreated, OrderShipped\ninfo WHIZ003: Found perspective 'InventoryPerspective' handling OrderCreated, OrderShipped, OrderCancelled\nBuild succeeded 3 perspectives discovered (8 event handlers)\n`\n---\nDiagnostics\nWHIZ003: Perspective Discovered\nSeverity: Info\nMessage: Found perspective '{0}' handling {1}\nExample:\n`\ninfo WHIZ003: Found perspective 'OrderSummaryPerspective' handling OrderCreated, OrderShipped, OrderCancelled\n`\nWhen: Reported for each discovered perspective during compilation Args:\n{0}: Perspective class name (e g , OrderSummaryPerspective)\n{1}: Comma-separated event types (e g",
        "startIndex": 14553,
        "preview": "Generate registration file: 5ms ‚îî‚îÄ Total: 75ms Subsequent compilation (no changes): ‚îú‚îÄ Check cache: 1ms (inputs unchanged) ‚îú‚îÄ Skip generation: 0ms ‚îî‚îÄ ..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-7",
        "text": "handlers) ` --- Diagnostics WHIZ003: Perspective Discovered Severity: Info Message: Found perspective '{0}' handling {1} Example: ` info WHIZ003: Found perspective 'OrderSummaryPerspective' handling OrderCreated, OrderShipped, OrderCancelled ` When: Reported for each discovered perspective during compilation Args: {0}: Perspective class name (e g , OrderSummaryPerspective) {1}: Comma-separated event types (e g , OrderCreated, OrderShipped, OrderCancelled)\n---\nMultiple Perspectives Per Event\nOne event, many read models:\n`csharp\n// Event\npublic record OrderCreated(\n    Guid OrderId,\n    Guid CustomerId,\n    decimal Total,\n    DateTimeOffset CreatedAt\n);\n// Perspective 1: Order summary view\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct) {\n        // Update order_summaries table\n    }\n}\n// Perspective 2: Customer statistics\npublic class CustomerStatisticsPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct) {\n        // Update customer_statistics table (aggregate)\n    }\n}\n// Perspective 3: Inventory reservation\npublic class InventoryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct) {\n        // Update inventory table (decrement available)\n    }\n}\n`\nGenerator registers all three:\n`csharp\nservices AddScoped<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\nservices AddScoped<IPerspectiveOf<OrderCreated>, CustomerStatisticsPerspective>();\nservices AddScoped<IPerspectiveOf<OrderCreated>, InventoryPerspective>();\n`\nEvent Store Coordinator invokes all in parallel (or configurable sequential) ---\nAOT Compatibility\nZero Reflection Guarantee\nGenerated registration uses no reflection:\n`csharp\n// ‚úÖ Direct type registration (AOT-compatible)\nservices AddScoped<IPerspectiveOf<OrderCreated>, OrderSummaryPerspective>();\n// ‚ùå Reflection-based registration (incompatible with AOT)\nvar perspectiveType = typeof(IPerspectiveOf<>) MakeGenericType(eventType);\nvar implementationType = assembly GetTypes() First(t => t IsAssignableTo(perspectiveType));\nservices AddScoped(perspectiveType, implementationType);\n`\nNative AOT Verification\n`xml\n<PropertyGroup>\n  <PublishAot>true</PublishAot>\n</PropertyGroup>\n`\nBuild output:\n`\ndotnet publish -c Release Generating native code\n  MyApp dll -> MyApp exe (Native AOT)\n  Startup time: < 10ms\n  Perspectives registered: 5 classes, 8 event handlers\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Implement IPerspectiveOf<TEvent> for each event your read model needs\n‚úÖ Group related updates in one perspective class (e g",
        "startIndex": 15998,
        "preview": "handlers) ` --- Diagnostics WHIZ003: Perspective Discovered Severity: Info Message: Found perspective '{0}' handling {1} Example: ` info WHIZ003: Foun..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-8",
        "text": "publish -c Release Generating native code MyApp dll -> MyApp exe (Native AOT) Startup time: < 10ms Perspectives registered: 5 classes, 8 event handlers ` --- Best Practices DO ‚úÖ ‚úÖ Implement IPerspectiveOf<TEvent> for each event your read model needs ‚úÖ Group related updates in one perspective class (e g , OrderSummaryPerspective)\n‚úÖ Use UPSERT for idempotency (ON CONFLICT DO UPDATE)\n‚úÖ Keep perspectives simple (no complex business logic)\n‚úÖ Use Dapper for high-performance reads/writes\n‚úÖ Design for rebuild (assume events can be replayed)\n‚úÖ Call AddWhizbangPerspectives() in Program cs\nDON'T ‚ùå\n‚ùå Put business logic in perspectives (belong in receptors)\n‚ùå Query other services in perspectives (use denormalized data from event)\n‚ùå Forget idempotency (events can be replayed )\n‚ùå Use EF Core for perspectives (Dapper is 20x faster)\n‚ùå Manually register perspectives (generator handles this)\n‚ùå Modify generated files (will be overwritten)\n---\nTroubleshooting\nProblem: Perspective Not Invoked\nSymptoms: Event published but perspective's UpdateAsync never called Causes:\nPerspective not implementing IPerspectiveOf<TEvent> correctly\nMissing AddWhizbangPerspectives() call\nEvent type mismatch (spelling, namespace)\nSolution:\n`csharp\n// ‚úÖ Correct interface implementation\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    public async Task UpdateAsync(OrderCreated @event, CancellationToken ct) {\n        // Implementation\n    }\n}\n// Program cs\nbuilder Services AddWhizbangPerspectives();  // Required `\nProblem: Duplicate Perspective Updates\nSymptoms: Same event processed multiple times by perspective Causes:\nMissing checkpoint tracking\nEvent Store replaying events without checking checkpoints\nSolution: Use IWorkCoordinator ProcessWorkBatchAsync with perspective checkpoint tracking:\n`csharp\nawait _coordinator ProcessWorkBatchAsync(\n    / /,\n    perspectiveCompletions: new[] {\n        new PerspectiveCheckpointCompletion {\n            StreamId = @event StreamId,\n            PerspectiveName = nameof(OrderSummaryPerspective),\n            LastEventId = @event EventId,\n            Status = PerspectiveProcessingStatus UpToDate\n        }\n    },\n    / /\n);\n`\nProblem: Generator Doesn't Find Perspectives\nSymptoms: PerspectiveRegistrations g cs not generated or empty",
        "startIndex": 18281,
        "preview": "publish -c Release Generating native code MyApp dll -> MyApp exe (Native AOT) Startup time: < 10ms Perspectives registered: 5 classes, 8 event handler..."
      },
      {
        "id": "v0.1.0/source-generators/perspective-discovery-chunk-9",
        "text": "with perspective checkpoint tracking: `csharp await _coordinator ProcessWorkBatchAsync( / /, perspectiveCompletions: new[] { new PerspectiveCheckpointCompletion { StreamId = @event StreamId, PerspectiveName = nameof(OrderSummaryPerspective), LastEventId = @event EventId, Status = PerspectiveProcessingStatus UpToDate } }, / / ); ` Problem: Generator Doesn't Find Perspectives Symptoms: PerspectiveRegistrations g cs not generated or empty Causes:\nNo perspectives in project\nPerspectives are abstract classes (can't be instantiated)\nSolution:\n`csharp\n// ‚úÖ Concrete class\npublic class OrderSummaryPerspective : IPerspectiveOf<OrderCreated> {\n    // Implementation\n}\n// ‚ùå Abstract class (skipped by generator)\npublic abstract class BasePerspective : IPerspectiveOf<OrderCreated> {\n    // Abstract classes can't be instantiated\n}\n`\n---\nFurther Reading\nSource Generators:\nReceptor Discovery - Compile-time receptor discovery\nMessage Registry - VSCode extension integration\nAggregate IDs - UUIDv7 generation for identity value objects\nJSON Contexts - AOT-compatible JSON serialization\nCore Concepts:\nPerspectives - Event-driven read models\nLenses - Query-optimized repositories\nData Access:\nPerspectives Storage - Read model schema design\nEvent Store - Event sourcing and replay\nMessaging:\nWork Coordinator - Atomic batch processing\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20274,
        "preview": "with perspective checkpoint tracking: `csharp await _coordinator ProcessWorkBatchAsync( / /, perspectiveCompletions: new[] { new PerspectiveCheckpoint..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/source-generators/receptor-discovery",
    "title": "Receptor Discovery",
    "category": "Source Generators",
    "url": "/docs/v0.1.0/source-generators/receptor-discovery",
    "chunks": [
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-0",
        "text": "Receptor Discovery\nThe ReceptorDiscoveryGenerator discovers all IReceptor<TMessage, TResponse> implementations at compile-time and generates zero-reflection message routing code This enables AOT compatibility and optimal runtime performance Zero Reflection Philosophy\nTraditional frameworks discover handlers at runtime using reflection:\n`csharp\n// ‚ùå Reflection-based (incompatible with AOT, slow startup)\nforeach (var type in assembly GetTypes()) {\n    if (type IsAssignableTo(typeof(IReceptor<,>))) {\n        services AddScoped(type GetInterfaces()[0], type);  // Runtime discovery\n    }\n}\n`\nWhizbang uses Roslyn source generators for compile-time discovery:\n`csharp\n// ‚úÖ Zero reflection (AOT-compatible, instant startup)\nservices AddScoped<IReceptor<CreateOrder, OrderCreated>, OrderReceptor>();\nservices AddScoped<IReceptor<ShipOrder, OrderShipped>, ShipOrderReceptor>();\n// Generated at compile-time `\nBenefits:\n‚úÖ AOT Compatible: No runtime reflection or assembly scanning\n‚úÖ Fast Startup: No discovery overhead (< 1ms registration)\n‚úÖ Type Safe: Compile-time validation of all receptors\n‚úÖ Optimal Performance: Direct dispatch without dictionary lookups (~20ns overhead)\n---\nHow It Works\nCompile-Time Discovery\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Your Code                                       ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  public class OrderReceptor                     ‚îÇ\n‚îÇ      : IReceptor<CreateOrder, OrderCreated> {   ‚îÇ\n‚îÇ    // Implementation ‚îÇ\n‚îÇ  }                                               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  ReceptorDiscoveryGenerator (Roslyn)            ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 Scan syntax tree for classes                ‚îÇ\n‚îÇ  2 Filter classes with base types              ‚îÇ\n‚îÇ  3 Check for IReceptor<TMessage, TResponse>    ‚îÇ\n‚îÇ  4 Extract: Class, Message, Response types     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Generated Code (3 files)                       ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  1 DispatcherRegistrations g cs                ‚îÇ\n‚îÇ     ‚îî‚îÄ services AddScoped<IReceptor< >, >()‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  2 Dispatcher g cs                             ‚îÇ\n‚îÇ     ‚îî‚îÄ Type-safe routing logic                  ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ  3 ReceptorDiscoveryDiagnostics g cs           ‚îÇ\n‚îÇ     ‚îî‚îÄ Startup diagnostics                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nGenerated Files\nDispatcherRegistrations g cs (DI Registration):\n`csharp\nusing Microsoft Extensions DependencyInjection;\nusing Whizbang Core;\nnamespace MyApp Generated;\npublic static class DispatcherRegistrations {\n    public static IServiceCollection AddWhizbangDispatchers(\n        this IServiceCollection services) {\n        // Generated receptor registrations (3 found)\n        services AddScoped<IReceptor<CreateOrder, OrderCreated>, OrderReceptor>();\n        services",
        "startIndex": 0,
        "preview": "Receptor Discovery\nThe ReceptorDiscoveryGenerator discovers all IReceptor<TMessage, TResponse> implementations at compile-time and generates zero-refl..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-1",
        "text": "‚îÇ ‚îÇ ‚îî‚îÄ Startup diagnostics ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Generated Files DispatcherRegistrations g cs (DI Registration): `csharp using Microsoft Extensions DependencyInjection; using Whizbang Core; namespace MyApp Generated; public static class DispatcherRegistrations { public static IServiceCollection AddWhizbangDispatchers( this IServiceCollection services) { // Generated receptor registrations (3 found) services AddScoped<IReceptor<CreateOrder, OrderCreated>, OrderReceptor>(); services AddScoped<IReceptor<ShipOrder, OrderShipped>, ShipOrderReceptor>();\n        services AddScoped<IReceptor<CancelOrder, OrderCancelled>, CancelOrderReceptor>();\n        // Register generated dispatcher\n        services AddScoped<IDispatcher, GeneratedDispatcher>();\n        return services;\n    }\n}\n`\nDispatcher g cs (Type-Safe Routing):\n`csharp\nusing System;\nusing System Threading;\nusing System Threading Tasks;\nusing Microsoft Extensions DependencyInjection;\nusing Whizbang Core;\nnamespace MyApp Generated;\npublic class GeneratedDispatcher : Dispatcher {\n    public GeneratedDispatcher(IServiceProvider services) : base(services) { }\n    protected override ReceptorInvoker<TResult> GetReceptorInvoker<TResult>(\n        object message,\n        Type messageType) {\n        // Generated routing (zero reflection, zero allocations)\n        if (messageType == typeof(CreateOrder)) {\n            var receptor = _serviceProvider GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n            return async msg => (TResult)(object)await receptor HandleAsync((CreateOrder)msg);\n        }\n        if (messageType == typeof(ShipOrder)) {\n            var receptor = _serviceProvider GetRequiredService<IReceptor<ShipOrder, OrderShipped>>();\n            return async msg => (TResult)(object)await receptor HandleAsync((ShipOrder)msg);\n        }\n        if (messageType == typeof(CancelOrder)) {\n            var receptor = _serviceProvider GetRequiredService<IReceptor<CancelOrder, OrderCancelled>>();\n            return async msg => (TResult)(object)await receptor HandleAsync((CancelOrder)msg);\n        }\n        return null;  // No receptor found\n    }\n}\n`\nReceptorDiscoveryDiagnostics g cs (Startup Info):\n`csharp\nusing System Text;\nusing Whizbang Core Diagnostics;\nnamespace MyApp Generated;\n[WhizbangDiagnosticCollector]\ninternal static class ReceptorDiscoveryDiagnostics {\n    public static void Register() {\n        WhizbangDiagnostics RegisterDiagnostic(\"Receptor Discovery\", () => {\n            var message = new StringBuilder();\n            message AppendLine(\"Discovered 3 receptors at compile-time:\");\n            message AppendLine();\n            message AppendLine(\"  1 OrderReceptor: CreateOrder ‚Üí OrderCreated\");\n            message AppendLine(\"  2 ShipOrderReceptor: ShipOrder ‚Üí OrderShipped\");\n            message AppendLine(\"  3 CancelOrderReceptor: CancelOrder ‚Üí OrderCancelled\");\n            return message ToString();\n        });\n    }\n}\n`\n---\nUsing Generated Registration\nRegistration in Program cs\n`csharp\n// Program cs\nusing MyApp Generated;  // Generated namespace\nvar builder = WebApplication CreateBuilder(args);\n// Register Whizbang dispatchers (generated method)\nbuilder Services AddWhizbangDispatchers();\nvar app = builder",
        "startIndex": 3244,
        "preview": "‚îÇ ‚îÇ ‚îî‚îÄ Startup diagnostics ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Generated Files DispatcherRegistrations g cs (DI Registration): `c..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-2",
        "text": "message AppendLine(\" 3 CancelOrderReceptor: CancelOrder ‚Üí OrderCancelled\"); return message ToString(); }); } } ` --- Using Generated Registration Registration in Program cs `csharp // Program cs using MyApp Generated; // Generated namespace var builder = WebApplication CreateBuilder(args); // Register Whizbang dispatchers (generated method) builder Services AddWhizbangDispatchers(); var app = builder Build();\napp Run();\n`\nThat's it No manual registration, no reflection, no assembly scanning ---\nReceptor Patterns\nPattern 1: Command ‚Üí Event\n`csharp\npublic class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(\n        CreateOrder message,\n        CancellationToken ct = default) {\n        // Business logic\n        var order = new Order(message CustomerId, message Items);\n        // Return event\n        return new OrderCreated(\n            OrderId: order Id,\n            CustomerId: order CustomerId,\n            Total: order Total,\n            CreatedAt: DateTimeOffset UtcNow\n        );\n    }\n}\n`\nGenerated routing:\n`csharp\nif (messageType == typeof(CreateOrder)) {\n    var receptor = _serviceProvider GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n    return async msg => (TResult)(object)await receptor HandleAsync((CreateOrder)msg);\n}\n`\nPattern 2: Query ‚Üí Result\n`csharp\npublic class GetOrderReceptor : IReceptor<GetOrder, OrderSummary> {\n    private readonly IDbConnectionFactory _db;\n    public async ValueTask<OrderSummary> HandleAsync(\n        GetOrder query,\n        CancellationToken ct = default) {\n        await using var conn = _db CreateConnection();\n        return await conn QuerySingleOrDefaultAsync<OrderSummary>(\n            \"SELECT * FROM order_summaries WHERE order_id = @OrderId\",\n            new { query OrderId },\n            cancellationToken: ct\n        ) throw new NotFoundException($\"Order {query OrderId} not found\");\n    }\n}\n`\nPattern 3: Void Receptor (No Response)\n`csharp\npublic class SendEmailReceptor : IReceptor<SendEmail> {  // No response type\n    private readonly IEmailService _email;\n    public async ValueTask HandleAsync(\n        SendEmail message,\n        CancellationToken ct = default) {\n        await _email SendAsync(\n            to: message To,\n            subject: message Subject,\n            body: message Body,\n            ct: ct\n        );\n        // No return value\n    }\n}\n`\nGenerated routing (void pattern):\n`csharp\nif (messageType == typeof(SendEmail)) {\n    var receptor = _serviceProvider GetRequiredService<IReceptor<SendEmail>>();\n    await receptor",
        "startIndex": 5998,
        "preview": "message AppendLine(\" 3 CancelOrderReceptor: CancelOrder ‚Üí OrderCancelled\"); return message ToString(); }); } } ` --- Using Generated Registration Regi..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-3",
        "text": "public async ValueTask HandleAsync( SendEmail message, CancellationToken ct = default) { await _email SendAsync( to: message To, subject: message Subject, body: message Body, ct: ct ); // No return value } } ` Generated routing (void pattern): `csharp if (messageType == typeof(SendEmail)) { var receptor = _serviceProvider GetRequiredService<IReceptor<SendEmail>>(); await receptor HandleAsync((SendEmail)msg);\n    return default;  // Void receptor\n}\n`\n---\nGenerator Performance\nIncremental Compilation\nRoslyn incremental generators use value-based caching to skip work when inputs haven't changed:\n`\nFirst compilation:\n‚îú‚îÄ Scan syntax tree: 50ms\n‚îú‚îÄ Extract receptor info: 20ms\n‚îú‚îÄ Generate 3 files: 10ms\n‚îî‚îÄ Total: 80ms\nSubsequent compilation (no changes):\n‚îú‚îÄ Check cache: 1ms (inputs unchanged)\n‚îú‚îÄ Skip generation: 0ms\n‚îî‚îÄ Total: 1ms (79ms saved )\nCompilation after receptor change:\n‚îú‚îÄ Check cache: 1ms (CreateOrder receptor changed)\n‚îú‚îÄ Scan syntax tree: 50ms\n‚îú‚îÄ Extract receptor info: 20ms\n‚îú‚îÄ Generate 3 files: 10ms\n‚îî‚îÄ Total: 81ms (only re-runs affected pipeline)\n`\nKey Insight: Generator only re-runs when receptors actually change, not on every compilation Syntactic Filtering\nGenerator uses syntactic predicates to filter 95%+ of nodes before expensive semantic analysis:\n`csharp\n// Fast syntactic check (no semantic model access)\npredicate: static (node, _) => node is ClassDeclarationSyntax { BaseList Types Count: > 0 },\n// Only runs on ~5% of nodes (those with base types)\ntransform: static (ctx, ct) => ExtractReceptorInfo(ctx, ct)\n`\nPerformance:\nWithout predicate: ~10,000ms on 10,000 types (analyzes everything)\nWith predicate: ~50-100ms on 10,000 types (analyzes only 500 classes with base types)\n100x faster with proper filtering ---\nDebugging Generated Code\nView Generated Files\nGenerated files are written to:\n`\nobj/Debug/net10 0/generated/Whizbang Generators/ReceptorDiscoveryGenerator/\n‚îú‚îÄ‚îÄ DispatcherRegistrations g cs\n‚îú‚îÄ‚îÄ Dispatcher g cs\n‚îî‚îÄ‚îÄ ReceptorDiscoveryDiagnostics g cs\n`\nOr optionally configured output folder:\n`xml\n<PropertyGroup>\n  <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>\n  <CompilerGeneratedFilesOutputPath> whizbang-generated</CompilerGeneratedFilesOutputPath>\n</PropertyGroup>\n`\nBuild Diagnostics\nGenerator reports discoveries during build:\n`\nBuild started",
        "startIndex": 8191,
        "preview": "public async ValueTask HandleAsync( SendEmail message, CancellationToken ct = default) { await _email SendAsync( to: message To, subject: message Subj..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-4",
        "text": "Debugging Generated Code View Generated Files Generated files are written to: ` obj/Debug/net10 0/generated/Whizbang Generators/ReceptorDiscoveryGenerator/ ‚îú‚îÄ‚îÄ DispatcherRegistrations g cs ‚îú‚îÄ‚îÄ Dispatcher g cs ‚îî‚îÄ‚îÄ ReceptorDiscoveryDiagnostics g cs ` Or optionally configured output folder: `xml <PropertyGroup> <EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles> <CompilerGeneratedFilesOutputPath> whizbang-generated</CompilerGeneratedFilesOutputPath> </PropertyGroup> ` Build Diagnostics Generator reports discoveries during build: ` Build started info WHIZ001: Found receptor 'OrderReceptor' handling CreateOrder ‚Üí OrderCreated\ninfo WHIZ001: Found receptor 'ShipOrderReceptor' handling ShipOrder ‚Üí OrderShipped\ninfo WHIZ001: Found receptor 'CancelOrderReceptor' handling CancelOrder ‚Üí OrderCancelled\nBuild succeeded 3 receptors discovered\n`\nStartup Diagnostics\nView discovered receptors at application startup:\n`csharp\n// Enable diagnostics\nWhizbangDiagnostics EnableLogging = true;\nvar app = builder Build();\n// View diagnostics before running\nvar diagnostics = WhizbangDiagnostics GetAllDiagnostics();\nforeach (var (category, messageFn) in diagnostics) {\n    Console WriteLine($\"[{category}]\");\n    Console WriteLine(messageFn());\n    Console WriteLine();\n}\napp Run();\n`\nOutput:\n`\n[Receptor Discovery]\nDiscovered 3 receptors at compile-time:\nOrderReceptor: CreateOrder ‚Üí OrderCreated\nShipOrderReceptor: ShipOrder ‚Üí OrderShipped\nCancelOrderReceptor: CancelOrder ‚Üí OrderCancelled\n`\n---\nDiagnostics\nWHIZ001: Receptor Discovered\nSeverity: Info\nMessage: Found receptor '{0}' handling {1} ‚Üí {2}\nExample:\n`\ninfo WHIZ001: Found receptor 'OrderReceptor' handling CreateOrder ‚Üí OrderCreated\n`\nWhen: Reported for each discovered receptor during compilation ---\nWHIZ002: No Receptors Found\nSeverity: Warning\nMessage: No IReceptor implementations were found in the compilation\nExample:\n`\nwarning WHIZ002: No IReceptor implementations were found in the compilation\n`\nWhen: No receptors discovered (may indicate missing implementations or namespace issues) Fix:\nEnsure receptors implement IReceptor<TMessage, TResponse>\nVerify using Whizbang Core; is present\nCheck that receptors are in the same project or referenced project\n---\nMultiple Receptors Per Message\nOne message, multiple destinations:\n`csharp\n// Local receptor (in-process)\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) {\n        // Create order locally\n        return new OrderCreated(/",
        "startIndex": 10121,
        "preview": "Debugging Generated Code View Generated Files Generated files are written to: ` obj/Debug/net10 0/generated/Whizbang Generators/ReceptorDiscoveryGener..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-5",
        "text": "Core; is present Check that receptors are in the same project or referenced project --- Multiple Receptors Per Message One message, multiple destinations: `csharp // Local receptor (in-process) public class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> { public async ValueTask<OrderCreated> HandleAsync(CreateOrder message, CancellationToken ct) { // Create order locally return new OrderCreated(/ /);\n    }\n}\n// Remote receptor (via outbox)\npublic class NotifyInventoryReceptor : IReceptor<CreateOrder, InventoryNotified> {\n    public async ValueTask<InventoryNotified> HandleAsync(CreateOrder message, CancellationToken ct) {\n        // Send to inventory service via outbox\n        return new InventoryNotified(/ /);\n    }\n}\n`\nGenerator handles both:\n`csharp\n// SendAsync: Routes to first receptor\nif (messageType == typeof(CreateOrder)) {\n    var receptor = _serviceProvider GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n    return async msg => await receptor HandleAsync((CreateOrder)msg);\n}\n// PublishAsync: Routes to all receptors\nif (messageType == typeof(CreateOrder)) {\n    var receptors = _serviceProvider GetServices<IReceptor<CreateOrder, *>>();\n    foreach (var receptor in receptors) {\n        await receptor HandleAsync((CreateOrder)msg);\n    }\n}\n`\n---\nAOT Compatibility\nZero Reflection Guarantee\nGenerated code uses no reflection:\n`csharp\n// ‚úÖ Direct type checks (AOT-compatible)\nif (messageType == typeof(CreateOrder)) {\n    var receptor = _serviceProvider GetRequiredService<IReceptor<CreateOrder, OrderCreated>>();\n    return async msg => await receptor HandleAsync((CreateOrder)msg);\n}\n// ‚ùå Reflection-based routing (incompatible with AOT)\nvar receptorType = typeof(IReceptor<,>) MakeGenericType(messageType, responseType);\nvar receptor = _serviceProvider GetService(receptorType);\nvar method = receptorType GetMethod(\"HandleAsync\");\nreturn method Invoke(receptor, new[] { message });\n`\nNative AOT Verification\n`xml\n< -- Enable Native AOT -->\n<PropertyGroup>\n  <PublishAot>true</PublishAot>\n</PropertyGroup>\n`\nBuild output:\n`\ndotnet publish -c Release Generating native code\n  MyApp dll -> MyApp exe (Native AOT)\n  Binary size: 8 2 MB\n  Startup time: < 10ms\n`\nWhizbang dispatcher adds < 1KB to native binary size",
        "startIndex": 12146,
        "preview": "Core; is present Check that receptors are in the same project or referenced project --- Multiple Receptors Per Message One message, multiple destinati..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-6",
        "text": "Native AOT Verification `xml < -- Enable Native AOT --> <PropertyGroup> <PublishAot>true</PublishAot> </PropertyGroup> ` Build output: ` dotnet publish -c Release Generating native code MyApp dll -> MyApp exe (Native AOT) Binary size: 8 2 MB Startup time: < 10ms ` Whizbang dispatcher adds < 1KB to native binary size ---\nPerformance Characteristics\nDispatch Overhead\n| Method | Overhead | Notes |\n|--------|----------|-------|\n| LocalInvokeAsync | < 20ns | Direct method call via delegate |\n| SendAsync | ~100ns | Includes outbox storage if no local receptor |\n| PublishAsync | ~50ns per receptor | Parallel invocation |\nBenchmark:\n`csharp\n[Benchmark]\npublic async Task LocalInvokeAsync_CreateOrder() {\n    var result = await _dispatcher LocalInvokeAsync<CreateOrder, OrderCreated>(\n        new CreateOrder(/ /)\n    );\n}\n// Result: ~18ns per dispatch (3 5M operations/second)\n`\nZero Allocations\nGenerated routing uses object pooling to avoid allocations:\n`csharp\n// Generated code (simplified)\nprotected override ReceptorInvoker<TResult> GetReceptorInvoker<TResult>(\n    object message,\n    Type messageType) {\n    // Cached delegate (zero allocations after first call)\n    if (messageType == typeof(CreateOrder)) {\n        return _cachedOrderReceptorInvoker = CreateInvoker();\n    }\n    return null;\n}\n`\nBenchmark:\n`\nMemory Diagnostics:\n  Gen 0: 0\n  Gen 1: 0\n  Gen 2: 0\n  Allocated: 0 bytes\n`\n---\nGenerator Internals\nValue Type Records for Caching\n`csharp\ninternal sealed record ReceptorInfo(\n    string ClassName,\n    string MessageType,\n    string ResponseType\n);\n`\nWhy sealed record Value equality: Incremental caching relies on structural comparison\nImmutable: No risk of cache invalidation from mutation\nPerformance: Compiler optimizes sealed types\nComparison:\n`csharp\n// With record (value equality)\nvar cached = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\", \"OrderCreated\");\nvar current = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\", \"OrderCreated\");\ncached == current;  // ‚úÖ true (fields match, generator skips re-generation)\n// With class (reference equality)\nvar cached = new ReceptorInfo { ClassName = \"OrderReceptor\", };\nvar current = new ReceptorInfo { ClassName = \"OrderReceptor\",",
        "startIndex": 14004,
        "preview": "Native AOT Verification `xml < -- Enable Native AOT --> <PropertyGroup> <PublishAot>true</PublishAot> </PropertyGroup> ` Build output: ` dotnet publis..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-7",
        "text": "equality) var cached = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\", \"OrderCreated\"); var current = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\", \"OrderCreated\"); cached == current; // ‚úÖ true (fields match, generator skips re-generation) // With class (reference equality) var cached = new ReceptorInfo { ClassName = \"OrderReceptor\", }; var current = new ReceptorInfo { ClassName = \"OrderReceptor\", };\ncached == current;  // ‚ùå false (different references, generator always re-runs)\n`\nImpact: Record caching saves 50-200ms per incremental build Template-Based Generation\nGenerator uses real Ctemplates with IDE support:\n`csharp\n// Templates/DispatcherTemplate cs\nnamespace Whizbang Core Generated;\npublic class GeneratedDispatcher : Dispatcher {\n    protected override ReceptorInvoker<TResult> GetReceptorInvoker<TResult>(\n        object message,\n        Type messageType) {\n        #region SEND_ROUTING\n        // Generator replaces this region with routing code\n        #endregion\n        return null;\n    }\n}\n`\nBenefits:\nFull IntelliSense and syntax highlighting\nCompile-time validation via placeholder types\nEasy to update and maintain\nNo string concatenation nightmares\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Implement IReceptor<TMessage, TResponse> for all message handlers\n‚úÖ Use descriptive receptor names (e g , CreateOrderReceptor, not Receptor1)\n‚úÖ Keep receptors small (single responsibility)\n‚úÖ Use dependency injection for services\n‚úÖ Return events from commands (enables perspectives)\n‚úÖ Call AddWhizbangDispatchers() in Program cs\nDON'T ‚ùå\n‚ùå Manually register receptors (generator handles this)\n‚ùå Use reflection to discover receptors (defeats AOT compatibility)\n‚ùå Create receptors in other assemblies without referencing Whizbang Generators\n‚ùå Modify generated files (will be overwritten)\n‚ùå Skip CancellationToken parameter (required for graceful shutdown)\n---\nTroubleshooting\nProblem: Generator Doesn't Run\nSymptoms: No generated files in obj/ directory Causes:\nWhizbang Generators not referenced\nGenerator disabled in project file\nSolution:\n`xml\n<ItemGroup>\n  <PackageReference Include=\"Whizbang Generators\" OutputItemType=\"Analyzer\" />\n</ItemGroup>\n`\nProblem: No Receptors Found (WHIZ002)\nSymptoms: warning WHIZ002: No IReceptor implementations were found\nCauses:\nReceptors not implementing correct interface\nNamespace import missing\nSolution:\n`csharp\nusing Whizbang Core;  // Required",
        "startIndex": 15906,
        "preview": "equality) var cached = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\", \"OrderCreated\"); var current = new ReceptorInfo(\"OrderReceptor\", \"CreateOrder\"..."
      },
      {
        "id": "v0.1.0/source-generators/receptor-discovery-chunk-8",
        "text": "directory Causes: Whizbang Generators not referenced Generator disabled in project file Solution: `xml <ItemGroup> <PackageReference Include=\"Whizbang Generators\" OutputItemType=\"Analyzer\" /> </ItemGroup> ` Problem: No Receptors Found (WHIZ002) Symptoms: warning WHIZ002: No IReceptor implementations were found Causes: Receptors not implementing correct interface Namespace import missing Solution: `csharp using Whizbang Core; // Required public class OrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n    // Implementation }\n`\nProblem: Type Not Found in Generated Code\nSymptoms: Compilation error in generated Dispatcher g cs Causes:\nMessage type not public\nMessage type in different assembly not referenced\nSolution:\n`csharp\n// ‚úÖ Public message types\npublic record CreateOrder(Guid CustomerId, OrderItem[] Items);\n// ‚ùå Internal message types\ninternal record CreateOrder(Guid CustomerId, OrderItem[] Items);\n`\n---\nFurther Reading\nSource Generators:\nPerspective Discovery - Discovering IPerspectiveOf implementations\nMessage Registry - VSCode extension integration\nAggregate IDs - UUIDv7 generation for identity value objects\nJSON Contexts - AOT-compatible JSON serialization\nCore Concepts:\nReceptors - Message handler pattern\nDispatcher - Message routing patterns\nAdvanced:\nPerformance: Local Invoke - Sub-20ns dispatch\nTesting: Receptor Testing - Unit testing receptors\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 17895,
        "preview": "directory Causes: Whizbang Generators not referenced Generator disabled in project file Solution: `xml <ItemGroup> <PackageReference Include=\"Whizbang..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/transports/azure-service-bus",
    "title": "Azure Service Bus Transport",
    "category": "Transports",
    "url": "/docs/v0.1.0/transports/azure-service-bus",
    "chunks": [
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-0",
        "text": "Azure Service Bus Transport\nThe Azure Service Bus transport provides reliable, ordered message delivery across services using Azure Service Bus topics and subscriptions This enables pub/sub patterns with correlation-based routing for multi-tenant and distributed architectures Why Azure Service Bus Azure Service Bus offers enterprise-grade messaging with:\n| Feature | Description | Benefit |\n|---------|-------------|---------|\n| Topics & Subscriptions | Publish once, multiple subscribers | True pub/sub pattern |\n| Correlation Filters | Route messages by properties | Multi-tenant isolation |\n| At-Least-Once Delivery | Guaranteed message delivery | Reliability |\n| Message Ordering | FIFO within sessions | Consistency |\n| Dead Letter Queue | Automatic failure handling | Observability |\n| Lock Renewal | Automatic lock extension | Long-running handlers |\nWhizbang Integration:\n‚úÖ AOT-Compatible - Uses JsonContextRegistry for serialization\n‚úÖ Aspire Integration - First-class support for NET Aspire orchestration\n‚úÖ Correlation Filters - Automatic routing based on message properties\n‚úÖ Emulator Support - Works with Aspire Service Bus emulator\n‚úÖ Observability - OpenTelemetry tracing for all operations\n---\nArchitecture\nTopic/Subscription Pattern\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Azure Service Bus Namespace                           ‚îÇ\n‚îÇ                                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ  ‚îÇ  Topic: \"whizbang",
        "startIndex": 0,
        "preview": "Azure Service Bus Transport\nThe Azure Service Bus transport provides reliable, ordered message delivery across services using Azure Service Bus topics..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-1",
        "text": "orchestration ‚úÖ Correlation Filters - Automatic routing based on message properties ‚úÖ Emulator Support - Works with Aspire Service Bus emulator ‚úÖ Observability - OpenTelemetry tracing for all operations --- Architecture Topic/Subscription Pattern ` ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Azure Service Bus Namespace ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ Topic: \"whizbang events\"                      ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ                                                 ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Subscription: \"inventory-service\"       ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Filter: Destination = \"inventory\"       ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚Üí Inventory Service                     ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ                                                 ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Subscription: \"notification-service\"    ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Filter: Destination = \"notifications\"   ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚Üí Notification Service                  ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ                                                 ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Subscription: \"analytics-service\"       ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  Filter: Destination = \"analytics\"       ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ  ‚Üí Analytics Service                     ‚îÇ ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nMessage Flow\n`\nPublisher (Order Service)\n  ‚îÇ\n  ‚îÇ 1 PublishAsync(envelope, destination)\n  ‚îÇ    Destination: \"inventory\"\n  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  AzureServiceBusTransport           ‚îÇ\n‚îÇ                                     ‚îÇ\n‚îÇ  - Serialize MessageEnvelope        ‚îÇ\n‚îÇ  - Set ApplicationProperties:       ‚îÇ\n‚îÇ    ‚Ä¢ MessageId                      ‚îÇ\n‚îÇ    ‚Ä¢ CorrelationId                  ‚îÇ\n‚îÇ    ‚Ä¢ CausationId                    ‚îÇ\n‚îÇ    ‚Ä¢ Destination = \"inventory\"      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ\n  ‚îÇ 2 SendMessageAsync()\n  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Azure Service Bus Topic            ‚îÇ\n‚îÇ  \"whizbang events\"                  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ\n  ‚îÇ 3 Correlation Filter\n  ‚îÇ    WHERE Destination = \"inventory\"\n  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Subscription: \"inventory-service\"  ‚îÇ\n‚îÇ  (Only messages with matching       ‚îÇ\n‚îÇ   Destination property)             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ\n  ‚îÇ 4",
        "startIndex": 1514,
        "preview": "orchestration ‚úÖ Correlation Filters - Automatic routing based on message properties ‚úÖ Emulator Support - Works with Aspire Service Bus emulator ‚úÖ Obse..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-2",
        "text": "\"inventory\" ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 2 SendMessageAsync() ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Azure Service Bus Topic ‚îÇ ‚îÇ \"whizbang events\" ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 3 Correlation Filter ‚îÇ WHERE Destination = \"inventory\" ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Subscription: \"inventory-service\" ‚îÇ ‚îÇ (Only messages with matching ‚îÇ ‚îÇ Destination property) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 4 ProcessMessageAsync()\n  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Inventory Service Subscriber       ‚îÇ\n‚îÇ                                     ‚îÇ\n‚îÇ  - Deserialize MessageEnvelope      ‚îÇ\n‚îÇ  - Extract metadata (IDs, hops)     ‚îÇ\n‚îÇ  - Invoke handler                   ‚îÇ\n‚îÇ  - Complete or Abandon message      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nConfiguration\nAdd NuGet Package\n`bash\ndotnet add package Whizbang Transports AzureServiceBus\n`\nRegister Transport (Standard NET)\n`csharp\nusing Whizbang Transports AzureServiceBus;\nvar builder = WebApplication CreateBuilder(args);\n// Register Azure Service Bus transport\nbuilder Services AddAzureServiceBusTransport(\n  connectionString: \"Endpoint=sb:// \",\n  configureOptions: options => {\n    options MaxConcurrentCalls = 20;              // Default: 10\n    options MaxAutoLockRenewalDuration = TimeSpan FromMinutes(5);\n    options MaxDeliveryAttempts = 10;             // Default: 10\n    options DefaultSubscriptionName = \"default\";  // Default: \"default\"\n  }\n);\n// Optional: Add health checks\nbuilder Services AddAzureServiceBusHealthChecks();\nvar app = builder Build();\napp Run();\n`\nRegister Transport ( NET Aspire) NET Aspire App Host (AppHost/Program cs):\n`csharp\nvar builder = DistributedApplication CreateBuilder(args);\n// Add Azure Service Bus resource (or emulator)\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();  // Or PublishAsAzureServiceBusNamespace() for production\n// Add topic with subscriptions\nvar topic = serviceBus AddTopic(\"whizbang-events\");\n// Inventory service subscription with correlation filter\nvar inventorySub = topic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");  // Whizbang extension method\nvar notificationSub = topic AddSubscription(\"notification-service\") WithDestinationFilter(\"notifications\");\n// Add service projects with references\nvar inventoryService = builder AddProject<Projects InventoryService>(\"inventory-service\") WithReference(serviceBus) WithReference(inventorySub);  // Grants access to subscription\nvar notificationService = builder AddProject<Projects NotificationService>(\"notification-service\") WithReference(serviceBus) WithReference(notificationSub);\n`\nService Project (InventoryService/Program cs):\n`csharp\nvar builder = WebApplication CreateBuilder(args);\n// Aspire adds Service Bus connection string via environment variables\nbuilder",
        "startIndex": 3702,
        "preview": "\"inventory\" ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 2 SendMessageAsync() ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Azure Service Bus Topic ‚îÇ ‚îÇ..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-3",
        "text": "WithDestinationFilter(\"notifications\"); // Add service projects with references var inventoryService = builder AddProject<Projects InventoryService>(\"inventory-service\") WithReference(serviceBus) WithReference(inventorySub); // Grants access to subscription var notificationService = builder AddProject<Projects NotificationService>(\"notification-service\") WithReference(serviceBus) WithReference(notificationSub); ` Service Project (InventoryService/Program cs): `csharp var builder = WebApplication CreateBuilder(args); // Aspire adds Service Bus connection string via environment variables builder AddServiceDefaults();  // Includes Service Bus integration\n// Register Azure Service Bus transport\n// Connection string injected by Aspire\nvar connectionString = builder Configuration GetConnectionString(\"messaging\") throw new InvalidOperationException(\"Service Bus connection string not found\");\nbuilder Services AddAzureServiceBusTransport(connectionString);\nvar app = builder Build();\napp Run();\n`\n---\nUsage Patterns\nPublishing Messages\n`csharp\nusing Whizbang Core Transports;\npublic class OrderService {\n  private readonly ITransport _transport;\n  public OrderService(ITransport transport) {\n    _transport = transport;\n  }\n  public async Task CreateOrderAsync(CreateOrder command) {\n    // Process order var @event = new OrderCreated(orderId, customerId, total, DateTimeOffset UtcNow);\n    // Create envelope\n    var envelope = MessageEnvelope Create(\n      messageId: MessageId New(),\n      correlationId: CorrelationId New(),\n      causationId: null,\n      payload: @event,\n      currentHop: new MessageHop {\n        StreamKey = orderId ToString(),\n        Timestamp = DateTimeOffset UtcNow\n      }\n    );\n    // Publish to multiple destinations\n    var inventoryDest = new TransportDestination(\n      Address: \"whizbang-events\",\n      RoutingKey: \"inventory-service\",\n      Metadata: new Dictionary<string, JsonElement> {\n        [\"Destination\"] = JsonSerializer SerializeToElement(\"inventory\")\n      }\n    );\n    var notificationDest = new TransportDestination(\n      Address: \"whizbang-events\",\n      RoutingKey: \"notification-service\",\n      Metadata: new Dictionary<string, JsonElement> {\n        [\"Destination\"] = JsonSerializer SerializeToElement(\"notifications\")\n      }\n    );\n    await _transport PublishAsync(envelope, inventoryDest);\n    await _transport PublishAsync(envelope, notificationDest);\n  }\n}\n`\nSubscribing to Messages\n`csharp\nusing Whizbang Core Transports;\npublic class InventoryServiceWorker : BackgroundService {\n  private readonly ITransport _transport;\n  private readonly IDispatcher _dispatcher;\n  private ISubscription _subscription;\n  public InventoryServiceWorker(ITransport transport, IDispatcher dispatcher) {\n    _transport = transport;\n    _dispatcher = dispatcher;\n  }\n  protected override async Task ExecuteAsync(CancellationToken stoppingToken) {\n    // Initialize transport\n    await _transport InitializeAsync(stoppingToken);\n    // Subscribe to messages\n    var destination = new TransportDestination(\n      Address: \"whizbang-events\",\n      RoutingKey: \"inventory-service\",\n      Metadata: new Dictionary<string, JsonElement> {\n        [\"DestinationFilter\"] = JsonSerializer",
        "startIndex": 6126,
        "preview": "WithDestinationFilter(\"notifications\"); // Add service projects with references var inventoryService = builder AddProject<Projects InventoryService>(\"..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-4",
        "text": "private ISubscription _subscription; public InventoryServiceWorker(ITransport transport, IDispatcher dispatcher) { _transport = transport; _dispatcher = dispatcher; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { // Initialize transport await _transport InitializeAsync(stoppingToken); // Subscribe to messages var destination = new TransportDestination( Address: \"whizbang-events\", RoutingKey: \"inventory-service\", Metadata: new Dictionary<string, JsonElement> { [\"DestinationFilter\"] = JsonSerializer SerializeToElement(\"inventory\")\n      }\n    );\n    _subscription = await _transport SubscribeAsync(\n      handler: async (envelope, ct) => {\n        // Dispatch message to appropriate receptor\n        await _dispatcher LocalInvokeAsync(envelope Payload, ct);\n      },\n      destination: destination,\n      cancellationToken: stoppingToken\n    );\n    // Keep worker running\n    await Task Delay(Timeout Infinite, stoppingToken);\n  }\n  public override async Task StopAsync(CancellationToken cancellationToken) {\n    if (_subscription = null) {\n      await _subscription DisposeAsync();\n    }\n    await base StopAsync(cancellationToken);\n  }\n}\n`\nCorrelation Filters (Production)\nWithout Aspire - Manual filter provisioning:\n`csharp\n// Destination metadata triggers automatic filter provisioning\nvar destination = new TransportDestination(\n  Address: \"whizbang-events\",\n  RoutingKey: \"inventory-service\",\n  Metadata: new Dictionary<string, JsonElement> {\n    // DestinationFilter triggers ApplyCorrelationFilterAsync()\n    [\"DestinationFilter\"] = JsonSerializer SerializeToElement(\"inventory\")\n  }\n);\n// Transport automatically provisions CorrelationFilter:\n// - Deletes $Default rule\n// - Creates DestinationFilter rule with Destination = \"inventory\"\nvar subscription = await transport SubscribeAsync(handler, destination);\n`\nWith Aspire - Automatic filter provisioning:\n`csharp\n// Aspire handles filter provisioning in AppHost\nvar subscription = topic AddSubscription(\"inventory-service\") WithDestinationFilter(\"inventory\");  // Provisioned by Aspire at startup\n`\n---\nTransport Capabilities\nThe Azure Service Bus transport declares these capabilities:\n`csharp\nTransportCapabilities PublishSubscribe |   // ‚úÖ Pub/sub via topics\nTransportCapabilities Reliable |           // ‚úÖ At-least-once delivery\nTransportCapabilities Ordered              // ‚úÖ FIFO within sessions\n`\nNot Supported:\n‚ùå RequestResponse - Use Inbox/Outbox with correlation IDs instead\n‚ùå ExactlyOnce - Requires Inbox pattern for deduplication\n‚ùå Streaming - Use pub/sub with multiple messages\n---\nSerialization (AOT-Compatible)\nJsonContextRegistry Integration\nAzure Service Bus transport uses JsonContextRegistry for AOT-compatible serialization:\n`csharp\n// Publishing (serialize envelope)\nvar envelopeType = envelope GetType();\nvar typeInfo = _jsonOptions GetTypeInfo(envelopeType)",
        "startIndex": 8764,
        "preview": "private ISubscription _subscription; public InventoryServiceWorker(ITransport transport, IDispatcher dispatcher) { _transport = transport; _dispatcher..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-5",
        "text": "Inbox/Outbox with correlation IDs instead ‚ùå ExactlyOnce - Requires Inbox pattern for deduplication ‚ùå Streaming - Use pub/sub with multiple messages --- Serialization (AOT-Compatible) JsonContextRegistry Integration Azure Service Bus transport uses JsonContextRegistry for AOT-compatible serialization: `csharp // Publishing (serialize envelope) var envelopeType = envelope GetType(); var typeInfo = _jsonOptions GetTypeInfo(envelopeType) throw new InvalidOperationException($\"No JsonTypeInfo found for {envelopeType Name}\");\nvar json = JsonSerializer Serialize(envelope, typeInfo);  // Zero reflection\n// Message metadata stores envelope type\nmessage ApplicationProperties[\"EnvelopeType\"] = envelopeType AssemblyQualifiedName;\n`\nSubscribing (deserialize envelope):\n`csharp\n// Get envelope type from metadata\nvar envelopeTypeName = message ApplicationProperties[\"EnvelopeType\"] as string;\nvar envelopeType = Type GetType(envelopeTypeName);\n// Deserialize using JsonTypeInfo\nvar typeInfo = _jsonOptions GetTypeInfo(envelopeType);\nvar envelope = JsonSerializer Deserialize(json, typeInfo) as IMessageEnvelope;\n`\nWhy AOT-compatible JsonContextRegistry pre-generates JsonTypeInfo for all message types\nNo reflection at runtime - all serialization metadata compiled\nFull Native AOT support\n---\nEmulator Support\nAspire Service Bus Emulator\nWhizbang detects the emulator automatically:\n`csharp\n// Detection logic\n_isEmulator = connectionString Contains(\"localhost\") ||\n              connectionString Contains(\"127 0 0 1\");\n`\nEmulator Differences:\n| Feature | Production | Emulator |\n|---------|-----------|----------|\n| Admin API | ‚úÖ Available (port 443) | ‚ùå Not supported |\n| Connectivity Check | Via GetNamespacePropertiesAsync() | Skipped (client open check) |\n| Filter Provisioning | Manual via Admin API | Aspire provisions at startup |\n| Initialization | Full verification | Simplified verification |\nExample:\n`csharp\n// AppHost\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();  // Starts container with emulator\n// Transport detects emulator and skips Admin API calls\nvar transport = new AzureServiceBusTransport(connectionString, jsonOptions);\nawait transport InitializeAsync();  // Skips admin verification for emulator\n`\n---\nRetry and Error Handling\nAutomatic Retry with Abandon\n`csharp\ntry {\n  // Invoke handler\n  await handler(envelope, ct);\n  // Complete on success\n  await args",
        "startIndex": 11117,
        "preview": "Inbox/Outbox with correlation IDs instead ‚ùå ExactlyOnce - Requires Inbox pattern for deduplication ‚ùå Streaming - Use pub/sub with multiple messages --..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-6",
        "text": "emulator // Transport detects emulator and skips Admin API calls var transport = new AzureServiceBusTransport(connectionString, jsonOptions); await transport InitializeAsync(); // Skips admin verification for emulator ` --- Retry and Error Handling Automatic Retry with Abandon `csharp try { // Invoke handler await handler(envelope, ct); // Complete on success await args CompleteMessageAsync(message, ct);\n} catch (Exception ex) {\n  var deliveryCount = message DeliveryCount;\n  if (deliveryCount >= MaxDeliveryAttempts) {\n    // Dead-letter after max attempts\n    await args DeadLetterMessageAsync(\n      message,\n      \"MaxDeliveryAttemptsExceeded\",\n      ex Message,\n      ct\n    );\n  } else {\n    // Abandon to retry (message returns to subscription)\n    await args AbandonMessageAsync(message, ct);\n  }\n}\n`\nRetry Behavior:\nMessage abandoned ‚Üí returns to subscription queue\nService Bus applies exponential backoff\nAfter 10 attempts (default) ‚Üí dead-lettered\nDead Letter Queue Monitoring\n`csharp\n// Monitor DLQ for failed messages\nvar receiver = client CreateReceiver(\n  \"whizbang-events\",\n  \"inventory-service\",\n  new ServiceBusReceiverOptions {\n    SubQueue = SubQueue DeadLetter\n  }\n);\nawait foreach (var message in receiver ReceiveMessagesAsync()) {\n  // Analyze failure reason\n  var reason = message DeadLetterReason;\n  var description = message DeadLetterErrorDescription;\n  // Log for investigation\n  logger LogError(\"DLQ: {Reason} - {Description}\", reason, description);\n}\n`\n---\nLock Renewal\nAutomatic Lock Extension\n`csharp\nvar processorOptions = new ServiceBusProcessorOptions {\n  MaxConcurrentCalls = 20,\n  AutoCompleteMessages = false,  // Manual completion after handler succeeds\n  MaxAutoLockRenewalDuration = TimeSpan FromMinutes(5)  // Auto-renew lock for 5 min\n};\n`\nHow It Works:\nHandler processes message (may take several minutes)\nService Bus client automatically renews lock every 30 seconds\nMax renewal duration: 5 minutes (configurable)\nIf processing exceeds 5 min ‚Üí lock expires ‚Üí message abandoned\nBest Practice: Set MaxAutoLockRenewalDuration to expected max processing time + buffer ---\nObservability\nOpenTelemetry Integration\nAzure Service Bus transport emits OpenTelemetry spans:\n`csharp\nusing var activity = WhizbangActivitySource Transport StartActivity(\"PublishAsync\");\nactivity SetTag(\"transport type\", \"AzureServiceBus\");\nactivity SetTag(\"transport topic\", topicName);\nactivity SetTag(\"transport subscription\", subscriptionName);\nactivity SetTag(\"transport",
        "startIndex": 13092,
        "preview": "emulator // Transport detects emulator and skips Admin API calls var transport = new AzureServiceBusTransport(connectionString, jsonOptions); await tr..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-7",
        "text": "‚Üí lock expires ‚Üí message abandoned Best Practice: Set MaxAutoLockRenewalDuration to expected max processing time + buffer --- Observability OpenTelemetry Integration Azure Service Bus transport emits OpenTelemetry spans: `csharp using var activity = WhizbangActivitySource Transport StartActivity(\"PublishAsync\"); activity SetTag(\"transport type\", \"AzureServiceBus\"); activity SetTag(\"transport topic\", topicName); activity SetTag(\"transport subscription\", subscriptionName); activity SetTag(\"transport emulator\", isEmulator);\nactivity SetTag(\"message id\", envelope MessageId Value);\nactivity SetTag(\"message correlation_id\", correlationId);\n`\nTrace Correlation:\nMessageId ‚Üí Unique message identifier\nCorrelationId ‚Üí Request correlation across services\nCausationId ‚Üí Parent message that caused this message\nHealth Checks\n`csharp\n// Register health check\nbuilder Services AddAzureServiceBusHealthChecks();\n// Health check endpoint\napp MapHealthChecks(\"/health\");\n`\nHealth Check Logic:\n`csharp\npublic async Task<HealthCheckResult> CheckHealthAsync(HealthCheckContext context, CancellationToken ct) {\n  if ( _transport IsInitialized) {\n    return HealthCheckResult Unhealthy(\"Transport not initialized\");\n  }\n  // Check if client is open\n  if (_client IsClosed) {\n    return HealthCheckResult Unhealthy(\"ServiceBusClient is closed\");\n  }\n  return HealthCheckResult Healthy(\"Azure Service Bus transport is healthy\");\n}\n`\n---\nPerformance\nThroughput Benchmarks\n| Metric | Value | Notes |\n|--------|-------|-------|\n| Publish Latency | ~10-50ms | Network + serialization |\n| Subscribe Latency | ~20-100ms | Network + deserialization + handler |\n| Max Throughput | ~10,000 msg/sec | Depends on namespace tier |\n| Serialization | ~100ns | AOT-compiled JsonTypeInfo |\nConcurrency\n`csharp\noptions MaxConcurrentCalls = 20;  // Process 20 messages in parallel\n`\nGuidelines:\nCPU-bound handlers: Set to CPU core count\nI/O-bound handlers: Set to 2-4x CPU core count\nHigh throughput: Increase to 50-100 (monitor memory)\nBatching (Future)\nService Bus supports batch sends (not yet implemented):\n`csharp\n// TODO: Batch sending for higher throughput\nawait sender",
        "startIndex": 15218,
        "preview": "‚Üí lock expires ‚Üí message abandoned Best Practice: Set MaxAutoLockRenewalDuration to expected max processing time + buffer --- Observability OpenTeleme..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-8",
        "text": "// Process 20 messages in parallel ` Guidelines: CPU-bound handlers: Set to CPU core count I/O-bound handlers: Set to 2-4x CPU core count High throughput: Increase to 50-100 (monitor memory) Batching (Future) Service Bus supports batch sends (not yet implemented): `csharp // TODO: Batch sending for higher throughput await sender SendMessagesAsync(batch);  // Send multiple at once\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use Correlation Filters for multi-tenant routing\n‚úÖ Set MaxAutoLockRenewalDuration to expected processing time + buffer\n‚úÖ Monitor Dead Letter Queue for failed messages\n‚úÖ Use Aspire for local development (emulator + automatic provisioning)\n‚úÖ Initialize transport during startup to fail fast if unreachable\n‚úÖ Complete messages manually after successful handling\n‚úÖ Use IDispatcher in subscription handlers for receptor routing\nDON'T ‚ùå\n‚ùå Use for request/response patterns (not supported - use Inbox/Outbox)\n‚ùå Forget to abandon messages on transient errors (breaks retry)\n‚ùå Dead-letter messages on transient errors (use abandon instead)\n‚ùå Hardcode connection strings (use configuration/Aspire)\n‚ùå Skip emulator detection (breaks admin API calls)\n‚ùå Set MaxConcurrentCalls too high (causes memory pressure)\n---\nTroubleshooting\nProblem: Messages Not Reaching Subscriber\nSymptoms: Publisher succeeds, but subscriber never receives messages Causes:\nCorrelation filter misconfiguration\nSubscription doesn't exist\nDestination property mismatch\nSolution:\n`csharp\n// Verify destination property matches filter\nvar destination = new TransportDestination(\n  Address: \"whizbang-events\",\n  RoutingKey: \"inventory-service\",\n  Metadata: new Dictionary<string, JsonElement> {\n    [\"Destination\"] = JsonSerializer SerializeToElement(\"inventory\")  // Must match filter\n  }\n);\n// Check filter in Azure Portal:\n// Service Bus Namespace ‚Üí Topics ‚Üí whizbang-events ‚Üí Subscriptions ‚Üí inventory-service ‚Üí Rules\n// Expected: DestinationFilter with Destination = \"inventory\"\n`\nProblem: \"No JsonTypeInfo found for envelope type\"\nSymptoms: Deserialization fails with missing JsonTypeInfo error Cause: Envelope type not registered in JsonContextRegistry",
        "startIndex": 16860,
        "preview": "// Process 20 messages in parallel ` Guidelines: CPU-bound handlers: Set to CPU core count I/O-bound handlers: Set to 2-4x CPU core count High through..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-9",
        "text": "); // Check filter in Azure Portal: // Service Bus Namespace ‚Üí Topics ‚Üí whizbang-events ‚Üí Subscriptions ‚Üí inventory-service ‚Üí Rules // Expected: DestinationFilter with Destination = \"inventory\" ` Problem: \"No JsonTypeInfo found for envelope type\" Symptoms: Deserialization fails with missing JsonTypeInfo error Cause: Envelope type not registered in JsonContextRegistry Solution:\n`csharp\n// Ensure envelope type is registered\n// In library: MessageEnvelope<T> should auto-register via MessageJsonContextGenerator\n// Verify registration\nvar jsonOptions = JsonContextRegistry CreateCombinedOptions();\nvar typeInfo = jsonOptions GetTypeInfo(typeof(MessageEnvelope<OrderCreated>));\nif (typeInfo == null) {\n  // Not registered - check generator output\n}\n`\nProblem: Transport Initialization Fails\nSymptoms: InitializeAsync() throws InvalidOperationException Causes:\nInvalid connection string\nService Bus namespace unreachable\nAdmin client not available (production)\nSolution:\n`csharp\ntry {\n  await transport InitializeAsync();\n} catch (InvalidOperationException ex) {\n  // Check connection string\n  logger LogError(ex, \"Invalid connection string or Service Bus unreachable\");\n  // For emulator: Ensure Aspire AppHost is running\n  // For production: Check network connectivity and connection string\n}\n`\nProblem: Messages Dead-Lettered Immediately\nSymptoms: All messages go to DLQ without processing Causes:\nHandler throws exception\nMissing envelope type metadata\nDeserialization failure\nSolution:\n`csharp\n// Check DLQ for failure reason\nvar dlqReceiver = client CreateReceiver(\n  \"whizbang-events\",\n  \"inventory-service\",\n  new ServiceBusReceiverOptions { SubQueue = SubQueue DeadLetter }\n);\nawait foreach (var message in dlqReceiver ReceiveMessagesAsync()) {\n  logger LogError(\n    \"DLQ: {Reason} - {Description} MessageId={MessageId}\",\n    message DeadLetterReason,\n    message DeadLetterErrorDescription,\n    message",
        "startIndex": 18661,
        "preview": "); // Check filter in Azure Portal: // Service Bus Namespace ‚Üí Topics ‚Üí whizbang-events ‚Üí Subscriptions ‚Üí inventory-service ‚Üí Rules // Expected: Desti..."
      },
      {
        "id": "v0.1.0/transports/azure-service-bus-chunk-10",
        "text": "Missing envelope type metadata Deserialization failure Solution: `csharp // Check DLQ for failure reason var dlqReceiver = client CreateReceiver( \"whizbang-events\", \"inventory-service\", new ServiceBusReceiverOptions { SubQueue = SubQueue DeadLetter } ); await foreach (var message in dlqReceiver ReceiveMessagesAsync()) { logger LogError( \"DLQ: {Reason} - {Description} MessageId={MessageId}\", message DeadLetterReason, message DeadLetterErrorDescription, message MessageId\n  );\n  // Common reasons:\n  // - \"MissingEnvelopeType\" ‚Üí Publisher didn't set ApplicationProperties[\"EnvelopeType\"]\n  // - \"UnresolvableEnvelopeType\" ‚Üí Type not found (assembly not loaded)\n  // - \"DeserializationFailed\" ‚Üí JSON mismatch or missing JsonTypeInfo\n  // - \"MaxDeliveryAttemptsExceeded\" ‚Üí Handler keeps failing\n}\n`\n---\nFurther Reading\nTransports:\nIn-Memory Transport - Local testing and development\nMessaging Patterns:\nOutbox Pattern - Reliable cross-service events\nInbox Pattern - Exactly-once processing\nWork Coordination - Lease-based message processing\nSource Generators:\nJSON Contexts - AOT-compatible JSON serialization\nInfrastructure:\nAspire Integration - NET Aspire orchestration\nHealth Checks - Application health monitoring\nAdvanced:\nCustom Transports - Implementing custom transports\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20207,
        "preview": "Missing envelope type metadata Deserialization failure Solution: `csharp // Check DLQ for failure reason var dlqReceiver = client CreateReceiver( \"whi..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/transports/in-memory",
    "title": "In-Memory Transport",
    "category": "Transports",
    "url": "/docs/v0.1.0/transports/in-memory",
    "chunks": [
      {
        "id": "v0.1.0/transports/in-memory-chunk-0",
        "text": "In-Memory Transport\nThe In-Memory transport provides synchronous, in-process message delivery without external dependencies This transport is ideal for testing, development, and single-process applications where cross-process communication isn't needed Why In-Memory Transport In-Memory offers simplicity and speed for local scenarios:\n| Feature | Description | Benefit |\n|---------|-------------|---------|\n| Zero Dependencies | No external infrastructure | Simple setup |\n| Synchronous Delivery | Messages delivered immediately | Predictable testing |\n| Thread-Safe | Concurrent publish/subscribe | Multi-threaded safety |\n| Full Capabilities | Pub/sub + request/response | Complete feature set |\n| Instant Initialization | No network checks | Fast startup |\n| Subscription Lifecycle | Pause/resume/dispose | Fine-grained control |\nUse Cases:\n‚úÖ Unit Testing - Test receptors without external infrastructure\n‚úÖ Integration Testing - Test message flows in-process\n‚úÖ Single-Process Apps - Modular applications without distributed messaging\n‚úÖ Local Development - No need for Service Bus/RabbitMQ during development\n‚úÖ Prototyping - Quick experimentation with messaging patterns\n---\nArchitecture\nSynchronous Delivery Model\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  InProcessTransport                                     ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Subscriptions Dictionary                      ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  \"orders\" ‚Üí [Handler1, Handler2]               ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  \"payments\" ‚Üí [Handler3]                       ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  \"notifications\" ‚Üí [Handler4, Handler5]        ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nPublisher                                      Subscriber\n  ‚îÇ                                                ‚îÇ\n  ‚îÇ 1 PublishAsync(envelope, destination)        ‚îÇ\n  ‚îÇ    Destination: \"orders\"                       ‚îÇ\n  ‚ñº                                                ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n‚îÇ  Lookup subscriptions[\"orders\"]  ‚îÇ              ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n  ‚îÇ                                                ‚îÇ\n  ‚îÇ 2 Foreach handler in subscriptions           ‚îÇ\n  ‚îÇ    ‚Üí Await handler(envelope)                  ‚îÇ\n  ‚ñº                                                ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Handler1(envelope)              ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Process message ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ                                                ‚îÇ\n  ‚îÇ 3 Sequential execution                       ‚îÇ\n  ‚ñº                                                ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Handler2(envelope)              ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Process message ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚îÇ\n  ‚îÇ 4",
        "startIndex": 0,
        "preview": "In-Memory Transport\nThe In-Memory transport provides synchronous, in-process message delivery without external dependencies This transport is ideal fo..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-1",
        "text": "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 Foreach handler in subscriptions ‚îÇ ‚îÇ ‚Üí Await handler(envelope) ‚îÇ ‚ñº ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Handler1(envelope) ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Process message ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ 3 Sequential execution ‚îÇ ‚ñº ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Handler2(envelope) ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Process message ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ 4 PublishAsync completes after ALL handlers\n  ‚ñº\n`\nKey Characteristics:\nSynchronous: PublishAsync awaits all handlers before returning\nOrdered: Handlers invoked in subscription order\nThread-Safe: Uses ConcurrentDictionary and locking\nNo Retry: Exceptions propagate to publisher\n---\nConfiguration\nRegister Transport (Built-In)\n`csharp\nusing Whizbang Core Transports;\nvar builder = WebApplication CreateBuilder(args);\n// In-memory transport is part of Whizbang Core - no separate package needed\nbuilder Services AddSingleton<ITransport, InProcessTransport>();\nvar app = builder Build();\napp Run();\n`\nNote: No additional configuration needed - transport is ready immediately Initialization\n`csharp\nvar transport = new InProcessTransport();\nawait transport InitializeAsync();  // Returns immediately (idempotent)\n// IsInitialized is true immediately\nConsole WriteLine(transport IsInitialized);  // True\n`\n---\nUsage Patterns\nPublish/Subscribe\n`csharp\nusing Whizbang Core Transports;\nvar transport = new InProcessTransport();\n// Subscribe to messages\nvar subscription = await transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    Console WriteLine($\"Received: {envelope MessageId}\");\n    await ProcessMessageAsync(envelope);\n  },\n  destination: new TransportDestination(\"orders\")\n);\n// Publish message\nvar envelope = MessageEnvelope Create(\n  messageId: MessageId New(),\n  correlationId: CorrelationId New(),\n  causationId: null,\n  payload: new OrderCreated(orderId, customerId, total),\n  currentHop: new MessageHop { Timestamp = DateTimeOffset UtcNow }\n);\nawait transport PublishAsync(\n  envelope,\n  new TransportDestination(\"orders\")\n);\n// Handler invoked synchronously before PublishAsync returns\n`\nMultiple Subscribers\n`csharp\n// Multiple subscribers receive the same message\nawait transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    // Update read model\n    await _perspectiveStore UpdateAsync(envelope Payload);\n  },\n  destination: new TransportDestination(\"orders\")\n);\nawait transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    // Send notification\n    await _emailService SendOrderConfirmationAsync(envelope",
        "startIndex": 3048,
        "preview": "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 Foreach handler in subscriptions ‚îÇ ‚îÇ ‚Üí Await handler(envelope) ‚îÇ ‚ñº ‚ñº ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-2",
        "text": "PublishAsync returns ` Multiple Subscribers `csharp // Multiple subscribers receive the same message await transport SubscribeAsync( handler: async (envelope, ct) => { // Update read model await _perspectiveStore UpdateAsync(envelope Payload); }, destination: new TransportDestination(\"orders\") ); await transport SubscribeAsync( handler: async (envelope, ct) => { // Send notification await _emailService SendOrderConfirmationAsync(envelope Payload);\n  },\n  destination: new TransportDestination(\"orders\")\n);\n// Publish - both handlers invoked sequentially\nawait transport PublishAsync(envelope, new TransportDestination(\"orders\"));\n`\nRequest/Response Pattern\n`csharp\n// Setup responder\nawait transport SubscribeAsync(\n  handler: async (requestEnvelope, ct) => {\n    // Process request\n    var response = ProcessOrder(requestEnvelope Payload);\n    // Send response to response destination\n    var responseEnvelope = MessageEnvelope Create(\n      messageId: MessageId New(),\n      correlationId: requestEnvelope GetCorrelationId(),\n      causationId: requestEnvelope MessageId,\n      payload: response,\n      currentHop: new MessageHop { Timestamp = DateTimeOffset UtcNow }\n    );\n    var responseDest = new TransportDestination($\"response-{requestEnvelope MessageId Value}\");\n    await transport PublishAsync(responseEnvelope, responseDest, ct);\n  },\n  destination: new TransportDestination(\"order-service\")\n);\n// Send request and wait for response\nvar requestEnvelope = MessageEnvelope Create(\n  messageId: MessageId New(),\n  correlationId: CorrelationId New(),\n  causationId: null,\n  payload: new CreateOrder(items),\n  currentHop: new MessageHop { Timestamp = DateTimeOffset UtcNow }\n);\nvar responseEnvelope = await transport SendAsync<CreateOrder, OrderCreated>(\n  requestEnvelope,\n  new TransportDestination(\"order-service\")\n);\nConsole WriteLine($\"Order created: {responseEnvelope Payload}\");\n`\nHow SendAsync Works:\nCreates temporary response destination: response-{messageId}\nSubscribes to response destination\nPublishes request to target destination\nWaits for response (via TaskCompletionSource)\nCleans up response subscription (in finally block)\n---\nSubscription Lifecycle\nPause and Resume\n`csharp\nvar subscription = await transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    await ProcessAsync(envelope);\n  },\n  destination: new TransportDestination(\"orders\")\n);\n// Pause subscription - handler won't be invoked\nawait subscription PauseAsync();\nConsole WriteLine(subscription IsActive);  // False\nawait transport PublishAsync(envelope, destination);  // Handler NOT invoked\n// Resume subscription\nawait subscription ResumeAsync();\nConsole WriteLine(subscription IsActive);  // True\nawait transport",
        "startIndex": 5198,
        "preview": "PublishAsync returns ` Multiple Subscribers `csharp // Multiple subscribers receive the same message await transport SubscribeAsync( handler: async (e..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-3",
        "text": "handler: async (envelope, ct) => { await ProcessAsync(envelope); }, destination: new TransportDestination(\"orders\") ); // Pause subscription - handler won't be invoked await subscription PauseAsync(); Console WriteLine(subscription IsActive); // False await transport PublishAsync(envelope, destination); // Handler NOT invoked // Resume subscription await subscription ResumeAsync(); Console WriteLine(subscription IsActive); // True await transport PublishAsync(envelope, destination);  // Handler invoked\n`\nUse Cases:\nTemporarily stop processing during maintenance\nRate limiting or backpressure handling\nGraceful shutdown (pause before disposing)\nDispose\n`csharp\n// Remove subscription entirely\nsubscription Dispose();\n// Handler removed from transport\nawait transport PublishAsync(envelope, destination);  // Handler NOT invoked\n// Dispose is idempotent\nsubscription Dispose();  // Safe to call multiple times\n`\n---\nTransport Capabilities\nThe in-memory transport declares these capabilities:\n`csharp\nTransportCapabilities RequestResponse |   // ‚úÖ SendAsync support\nTransportCapabilities PublishSubscribe |  // ‚úÖ PublishAsync/SubscribeAsync\nTransportCapabilities Ordered |           // ‚úÖ Sequential handler execution\nTransportCapabilities Reliable            // ‚úÖ Direct invocation (no network failures)\n`\nNot Supported:\n‚ùå ExactlyOnce - Handlers invoked for each publish (no deduplication)\n‚ùå Streaming - Not applicable to in-memory\nReliability Note: \"Reliable\" means messages won't be lost due to network failures, but exceptions in handlers propagate to publisher ---\nThread Safety\nConcurrent Publishes\n`csharp\nvar transport = new InProcessTransport();\nvar destination = new TransportDestination(\"orders\");\n// Subscribe once\nawait transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    await ProcessAsync(envelope);\n  },\n  destination: destination\n);\n// Publish concurrently from multiple threads\nvar tasks = Enumerable Range(0, 100) Select(i => {\n    var envelope = CreateEnvelope($\"order-{i}\");\n    return transport PublishAsync(envelope, destination);\n  }) ToArray();\nawait Task WhenAll(tasks);  // Thread-safe - all handlers invoked\n`\nConcurrent Subscriptions\n`csharp\n// Subscribe concurrently from multiple threads\nvar subscribeTasks = Enumerable Range(0, 50) Select(i => transport SubscribeAsync(\n    handler: async (envelope, ct) => {\n      await ProcessAsync(envelope, handlerIndex: i);\n    },\n    destination: new TransportDestination(\"orders\")\n  )) ToArray();\nawait Task",
        "startIndex": 7477,
        "preview": "handler: async (envelope, ct) => { await ProcessAsync(envelope); }, destination: new TransportDestination(\"orders\") ); // Pause subscription - handler..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-4",
        "text": "destination); }) ToArray(); await Task WhenAll(tasks); // Thread-safe - all handlers invoked ` Concurrent Subscriptions `csharp // Subscribe concurrently from multiple threads var subscribeTasks = Enumerable Range(0, 50) Select(i => transport SubscribeAsync( handler: async (envelope, ct) => { await ProcessAsync(envelope, handlerIndex: i); }, destination: new TransportDestination(\"orders\") )) ToArray(); await Task WhenAll(subscribeTasks);  // Thread-safe - all registered\n// Publish message - all 50 handlers invoked\nawait transport PublishAsync(envelope, new TransportDestination(\"orders\"));\n`\nImplementation:\nConcurrentDictionary<string, List< >> for subscriptions\nlock on subscription list during add/remove\nThread-safe iteration with ToArray() snapshot\n---\nError Handling\nHandler Exceptions\n`csharp\nawait transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    throw new InvalidOperationException(\"Handler failed \");\n  },\n  destination: new TransportDestination(\"orders\")\n);\ntry {\n  await transport PublishAsync(envelope, destination);\n} catch (InvalidOperationException ex) {\n  // Exception propagates to publisher\n  Console WriteLine($\"Handler failed: {ex Message}\");\n}\n`\nBehavior:\nException thrown in handler ‚Üí exception propagates to PublishAsync caller\nSubsequent handlers may not execute (depends on exception handling)\nNo retry - caller must handle retry logic\nCancellation\n`csharp\nvar cts = new CancellationTokenSource(TimeSpan FromSeconds(5));\ntry {\n  await transport SendAsync<CreateOrder, OrderCreated>(\n    requestEnvelope,\n    destination,\n    cts Token  // Timeout after 5 seconds\n  );\n} catch (OperationCanceledException) {\n  Console",
        "startIndex": 9536,
        "preview": "destination); }) ToArray(); await Task WhenAll(tasks); // Thread-safe - all handlers invoked ` Concurrent Subscriptions `csharp // Subscribe concurren..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-5",
        "text": "propagates to PublishAsync caller Subsequent handlers may not execute (depends on exception handling) No retry - caller must handle retry logic Cancellation `csharp var cts = new CancellationTokenSource(TimeSpan FromSeconds(5)); try { await transport SendAsync<CreateOrder, OrderCreated>( requestEnvelope, destination, cts Token // Timeout after 5 seconds ); } catch (OperationCanceledException) { Console WriteLine(\"Request timed out - no response received\");\n}\n`\nSendAsync Cancellation:\nResponse subscription cleaned up (finally block)\nTaskCompletionSource cancelled\nNo orphaned subscriptions\n---\nPerformance\nBenchmarks\n| Metric | Value | Notes |\n|--------|-------|-------|\n| PublishAsync Latency | ~1-5¬µs | Direct method call |\n| SendAsync Latency | ~10-50¬µs | Includes subscription setup/teardown |\n| Throughput | ~1M msg/sec | Limited by handler execution time |\n| Memory | ~100 bytes/subscription | Minimal overhead |\nComparison: In-Memory vs Azure Service Bus\n| Metric | In-Memory | Azure Service Bus |\n|--------|-----------|-------------------|\n| Latency | ~5¬µs | ~10-50ms (network) |\n| Throughput | ~1M msg/sec | ~10K msg/sec |\n| Cross-Process | ‚ùå Same process only | ‚úÖ Distributed |\n| Persistence | ‚ùå No | ‚úÖ Durable queues |\n| Retry | ‚ùå Manual | ‚úÖ Automatic |\n| Dead Letter | ‚ùå No | ‚úÖ Yes |\n| Setup Complexity | ‚úÖ None | ‚ö†Ô∏è Infrastructure required |\nWhen to Use Each:\n| Scenario | Transport |\n|----------|-----------|\n| Unit/Integration Tests | In-Memory |\n| Single-Process App | In-Memory |\n| Distributed Services | Azure Service Bus |\n| High Availability | Azure Service Bus |\n| Local Development | In-Memory |\n| Production Multi-Service | Azure Service Bus |\n---\nTesting Patterns\nUnit Testing Receptors\n`csharp\n[Test]\npublic async Task OrderReceptor_CreateOrder_PublishesOrderCreatedAsync() {\n  // Arrange\n  var transport = new InProcessTransport();\n  var receptor = new OrderReceptor(transport);\n  IMessageEnvelope publishedEvent = null;\n  await transport",
        "startIndex": 10789,
        "preview": "propagates to PublishAsync caller Subsequent handlers may not execute (depends on exception handling) No retry - caller must handle retry logic Cancel..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-6",
        "text": "| Azure Service Bus | | Local Development | In-Memory | | Production Multi-Service | Azure Service Bus | --- Testing Patterns Unit Testing Receptors `csharp [Test] public async Task OrderReceptor_CreateOrder_PublishesOrderCreatedAsync() { // Arrange var transport = new InProcessTransport(); var receptor = new OrderReceptor(transport); IMessageEnvelope publishedEvent = null; await transport SubscribeAsync(\n    handler: (envelope, ct) => {\n      publishedEvent = envelope;\n      return Task CompletedTask;\n    },\n    destination: new TransportDestination(\"order-events\")\n  );\n  var command = new CreateOrder(orderId, customerId, items);\n  // Act\n  var result = await receptor HandleAsync(command);\n  // Assert\n  await Assert That(publishedEvent) IsNotNull();\n  await Assert That(publishedEvent Payload) IsOfType<OrderCreated>();\n}\n`\nTesting Message Flows\n`csharp\n[Test]\npublic async Task OrderFlow_CreateAndShip_FullMessageChainAsync() {\n  // Arrange\n  var transport = new InProcessTransport();\n  // Setup receptors\n  var orderReceptor = new OrderReceptor(transport);\n  var inventoryReceptor = new InventoryReceptor(transport);\n  var shippingReceptor = new ShippingReceptor(transport);\n  // Subscribe to each stage\n  await transport SubscribeAsync(\n    handler: (env, ct) => inventoryReceptor HandleAsync(env Payload as OrderCreated),\n    destination: new TransportDestination(\"inventory\")\n  );\n  await transport SubscribeAsync(\n    handler: (env, ct) => shippingReceptor HandleAsync(env Payload as InventoryReserved),\n    destination: new TransportDestination(\"shipping\")\n  );\n  // Act - Trigger flow\n  var command = new CreateOrder(orderId, customerId, items);\n  await orderReceptor HandleAsync(command);\n  // Assert - Verify all stages completed\n  var order = await _orderRepository GetAsync(orderId);\n  await Assert That(order Status) IsEqualTo(OrderStatus Shipped);\n}\n`\nTesting with IDispatcher\n`csharp\n[Test]\npublic async Task MessageFlow_ViaDispatcher_RoutesToCorrectReceptorAsync() {\n  // Arrange\n  var serviceProvider = BuildServiceProvider();  // Includes receptors\n  var dispatcher = serviceProvider GetRequiredService<IDispatcher>();\n  var transport = serviceProvider GetRequiredService<ITransport>() as InProcessTransport;\n  // Subscribe dispatcher to transport\n  await transport SubscribeAsync(\n    handler: async (envelope, ct) => {\n      await dispatcher LocalInvokeAsync(envelope Payload, ct);\n    },\n    destination: new TransportDestination(\"messages\")\n  );\n  // Act - Publish command\n  var command = new CreateOrder(orderId, customerId, items);\n  var envelope = MessageEnvelope Create(\n    MessageId New(), CorrelationId New(), null,\n    command,\n    new MessageHop { Timestamp = DateTimeOffset UtcNow }\n  );\n  await transport",
        "startIndex": 12354,
        "preview": "| Azure Service Bus | | Local Development | In-Memory | | Production Multi-Service | Azure Service Bus | --- Testing Patterns Unit Testing Receptors `..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-7",
        "text": "handler: async (envelope, ct) => { await dispatcher LocalInvokeAsync(envelope Payload, ct); }, destination: new TransportDestination(\"messages\") ); // Act - Publish command var command = new CreateOrder(orderId, customerId, items); var envelope = MessageEnvelope Create( MessageId New(), CorrelationId New(), null, command, new MessageHop { Timestamp = DateTimeOffset UtcNow } ); await transport PublishAsync(envelope, new TransportDestination(\"messages\"));\n  // Assert - Receptor invoked via dispatcher\n  var order = await _orderRepository GetAsync(orderId);\n  await Assert That(order) IsNotNull();\n}\n`\n---\nBest Practices\nDO ‚úÖ\n‚úÖ Use for unit and integration tests - Fastest, no infrastructure\n‚úÖ Dispose subscriptions when done - Prevent handler leaks\n‚úÖ Handle exceptions in handlers - Prevent propagation to publisher\n‚úÖ Use pause/resume for backpressure - Graceful flow control\n‚úÖ Test error paths - Verify exception handling\n‚úÖ Use for single-process apps - Simple modular architecture\nDON'T ‚ùå\n‚ùå Use for production distributed systems (use Azure Service Bus)\n‚ùå Rely on retry/dead-letter (not supported - handle manually)\n‚ùå Forget to dispose subscriptions (causes memory leaks)\n‚ùå Assume asynchronous delivery (handlers execute synchronously)\n‚ùå Use for cross-process communication (in-memory only)\n‚ùå Ignore handler exceptions (they propagate to publisher)\n---\nTroubleshooting\nProblem: Handler Not Invoked\nSymptoms: Published messages don't trigger handler Causes:\nDestination address mismatch\nSubscription paused or disposed\nHandler threw exception in previous call\nSolution:\n`csharp\n// Verify destination addresses match EXACTLY\nvar publishDest = new TransportDestination(\"orders\");\nvar subscribeDest = new TransportDestination(\"orders\");\n// Verify subscription is active\nvar subscription = await transport SubscribeAsync(handler, subscribeDest);\nConsole WriteLine(subscription IsActive);  // Should be true\n// Check for paused subscription\nawait subscription ResumeAsync();\n`\nProblem: SendAsync Hangs Forever\nSymptoms: SendAsync never returns, no timeout Cause: No responder subscribed to request destination Solution:\n`csharp\n// Always use timeout with SendAsync\nvar cts = new CancellationTokenSource(TimeSpan FromSeconds(30));\ntry {\n  var response = await transport SendAsync<TRequest, TResponse>(\n    requestEnvelope,\n    destination,\n    cts",
        "startIndex": 14712,
        "preview": "handler: async (envelope, ct) => { await dispatcher LocalInvokeAsync(envelope Payload, ct); }, destination: new TransportDestination(\"messages\") ); //..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-8",
        "text": "for paused subscription await subscription ResumeAsync(); ` Problem: SendAsync Hangs Forever Symptoms: SendAsync never returns, no timeout Cause: No responder subscribed to request destination Solution: `csharp // Always use timeout with SendAsync var cts = new CancellationTokenSource(TimeSpan FromSeconds(30)); try { var response = await transport SendAsync<TRequest, TResponse>( requestEnvelope, destination, cts Token  // ‚úÖ Timeout after 30 seconds\n  );\n} catch (OperationCanceledException) {\n  // No response received - handle timeout\n  Console WriteLine(\"Request timed out\");\n}\n`\nProblem: Memory Leak with Subscriptions\nSymptoms: Memory usage grows over time Cause: Subscriptions not disposed when no longer needed Solution:\n`csharp\n// Always dispose subscriptions\nvar subscription = await transport SubscribeAsync(handler, destination);\ntry {\n  // Use subscription } finally {\n  subscription Dispose();  // ‚úÖ Cleanup\n}\n// Or use IAsyncDisposable\nawait using var subscription = await transport SubscribeAsync(handler, destination);\n// Auto-disposed when out of scope\n`\nProblem: Concurrent Handler Execution\nSymptoms: Handlers execute in unpredictable order Cause: Multiple concurrent PublishAsync calls Clarification: This is expected behavior for concurrent publishes `csharp\n// Concurrent publishes ‚Üí concurrent handler execution\nawait Task WhenAll(\n  transport PublishAsync(envelope1, destination),  // Handler invoked\n  transport PublishAsync(envelope2, destination),  // Handler invoked concurrently\n  transport PublishAsync(envelope3, destination)   // Handler invoked concurrently\n);\n// Solution: If strict ordering required, publish sequentially\nawait transport PublishAsync(envelope1, destination);  // Completes before next\nawait transport PublishAsync(envelope2, destination);\nawait transport PublishAsync(envelope3, destination);\n`\n---\nAdvanced Patterns\nConditional Handler Execution\n`csharp\nawait transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    // Skip processing based on metadata\n    var hop = envelope Hops First();\n    if (hop ServiceInstance ServiceName == \"InventoryService\") {\n      return;  // Skip messages from InventoryService\n    }\n    await ProcessAsync(envelope);\n  },\n  destination: new TransportDestination(\"orders\")\n);\n`\nCircuit Breaker Pattern\n`csharp\nint failureCount = 0;\nconst int maxFailures = 3;\nvar subscription = await transport",
        "startIndex": 16665,
        "preview": "for paused subscription await subscription ResumeAsync(); ` Problem: SendAsync Hangs Forever Symptoms: SendAsync never returns, no timeout Cause: No r..."
      },
      {
        "id": "v0.1.0/transports/in-memory-chunk-9",
        "text": "processing based on metadata var hop = envelope Hops First(); if (hop ServiceInstance ServiceName == \"InventoryService\") { return; // Skip messages from InventoryService } await ProcessAsync(envelope); }, destination: new TransportDestination(\"orders\") ); ` Circuit Breaker Pattern `csharp int failureCount = 0; const int maxFailures = 3; var subscription = await transport SubscribeAsync(\n  handler: async (envelope, ct) => {\n    try {\n      await ProcessAsync(envelope);\n      failureCount = 0;  // Reset on success\n    } catch (Exception ex) {\n      failureCount++;\n      if (failureCount >= maxFailures) {\n        // Open circuit - pause subscription\n        await subscription PauseAsync();\n        Console WriteLine(\"Circuit opened - pausing subscription\");\n        // Schedule resume after cooldown\n        _ = Task Delay(TimeSpan FromMinutes(1)) ContinueWith(async _ => {\n            await subscription ResumeAsync();\n            failureCount = 0;\n            Console WriteLine(\"Circuit closed - resuming subscription\");\n          });\n      }\n      throw;  // Re-throw to propagate to publisher\n    }\n  },\n  destination: new TransportDestination(\"orders\")\n);\n`\nFan-Out Pattern\n`csharp\n// Single publisher, multiple subscribers (fan-out)\nvar transport = new InProcessTransport();\nvar destination = new TransportDestination(\"order-created\");\n// Subscribe multiple services\nawait transport SubscribeAsync(\n  handler: async (env, ct) => await _inventoryService ReserveStockAsync(env Payload),\n  destination: destination\n);\nawait transport SubscribeAsync(\n  handler: async (env, ct) => await _notificationService SendEmailAsync(env Payload),\n  destination: destination\n);\nawait transport SubscribeAsync(\n  handler: async (env, ct) => await _analyticsService TrackEventAsync(env Payload),\n  destination: destination\n);\n// Publish once - all three services invoked\nawait transport PublishAsync(orderCreatedEnvelope, destination);\n`\n---\nFurther Reading\nTransports:\nAzure Service Bus Transport - Distributed messaging for production\nMessaging Patterns:\nOutbox Pattern - Reliable event publishing (not needed for in-memory)\nInbox Pattern - Exactly-once processing (not needed for in-memory)\nTesting:\nTesting Receptors - Unit testing message handlers\nExtensibility:\nCustom Transports - Implementing custom transports\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 18650,
        "preview": "processing based on metadata var hop = envelope Hops First(); if (hop ServiceInstance ServiceName == \"InventoryService\") { return; // Skip messages fr..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/analytics-service",
    "title": "Analytics Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/analytics-service",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-0",
        "text": "Analytics Service\nBuild the Analytics Worker - a background service that subscribes to all domain events, aggregates metrics in real-time, and provides analytics dashboards :::note\nThis is Part 7 of the ECommerce Tutorial Complete Customer Service first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Analytics Service Architecture                              ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  ALL domain events                          ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ  (OrderCreated, PaymentProcessed, etc )     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îÇ\n‚îÇ         ‚îÇ                                                     ‚îÇ\n‚îÇ         ‚ñº                                                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ\n‚îÇ  ‚îÇ  Time-Series Perspectives          ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  - DailySalesAnalyticsPerspective  ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  - HourlySalesAnalyticsPerspective ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  - ProductAnalyticsPerspective     ‚îÇ                      ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ\n‚îÇ             ‚îÇ                                                 ‚îÇ\n‚îÇ             ‚ñº                                                 ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ\n‚îÇ  ‚îÇ  PostgreSQL Time-Series Tables     ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  (Partitioned by date)             ‚îÇ                      ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ\n‚îÇ             ‚îÇ                                                 ‚îÇ\n‚îÇ             ‚ñº                                                 ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ\n‚îÇ  ‚îÇ  Analytics API (REST)              ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  GET /analytics/sales/daily        ‚îÇ                      ‚îÇ\n‚îÇ  ‚îÇ  GET /analytics/products/top       ‚îÇ                      ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Real-time event aggregation\n‚úÖ Time-series perspectives (hourly, daily, monthly)\n‚úÖ Product performance analytics\n‚úÖ Customer cohort analysis\n‚úÖ Partitioned tables for performance\n‚úÖ Dashboard APIs\n---\nStep 1: Database Schema (Time-Series Tables)\nDaily Sales Analytics\nECommerce AnalyticsWorker/Database/Migrations/001_CreateDailySalesAnalyticsTable",
        "startIndex": 0,
        "preview": "Analytics Service\nBuild the Analytics Worker - a background service that subscribes to all domain events, aggregates metrics in real-time, and provide..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-1",
        "text": "‚îÇ ‚îÇ GET /analytics/products/top ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Features: ‚úÖ Real-time event aggregation ‚úÖ Time-series perspectives (hourly, daily, monthly) ‚úÖ Product performance analytics ‚úÖ Customer cohort analysis ‚úÖ Partitioned tables for performance ‚úÖ Dashboard APIs --- Step 1: Database Schema (Time-Series Tables) Daily Sales Analytics ECommerce AnalyticsWorker/Database/Migrations/001_CreateDailySalesAnalyticsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS daily_sales_analytics (\n  date DATE NOT NULL,\n  total_orders BIGINT NOT NULL DEFAULT 0,\n  total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0,\n  total_items_sold BIGINT NOT NULL DEFAULT 0,\n  avg_order_value NUMERIC(10, 2) NOT NULL DEFAULT 0,\n  unique_customers BIGINT NOT NULL DEFAULT 0,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  PRIMARY KEY (date)\n) PARTITION BY RANGE (date);\n-- Create partitions for current and next year\nCREATE TABLE daily_sales_analytics_2024 PARTITION OF daily_sales_analytics\n  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\nCREATE TABLE daily_sales_analytics_2025 PARTITION OF daily_sales_analytics\n  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');\nCREATE INDEX idx_daily_sales_date ON daily_sales_analytics(date DESC);\n`\nHourly Sales Analytics\nECommerce AnalyticsWorker/Database/Migrations/002_CreateHourlySalesAnalyticsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS hourly_sales_analytics (\n  hour TIMESTAMP NOT NULL,  -- Truncated to hour (e g , 2024-12-12 10:00:00)\n  total_orders BIGINT NOT NULL DEFAULT 0,\n  total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  PRIMARY KEY (hour)\n);\nCREATE INDEX idx_hourly_sales_hour ON hourly_sales_analytics(hour DESC);\n`\nProduct Analytics\nECommerce AnalyticsWorker/Database/Migrations/003_CreateProductAnalyticsTable",
        "startIndex": 2536,
        "preview": "‚îÇ ‚îÇ GET /analytics/products/top ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Feat..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-2",
        "text": "NULL, -- Truncated to hour (e g , 2024-12-12 10:00:00) total_orders BIGINT NOT NULL DEFAULT 0, total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0, created_at TIMESTAMP NOT NULL DEFAULT NOW(), updated_at TIMESTAMP NOT NULL DEFAULT NOW(), PRIMARY KEY (hour) ); CREATE INDEX idx_hourly_sales_hour ON hourly_sales_analytics(hour DESC); ` Product Analytics ECommerce AnalyticsWorker/Database/Migrations/003_CreateProductAnalyticsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS product_analytics (\n  product_id TEXT NOT NULL,\n  date DATE NOT NULL,\n  times_ordered BIGINT NOT NULL DEFAULT 0,\n  units_sold BIGINT NOT NULL DEFAULT 0,\n  total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  PRIMARY KEY (product_id, date)\n) PARTITION BY RANGE (date);\n-- Create partitions\nCREATE TABLE product_analytics_2024 PARTITION OF product_analytics\n  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\nCREATE TABLE product_analytics_2025 PARTITION OF product_analytics\n  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');\nCREATE INDEX idx_product_analytics_product_date ON product_analytics(product_id, date DESC);\nCREATE INDEX idx_product_analytics_revenue ON product_analytics(total_revenue DESC);\n`\n---\nStep 2: Perspectives\nDaily Sales Analytics Perspective\nECommerce AnalyticsWorker/Perspectives/DailySalesAnalyticsPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce AnalyticsWorker Perspectives;\npublic class DailySalesAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<DailySalesAnalyticsPerspective> _logger;\n  public DailySalesAnalyticsPerspective(\n    NpgsqlConnection db,\n    ILogger<DailySalesAnalyticsPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    var date = @event CreatedAt Date;\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO daily_sales_analytics (\n        date, total_orders, total_revenue, total_items_sold, avg_order_value, unique_customers, updated_at\n      )\n      VALUES (@Date, 1, @TotalAmount, @ItemCount, @TotalAmount, 1, NOW())\n      ON CONFLICT (date) DO UPDATE SET\n        total_orders = daily_sales_analytics total_orders + 1,\n        total_revenue = daily_sales_analytics total_revenue + @TotalAmount,\n        total_items_sold = daily_sales_analytics total_items_sold + @ItemCount,\n        avg_order_value = (daily_sales_analytics total_revenue + @TotalAmount) / (daily_sales_analytics total_orders + 1),\n        updated_at = NOW()\n      \"\"\",\n      new {\n        Date = date,\n        TotalAmount = @event TotalAmount,\n        ItemCount = @event Items",
        "startIndex": 4001,
        "preview": "NULL, -- Truncated to hour (e g , 2024-12-12 10:00:00) total_orders BIGINT NOT NULL DEFAULT 0, total_revenue NUMERIC(12, 2) NOT NULL DEFAULT 0, create..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-3",
        "text": "(date) DO UPDATE SET total_orders = daily_sales_analytics total_orders + 1, total_revenue = daily_sales_analytics total_revenue + @TotalAmount, total_items_sold = daily_sales_analytics total_items_sold + @ItemCount, avg_order_value = (daily_sales_analytics total_revenue + @TotalAmount) / (daily_sales_analytics total_orders + 1), updated_at = NOW() \"\"\", new { Date = date, TotalAmount = @event TotalAmount, ItemCount = @event Items Sum(i => i Quantity)\n      }\n    );\n    _logger LogInformation(\n      \"Daily sales analytics updated for {Date}: +${Amount}\",\n      date,\n      @event TotalAmount\n    );\n  }\n}\n`\nHourly Sales Analytics Perspective\nECommerce AnalyticsWorker/Perspectives/HourlySalesAnalyticsPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce AnalyticsWorker Perspectives;\npublic class HourlySalesAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<HourlySalesAnalyticsPerspective> _logger;\n  public HourlySalesAnalyticsPerspective(\n    NpgsqlConnection db,\n    ILogger<HourlySalesAnalyticsPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    // Truncate to hour (e g , 2024-12-12 10:00:00)\n    var hour = new DateTime(\n      @event CreatedAt Year,\n      @event CreatedAt Month,\n      @event CreatedAt Day,\n      @event CreatedAt Hour,\n      0,\n      0\n    );\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO hourly_sales_analytics (hour, total_orders, total_revenue, updated_at)\n      VALUES (@Hour, 1, @TotalAmount, NOW())\n      ON CONFLICT (hour) DO UPDATE SET\n        total_orders = hourly_sales_analytics total_orders + 1,\n        total_revenue = hourly_sales_analytics total_revenue + @TotalAmount,\n        updated_at = NOW()\n      \"\"\",\n      new {\n        Hour = hour,\n        TotalAmount = @event TotalAmount\n      }\n    );\n    _logger LogInformation(\n      \"Hourly sales analytics updated for {Hour}: +${Amount}\",\n      hour,\n      @event TotalAmount\n    );\n  }\n}\n`\nProduct Analytics Perspective\nECommerce AnalyticsWorker/Perspectives/ProductAnalyticsPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce AnalyticsWorker Perspectives;\npublic class ProductAnalyticsPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<ProductAnalyticsPerspective> _logger;\n  public ProductAnalyticsPerspective(\n    NpgsqlConnection db,\n    ILogger<ProductAnalyticsPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    var date = @event CreatedAt",
        "startIndex": 6393,
        "preview": "(date) DO UPDATE SET total_orders = daily_sales_analytics total_orders + 1, total_revenue = daily_sales_analytics total_revenue + @TotalAmount, total_..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-4",
        "text": "namespace ECommerce AnalyticsWorker Perspectives; public class ProductAnalyticsPerspective : IPerspectiveOf<OrderCreated> { private readonly NpgsqlConnection _db; private readonly ILogger<ProductAnalyticsPerspective> _logger; public ProductAnalyticsPerspective( NpgsqlConnection db, ILogger<ProductAnalyticsPerspective> logger ) { _db = db; _logger = logger; } public async Task HandleAsync( OrderCreated @event, CancellationToken ct = default ) { var date = @event CreatedAt Date;\n    // Update analytics for each product in the order\n    foreach (var item in @event Items) {\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO product_analytics (\n          product_id, date, times_ordered, units_sold, total_revenue, updated_at\n        )\n        VALUES (@ProductId, @Date, 1, @Quantity, @LineTotal, NOW())\n        ON CONFLICT (product_id, date) DO UPDATE SET\n          times_ordered = product_analytics times_ordered + 1,\n          units_sold = product_analytics units_sold + @Quantity,\n          total_revenue = product_analytics total_revenue + @LineTotal,\n          updated_at = NOW()\n        \"\"\",\n        new {\n          ProductId = item ProductId,\n          Date = date,\n          Quantity = item Quantity,\n          LineTotal = item LineTotal\n        }\n      );\n      _logger LogInformation(\n        \"Product analytics updated for {ProductId} on {Date}: +{Quantity} units, +${LineTotal}\",\n        item ProductId,\n        date,\n        item Quantity,\n        item LineTotal\n      );\n    }\n  }\n}\n`\n---\nStep 3: Analytics API\nDTOs\nECommerce AnalyticsWorker/Models/DailySalesDto cs:\n`csharp\nnamespace ECommerce AnalyticsWorker Models;\npublic record DailySalesDto(\n  DateTime Date,\n  long TotalOrders,\n  decimal TotalRevenue,\n  long TotalItemsSold,\n  decimal AvgOrderValue,\n  long UniqueCustomers\n);\n`\nECommerce AnalyticsWorker/Models/ProductPerformanceDto cs:\n`csharp\nnamespace ECommerce AnalyticsWorker Models;\npublic record ProductPerformanceDto(\n  string ProductId,\n  long TimesOrdered,\n  long UnitsSold,\n  decimal TotalRevenue,\n  decimal AvgRevenuePerOrder\n);\n`\nControllers\nECommerce AnalyticsWorker/Controllers/AnalyticsController cs:\n`csharp\nusing Microsoft AspNetCore Mvc;\nusing Npgsql;\nusing Dapper;\nusing ECommerce AnalyticsWorker Models;\nnamespace ECommerce AnalyticsWorker Controllers;\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class AnalyticsController : ControllerBase {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<AnalyticsController> _logger;\n  public AnalyticsController(\n    NpgsqlConnection db,\n    ILogger<AnalyticsController> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  [HttpGet(\"sales/daily\")]\n  [ProducesResponseType(typeof(DailySalesDto[]), StatusCodes Status200OK)]\n  public async Task<IActionResult> GetDailySales(\n    [FromQuery] DateTime startDate = null,\n    [FromQuery] DateTime endDate = null\n  ) {\n    var start = startDate DateTime UtcNow AddDays(-30) Date;\n    var end = endDate DateTime",
        "startIndex": 8827,
        "preview": "namespace ECommerce AnalyticsWorker Perspectives; public class ProductAnalyticsPerspective : IPerspectiveOf<OrderCreated> { private readonly NpgsqlCon..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-5",
        "text": "ILogger<AnalyticsController> _logger; public AnalyticsController( NpgsqlConnection db, ILogger<AnalyticsController> logger ) { _db = db; _logger = logger; } [HttpGet(\"sales/daily\")] [ProducesResponseType(typeof(DailySalesDto[]), StatusCodes Status200OK)] public async Task<IActionResult> GetDailySales( [FromQuery] DateTime startDate = null, [FromQuery] DateTime endDate = null ) { var start = startDate DateTime UtcNow AddDays(-30) Date; var end = endDate DateTime UtcNow Date;\n    var sales = await _db QueryAsync<DailySalesRow>(\n      \"\"\"\n      SELECT date, total_orders, total_revenue, total_items_sold, avg_order_value, unique_customers\n      FROM daily_sales_analytics\n      WHERE date >= @StartDate AND date <= @EndDate\n      ORDER BY date DESC\n      \"\"\",\n      new { StartDate = start, EndDate = end }\n    );\n    var dtos = sales Select(s => new DailySalesDto(\n      Date: s Date,\n      TotalOrders: s TotalOrders,\n      TotalRevenue: s TotalRevenue,\n      TotalItemsSold: s TotalItemsSold,\n      AvgOrderValue: s AvgOrderValue,\n      UniqueCustomers: s UniqueCustomers\n    )) ToArray();\n    return Ok(dtos);\n  }\n  [HttpGet(\"sales/hourly\")]\n  [ProducesResponseType(typeof(HourlySalesDto[]), StatusCodes Status200OK)]\n  public async Task<IActionResult> GetHourlySales(\n    [FromQuery] DateTime date = null\n  ) {\n    var targetDate = date DateTime UtcNow Date;\n    var startHour = targetDate;\n    var endHour = targetDate AddDays(1);\n    var sales = await _db QueryAsync<HourlySalesRow>(\n      \"\"\"\n      SELECT hour, total_orders, total_revenue\n      FROM hourly_sales_analytics\n      WHERE hour >= @StartHour AND hour < @EndHour\n      ORDER BY hour ASC\n      \"\"\",\n      new { StartHour = startHour, EndHour = endHour }\n    );\n    var dtos = sales Select(s => new HourlySalesDto(\n      Hour: s Hour,\n      TotalOrders: s TotalOrders,\n      TotalRevenue: s TotalRevenue\n    )) ToArray();\n    return Ok(dtos);\n  }\n  [HttpGet(\"products/top\")]\n  [ProducesResponseType(typeof(ProductPerformanceDto[]), StatusCodes Status200OK)]\n  public async Task<IActionResult> GetTopProducts(\n    [FromQuery] DateTime startDate = null,\n    [FromQuery] DateTime endDate = null,\n    [FromQuery] int limit = 10\n  ) {\n    var start = startDate DateTime UtcNow AddDays(-30) Date;\n    var end = endDate DateTime UtcNow Date;\n    var products = await _db",
        "startIndex": 11277,
        "preview": "ILogger<AnalyticsController> _logger; public AnalyticsController( NpgsqlConnection db, ILogger<AnalyticsController> logger ) { _db = db; _logger = log..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-6",
        "text": ")) ToArray(); return Ok(dtos); } [HttpGet(\"products/top\")] [ProducesResponseType(typeof(ProductPerformanceDto[]), StatusCodes Status200OK)] public async Task<IActionResult> GetTopProducts( [FromQuery] DateTime startDate = null, [FromQuery] DateTime endDate = null, [FromQuery] int limit = 10 ) { var start = startDate DateTime UtcNow AddDays(-30) Date; var end = endDate DateTime UtcNow Date; var products = await _db QueryAsync<ProductAnalyticsRow>(\n      \"\"\"\n      SELECT\n        product_id,\n        SUM(times_ordered) AS times_ordered,\n        SUM(units_sold) AS units_sold,\n        SUM(total_revenue) AS total_revenue\n      FROM product_analytics\n      WHERE date >= @StartDate AND date <= @EndDate\n      GROUP BY product_id\n      ORDER BY total_revenue DESC\n      LIMIT @Limit\n      \"\"\",\n      new { StartDate = start, EndDate = end, Limit = limit }\n    );\n    var dtos = products Select(p => new ProductPerformanceDto(\n      ProductId: p ProductId,\n      TimesOrdered: p TimesOrdered,\n      UnitsSold: p UnitsSold,\n      TotalRevenue: p TotalRevenue,\n      AvgRevenuePerOrder: p TimesOrdered > 0 p TotalRevenue / p TimesOrdered : 0\n    )) ToArray();\n    return Ok(dtos);\n  }\n}\npublic record DailySalesRow(\n  DateTime Date,\n  long TotalOrders,\n  decimal TotalRevenue,\n  long TotalItemsSold,\n  decimal AvgOrderValue,\n  long UniqueCustomers\n);\npublic record HourlySalesDto(\n  DateTime Hour,\n  long TotalOrders,\n  decimal TotalRevenue\n);\npublic record HourlySalesRow(\n  DateTime Hour,\n  long TotalOrders,\n  decimal TotalRevenue\n);\npublic record ProductAnalyticsRow(\n  string ProductId,\n  long TimesOrdered,\n  long UnitsSold,\n  decimal TotalRevenue\n);\n`\n---\nStep 4: Service Configuration\nECommerce AnalyticsWorker/Program cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Npgsql;\nvar builder = WebApplication CreateBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"AnalyticsWorker\";\n  options EnableInbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"AnalyticsDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Add controllers\nbuilder Services AddControllers();\nbuilder Services AddEndpointsApiExplorer();\nbuilder Services AddSwaggerGen();\nvar app = builder Build();\nif (app Environment IsDevelopment()) {\n  app UseSwagger();\n  app UseSwaggerUI();\n}\napp UseHttpsRedirection();\napp UseAuthorization();\napp MapControllers();\nawait app MigrateDatabaseAsync();\napp",
        "startIndex": 13218,
        "preview": ")) ToArray(); return Ok(dtos); } [HttpGet(\"products/top\")] [ProducesResponseType(typeof(ProductPerformanceDto[]), StatusCodes Status200OK)] public asy..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-7",
        "text": "return new NpgsqlConnection(connectionString); }); // 3 Add Azure Service Bus builder AddAzureServiceBus(\"messaging\"); // 4 Add controllers builder Services AddControllers(); builder Services AddEndpointsApiExplorer(); builder Services AddSwaggerGen(); var app = builder Build(); if (app Environment IsDevelopment()) { app UseSwagger(); app UseSwaggerUI(); } app UseHttpsRedirection(); app UseAuthorization(); app MapControllers(); await app MigrateDatabaseAsync(); app Run();\n`\n---\nStep 5: Test Analytics\nCreate Orders (Generate Data)\n`bash\nCreate 10 orders\nfor i in {1 10}; do\n  curl -X POST http://localhost:5000/api/orders \\\n    -H \"Content-Type: application/json\" \\\n    -d '{ \"customerId\": \"cust-'$i'\", }'\n  sleep 1\ndone\n`\nQuery Daily Sales\n`bash\ncurl \"http://localhost:5002/api/analytics/sales/daily startDate=2024-12-01&endDate=2024-12-31\"\n`\nResponse:\n`json\n[\n  {\n    \"date\": \"2024-12-12\",\n    \"totalOrders\": 10,\n    \"totalRevenue\": 399 80,\n    \"totalItemsSold\": 20,\n    \"avgOrderValue\": 39 98,\n    \"uniqueCustomers\": 10\n  }\n]\n`\nQuery Hourly Sales\n`bash\ncurl \"http://localhost:5002/api/analytics/sales/hourly date=2024-12-12\"\n`\nResponse:\n`json\n[\n  { \"hour\": \"2024-12-12T10:00:00Z\", \"totalOrders\": 3, \"totalRevenue\": 119 94 },\n  { \"hour\": \"2024-12-12T11:00:00Z\", \"totalOrders\": 5, \"totalRevenue\": 199 90 },\n  { \"hour\": \"2024-12-12T12:00:00Z\", \"totalOrders\": 2, \"totalRevenue\": 79 96 }\n]\n`\nQuery Top Products\n`bash\ncurl \"http://localhost:5002/api/analytics/products/top limit=5\"\n`\nResponse:\n`json\n[\n  {\n    \"productId\": \"prod-456\",\n    \"timesOrdered\": 8,\n    \"unitsSold\": 16,\n    \"totalRevenue\": 319 84,\n    \"avgRevenuePerOrder\": 39 98\n  },\n  {\n    \"productId\": \"prod-789\",\n    \"timesOrdered\": 2,\n    \"unitsSold\": 2,\n    \"totalRevenue\": 99 98,\n    \"avgRevenuePerOrder\": 49 99\n  }\n]\n`\n---\nKey Concepts\nTime-Series Perspectives\n`csharp\n// Truncate timestamp to hour for hourly aggregation\nvar hour = new DateTime(\n  @event CreatedAt Year,\n  @event CreatedAt Month,\n  @event CreatedAt Day,\n  @event CreatedAt Hour,\n  0,\n  0\n);\n// Upsert with aggregation\nINSERT INTO hourly_sales_analytics (hour, total_orders, total_revenue)\nVALUES (@Hour, 1, @TotalAmount)\nON CONFLICT (hour) DO UPDATE SET\n  total_orders = hourly_sales_analytics total_orders + 1,\n  total_revenue = hourly_sales_analytics total_revenue + @TotalAmount\n`\nResult: Real-time hourly metrics without batch processing Partitioned Tables\n`sql\nCREATE TABLE daily_sales_analytics (",
        "startIndex": 15468,
        "preview": "return new NpgsqlConnection(connectionString); }); // 3 Add Azure Service Bus builder AddAzureServiceBus(\"messaging\"); // 4 Add controllers builder Se..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-8",
        "text": "0, 0 ); // Upsert with aggregation INSERT INTO hourly_sales_analytics (hour, total_orders, total_revenue) VALUES (@Hour, 1, @TotalAmount) ON CONFLICT (hour) DO UPDATE SET total_orders = hourly_sales_analytics total_orders + 1, total_revenue = hourly_sales_analytics total_revenue + @TotalAmount ` Result: Real-time hourly metrics without batch processing Partitioned Tables `sql CREATE TABLE daily_sales_analytics ( )\nPARTITION BY RANGE (date);\n-- Separate physical tables per year\nCREATE TABLE daily_sales_analytics_2024 PARTITION OF daily_sales_analytics\n  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\n`\nBenefits:\n‚úÖ Performance: Queries only scan relevant partitions\n‚úÖ Maintenance: Drop old partitions easily (e g , GDPR retention)\n‚úÖ Scalability: Add future partitions dynamically\n---\nAdvanced: Materialized Views\nFor complex aggregations, use materialized views:\nECommerce AnalyticsWorker/Database/Migrations/004_CreateMaterializedViews sql:\n`sql\nCREATE MATERIALIZED VIEW monthly_sales_summary AS\nSELECT\n  DATE_TRUNC('month', date) AS month,\n  SUM(total_orders) AS total_orders,\n  SUM(total_revenue) AS total_revenue,\n  AVG(avg_order_value) AS avg_order_value\nFROM daily_sales_analytics\nGROUP BY DATE_TRUNC('month', date)\nORDER BY month DESC;\nCREATE UNIQUE INDEX idx_monthly_sales_month ON monthly_sales_summary(month);\n-- Refresh monthly (can be automated via background job)\nREFRESH MATERIALIZED VIEW CONCURRENTLY monthly_sales_summary;\n`\n---\nTesting\nUnit Test - Daily Sales Perspective\n`csharp\n[Test]\npublic async Task DailySalesPerspective_OrderCreated_UpdatesDailySalesAsync() {\n  // Arrange\n  var db = new MockNpgsqlConnection();\n  var perspective = new DailySalesAnalyticsPerspective(db, mockLogger);\n  var @event = new OrderCreated(\n    OrderId: \"order-123\",\n    CustomerId: \"cust-456\",\n    Items: [new OrderItem(\"prod-789\", 2, 19 99m, 39 98m)],\n    TotalAmount: 39 98m,\n    CreatedAt: new DateTime(2024, 12, 12, 10, 30, 0)\n    // other fields\n  );\n  // Act\n  await perspective HandleAsync(@event);\n  // Assert\n  var sales = db GetDailySales(new DateTime(2024, 12, 12));\n  await Assert That(sales TotalOrders) IsEqualTo(1);\n  await Assert That(sales TotalRevenue) IsEqualTo(39",
        "startIndex": 17447,
        "preview": "0, 0 ); // Upsert with aggregation INSERT INTO hourly_sales_analytics (hour, total_orders, total_revenue) VALUES (@Hour, 1, @TotalAmount) ON CONFLICT ..."
      },
      {
        "id": "v0.1.0/tutorial/analytics-service-chunk-9",
        "text": "CustomerId: \"cust-456\", Items: [new OrderItem(\"prod-789\", 2, 19 99m, 39 98m)], TotalAmount: 39 98m, CreatedAt: new DateTime(2024, 12, 12, 10, 30, 0) // other fields ); // Act await perspective HandleAsync(@event); // Assert var sales = db GetDailySales(new DateTime(2024, 12, 12)); await Assert That(sales TotalOrders) IsEqualTo(1); await Assert That(sales TotalRevenue) IsEqualTo(39 98m);\n}\n`\n---\nNext Steps\nContinue to Testing Strategy to:\nWrite unit tests for receptors and perspectives\nImplement integration tests for event flows\nCreate end-to-end tests for full order lifecycle\nSet up test fixtures and mocks\n---\nKey Takeaways\n‚úÖ Time-Series Perspectives - Real-time aggregation with hour/day truncation\n‚úÖ Partitioned Tables - Performance optimization for large datasets\n‚úÖ Event Aggregation - Single perspective handles all analytics\n‚úÖ Dashboard APIs - REST endpoints for frontend dashboards\n‚úÖ Materialized Views - Pre-computed complex aggregations\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 19228,
        "preview": "CustomerId: \"cust-456\", Items: [new OrderItem(\"prod-789\", 2, 19 99m, 39 98m)], TotalAmount: 39 98m, CreatedAt: new DateTime(2024, 12, 12, 10, 30, 0) /..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/customer-service",
    "title": "Customer Service (BFF)",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/customer-service",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-0",
        "text": "Customer Service (BFF)\nBuild the Customer Service - a Backend for Frontend (BFF) API that provides denormalized read models via Perspectives, demonstrating the query side of CQRS :::note\nThis is Part 6 of the ECommerce Tutorial Complete Shipping Service first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Customer Service Architecture (BFF)                         ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  OrderCreated, PaymentProcessed, etc ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ                  ‚îÇ\n‚îÇ                                            ‚ñº                  ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n‚îÇ                          ‚îÇ  Perspectives (Event       ‚îÇ      ‚îÇ\n‚îÇ                          ‚îÇ  Handlers for Read Models) ‚îÇ      ‚îÇ\n‚îÇ                          ‚îÇ  - OrderSummaryPerspective ‚îÇ      ‚îÇ\n‚îÇ                          ‚îÇ  - CustomerActivityPersp ‚îÇ      ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n‚îÇ                                     ‚îÇ                         ‚îÇ\n‚îÇ                                     ‚ñº                         ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ\n‚îÇ                          ‚îÇ  PostgreSQL Read Models‚îÇ          ‚îÇ\n‚îÇ                          ‚îÇ  (Denormalized Views)  ‚îÇ          ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ\n‚îÇ                                     ‚îÇ                         ‚îÇ\n‚îÇ                                     ‚ñº                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ\n‚îÇ  ‚îÇ  HTTP Client ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  HTTP API (REST)       ‚îÇ          ‚îÇ\n‚îÇ  ‚îÇ  (Frontend)  ‚îÇ        ‚îÇ  GET /customers/{id}   ‚îÇ          ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ  GET /orders/{id}      ‚îÇ          ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Perspectives (event-driven read models)\n‚úÖ Denormalized views (fast queries)\n‚úÖ CQRS query side\n‚úÖ BFF pattern (tailored to frontend needs)\n‚úÖ REST API with rich DTOs\n‚úÖ Event sourcing with time-travel queries\n---\nStep 1: Database Schema (Read Models)\nOrder Summary View\nECommerce CustomerService API/Database/Migrations/001_CreateOrderSummaryTable",
        "startIndex": 0,
        "preview": "Customer Service (BFF)\nBuild the Customer Service - a Backend for Frontend (BFF) API that provides denormalized read models via Perspectives, demonstr..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-1",
        "text": "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Features: ‚úÖ Perspectives (event-driven read models) ‚úÖ Denormalized views (fast queries) ‚úÖ CQRS query side ‚úÖ BFF pattern (tailored to frontend needs) ‚úÖ REST API with rich DTOs ‚úÖ Event sourcing with time-travel queries --- Step 1: Database Schema (Read Models) Order Summary View ECommerce CustomerService API/Database/Migrations/001_CreateOrderSummaryTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS order_summary (\n  order_id TEXT PRIMARY KEY,\n  customer_id TEXT NOT NULL,\n  total_amount NUMERIC(10, 2) NOT NULL,\n  status TEXT NOT NULL,  -- 'Pending', 'PaymentProcessed', 'Shipped', 'Delivered', 'Cancelled'\n  item_count INTEGER NOT NULL,\n  shipping_address JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL,\n  payment_id TEXT,\n  payment_status TEXT,\n  payment_processed_at TIMESTAMP,\n  shipment_id TEXT,\n  tracking_number TEXT,\n  estimated_delivery TIMESTAMP,\n  actual_delivery TIMESTAMP,\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_order_summary_customer_id ON order_summary(customer_id);\nCREATE INDEX idx_order_summary_status ON order_summary(status);\nCREATE INDEX idx_order_summary_created_at ON order_summary(created_at DESC);\n`\nCustomer Activity View\nECommerce CustomerService API/Database/Migrations/002_CreateCustomerActivityTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS customer_activity (\n  customer_id TEXT PRIMARY KEY,\n  total_orders INTEGER NOT NULL DEFAULT 0,\n  total_spent NUMERIC(10, 2) NOT NULL DEFAULT 0,\n  last_order_id TEXT,\n  last_order_at TIMESTAMP,\n  first_order_at TIMESTAMP,\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_customer_activity_total_spent ON customer_activity(total_spent DESC);\nCREATE INDEX idx_customer_activity_last_order_at ON customer_activity(last_order_at DESC);\n`\n---\nStep 2: Perspectives\nOrder Summary Perspective\nECommerce CustomerService API/Perspectives/OrderSummaryPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce CustomerService API Perspectives;\npublic class OrderSummaryPerspective :\n  IPerspectiveOf<OrderCreated>,\n  IPerspectiveOf<PaymentProcessed>,\n  IPerspectiveOf<ShipmentCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<OrderSummaryPerspective> _logger;\n  public OrderSummaryPerspective(\n    NpgsqlConnection db,\n    ILogger<OrderSummaryPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  // Handle OrderCreated event\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    await _db",
        "startIndex": 2475,
        "preview": "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Features: ‚úÖ Perspectives (event-driven read models) ‚úÖ Denormalized views (fast qu..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-2",
        "text": "Perspectives; public class OrderSummaryPerspective : IPerspectiveOf<OrderCreated>, IPerspectiveOf<PaymentProcessed>, IPerspectiveOf<ShipmentCreated> { private readonly NpgsqlConnection _db; private readonly ILogger<OrderSummaryPerspective> _logger; public OrderSummaryPerspective( NpgsqlConnection db, ILogger<OrderSummaryPerspective> logger ) { _db = db; _logger = logger; } // Handle OrderCreated event public async Task HandleAsync( OrderCreated @event, CancellationToken ct = default ) { await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO order_summary (\n        order_id, customer_id, total_amount, status, item_count, shipping_address, created_at, updated_at\n      )\n      VALUES (@OrderId, @CustomerId, @TotalAmount, @Status, @ItemCount, @ShippingAddress::jsonb, @CreatedAt, NOW())\n      ON CONFLICT (order_id) DO UPDATE SET\n        updated_at = NOW()\n      \"\"\",\n      new {\n        OrderId = @event OrderId,\n        CustomerId = @event CustomerId,\n        TotalAmount = @event TotalAmount,\n        Status = \"Pending\",\n        ItemCount = @event Items Length,\n        ShippingAddress = System Text Json JsonSerializer Serialize(@event ShippingAddress),\n        CreatedAt = @event CreatedAt\n      }\n    );\n    _logger LogInformation(\n      \"Order summary created for order {OrderId}\",\n      @event OrderId\n    );\n  }\n  // Handle PaymentProcessed event\n  public async Task HandleAsync(\n    PaymentProcessed @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE order_summary\n      SET\n        status = 'PaymentProcessed',\n        payment_id = @PaymentId,\n        payment_status = @PaymentStatus,\n        payment_processed_at = @ProcessedAt,\n        updated_at = NOW()\n      WHERE order_id = @OrderId\n      \"\"\",\n      new {\n        OrderId = @event OrderId,\n        PaymentId = @event PaymentId,\n        PaymentStatus = @event Status ToString(),\n        ProcessedAt = @event ProcessedAt\n      }\n    );\n    _logger LogInformation(\n      \"Order summary updated with payment for order {OrderId}\",\n      @event OrderId\n    );\n  }\n  // Handle ShipmentCreated event\n  public async Task HandleAsync(\n    ShipmentCreated @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      UPDATE order_summary\n      SET\n        status = 'Shipped',\n        shipment_id = @ShipmentId,\n        tracking_number = @TrackingNumber,\n        estimated_delivery = @EstimatedDelivery,\n        updated_at = NOW()\n      WHERE order_id = @OrderId\n      \"\"\",\n      new {\n        OrderId = @event OrderId,\n        ShipmentId = @event ShipmentId,\n        TrackingNumber = @event TrackingNumber,\n        EstimatedDelivery = @event EstimatedDelivery\n      }\n    );\n    _logger LogInformation(\n      \"Order summary updated with shipment for order {OrderId}\",\n      @event",
        "startIndex": 4664,
        "preview": "Perspectives; public class OrderSummaryPerspective : IPerspectiveOf<OrderCreated>, IPerspectiveOf<PaymentProcessed>, IPerspectiveOf<ShipmentCreated> {..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-3",
        "text": "= 'Shipped', shipment_id = @ShipmentId, tracking_number = @TrackingNumber, estimated_delivery = @EstimatedDelivery, updated_at = NOW() WHERE order_id = @OrderId \"\"\", new { OrderId = @event OrderId, ShipmentId = @event ShipmentId, TrackingNumber = @event TrackingNumber, EstimatedDelivery = @event EstimatedDelivery } ); _logger LogInformation( \"Order summary updated with shipment for order {OrderId}\", @event OrderId\n    );\n  }\n}\n`\nKey pattern: Single perspective handles multiple events to build a denormalized view Customer Activity Perspective\nECommerce CustomerService API/Perspectives/CustomerActivityPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce CustomerService API Perspectives;\npublic class CustomerActivityPerspective : IPerspectiveOf<OrderCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<CustomerActivityPerspective> _logger;\n  public CustomerActivityPerspective(\n    NpgsqlConnection db,\n    ILogger<CustomerActivityPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  public async Task HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO customer_activity (\n        customer_id, total_orders, total_spent, last_order_id, last_order_at, first_order_at, updated_at\n      )\n      VALUES (@CustomerId, 1, @TotalAmount, @OrderId, @CreatedAt, @CreatedAt, NOW())\n      ON CONFLICT (customer_id) DO UPDATE SET\n        total_orders = customer_activity total_orders + 1,\n        total_spent = customer_activity total_spent + @TotalAmount,\n        last_order_id = @OrderId,\n        last_order_at = @CreatedAt,\n        updated_at = NOW()\n      \"\"\",\n      new {\n        CustomerId = @event CustomerId,\n        TotalAmount = @event TotalAmount,\n        OrderId = @event OrderId,\n        CreatedAt = @event CreatedAt\n      }\n    );\n    _logger LogInformation(\n      \"Customer activity updated for customer {CustomerId}\",\n      @event CustomerId\n    );\n  }\n}\n`\n---\nStep 3: HTTP API\nDTOs\nECommerce CustomerService API/Models/OrderSummaryDto cs:\n`csharp\nnamespace ECommerce CustomerService API Models;\npublic record OrderSummaryDto(\n  string OrderId,\n  string CustomerId,\n  decimal TotalAmount,\n  string Status,\n  int ItemCount,\n  ShippingAddressDto ShippingAddress,\n  DateTime CreatedAt,\n  PaymentInfoDto PaymentInfo,\n  ShipmentInfoDto ShipmentInfo\n);\npublic record ShippingAddressDto(\n  string Street,\n  string City,\n  string State,\n  string ZipCode,\n  string Country\n);\npublic record PaymentInfoDto(\n  string PaymentId,\n  string Status,\n  DateTime ProcessedAt\n);\npublic record ShipmentInfoDto(\n  string ShipmentId,\n  string TrackingNumber,\n  DateTime EstimatedDelivery,\n  DateTime ActualDelivery\n);\n`\nECommerce CustomerService API/Models/CustomerActivityDto cs:\n`csharp\nnamespace ECommerce",
        "startIndex": 6983,
        "preview": "= 'Shipped', shipment_id = @ShipmentId, tracking_number = @TrackingNumber, estimated_delivery = @EstimatedDelivery, updated_at = NOW() WHERE order_id ..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-4",
        "text": "CreatedAt, PaymentInfoDto PaymentInfo, ShipmentInfoDto ShipmentInfo ); public record ShippingAddressDto( string Street, string City, string State, string ZipCode, string Country ); public record PaymentInfoDto( string PaymentId, string Status, DateTime ProcessedAt ); public record ShipmentInfoDto( string ShipmentId, string TrackingNumber, DateTime EstimatedDelivery, DateTime ActualDelivery ); ` ECommerce CustomerService API/Models/CustomerActivityDto cs: `csharp namespace ECommerce CustomerService API Models;\npublic record CustomerActivityDto(\n  string CustomerId,\n  int TotalOrders,\n  decimal TotalSpent,\n  string LastOrderId,\n  DateTime LastOrderAt,\n  DateTime FirstOrderAt\n);\n`\nControllers\nECommerce CustomerService API/Controllers/CustomersController cs:\n`csharp\nusing Microsoft AspNetCore Mvc;\nusing Npgsql;\nusing Dapper;\nusing ECommerce CustomerService API Models;\nnamespace ECommerce CustomerService API Controllers;\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class CustomersController : ControllerBase {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<CustomersController> _logger;\n  public CustomersController(\n    NpgsqlConnection db,\n    ILogger<CustomersController> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  [HttpGet(\"{customerId}\")]\n  [ProducesResponseType(typeof(CustomerActivityDto), StatusCodes Status200OK)]\n  [ProducesResponseType(StatusCodes Status404NotFound)]\n  public async Task<IActionResult> GetCustomer(string customerId) {\n    var customer = await _db QuerySingleOrDefaultAsync<CustomerActivityRow>(\n      \"\"\"\n      SELECT customer_id, total_orders, total_spent, last_order_id, last_order_at, first_order_at\n      FROM customer_activity\n      WHERE customer_id = @CustomerId\n      \"\"\",\n      new { CustomerId = customerId }\n    );\n    if (customer == null) {\n      return NotFound();\n    }\n    return Ok(new CustomerActivityDto(\n      CustomerId: customer CustomerId,\n      TotalOrders: customer TotalOrders,\n      TotalSpent: customer TotalSpent,\n      LastOrderId: customer LastOrderId,\n      LastOrderAt: customer LastOrderAt,\n      FirstOrderAt: customer FirstOrderAt\n    ));\n  }\n  [HttpGet(\"{customerId}/orders\")]\n  [ProducesResponseType(typeof(OrderSummaryDto[]), StatusCodes Status200OK)]\n  public async Task<IActionResult> GetCustomerOrders(string customerId) {\n    var orders = await _db QueryAsync<OrderSummaryRow>(\n      \"\"\"\n      SELECT\n        order_id, customer_id, total_amount, status, item_count, shipping_address,\n        created_at, payment_id, payment_status, payment_processed_at,\n        shipment_id, tracking_number, estimated_delivery, actual_delivery\n      FROM order_summary\n      WHERE customer_id = @CustomerId\n      ORDER BY created_at DESC\n      \"\"\",\n      new { CustomerId = customerId }\n    );\n    var dtos = orders Select(o => new OrderSummaryDto(\n      OrderId: o OrderId,\n      CustomerId: o CustomerId,\n      TotalAmount: o TotalAmount,\n      Status: o Status,\n      ItemCount: o ItemCount,\n      ShippingAddress: System Text Json JsonSerializer Deserialize<ShippingAddressDto>(o ShippingAddress) ,\n      CreatedAt: o CreatedAt,\n      PaymentInfo: o PaymentId = null new PaymentInfoDto(\n        PaymentId: o PaymentId,\n        Status: o PaymentStatus ,\n        ProcessedAt: o PaymentProcessedAt",
        "startIndex": 2407,
        "preview": "CreatedAt, PaymentInfoDto PaymentInfo, ShipmentInfoDto ShipmentInfo ); public record ShippingAddressDto( string Street, string City, string State, str..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-5",
        "text": "dtos = orders Select(o => new OrderSummaryDto( OrderId: o OrderId, CustomerId: o CustomerId, TotalAmount: o TotalAmount, Status: o Status, ItemCount: o ItemCount, ShippingAddress: System Text Json JsonSerializer Deserialize<ShippingAddressDto>(o ShippingAddress) , CreatedAt: o CreatedAt, PaymentInfo: o PaymentId = null new PaymentInfoDto( PaymentId: o PaymentId, Status: o PaymentStatus , ProcessedAt: o PaymentProcessedAt Value\n      ) : null,\n      ShipmentInfo: o ShipmentId = null new ShipmentInfoDto(\n        ShipmentId: o ShipmentId,\n        TrackingNumber: o TrackingNumber ,\n        EstimatedDelivery: o EstimatedDelivery Value,\n        ActualDelivery: o ActualDelivery\n      ) : null\n    )) ToArray();\n    return Ok(dtos);\n  }\n}\npublic record CustomerActivityRow(\n  string CustomerId,\n  int TotalOrders,\n  decimal TotalSpent,\n  string LastOrderId,\n  DateTime LastOrderAt,\n  DateTime FirstOrderAt\n);\npublic record OrderSummaryRow(\n  string OrderId,\n  string CustomerId,\n  decimal TotalAmount,\n  string Status,\n  int ItemCount,\n  string ShippingAddress,  // JSONB\n  DateTime CreatedAt,\n  string PaymentId,\n  string PaymentStatus,\n  DateTime PaymentProcessedAt,\n  string ShipmentId,\n  string TrackingNumber,\n  DateTime EstimatedDelivery,\n  DateTime ActualDelivery\n);\n`\nECommerce CustomerService API/Controllers/OrdersController cs:\n`csharp\nusing Microsoft AspNetCore Mvc;\nusing Npgsql;\nusing Dapper;\nusing ECommerce CustomerService API Models;\nnamespace ECommerce CustomerService API Controllers;\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class OrdersController : ControllerBase {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<OrdersController> _logger;\n  public OrdersController(\n    NpgsqlConnection db,\n    ILogger<OrdersController> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  [HttpGet(\"{orderId}\")]\n  [ProducesResponseType(typeof(OrderSummaryDto), StatusCodes Status200OK)]\n  [ProducesResponseType(StatusCodes Status404NotFound)]\n  public async Task<IActionResult> GetOrder(string orderId) {\n    var order = await _db QuerySingleOrDefaultAsync<OrderSummaryRow>(\n      \"\"\"\n      SELECT\n        order_id, customer_id, total_amount, status, item_count, shipping_address,\n        created_at, payment_id, payment_status, payment_processed_at,\n        shipment_id, tracking_number, estimated_delivery, actual_delivery\n      FROM order_summary\n      WHERE order_id = @OrderId\n      \"\"\",\n      new { OrderId = orderId }\n    );\n    if (order == null) {\n      return NotFound();\n    }\n    return Ok(new OrderSummaryDto(\n      OrderId: order OrderId,\n      CustomerId: order CustomerId,\n      TotalAmount: order TotalAmount,\n      Status: order Status,\n      ItemCount: order ItemCount,\n      ShippingAddress: System Text Json JsonSerializer Deserialize<ShippingAddressDto>(order ShippingAddress) ,\n      CreatedAt: order CreatedAt,\n      PaymentInfo: order PaymentId = null new PaymentInfoDto(\n        PaymentId: order PaymentId,\n        Status: order PaymentStatus ,\n        ProcessedAt: order PaymentProcessedAt Value\n      ) : null,\n      ShipmentInfo: order ShipmentId = null",
        "startIndex": 12298,
        "preview": "dtos = orders Select(o => new OrderSummaryDto( OrderId: o OrderId, CustomerId: o CustomerId, TotalAmount: o TotalAmount, Status: o Status, ItemCount: ..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-6",
        "text": "OrderId, CustomerId: order CustomerId, TotalAmount: order TotalAmount, Status: order Status, ItemCount: order ItemCount, ShippingAddress: System Text Json JsonSerializer Deserialize<ShippingAddressDto>(order ShippingAddress) , CreatedAt: order CreatedAt, PaymentInfo: order PaymentId = null new PaymentInfoDto( PaymentId: order PaymentId, Status: order PaymentStatus , ProcessedAt: order PaymentProcessedAt Value ) : null, ShipmentInfo: order ShipmentId = null new ShipmentInfoDto(\n        ShipmentId: order ShipmentId,\n        TrackingNumber: order TrackingNumber ,\n        EstimatedDelivery: order EstimatedDelivery Value,\n        ActualDelivery: order ActualDelivery\n      ) : null\n    ));\n  }\n}\n`\n---\nStep 4: Service Configuration\nECommerce CustomerService API/Program cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Npgsql;\nvar builder = WebApplication CreateBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"CustomerService\";\n  options EnableInbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"CustomerDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Add Aspire service defaults\nbuilder AddServiceDefaults();\n// 5 Add controllers\nbuilder Services AddControllers();\nbuilder Services AddEndpointsApiExplorer();\nbuilder Services AddSwaggerGen();\nvar app = builder Build();\nif (app Environment IsDevelopment()) {\n  app UseSwagger();\n  app UseSwaggerUI();\n}\napp UseHttpsRedirection();\napp UseAuthorization();\napp MapControllers();\nawait app MigrateDatabaseAsync();\napp Run();\n`\n---\nStep 5: Test BFF API\nCreate Order (Full Flow)\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{ }'\n`\nWait for events to propagate through system (~10 seconds) Query Customer Activity\n`bash\ncurl http://localhost:5001/api/customers/cust-123\n`\nResponse:\n`json\n{\n  \"customerId\": \"cust-123\",\n  \"totalOrders\": 1,\n  \"totalSpent\": 39 98,\n  \"lastOrderId\": \"order-abc123\",\n  \"lastOrderAt\": \"2024-12-12T10:30:00Z\",\n  \"firstOrderAt\": \"2024-12-12T10:30:00Z\"\n}\n`\nQuery Customer Orders\n`bash\ncurl http://localhost:5001/api/customers/cust-123/orders\n`\nResponse:\n`json\n[\n  {\n    \"orderId\": \"order-abc123\",\n    \"customerId\": \"cust-123\",\n    \"totalAmount\": 39",
        "startIndex": 15018,
        "preview": "OrderId, CustomerId: order CustomerId, TotalAmount: order TotalAmount, Status: order Status, ItemCount: order ItemCount, ShippingAddress: System Text ..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-7",
        "text": "for events to propagate through system (~10 seconds) Query Customer Activity `bash curl http://localhost:5001/api/customers/cust-123 ` Response: `json { \"customerId\": \"cust-123\", \"totalOrders\": 1, \"totalSpent\": 39 98, \"lastOrderId\": \"order-abc123\", \"lastOrderAt\": \"2024-12-12T10:30:00Z\", \"firstOrderAt\": \"2024-12-12T10:30:00Z\" } ` Query Customer Orders `bash curl http://localhost:5001/api/customers/cust-123/orders ` Response: `json [ { \"orderId\": \"order-abc123\", \"customerId\": \"cust-123\", \"totalAmount\": 39 98,\n    \"status\": \"Shipped\",\n    \"itemCount\": 1,\n    \"shippingAddress\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"Springfield\",\n      \"state\": \"IL\",\n      \"zipCode\": \"62701\",\n      \"country\": \"USA\"\n    },\n    \"createdAt\": \"2024-12-12T10:30:00Z\",\n    \"paymentInfo\": {\n      \"paymentId\": \"pay-xyz789\",\n      \"status\": \"Captured\",\n      \"processedAt\": \"2024-12-12T10:31:00Z\"\n    },\n    \"shipmentInfo\": {\n      \"shipmentId\": \"ship-def456\",\n      \"trackingNumber\": \"123456789012\",\n      \"estimatedDelivery\": \"2024-12-15T12:00:00Z\",\n      \"actualDelivery\": null\n    }\n  }\n]\n`\nQuery Single Order\n`bash\ncurl http://localhost:5001/api/orders/order-abc123\n`\nResponse: Same as above (single order) ---\nKey Concepts\nCQRS (Command Query Responsibility Segregation)\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  CQRS Pattern                                            ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  WRITE SIDE (Commands)                                  ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n‚îÇ  ‚îÇ  Order Service                   ‚îÇ                   ‚îÇ\n‚îÇ  ‚îÇ  - CreateOrder command           ‚îÇ                   ‚îÇ\n‚îÇ  ‚îÇ  - Publishes OrderCreated event  ‚îÇ                   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n‚îÇ                 ‚îÇ                                        ‚îÇ\n‚îÇ                 ‚ñº                                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n‚îÇ  ‚îÇ  Azure Service Bus (Events)      ‚îÇ                   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n‚îÇ                 ‚îÇ                                        ‚îÇ\n‚îÇ                 ‚ñº                                        ‚îÇ\n‚îÇ  READ SIDE (Queries)                                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n‚îÇ  ‚îÇ  Customer Service                ‚îÇ                   ‚îÇ\n‚îÇ  ‚îÇ  - OrderSummaryPerspective       ‚îÇ                   ‚îÇ\n‚îÇ  ‚îÇ  - Denormalized order_summary    ‚îÇ                   ‚îÇ\n‚îÇ  ‚îÇ  - Fast queries (no joins",
        "startIndex": 17048,
        "preview": "for events to propagate through system (~10 seconds) Query Customer Activity `bash curl http://localhost:5001/api/customers/cust-123 ` Response: `json..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-8",
        "text": "‚îÇ Azure Service Bus (Events) ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚ñº ‚îÇ ‚îÇ READ SIDE (Queries) ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ Customer Service ‚îÇ ‚îÇ ‚îÇ ‚îÇ - OrderSummaryPerspective ‚îÇ ‚îÇ ‚îÇ ‚îÇ - Denormalized order_summary ‚îÇ ‚îÇ ‚îÇ ‚îÇ - Fast queries (no joins )      ‚îÇ                   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\n‚úÖ Write optimization: Order Service optimized for writes (ACID, validation)\n‚úÖ Read optimization: Customer Service optimized for reads (denormalized, indexed)\n‚úÖ Independent scaling: Scale read replicas independently\n‚úÖ Eventual consistency: Acceptable for most read queries\nEvent-Driven Read Models\n`csharp\n// Single perspective updates from multiple events\npublic class OrderSummaryPerspective :\n  IPerspectiveOf<OrderCreated>,       // Sets initial state\n  IPerspectiveOf<PaymentProcessed>,   // Updates payment info\n  IPerspectiveOf<ShipmentCreated> {   // Updates shipment info\n  public async Task HandleAsync(OrderCreated @event) {\n    // INSERT initial order summary\n  }\n  public async Task HandleAsync(PaymentProcessed @event) {\n    // UPDATE with payment details\n  }\n  public async Task HandleAsync(ShipmentCreated @event) {\n    // UPDATE with shipment details\n  }\n}\n`\nResult: Single order_summary row with data from 3 different events",
        "startIndex": 19106,
        "preview": "‚îÇ Azure Service Bus (Events) ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚ñº ‚îÇ ‚îÇ READ SIDE (Queries) ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ..."
      },
      {
        "id": "v0.1.0/tutorial/customer-service-chunk-9",
        "text": "shipment info public async Task HandleAsync(OrderCreated @event) { // INSERT initial order summary } public async Task HandleAsync(PaymentProcessed @event) { // UPDATE with payment details } public async Task HandleAsync(ShipmentCreated @event) { // UPDATE with shipment details } } ` Result: Single order_summary row with data from 3 different events BFF (Backend for Frontend)\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  BFF Pattern                                             ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ\n‚îÇ  ‚îÇ  Web Client  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ                               ‚îÇ\n‚îÇ                         ‚ñº                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ  ‚îÇMobile Client ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Customer Service ‚îÇ               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ      (BFF)       ‚îÇ               ‚îÇ\n‚îÇ                     ‚îÇ  - Tailored DTOs ‚îÇ               ‚îÇ\n‚îÇ                     ‚îÇ  - Aggregated data‚îÇ               ‚îÇ\n‚îÇ                     ‚îÇ  - Client-specific‚îÇ               ‚îÇ\n‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nKey characteristics:\n‚úÖ Client-specific: DTOs shaped for frontend needs\n‚úÖ Aggregation: Combines data from multiple events\n‚úÖ Denormalization: Pre-joins data for performance\n‚úÖ Versioning: API versions per client type\n---\nTesting\nUnit Test - Perspective\n`csharp\n[Test]\npublic async Task OrderSummaryPerspective_OrderCreated_CreatesOrderSummaryAsync() {\n  // Arrange\n  var db = new MockNpgsqlConnection();\n  var perspective = new OrderSummaryPerspective(db, mockLogger);\n  var @event = new OrderCreated( );\n  // Act\n  await perspective HandleAsync(@event);\n  // Assert\n  var summary = db GetOrderSummary(@event OrderId);\n  await Assert That(summary) IsNotNull();\n  await Assert That(summary Status) IsEqualTo(\"Pending\");\n}\n`\n---\nNext Steps\nContinue to Analytics Service to:\nBuild real-time analytics dashboards\nAggregate events across all services\nImplement time-series perspectives\nCreate daily/monthly reports\n---\nKey Takeaways\n‚úÖ CQRS - Separate write (commands) and read (queries) models\n‚úÖ Perspectives - Event-driven read model updates\n‚úÖ Denormalization - Pre-join data for fast queries\n‚úÖ BFF Pattern - Tailor API to frontend needs\n‚úÖ Eventual Consistency - Acceptable for most read queries\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20210,
        "preview": "shipment info public async Task HandleAsync(OrderCreated @event) { // INSERT initial order summary } public async Task HandleAsync(PaymentProcessed @e..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/deployment",
    "title": "Deployment",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/deployment",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/deployment-chunk-0",
        "text": "Deployment\nDeploy the ECommerce system to production using Azure Kubernetes Service (AKS), implement CI/CD pipelines, configure monitoring, and enable auto-scaling :::note\nThis is Part 9 (Final) of the ECommerce Tutorial Complete Testing Strategy first :::\n---\nDeployment Architecture\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Azure Kubernetes Service (AKS)                              ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Ingress Controller (nginx)                         ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  - SSL/TLS Termination                              ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  - Load Balancing                                   ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îÇ               ‚îÇ                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n‚îÇ  ‚îÇ  Order Service      ‚îÇ  ‚îÇ Customer Service ‚îÇ              ‚îÇ\n‚îÇ  ‚îÇ  (3 replicas)       ‚îÇ  ‚îÇ  (2 replicas)    ‚îÇ              ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n‚îÇ  ‚îÇ Inventory Worker    ‚îÇ  ‚îÇ  Payment Worker  ‚îÇ              ‚îÇ\n‚îÇ  ‚îÇ  (2 replicas)       ‚îÇ  ‚îÇ  (2 replicas)    ‚îÇ              ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n‚îÇ  ‚îÇNotification Worker  ‚îÇ  ‚îÇ Shipping Worker  ‚îÇ              ‚îÇ\n‚îÇ  ‚îÇ  (2 replicas)       ‚îÇ  ‚îÇ  (2 replicas)    ‚îÇ              ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ  ‚îÇ  Analytics Worker (1 replica)                        ‚îÇ   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Azure Managed Services                                      ‚îÇ\n‚îÇ                                                               ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n‚îÇ  ‚îÇ Azure Service    ‚îÇ  ‚îÇ Azure Database   ‚îÇ  ‚îÇ Azure      ‚îÇ‚îÇ\n‚îÇ  ‚îÇ Bus (Premium)    ‚îÇ  ‚îÇ for PostgreSQL   ‚îÇ  ‚îÇ Monitor    ‚îÇ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nStep 1: Dockerfiles\nOrder Service Dockerfile\nECommerce OrderService API/Dockerfile:\n`dockerfile\nBuild stage\nFROM mcr microsoft com/dotnet/sdk:10 0 AS build\nWORKDIR /src\nCopy solution and project files\nCOPY ECommerce sln COPY ECommerce OrderService API/ECommerce OrderService API csproj ECommerce OrderService API/\nCOPY ECommerce Contracts/ECommerce Contracts csproj ECommerce Contracts/\nRestore dependencies\nRUN dotnet restore ECommerce OrderService API/ECommerce OrderService API csproj\nCopy source code\nCOPY Build and publish\nWORKDIR /src/ECommerce OrderService",
        "startIndex": 0,
        "preview": "Deployment\nDeploy the ECommerce system to production using Azure Kubernetes Service (AKS), implement CI/CD pipelines, configure monitoring, and enable..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-1",
        "text": "AS build WORKDIR /src Copy solution and project files COPY ECommerce sln COPY ECommerce OrderService API/ECommerce OrderService API csproj ECommerce OrderService API/ COPY ECommerce Contracts/ECommerce Contracts csproj ECommerce Contracts/ Restore dependencies RUN dotnet restore ECommerce OrderService API/ECommerce OrderService API csproj Copy source code COPY Build and publish WORKDIR /src/ECommerce OrderService API\nRUN dotnet publish -c Release -o /app/publish \\\n  --no-restore \\\n  /p:UseAppHost=false\nRuntime stage\nFROM mcr microsoft com/dotnet/aspnet:10 0 AS runtime\nWORKDIR /app\nCopy published files\nCOPY --from=build /app/publish Create non-root user\nRUN adduser --disabled-password --gecos \"\" appuser && chown -R appuser /app\nUSER appuser\nHealth check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:8080/health || exit 1\nExpose port\nEXPOSE 8080\nENTRYPOINT [\"dotnet\", \"ECommerce OrderService API dll\"]\n`\nWorker Service Dockerfile\nECommerce InventoryWorker/Dockerfile:\n`dockerfile\nFROM mcr microsoft com/dotnet/sdk:10 0 AS build\nWORKDIR /src\nCOPY ECommerce sln COPY ECommerce InventoryWorker/ECommerce InventoryWorker csproj ECommerce InventoryWorker/\nCOPY ECommerce Contracts/ECommerce Contracts csproj ECommerce Contracts/\nRUN dotnet restore ECommerce InventoryWorker/ECommerce InventoryWorker csproj\nCOPY WORKDIR /src/ECommerce InventoryWorker\nRUN dotnet publish -c Release -o /app/publish \\\n  --no-restore \\\n  /p:UseAppHost=false\nFROM mcr microsoft com/dotnet/runtime:10 0 AS runtime\nWORKDIR /app\nCOPY --from=build /app/publish RUN adduser --disabled-password --gecos \"\" appuser && chown -R appuser /app\nUSER appuser\nENTRYPOINT [\"dotnet\", \"ECommerce InventoryWorker dll\"]\n`\n---\nStep 2: Kubernetes Manifests\nOrder Service Deployment\nk8s/order-service/deployment yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service\n  namespace: ecommerce\n  labels:\n    app: order-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\nname: order-service\n        image: ecommerceacr azurecr",
        "startIndex": 3184,
        "preview": "AS build WORKDIR /src Copy solution and project files COPY ECommerce sln COPY ECommerce OrderService API/ECommerce OrderService API csproj ECommerce O..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-2",
        "text": "USER appuser ENTRYPOINT [\"dotnet\", \"ECommerce InventoryWorker dll\"] ` --- Step 2: Kubernetes Manifests Order Service Deployment k8s/order-service/deployment yaml: `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service namespace: ecommerce labels: app: order-service spec: replicas: 3 selector: matchLabels: app: order-service template: metadata: labels: app: order-service spec: containers: name: order-service image: ecommerceacr azurecr io/order-service:latest\n        ports:\ncontainerPort: 8080\n          name: http\n        env:\nname: ASPNETCORE_ENVIRONMENT\n          value: \"Production\"\nname: ConnectionStrings__OrdersDb\n          valueFrom:\n            secretKeyRef:\n              name: database-secrets\n              key: orders-db-connection-string\nname: Whizbang__ServiceBus__ConnectionString\n          valueFrom:\n            secretKeyRef:\n              name: servicebus-secrets\n              key: connection-string\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: order-service\n  namespace: ecommerce\nspec:\n  selector:\n    app: order-service\n  ports:\nport: 80\n    targetPort: 8080\n    name: http\n  type: ClusterIP\n`\nHorizontal Pod Autoscaler\nk8s/order-service/hpa yaml:\n`yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: order-service-hpa\n  namespace: ecommerce\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: order-service\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\ntype: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\ntype: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\ntype: Percent\n        value: 50\n        periodSeconds: 60\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\ntype: Percent\n        value: 10\n        periodSeconds: 60\n`\nIngress\nk8s/ingress yaml:\n`yaml\napiVersion: networking k8s io/v1\nkind: Ingress\nmetadata:\n  name: ecommerce-ingress\n  namespace: ecommerce\n  annotations:\n    cert-manager io/cluster-issuer: letsencrypt-prod\n    nginx ingress kubernetes io/ssl-redirect: \"true\"\n    nginx ingress kubernetes io/rate-limit: \"100\"\nspec:\n  ingressClassName: nginx\n  tls:\nhosts:\napi ecommerce example com\n    secretName: ecommerce-tls\n  rules:\nhost: api ecommerce example com\n    http:\n      paths:\npath: /api/orders\n        pathType: Prefix\n        backend:\n          service:\n            name: order-service\n            port:\n              number: 80\npath: /api/customers\n        pathType: Prefix\n        backend:\n          service:\n            name: customer-service\n            port:\n              number: 80\npath: /api/analytics\n        pathType: Prefix\n        backend:\n          service:\n            name: analytics-service\n            port:\n              number: 80\n`\n---\nStep 3: Azure Infrastructure (Bicep)\ninfra/main",
        "startIndex": 4969,
        "preview": "USER appuser ENTRYPOINT [\"dotnet\", \"ECommerce InventoryWorker dll\"] ` --- Step 2: Kubernetes Manifests Order Service Deployment k8s/order-service/depl..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-3",
        "text": "ecommerce-tls rules: host: api ecommerce example com http: paths: path: /api/orders pathType: Prefix backend: service: name: order-service port: number: 80 path: /api/customers pathType: Prefix backend: service: name: customer-service port: number: 80 path: /api/analytics pathType: Prefix backend: service: name: analytics-service port: number: 80 ` --- Step 3: Azure Infrastructure (Bicep) infra/main bicep:\n`bicep\nparam location string = 'eastus'\nparam environment string = 'production'\n// Azure Kubernetes Service\nresource aks 'Microsoft ContainerService/managedClusters@2024-01-01' = {\n  name: 'ecommerce-aks-${environment}'\n  location: location\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    kubernetesVersion: '1 28'\n    dnsPrefix: 'ecommerce-${environment}'\n    agentPoolProfiles: [\n      {\n        name: 'nodepool1'\n        count: 3\n        vmSize: 'Standard_D4s_v3'\n        mode: 'System'\n        enableAutoScaling: true\n        minCount: 3\n        maxCount: 10\n        osDiskSizeGB: 128\n        osType: 'Linux'\n      }\n    ]\n    networkProfile: {\n      networkPlugin: 'azure'\n      loadBalancerSku: 'standard'\n      serviceCidr: '10 0 0 0/16'\n      dnsServiceIP: '10 0 0 10'\n    }\n    addonProfiles: {\n      azurePolicy: {\n        enabled: true\n      }\n      omsagent: {\n        enabled: true\n        config: {\n          logAnalyticsWorkspaceResourceID: logAnalytics id\n        }\n      }\n    }\n  }\n}\n// Azure Database for PostgreSQL\nresource postgres 'Microsoft DBforPostgreSQL/flexibleServers@2023-03-01-preview' = {\n  name: 'ecommerce-postgres-${environment}'\n  location: location\n  sku: {\n    name: 'Standard_D4s_v3'\n    tier: 'GeneralPurpose'\n  }\n  properties: {\n    version: '16'\n    administratorLogin: 'pgadmin'\n    administratorLoginPassword: '<secure-password>'\n    storage: {\n      storageSizeGB: 128\n    }\n    backup: {\n      backupRetentionDays: 7\n      geoRedundantBackup: 'Enabled'\n    }\n    highAvailability: {\n      mode: 'ZoneRedundant'\n    }\n  }\n}\n// Azure Service Bus\nresource serviceBus 'Microsoft ServiceBus/namespaces@2023-01-01-preview' = {\n  name: 'ecommerce-servicebus-${environment}'\n  location: location\n  sku: {\n    name: 'Premium'\n    tier: 'Premium'\n    capacity: 1\n  }\n  properties: {\n    zoneRedundant: true\n  }\n}\n// Azure Container Registry\nresource acr 'Microsoft ContainerRegistry/registries@2023-07-01' = {\n  name: 'ecommerceacr${environment}'\n  location: location\n  sku: {\n    name: 'Premium'\n  }\n  properties: {\n    adminUserEnabled: false\n    publicNetworkAccess: 'Enabled'\n  }\n}\n// Log Analytics Workspace\nresource logAnalytics 'Microsoft OperationalInsights/workspaces@2022-10-01' = {\n  name: 'ecommerce-logs-${environment}'\n  location: location\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n  }\n}\n// Application Insights\nresource appInsights 'Microsoft Insights/components@2020-02-02' = {\n  name: 'ecommerce-appinsights-${environment}'\n  location: location\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    WorkspaceResourceId: logAnalytics",
        "startIndex": 7949,
        "preview": "ecommerce-tls rules: host: api ecommerce example com http: paths: path: /api/orders pathType: Prefix backend: service: name: order-service port: numbe..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-4",
        "text": "publicNetworkAccess: 'Enabled' } } // Log Analytics Workspace resource logAnalytics 'Microsoft OperationalInsights/workspaces@2022-10-01' = { name: 'ecommerce-logs-${environment}' location: location properties: { sku: { name: 'PerGB2018' } retentionInDays: 30 } } // Application Insights resource appInsights 'Microsoft Insights/components@2020-02-02' = { name: 'ecommerce-appinsights-${environment}' location: location kind: 'web' properties: { Application_Type: 'web' WorkspaceResourceId: logAnalytics id\n  }\n}\noutput aksName string = aks name\noutput acrLoginServer string = acr properties loginServer\noutput postgresHost string = postgres properties fullyQualifiedDomainName\noutput serviceBusNamespace string = serviceBus name\n`\nDeploy infrastructure:\n`bash\naz deployment group create \\\n  --resource-group ecommerce-rg \\\n  --template-file infra/main bicep \\\n  --parameters environment=production\n`\n---\nStep 4: CI/CD Pipeline (GitHub Actions) github/workflows/deploy yaml:\n`yaml\nname: Build and Deploy\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\nenv:\n  AZURE_RESOURCE_GROUP: ecommerce-rg\n  AKS_CLUSTER_NAME: ecommerce-aks-production\n  ACR_NAME: ecommerceacrproduction\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\nuses: actions/checkout@v4\nname: Setup NET 10\n      uses: actions/setup-dotnet@v4\n      with:\n        dotnet-version: '10 0 x'\nname: Restore dependencies\n      run: dotnet restore\nname: Build\n      run: dotnet build --no-restore\nname: Run unit tests\n      run: dotnet test --no-build --verbosity normal --logger trx\nname: Run integration tests\n      run: |\n        docker-compose -f docker-compose test yml up -d\n        dotnet test tests/ECommerce IntegrationTests --no-build\n        docker-compose -f docker-compose test yml down\n  build-and-push:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github ref == 'refs/heads/main'\n    strategy:\n      matrix:\n        service:\norder-service\ninventory-worker\npayment-worker\nnotification-worker\nshipping-worker\ncustomer-service\nanalytics-worker\n    steps:\nuses: actions/checkout@v4\nname: Login to Azure Container Registry\n      uses: azure/docker-login@v1\n      with:\n        login-server: ${{ env ACR_NAME }} azurecr io\n        username: ${{ secrets ACR_USERNAME }}\n        password: ${{ secrets ACR_PASSWORD }}\nname: Build and push Docker image\n      run: |\n        docker build -t ${{ env ACR_NAME }} azurecr io/${{ matrix service }}:${{ github sha }} \\\n          -f ECommerce ${{ matrix service }}/Dockerfile docker push ${{ env ACR_NAME }} azurecr io/${{ matrix service }}:${{ github sha }}\n  deploy:\n    needs: build-and-push\n    runs-on: ubuntu-latest\n    if: github",
        "startIndex": 10605,
        "preview": "publicNetworkAccess: 'Enabled' } } // Log Analytics Workspace resource logAnalytics 'Microsoft OperationalInsights/workspaces@2022-10-01' = { name: 'e..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-5",
        "text": "Build and push Docker image run: | docker build -t ${{ env ACR_NAME }} azurecr io/${{ matrix service }}:${{ github sha }} \\ -f ECommerce ${{ matrix service }}/Dockerfile docker push ${{ env ACR_NAME }} azurecr io/${{ matrix service }}:${{ github sha }} deploy: needs: build-and-push runs-on: ubuntu-latest if: github ref == 'refs/heads/main'\n    steps:\nuses: actions/checkout@v4\nname: Azure Login\n      uses: azure/login@v1\n      with:\n        creds: ${{ secrets AZURE_CREDENTIALS }}\nname: Get AKS credentials\n      run: |\n        az aks get-credentials \\\n          --resource-group ${{ env AZURE_RESOURCE_GROUP }} \\\n          --name ${{ env AKS_CLUSTER_NAME }}\nname: Update Kubernetes manifests\n      run: |\n        sed -i \"s|:latest|:${{ github sha }}|g\" k8s//* yaml\nname: Deploy to AKS\n      run: |\n        kubectl apply -f k8s/namespace yaml\n        kubectl apply -f k8s/secrets/ --namespace ecommerce\n        kubectl apply -f k8s/ --recursive --namespace ecommerce\nname: Wait for rollout\n      run: |\n        kubectl rollout status deployment/order-service --namespace ecommerce --timeout=10m\n        kubectl rollout status deployment/inventory-worker --namespace ecommerce --timeout=10m\n`\n---\nStep 5: Monitoring and Observability\nApplication Insights Integration\nProgram cs:\n`csharp\nbuilder Services AddApplicationInsightsTelemetry(options => {\n  options ConnectionString = builder Configuration[\"ApplicationInsights:ConnectionString\"];\n});\nbuilder Services AddOpenTelemetryMetrics(metrics => {\n  metrics AddAspNetCoreInstrumentation() AddHttpClientInstrumentation() AddRuntimeInstrumentation();\n});\nbuilder Services AddOpenTelemetryTracing(tracing => {\n  tracing AddAspNetCoreInstrumentation() AddHttpClientInstrumentation() AddNpgsql() AddAzureServiceBusInstrumentation();\n});\n`\nPrometheus Metrics\nk8s/monitoring/prometheus yaml:\n`yaml\napiVersion: v1\nkind: ServiceMonitor\nmetadata:\n  name: ecommerce-services\n  namespace: ecommerce\nspec:\n  selector:\n    matchLabels:\n      app: order-service\n  endpoints:\nport: http\n    path: /metrics\n    interval: 30s\n`\nCustom Metrics\nReceptors/CreateOrderReceptor cs:\n`csharp\nprivate readonly Meter _meter = new(\"ECommerce OrderService\");\nprivate readonly Counter<long> _ordersCreated;\npublic CreateOrderReceptor( ) {\n  _ordersCreated = _meter CreateCounter<long>(\n    \"orders_created_total\",\n    description: \"Total number of orders created\"\n  );\n}\npublic async Task<OrderCreated> HandleAsync(CreateOrder command, CancellationToken ct) {\n  // process order\n  _ordersCreated Add(1, new TagList {\n    { \"customer_id\", command CustomerId },\n    { \"item_count\", command Items Length }\n  });\n  return @event;\n}\n`\n---\nStep 6: Database Migrations\nMigration Job\nk8s/jobs/migrate-orders-db",
        "startIndex": 12783,
        "preview": "Build and push Docker image run: | docker build -t ${{ env ACR_NAME }} azurecr io/${{ matrix service }}:${{ github sha }} \\ -f ECommerce ${{ matrix se..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-6",
        "text": "CreateCounter<long>( \"orders_created_total\", description: \"Total number of orders created\" ); } public async Task<OrderCreated> HandleAsync(CreateOrder command, CancellationToken ct) { // process order _ordersCreated Add(1, new TagList { { \"customer_id\", command CustomerId }, { \"item_count\", command Items Length } }); return @event; } ` --- Step 6: Database Migrations Migration Job k8s/jobs/migrate-orders-db yaml:\n`yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: migrate-orders-db\n  namespace: ecommerce\nspec:\n  template:\n    spec:\n      containers:\nname: migrate\n        image: ecommerceacr azurecr io/order-service:latest\n        command: [\"dotnet\", \"ECommerce OrderService API dll\", \"migrate\"]\n        env:\nname: ConnectionStrings__OrdersDb\n          valueFrom:\n            secretKeyRef:\n              name: database-secrets\n              key: orders-db-connection-string\n      restartPolicy: OnFailure\n  backoffLimit: 3\n`\nRun migration before deployment:\n`bash\nkubectl apply -f k8s/jobs/migrate-orders-db yaml\nkubectl wait --for=condition=complete job/migrate-orders-db --timeout=5m\n`\n---\nStep 7: Blue-Green Deployment\nk8s/order-service/deployment-blue yaml:\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service-blue\n  namespace: ecommerce\n  labels:\n    app: order-service\n    version: blue\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: order-service\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: order-service\n        version: blue\n    spec:\n      containers:\nname: order-service\n        image: ecommerceacr azurecr io/order-service:v1 0 0 `\nk8s/order-service/service-switch yaml:\n`yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: order-service\n  namespace: ecommerce\nspec:\n  selector:\n    app: order-service\n    version: blue  Switch to \"green\" for rollover\n  ports:\nport: 80\n    targetPort: 8080\n`\nDeployment process:\n`bash\nDeploy green version\nkubectl apply -f k8s/order-service/deployment-green",
        "startIndex": 15233,
        "preview": "CreateCounter<long>( \"orders_created_total\", description: \"Total number of orders created\" ); } public async Task<OrderCreated> HandleAsync(CreateOrde..."
      },
      {
        "id": "v0.1.0/tutorial/deployment-chunk-7",
        "text": "spec: containers: name: order-service image: ecommerceacr azurecr io/order-service:v1 0 0 ` k8s/order-service/service-switch yaml: `yaml apiVersion: v1 kind: Service metadata: name: order-service namespace: ecommerce spec: selector: app: order-service version: blue Switch to \"green\" for rollover ports: port: 80 targetPort: 8080 ` Deployment process: `bash Deploy green version kubectl apply -f k8s/order-service/deployment-green yaml\nWait for readiness\nkubectl wait --for=condition=available deployment/order-service-green --timeout=5m\nSwitch traffic to green\nkubectl patch service order-service -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'\nMonitor for errors (5 minutes)\nIf successful, delete blue\nkubectl delete deployment order-service-blue\n`\n---\nKey Takeaways\n‚úÖ Kubernetes Deployment - AKS with auto-scaling and health checks\n‚úÖ CI/CD Pipeline - GitHub Actions for automated testing and deployment\n‚úÖ Infrastructure as Code - Bicep for Azure resources\n‚úÖ Monitoring - Application Insights and Prometheus metrics\n‚úÖ Blue-Green Deployment - Zero-downtime deployments\n‚úÖ Database Migrations - Automated with Kubernetes jobs\n---\nProduction Checklist\nBefore going live:\n[ ] SSL/TLS certificates configured (cert-manager + Let's Encrypt)\n[ ] Secrets stored in Azure Key Vault (not ConfigMaps)\n[ ] Database backups configured (7-day retention)\n[ ] Log aggregation configured (Azure Monitor)\n[ ] Alerts configured for critical errors\n[ ] Auto-scaling tested under load\n[ ] Disaster recovery plan documented\n[ ] Security scanning in CI/CD pipeline\n[ ] Rate limiting configured on Ingress\n[ ] DDoS protection enabled\n---\nCongratulations You've completed the ECommerce Tutorial and built a production-ready, event-driven microservices system with Whizbang üéâ\nWhat you've learned:\nEvent-driven architecture with CQRS\nDistributed transactions with sagas\nRead models with perspectives\nTesting strategies (unit, integration, e2e)\nProduction deployment on Kubernetes\nNext steps:\nExplore Advanced Topics for performance tuning and scaling\nCheck out Customization Examples for real-world patterns\nJoin the community and share your Whizbang projects ---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 16813,
        "preview": "spec: containers: name: order-service image: ecommerceacr azurecr io/order-service:v1 0 0 ` k8s/order-service/service-switch yaml: `yaml apiVersion: v..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/inventory-service",
    "title": "Inventory Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/inventory-service",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-0",
        "text": "Inventory Service\nBuild the Inventory Worker - a background service that subscribes to OrderCreated events, reserves inventory, publishes InventoryReserved events, and maintains read models via perspectives :::note\nThis is Part 2 of the ECommerce Tutorial Complete Order Management first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Inventory Service Architecture                             ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                            ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  OrderCreated event                        ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ                     ‚îÇ\n‚îÇ                                        ‚ñº                     ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ  Inbox Pattern         ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  (Exactly-Once)        ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                                     ‚ñº                        ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ ReserveInventoryReceptor‚îÇ        ‚îÇ\n‚îÇ                          ‚îÇ  - Check stock         ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Reserve units       ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Publish event       ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ                      ‚îÇ              ‚îÇ              ‚îÇ        ‚îÇ\n‚îÇ                      ‚ñº              ‚ñº              ‚ñº        ‚îÇ\n‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ                 ‚îÇPostgres ‚îÇ   ‚îÇ Outbox  ‚îÇ   ‚îÇPerspective‚îÇ  ‚îÇ\n‚îÇ                 ‚îÇInventory‚îÇ   ‚îÇ Table   ‚îÇ   ‚îÇ  (Read    ‚îÇ  ‚îÇ\n‚îÇ                 ‚îÇ  Table  ‚îÇ   ‚îÇ         ‚îÇ   ‚îÇ  Model)   ‚îÇ  ‚îÇ\n‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                                     ‚ñº                        ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ Azure Service Bus      ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ InventoryReserved      ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Event subscription (OrderCreated)\n‚úÖ Inbox pattern (exactly-once processing)\n‚úÖ Inventory reservation logic\n‚úÖ Compensation (stock release on failure)\n‚úÖ Perspective read model (InventorySummary)\n‚úÖ Work coordination via PostgreSQL\n---\nStep 1: Define Events\nInventoryReserved Event\nECommerce Contracts/Events/InventoryReserved cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts Events;\npublic record InventoryReserved(\n  string OrderId,\n  string ProductId,\n  int QuantityReserved,\n  int RemainingStock,\n  DateTime ReservedAt\n) : IEvent;\n`\nInventoryInsufficient Event (Compensation)\nECommerce Contracts/Events/InventoryInsufficient cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts",
        "startIndex": 0,
        "preview": "Inventory Service\nBuild the Inventory Worker - a background service that subscribes to OrderCreated events, reserves inventory, publishes InventoryRes..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-1",
        "text": "via PostgreSQL --- Step 1: Define Events InventoryReserved Event ECommerce Contracts/Events/InventoryReserved cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events; public record InventoryReserved( string OrderId, string ProductId, int QuantityReserved, int RemainingStock, DateTime ReservedAt ) : IEvent; ` InventoryInsufficient Event (Compensation) ECommerce Contracts/Events/InventoryInsufficient cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events;\npublic record InventoryInsufficient(\n  string OrderId,\n  string ProductId,\n  int RequestedQuantity,\n  int AvailableStock,\n  DateTime CheckedAt\n) : IEvent;\n`\nWhy two events Success path: InventoryReserved triggers payment processing\nFailure path: InventoryInsufficient triggers order cancellation (compensation)\n---\nStep 2: Database Schema\nInventory Table\nECommerce InventoryWorker/Database/Migrations/001_CreateInventoryTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS inventory (\n  product_id TEXT PRIMARY KEY,\n  available_stock INTEGER NOT NULL CHECK (available_stock >= 0),\n  reserved_stock INTEGER NOT NULL DEFAULT 0 CHECK (reserved_stock >= 0),\n  total_stock INTEGER GENERATED ALWAYS AS (available_stock + reserved_stock) STORED,\n  last_updated TIMESTAMP NOT NULL DEFAULT NOW(),\n  version INTEGER NOT NULL DEFAULT 1  -- Optimistic concurrency\n);\nCREATE INDEX idx_inventory_product_id ON inventory(product_id);\n-- Seed data for demo\nINSERT INTO inventory (product_id, available_stock, reserved_stock)\nVALUES\n  ('prod-456', 100, 0),\n  ('prod-789', 50, 0)\nON CONFLICT (product_id) DO NOTHING;\n`\nReservations Table\nECommerce InventoryWorker/Database/Migrations/002_CreateReservationsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS inventory_reservations (\n  reservation_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL,\n  product_id TEXT NOT NULL REFERENCES inventory(product_id),\n  quantity_reserved INTEGER NOT NULL,\n  status TEXT NOT NULL,  -- 'Reserved', 'Released', 'Committed'\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  expires_at TIMESTAMP NOT NULL  -- Auto-release after N minutes\n);\nCREATE INDEX idx_reservations_order_id ON inventory_reservations(order_id);\nCREATE INDEX idx_reservations_product_id ON inventory_reservations(product_id);\nCREATE INDEX idx_reservations_expires_at ON inventory_reservations(expires_at)\n  WHERE status = 'Reserved';\n`\nInbox Table\nECommerce InventoryWorker/Database/Migrations/003_CreateInboxTable",
        "startIndex": 3340,
        "preview": "via PostgreSQL --- Step 1: Define Events InventoryReserved Event ECommerce Contracts/Events/InventoryReserved cs: `csharp using Whizbang Core; namespa..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-2",
        "text": "NOT NULL, status TEXT NOT NULL, -- 'Reserved', 'Released', 'Committed' created_at TIMESTAMP NOT NULL DEFAULT NOW(), expires_at TIMESTAMP NOT NULL -- Auto-release after N minutes ); CREATE INDEX idx_reservations_order_id ON inventory_reservations(order_id); CREATE INDEX idx_reservations_product_id ON inventory_reservations(product_id); CREATE INDEX idx_reservations_expires_at ON inventory_reservations(expires_at) WHERE status = 'Reserved'; ` Inbox Table ECommerce InventoryWorker/Database/Migrations/003_CreateInboxTable sql:\n`sql\n-- Whizbang inbox pattern for exactly-once processing\nCREATE TABLE IF NOT EXISTS inbox (\n  message_id UUID PRIMARY KEY,\n  message_type TEXT NOT NULL,\n  message_body JSONB NOT NULL,\n  received_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP,\n  retry_count INTEGER NOT NULL DEFAULT 0,\n  next_retry_at TIMESTAMP,\n  error_message TEXT\n);\nCREATE INDEX idx_inbox_unprocessed ON inbox(received_at)\n  WHERE processed_at IS NULL;\n`\n---\nStep 3: Implement Receptor\nECommerce InventoryWorker/Receptors/ReserveInventoryReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce InventoryWorker Receptors;\npublic class ReserveInventoryReceptor : IReceptor<OrderCreated, InventoryReserved> {\n  private readonly NpgsqlConnection _db;\n  private readonly IMessageContext _context;\n  private readonly ILogger<ReserveInventoryReceptor> _logger;\n  public ReserveInventoryReceptor(\n    NpgsqlConnection db,\n    IMessageContext context,\n    ILogger<ReserveInventoryReceptor> logger\n  ) {\n    _db = db;\n    _context = context;\n    _logger = logger;\n  }\n  public async Task<InventoryReserved> HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // Process each item in the order\n      foreach (var item in @event Items) {\n        // 1 Check available stock\n        var inventory = await _db QuerySingleOrDefaultAsync<InventoryRow>(\n          \"\"\"\n          SELECT product_id, available_stock, reserved_stock, version\n          FROM inventory\n          WHERE product_id = @ProductId\n          FOR UPDATE  -- Row-level lock for concurrency\n          \"\"\",\n          new { ProductId = item ProductId },\n          transaction: tx\n        );\n        if (inventory == null) {\n          throw new InvalidOperationException($\"Product {item ProductId} not found\");\n        }\n        // 2 Check if sufficient stock\n        if (inventory AvailableStock < item Quantity) {\n          // Publish InventoryInsufficient event (compensation)\n          var insufficientEvent = new InventoryInsufficient(\n            OrderId: @event OrderId,\n            ProductId: item ProductId,\n            RequestedQuantity: item Quantity,\n            AvailableStock: inventory AvailableStock,\n            CheckedAt: DateTime",
        "startIndex": 5279,
        "preview": "NOT NULL, status TEXT NOT NULL, -- 'Reserved', 'Released', 'Committed' created_at TIMESTAMP NOT NULL DEFAULT NOW(), expires_at TIMESTAMP NOT NULL -- A..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-3",
        "text": "if (inventory == null) { throw new InvalidOperationException($\"Product {item ProductId} not found\"); } // 2 Check if sufficient stock if (inventory AvailableStock < item Quantity) { // Publish InventoryInsufficient event (compensation) var insufficientEvent = new InventoryInsufficient( OrderId: @event OrderId, ProductId: item ProductId, RequestedQuantity: item Quantity, AvailableStock: inventory AvailableStock, CheckedAt: DateTime UtcNow\n          );\n          // Insert into outbox for publishing\n          await PublishEventAsync(insufficientEvent, tx, ct);\n          _logger LogWarning(\n            \"Insufficient inventory for order {OrderId}, product {ProductId}: requested {Requested}, available {Available}\",\n            @event OrderId,\n            item ProductId,\n            item Quantity,\n            inventory AvailableStock\n          );\n          throw new InsufficientInventoryException(\n            item ProductId,\n            item Quantity,\n            inventory AvailableStock\n          );\n        }\n        // 3 Reserve stock (optimistic concurrency via version)\n        var rowsAffected = await _db ExecuteAsync(\n          \"\"\"\n          UPDATE inventory\n          SET\n            available_stock = available_stock - @Quantity,\n            reserved_stock = reserved_stock + @Quantity,\n            last_updated = NOW(),\n            version = version + 1\n          WHERE product_id = @ProductId AND version = @Version\n          \"\"\",\n          new {\n            ProductId = item ProductId,\n            Quantity = item Quantity,\n            Version = inventory Version\n          },\n          transaction: tx\n        );\n        if (rowsAffected == 0) {\n          // Optimistic concurrency violation - retry\n          throw new ConcurrencyException($\"Inventory updated concurrently for product {item ProductId}\");\n        }\n        // 4 Create reservation record\n        await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO inventory_reservations (\n            reservation_id, order_id, product_id, quantity_reserved, status, created_at, expires_at\n          )\n          VALUES (@ReservationId, @OrderId, @ProductId, @Quantity, @Status, NOW(), NOW() + INTERVAL '15 minutes')\n          \"\"\",\n          new {\n            ReservationId = Guid NewGuid() ToString(\"N\"),\n            OrderId = @event OrderId,\n            ProductId = item ProductId,\n            Quantity = item Quantity,\n            Status = \"Reserved\"\n          },\n          transaction: tx\n        );\n        // 5 Publish InventoryReserved event\n        var reservedEvent = new InventoryReserved(\n          OrderId: @event OrderId,\n          ProductId: item ProductId,\n          QuantityReserved: item Quantity,\n          RemainingStock: inventory AvailableStock - item Quantity,\n          ReservedAt: DateTime UtcNow\n        );\n        await PublishEventAsync(reservedEvent, tx, ct);\n        _logger LogInformation(\n          \"Reserved {Quantity} units of product {ProductId} for order {OrderId}, remaining stock: {RemainingStock}\",\n          item Quantity,\n          item ProductId,\n          @event OrderId,\n          inventory AvailableStock - item",
        "startIndex": 7642,
        "preview": "if (inventory == null) { throw new InvalidOperationException($\"Product {item ProductId} not found\"); } // 2 Check if sufficient stock if (inventory Av..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-4",
        "text": "= new InventoryReserved( OrderId: @event OrderId, ProductId: item ProductId, QuantityReserved: item Quantity, RemainingStock: inventory AvailableStock - item Quantity, ReservedAt: DateTime UtcNow ); await PublishEventAsync(reservedEvent, tx, ct); _logger LogInformation( \"Reserved {Quantity} units of product {ProductId} for order {OrderId}, remaining stock: {RemainingStock}\", item Quantity, item ProductId, @event OrderId, inventory AvailableStock - item Quantity\n        );\n      }\n      await tx CommitAsync(ct);\n      // Return first item's event (simplification for demo)\n      return new InventoryReserved(\n        OrderId: @event OrderId,\n        ProductId: @event Items[0] ProductId,\n        QuantityReserved: @event Items[0] Quantity,\n        RemainingStock: 0,\n        ReservedAt: DateTime UtcNow\n      );\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n  private async Task PublishEventAsync<TEvent>(\n    TEvent @event,\n    NpgsqlTransaction tx,\n    CancellationToken ct\n  ) where TEvent : IEvent {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO outbox (message_id, message_type, message_body, created_at)\n      VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW())\n      \"\"\",\n      new {\n        MessageId = Guid NewGuid(),\n        MessageType = typeof(TEvent) FullName,\n        MessageBody = System Text Json JsonSerializer Serialize(@event)\n      },\n      transaction: tx\n    );\n  }\n}\npublic record InventoryRow(\n  string ProductId,\n  int AvailableStock,\n  int ReservedStock,\n  int Version\n);\npublic class InsufficientInventoryException : Exception {\n  public InsufficientInventoryException(\n    string productId,\n    int requested,\n    int available\n  ) : base($\"Insufficient inventory for {productId}: requested {requested}, available {available}\") { }\n}\npublic class ConcurrencyException : Exception {\n  public ConcurrencyException(string message) : base(message) { }\n}\n`\nKey patterns:\n‚úÖ Row-Level Locking: FOR UPDATE prevents concurrent stock deductions\n‚úÖ Optimistic Concurrency: version column detects concurrent updates\n‚úÖ Compensation: InventoryInsufficient event published on failure\n‚úÖ Transactional: All operations (stock update + reservation + outbox) in one transaction\n---\nStep 4: Perspective (Read Model)\nECommerce InventoryWorker/Perspectives/InventorySummaryPerspective cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce InventoryWorker",
        "startIndex": 10345,
        "preview": "= new InventoryReserved( OrderId: @event OrderId, ProductId: item ProductId, QuantityReserved: item Quantity, RemainingStock: inventory AvailableStock..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-5",
        "text": "Concurrency: version column detects concurrent updates ‚úÖ Compensation: InventoryInsufficient event published on failure ‚úÖ Transactional: All operations (stock update + reservation + outbox) in one transaction --- Step 4: Perspective (Read Model) ECommerce InventoryWorker/Perspectives/InventorySummaryPerspective cs: `csharp using Whizbang Core; using ECommerce Contracts Events; using Npgsql; using Dapper; namespace ECommerce InventoryWorker Perspectives;\npublic class InventorySummaryPerspective :\n  IPerspectiveOf<InventoryReserved>,\n  IPerspectiveOf<InventoryInsufficient> {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<InventorySummaryPerspective> _logger;\n  public InventorySummaryPerspective(\n    NpgsqlConnection db,\n    ILogger<InventorySummaryPerspective> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  // Handle InventoryReserved events\n  public async Task HandleAsync(\n    InventoryReserved @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO inventory_summary (\n        product_id,\n        total_reservations,\n        total_reserved_quantity,\n        last_reservation_at\n      )\n      VALUES (@ProductId, 1, @Quantity, @ReservedAt)\n      ON CONFLICT (product_id) DO UPDATE SET\n        total_reservations = inventory_summary total_reservations + 1,\n        total_reserved_quantity = inventory_summary total_reserved_quantity + @Quantity,\n        last_reservation_at = @ReservedAt\n      \"\"\",\n      new {\n        ProductId = @event ProductId,\n        Quantity = @event QuantityReserved,\n        ReservedAt = @event ReservedAt\n      }\n    );\n    _logger LogInformation(\n      \"Updated inventory summary for product {ProductId}\",\n      @event ProductId\n    );\n  }\n  // Handle InventoryInsufficient events\n  public async Task HandleAsync(\n    InventoryInsufficient @event,\n    CancellationToken ct = default\n  ) {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO inventory_summary (\n        product_id,\n        total_insufficient_count,\n        last_insufficient_at\n      )\n      VALUES (@ProductId, 1, @CheckedAt)\n      ON CONFLICT (product_id) DO UPDATE SET\n        total_insufficient_count = inventory_summary total_insufficient_count + 1,\n        last_insufficient_at = @CheckedAt\n      \"\"\",\n      new {\n        ProductId = @event ProductId,\n        CheckedAt = @event CheckedAt\n      }\n    );\n    _logger LogWarning(\n      \"Recorded insufficient inventory for product {ProductId}\",\n      @event ProductId\n    );\n  }\n}\n`\nPerspective schema:\nECommerce InventoryWorker/Database/Migrations/004_CreateInventorySummaryTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS inventory_summary (\n  product_id TEXT PRIMARY KEY,\n  total_reservations BIGINT NOT NULL DEFAULT 0,\n  total_reserved_quantity BIGINT NOT NULL DEFAULT 0,\n  total_insufficient_count BIGINT NOT NULL DEFAULT 0,\n  last_reservation_at TIMESTAMP,\n  last_insufficient_at TIMESTAMP\n);\nCREATE INDEX idx_inventory_summary_last_reservation ON inventory_summary(last_reservation_at DESC);\n`\nWhy perspectives",
        "startIndex": 12358,
        "preview": "Concurrency: version column detects concurrent updates ‚úÖ Compensation: InventoryInsufficient event published on failure ‚úÖ Transactional: All operation..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-6",
        "text": "` Perspective schema: ECommerce InventoryWorker/Database/Migrations/004_CreateInventorySummaryTable sql: `sql CREATE TABLE IF NOT EXISTS inventory_summary ( product_id TEXT PRIMARY KEY, total_reservations BIGINT NOT NULL DEFAULT 0, total_reserved_quantity BIGINT NOT NULL DEFAULT 0, total_insufficient_count BIGINT NOT NULL DEFAULT 0, last_reservation_at TIMESTAMP, last_insufficient_at TIMESTAMP ); CREATE INDEX idx_inventory_summary_last_reservation ON inventory_summary(last_reservation_at DESC); ` Why perspectives ‚úÖ Denormalized Read Models: Fast queries without joins\n‚úÖ Event-Driven Updates: Automatically updated from events\n‚úÖ CQRS: Separate read (perspective) from write (receptor) models\n---\nStep 5: Worker Configuration\nECommerce InventoryWorker/Worker cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce InventoryWorker;\npublic class Worker : BackgroundService {\n  private readonly IWorkCoordinator _coordinator;\n  private readonly IDispatcher _dispatcher;\n  private readonly ILogger<Worker> _logger;\n  public Worker(\n    IWorkCoordinator coordinator,\n    IDispatcher dispatcher,\n    ILogger<Worker> logger\n  ) {\n    _coordinator = coordinator;\n    _dispatcher = dispatcher;\n    _logger = logger;\n  }\n  protected override async Task ExecuteAsync(CancellationToken stoppingToken) {\n    _logger LogInformation(\"Inventory Worker started\");\n    while ( stoppingToken IsCancellationRequested) {\n      try {\n        // 1 Claim work batch from inbox\n        var workBatch = await _coordinator ProcessWorkBatchAsync(\n          instanceId: Guid NewGuid(),\n          serviceName: \"InventoryWorker\",\n          hostName: Environment MachineName,\n          processId: Environment ProcessId,\n          metadata: null,\n          outboxCompletions: [],\n          outboxFailures: [],\n          inboxCompletions: [],\n          inboxFailures: [],\n          receptorCompletions: [],\n          receptorFailures: [],\n          perspectiveCompletions: [],\n          perspectiveFailures: [],\n          newOutboxMessages: [],\n          newInboxMessages: [],\n          renewOutboxLeaseIds: [],\n          renewInboxLeaseIds: [],\n          cancellationToken: stoppingToken\n        );\n        // 2 Process each inbox message\n        foreach (var inboxMessage in workBatch ClaimedInboxMessages) {\n          var @event = DeserializeEvent(inboxMessage);\n          if (@event is OrderCreated orderCreated) {\n            await _dispatcher DispatchAsync(orderCreated, stoppingToken);\n          }\n        }\n        // 3 Poll every 5 seconds\n        await Task Delay(TimeSpan FromSeconds(5), stoppingToken);\n      } catch (Exception ex) when (ex is not OperationCanceledException) {\n        _logger LogError(ex, \"Error in worker loop\");\n        await Task Delay(TimeSpan FromSeconds(10), stoppingToken);\n      }\n    }\n    _logger LogInformation(\"Inventory Worker stopped\");\n  }\n  private IEvent DeserializeEvent(InboxMessage message) {\n    // Simplified deserialization (use JsonContextRegistry in production)\n    return System Text Json JsonSerializer Deserialize<OrderCreated>(\n      message MessageBody GetRawText()\n    ) ;\n  }\n}\n`\nProgram cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang",
        "startIndex": 14968,
        "preview": "` Perspective schema: ECommerce InventoryWorker/Database/Migrations/004_CreateInventorySummaryTable sql: `sql CREATE TABLE IF NOT EXISTS inventory_sum..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-7",
        "text": "\"Error in worker loop\"); await Task Delay(TimeSpan FromSeconds(10), stoppingToken); } } _logger LogInformation(\"Inventory Worker stopped\"); } private IEvent DeserializeEvent(InboxMessage message) { // Simplified deserialization (use JsonContextRegistry in production) return System Text Json JsonSerializer Deserialize<OrderCreated>( message MessageBody GetRawText() ) ; } } ` Program cs: `csharp using Whizbang Core; using Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Npgsql;\nusing ECommerce InventoryWorker;\nvar builder = Host CreateApplicationBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"InventoryWorker\";\n  options EnableInbox = true;\n  options EnableOutbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"InventoryDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Add Worker\nbuilder Services AddHostedService<Worker>();\nvar host = builder Build();\n// Run migrations\nawait host MigrateDatabaseAsync();\nawait host RunAsync();\n`\n---\nStep 6: Aspire Integration\nUpdate ECommerce AppHost/Program cs:\n`csharp\nvar builder = DistributedApplication CreateBuilder(args);\n// 1 PostgreSQL\nvar postgres = builder AddPostgres(\"postgres\") WithPgAdmin();\nvar ordersDb = postgres AddDatabase(\"orders-db\");\nvar inventoryDb = postgres AddDatabase(\"inventory-db\");  // NEW\n// 2 Azure Service Bus\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();\n// 3 Order Service\nvar orderService = builder AddProject<Projects ECommerce_OrderService_API>(\"order-service\") WithReference(ordersDb) WithReference(serviceBus);\n// 4 Inventory Worker (NEW)\nvar inventoryWorker = builder AddProject<Projects ECommerce_InventoryWorker>(\"inventory-worker\") WithReference(inventoryDb) WithReference(serviceBus);\nbuilder Build() Run();\n`\nappsettings json:\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Whizbang\": \"Debug\"\n    }\n  },\n  \"ConnectionStrings\": {\n    \"InventoryDb\": \"Host=localhost;Database=inventory;Username=postgres;Password=postgres\"\n  },\n  \"Whizbang\": {\n    \"ServiceName\": \"InventoryWorker\",\n    \"Inbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 100,\n      \"PollingInterval\": \"00:00:05\"\n    },\n    \"Outbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 100,\n      \"PollingInterval\": \"00:00:05\"\n    }\n  }\n}\n`\n---\nStep 7: Test the Flow\nStart Aspire\n`bash\ncd ECommerce AppHost\ndotnet run\n`\nCreate Order (Triggers Inventory Reservation)\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"cust-123\",\n    \"items\": [\n      { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19",
        "startIndex": 3672,
        "preview": "\"Error in worker loop\"); await Task Delay(TimeSpan FromSeconds(10), stoppingToken); } } _logger LogInformation(\"Inventory Worker stopped\"); } private ..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-8",
        "text": "100, \"PollingInterval\": \"00:00:05\" } } } ` --- Step 7: Test the Flow Start Aspire `bash cd ECommerce AppHost dotnet run ` Create Order (Triggers Inventory Reservation) `bash curl -X POST http://localhost:5000/api/orders \\ -H \"Content-Type: application/json\" \\ -d '{ \"customerId\": \"cust-123\", \"items\": [ { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19 99 }\n    ],\n    \"shippingAddress\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"Springfield\",\n      \"state\": \"IL\",\n      \"zipCode\": \"62701\",\n      \"country\": \"USA\"\n    }\n  }'\n`\nObserve Event Flow\nCheck Aspire Dashboard:\nOrder Service: OrderCreated event published to Service Bus\nService Bus: Event routed to OrderCreated topic\nInventory Worker: Receives event from inbox\nInventory Worker: Processes event via ReserveInventoryReceptor\nService Bus: InventoryReserved event published\nVerify Database\n`sql\n-- Check inventory (stock should be reduced)\nSELECT * FROM inventory WHERE product_id = 'prod-456';\n-- Check reservations\nSELECT * FROM inventory_reservations WHERE product_id = 'prod-456';\n-- Check perspective (read model)\nSELECT * FROM inventory_summary WHERE product_id = 'prod-456';\n`\nExpected:\ninventory available_stock decreased by 2\ninventory reserved_stock increased by 2\nNew row in inventory_reservations\ninventory_summary total_reservations incremented\n---\nKey Concepts\nInbox Pattern (Exactly-Once Processing)\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Inbox Pattern - Exactly-Once Processing            ‚îÇ\n‚îÇ                                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ  ‚îÇ  Azure Service Bus               ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  - Message delivered to worker   ‚îÇ               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îÇ                 ‚îÇ                                    ‚îÇ\n‚îÇ                 ‚ñº                                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ  ‚îÇ  PostgreSQL Transaction          ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ                                   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  1 INSERT INTO inbox (msg_id)   ‚îÇ ‚Üê Dedupe ‚îÇ\n‚îÇ  ‚îÇ  2 Process message (receptor)   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  3",
        "startIndex": 20052,
        "preview": "100, \"PollingInterval\": \"00:00:05\" } } } ` --- Step 7: Test the Flow Start Aspire `bash cd ECommerce AppHost dotnet run ` Create Order (Triggers Inven..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-9",
        "text": "Message delivered to worker ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚ñº ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ PostgreSQL Transaction ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 INSERT INTO inbox (msg_id) ‚îÇ ‚Üê Dedupe ‚îÇ ‚îÇ ‚îÇ 2 Process message (receptor) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 3 UPDATE inbox SET processed   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ                                   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  COMMIT;                          ‚îÇ               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îÇ                                                      ‚îÇ\n‚îÇ  If duplicate message arrives:                      ‚îÇ\n‚îÇ  - INSERT fails (unique constraint on msg_id)       ‚îÇ\n‚îÇ  - Message skipped (already processed)              ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\n‚úÖ Exactly-Once: Duplicate messages automatically skipped\n‚úÖ Idempotent: Safe to retry failed messages\n‚úÖ Transactional: Processing + inbox update atomic\nCompensation (Saga Pattern)\n`\nSuccess Flow:\nOrderCreated ‚Üí InventoryReserved ‚Üí PaymentProcessed ‚Üí ShipmentCreated\nFailure Flow (Insufficient Inventory):\nOrderCreated ‚Üí InventoryInsufficient ‚Üí CancelOrder (compensation)\nFailure Flow (Payment Failed):\nOrderCreated ‚Üí InventoryReserved ‚Üí PaymentFailed ‚Üí ReleaseInventory (compensation)\n`\nCompensation handler:\nECommerce InventoryWorker/Receptors/ReleaseInventoryReceptor cs:\n`csharp\npublic class ReleaseInventoryReceptor : IReceptor<PaymentFailed, InventoryReleased> {\n  public async Task<InventoryReleased> HandleAsync(\n    PaymentFailed @event,\n    CancellationToken ct = default\n  ) {\n    await using var tx = await _db BeginTransactionAsync(ct);\n    // 1 Find reservations for this order\n    var reservations = await _db QueryAsync<ReservationRow>(\n      \"\"\"\n      SELECT reservation_id, product_id, quantity_reserved\n      FROM inventory_reservations\n      WHERE order_id = @OrderId AND status = 'Reserved'\n      FOR UPDATE\n      \"\"\",\n      new { OrderId = @event OrderId },\n      transaction: tx\n    );\n    foreach (var reservation in reservations) {\n      // 2 Return stock to available\n      await _db ExecuteAsync(\n        \"\"\"\n        UPDATE inventory\n        SET\n          available_stock = available_stock + @Quantity,\n          reserved_stock = reserved_stock - @Quantity\n        WHERE product_id = @ProductId\n        \"\"\",\n        new { reservation ProductId, reservation QuantityReserved },\n        transaction: tx\n      );\n      // 3 Mark reservation as released\n      await _db ExecuteAsync(\n        \"\"\"\n        UPDATE inventory_reservations\n        SET status = 'Released'\n        WHERE reservation_id = @ReservationId\n        \"\"\",\n        new { reservation",
        "startIndex": 21875,
        "preview": "Message delivered to worker ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚ñº ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ PostgreSQL Transacti..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-10",
        "text": "SET available_stock = available_stock + @Quantity, reserved_stock = reserved_stock - @Quantity WHERE product_id = @ProductId \"\"\", new { reservation ProductId, reservation QuantityReserved }, transaction: tx ); // 3 Mark reservation as released await _db ExecuteAsync( \"\"\" UPDATE inventory_reservations SET status = 'Released' WHERE reservation_id = @ReservationId \"\"\", new { reservation ReservationId },\n        transaction: tx\n      );\n    }\n    await tx CommitAsync(ct);\n    return new InventoryReleased(@event OrderId, DateTime UtcNow);\n  }\n}\n`\n---\nTesting\nUnit Test - Sufficient Stock\n`csharp\n[Test]\npublic async Task ReserveInventory_SufficientStock_ReservesAndPublishesEventAsync() {\n  // Arrange\n  var db = new MockNpgsqlConnection();\n  db SeedInventory(\"prod-456\", availableStock: 100, reservedStock: 0);\n  var receptor = new ReserveInventoryReceptor(db, mockContext, mockLogger);\n  var @event = new OrderCreated(\n    OrderId: \"order-123\",\n    CustomerId: \"cust-456\",\n    Items: [new OrderItem(\"prod-456\", 2, 19 99m, 39 98m)],\n    // other fields\n  );\n  // Act\n  var result = await receptor HandleAsync(@event);\n  // Assert\n  await Assert That(result QuantityReserved) IsEqualTo(2);\n  await Assert That(result RemainingStock) IsEqualTo(98);\n  var inventory = db GetInventory(\"prod-456\");\n  await Assert That(inventory AvailableStock) IsEqualTo(98);\n  await Assert That(inventory ReservedStock) IsEqualTo(2);\n}\n`\nUnit Test - Insufficient Stock\n`csharp\n[Test]\npublic async Task ReserveInventory_InsufficientStock_ThrowsExceptionAsync() {\n  // Arrange\n  var db = new MockNpgsqlConnection();\n  db SeedInventory(\"prod-456\", availableStock: 1, reservedStock: 0);\n  var receptor = new ReserveInventoryReceptor(db, mockContext, mockLogger);\n  var @event = new OrderCreated(\n    OrderId: \"order-123\",\n    CustomerId: \"cust-456\",\n    Items: [new OrderItem(\"prod-456\", 2, 19 99m, 39 98m)],\n    // other fields\n  );\n  // Act & Assert\n  await Assert That(async () => await receptor HandleAsync(@event))",
        "startIndex": 24260,
        "preview": "SET available_stock = available_stock + @Quantity, reserved_stock = reserved_stock - @Quantity WHERE product_id = @ProductId \"\"\", new { reservation Pr..."
      },
      {
        "id": "v0.1.0/tutorial/inventory-service-chunk-11",
        "text": "db = new MockNpgsqlConnection(); db SeedInventory(\"prod-456\", availableStock: 1, reservedStock: 0); var receptor = new ReserveInventoryReceptor(db, mockContext, mockLogger); var @event = new OrderCreated( OrderId: \"order-123\", CustomerId: \"cust-456\", Items: [new OrderItem(\"prod-456\", 2, 19 99m, 39 98m)], // other fields ); // Act & Assert await Assert That(async () => await receptor HandleAsync(@event)) Throws<InsufficientInventoryException>();\n}\n`\n---\nNext Steps\nContinue to Payment Processing to:\nSubscribe to InventoryReserved events\nImplement payment gateway integration\nPublish PaymentProcessed events\nHandle payment failures (compensation)\n---\nKey Takeaways\n‚úÖ Inbox Pattern - Exactly-once event processing with database deduplication\n‚úÖ Row-Level Locking - FOR UPDATE prevents race conditions\n‚úÖ Optimistic Concurrency - version column detects concurrent updates\n‚úÖ Compensation - InventoryInsufficient event triggers order cancellation\n‚úÖ Perspectives - Denormalized read models for fast queries\n‚úÖ Saga Pattern - Distributed transactions with compensating actions\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 25884,
        "preview": "db = new MockNpgsqlConnection(); db SeedInventory(\"prod-456\", availableStock: 1, reservedStock: 0); var receptor = new ReserveInventoryReceptor(db, mo..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/notification-service",
    "title": "Notification Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/notification-service",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-0",
        "text": "Notification Service\nBuild the Notification Worker - a background service that subscribes to multiple events (OrderCreated, PaymentProcessed, ShipmentCreated) and sends notifications via email/SMS :::note\nThis is Part 4 of the ECommerce Tutorial Complete Payment Processing first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Notification Service Architecture                          ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                            ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  OrderCreated, PaymentProcessed, etc ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ                 ‚îÇ\n‚îÇ                                            ‚ñº                 ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n‚îÇ                          ‚îÇ  Multiple Event Receptors  ‚îÇ     ‚îÇ\n‚îÇ                          ‚îÇ  - OrderConfirmationReceptor‚îÇ    ‚îÇ\n‚îÇ                          ‚îÇ  - PaymentReceiptReceptor  ‚îÇ     ‚îÇ\n‚îÇ                          ‚îÇ  - ShipmentNotificationReceptor‚îÇ ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ                      ‚îÇ              ‚îÇ              ‚îÇ        ‚îÇ\n‚îÇ                      ‚ñº              ‚ñº              ‚ñº        ‚îÇ\n‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ                 ‚îÇTemplate ‚îÇ   ‚îÇ  Email  ‚îÇ   ‚îÇPostgres  ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇ Engine  ‚îÇ   ‚îÇProvider ‚îÇ   ‚îÇ Tracking ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇ(Scriban)‚îÇ   ‚îÇ(SendGrid‚îÇ   ‚îÇ  Table   ‚îÇ   ‚îÇ\n‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ/Twilio) ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îÇ                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Multi-event subscriptions\n‚úÖ Email notifications (SendGrid)\n‚úÖ SMS notifications (Twilio)\n‚úÖ Template rendering (Scriban)\n‚úÖ Delivery tracking\n‚úÖ Retry logic for failed sends\n---\nStep 1: Notification Providers\nEmail Provider (SendGrid)\nECommerce NotificationWorker/Services/IEmailProvider cs:\n`csharp\nnamespace ECommerce NotificationWorker Services;\npublic interface IEmailProvider {\n  Task<EmailResult> SendEmailAsync(\n    string to,\n    string subject,\n    string htmlBody,\n    string textBody = null,\n    CancellationToken ct = default\n  );\n}\npublic record EmailResult(\n  bool Success,\n  string MessageId,\n  string ErrorMessage\n);\n`\nECommerce NotificationWorker/Services/SendGridEmailProvider cs:\n`csharp\nusing SendGrid;\nusing SendGrid Helpers Mail;\nnamespace ECommerce NotificationWorker Services;\npublic class SendGridEmailProvider : IEmailProvider {\n  private readonly SendGridClient _client;\n  private readonly string _fromEmail;\n  private readonly string _fromName;\n  private readonly ILogger<SendGridEmailProvider> _logger;\n  public SendGridEmailProvider(\n    IConfiguration configuration,\n    ILogger<SendGridEmailProvider> logger\n  ) {\n    var apiKey = configuration[\"SendGrid:ApiKey\"] throw new InvalidOperationException(\"SendGrid:ApiKey not configured\");\n    _client = new SendGridClient(apiKey);\n    _fromEmail = configuration[\"SendGrid:FromEmail\"] \"noreply@ecommerce example com\";\n    _fromName = configuration[\"SendGrid:FromName\"]",
        "startIndex": 0,
        "preview": "Notification Service\nBuild the Notification Worker - a background service that subscribes to multiple events (OrderCreated, PaymentProcessed, Shipment..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-1",
        "text": "SendGridEmailProvider : IEmailProvider { private readonly SendGridClient _client; private readonly string _fromEmail; private readonly string _fromName; private readonly ILogger<SendGridEmailProvider> _logger; public SendGridEmailProvider( IConfiguration configuration, ILogger<SendGridEmailProvider> logger ) { var apiKey = configuration[\"SendGrid:ApiKey\"] throw new InvalidOperationException(\"SendGrid:ApiKey not configured\"); _client = new SendGridClient(apiKey); _fromEmail = configuration[\"SendGrid:FromEmail\"] \"noreply@ecommerce example com\"; _fromName = configuration[\"SendGrid:FromName\"] \"ECommerce Platform\";\n    _logger = logger;\n  }\n  public async Task<EmailResult> SendEmailAsync(\n    string to,\n    string subject,\n    string htmlBody,\n    string textBody = null,\n    CancellationToken ct = default\n  ) {\n    try {\n      var from = new EmailAddress(_fromEmail, _fromName);\n      var toAddress = new EmailAddress(to);\n      var msg = MailHelper CreateSingleEmail(\n        from,\n        toAddress,\n        subject,\n        textBody htmlBody,\n        htmlBody\n      );\n      var response = await _client SendEmailAsync(msg, ct);\n      if (response IsSuccessStatusCode) {\n        var messageId = response Headers GetValues(\"X-Message-Id\") FirstOrDefault();\n        _logger LogInformation(\n          \"Email sent to {To}, subject: {Subject}, messageId: {MessageId}\",\n          to,\n          subject,\n          messageId\n        );\n        return new EmailResult(\n          Success: true,\n          MessageId: messageId,\n          ErrorMessage: null\n        );\n      } else {\n        var errorBody = await response Body ReadAsStringAsync();\n        _logger LogError(\n          \"Email send failed to {To}: {StatusCode} - {Error}\",\n          to,\n          response StatusCode,\n          errorBody\n        );\n        return new EmailResult(\n          Success: false,\n          MessageId: null,\n          ErrorMessage: $\"{response StatusCode}: {errorBody}\"\n        );\n      }\n    } catch (Exception ex) {\n      _logger LogError(ex, \"Email send exception for {To}\", to);\n      return new EmailResult(\n        Success: false,\n        MessageId: null,\n        ErrorMessage: ex Message\n      );\n    }\n  }\n}\n`\nSMS Provider (Twilio)\nECommerce NotificationWorker/Services/ISmsProvider cs:\n`csharp\nnamespace ECommerce NotificationWorker Services;\npublic interface ISmsProvider {\n  Task<SmsResult> SendSmsAsync(\n    string to,\n    string message,\n    CancellationToken ct = default\n  );\n}\npublic record SmsResult(\n  bool Success,\n  string MessageSid,\n  string ErrorMessage\n);\n`\nECommerce NotificationWorker/Services/TwilioSmsProvider cs:\n`csharp\nusing Twilio;\nusing Twilio Rest Api V2010 Account;\nusing Twilio Types;\nnamespace ECommerce NotificationWorker Services;\npublic class TwilioSmsProvider : ISmsProvider {\n  private readonly string _fromNumber;\n  private readonly ILogger<TwilioSmsProvider> _logger;\n  public TwilioSmsProvider(\n    IConfiguration configuration,\n    ILogger<TwilioSmsProvider> logger\n  ) {\n    var accountSid = configuration[\"Twilio:AccountSid\"]",
        "startIndex": 3384,
        "preview": "SendGridEmailProvider : IEmailProvider { private readonly SendGridClient _client; private readonly string _fromEmail; private readonly string _fromNam..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-2",
        "text": "MessageSid, string ErrorMessage ); ` ECommerce NotificationWorker/Services/TwilioSmsProvider cs: `csharp using Twilio; using Twilio Rest Api V2010 Account; using Twilio Types; namespace ECommerce NotificationWorker Services; public class TwilioSmsProvider : ISmsProvider { private readonly string _fromNumber; private readonly ILogger<TwilioSmsProvider> _logger; public TwilioSmsProvider( IConfiguration configuration, ILogger<TwilioSmsProvider> logger ) { var accountSid = configuration[\"Twilio:AccountSid\"] throw new InvalidOperationException(\"Twilio:AccountSid not configured\");\n    var authToken = configuration[\"Twilio:AuthToken\"] throw new InvalidOperationException(\"Twilio:AuthToken not configured\");\n    _fromNumber = configuration[\"Twilio:FromNumber\"] \"+15551234567\";\n    TwilioClient Init(accountSid, authToken);\n    _logger = logger;\n  }\n  public async Task<SmsResult> SendSmsAsync(\n    string to,\n    string message,\n    CancellationToken ct = default\n  ) {\n    try {\n      var smsMessage = await MessageResource CreateAsync(\n        to: new PhoneNumber(to),\n        from: new PhoneNumber(_fromNumber),\n        body: message\n      );\n      if (smsMessage Status == MessageResource StatusEnum Queued ||\n          smsMessage Status == MessageResource StatusEnum Sent) {\n        _logger LogInformation(\n          \"SMS sent to {To}, sid: {Sid}\",\n          to,\n          smsMessage Sid\n        );\n        return new SmsResult(\n          Success: true,\n          MessageSid: smsMessage Sid,\n          ErrorMessage: null\n        );\n      } else {\n        _logger LogError(\n          \"SMS send failed to {To}: {Status} - {ErrorMessage}\",\n          to,\n          smsMessage Status,\n          smsMessage ErrorMessage\n        );\n        return new SmsResult(\n          Success: false,\n          MessageSid: null,\n          ErrorMessage: smsMessage ErrorMessage\n        );\n      }\n    } catch (Exception ex) {\n      _logger LogError(ex, \"SMS send exception for {To}\", to);\n      return new SmsResult(\n        Success: false,\n        MessageSid: null,\n        ErrorMessage: ex Message\n      );\n    }\n  }\n}\n`\n---\nStep 2: Template Engine\nECommerce NotificationWorker/Services/ITemplateRenderer cs:\n`csharp\nnamespace ECommerce NotificationWorker Services;\npublic interface ITemplateRenderer {\n  Task<string> RenderAsync<TModel>(\n    string templateName,\n    TModel model,\n    CancellationToken ct = default\n  );\n}\n`\nECommerce NotificationWorker/Services/ScribanTemplateRenderer cs:\n`csharp\nusing Scriban;\nusing Scriban Runtime;\nnamespace ECommerce NotificationWorker Services;\npublic class ScribanTemplateRenderer : ITemplateRenderer {\n  private readonly string _templateDirectory;\n  private readonly Dictionary<string, Template> _cache = new();\n  private readonly ILogger<ScribanTemplateRenderer> _logger;\n  public ScribanTemplateRenderer(\n    IConfiguration configuration,\n    ILogger<ScribanTemplateRenderer> logger\n  ) {\n    _templateDirectory = configuration[\"Templates:Directory\"]",
        "startIndex": 5866,
        "preview": "MessageSid, string ErrorMessage ); ` ECommerce NotificationWorker/Services/TwilioSmsProvider cs: `csharp using Twilio; using Twilio Rest Api V2010 Acc..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-3",
        "text": "= default ); } ` ECommerce NotificationWorker/Services/ScribanTemplateRenderer cs: `csharp using Scriban; using Scriban Runtime; namespace ECommerce NotificationWorker Services; public class ScribanTemplateRenderer : ITemplateRenderer { private readonly string _templateDirectory; private readonly Dictionary<string, Template> _cache = new(); private readonly ILogger<ScribanTemplateRenderer> _logger; public ScribanTemplateRenderer( IConfiguration configuration, ILogger<ScribanTemplateRenderer> logger ) { _templateDirectory = configuration[\"Templates:Directory\"] \"Templates\";\n    _logger = logger;\n  }\n  public async Task<string> RenderAsync<TModel>(\n    string templateName,\n    TModel model,\n    CancellationToken ct = default\n  ) {\n    var template = await GetTemplateAsync(templateName, ct);\n    var scriptObject = new ScriptObject();\n    scriptObject Import(model, renamer: member => member Name);\n    var context = new TemplateContext();\n    context PushGlobal(scriptObject);\n    return await template RenderAsync(context);\n  }\n  private async Task<Template> GetTemplateAsync(string templateName, CancellationToken ct) {\n    if (_cache TryGetValue(templateName, out var cachedTemplate)) {\n      return cachedTemplate;\n    }\n    var templatePath = Path Combine(_templateDirectory, $\"{templateName} liquid\");\n    if ( File Exists(templatePath)) {\n      throw new FileNotFoundException($\"Template not found: {templatePath}\");\n    }\n    var templateContent = await File ReadAllTextAsync(templatePath, ct);\n    var template = Template Parse(templateContent);\n    if (template HasErrors) {\n      var errors = string Join(\", \", template Messages);\n      throw new InvalidOperationException($\"Template parse errors: {errors}\");\n    }\n    _cache[templateName] = template;\n    return template;\n  }\n}\n`\nTemplates/order-confirmation liquid:\n`liquid\n< DOCTYPE html>\n<html>\n<head>\n  <style>\n    body { font-family: Arial, sans-serif; } header { background-color: #4CAF50; color: white; padding: 20px; } content { padding: 20px; } order-items { border-collapse: collapse; width: 100%; } order-items th, order-items td { border: 1px solid #ddd; padding: 8px; } total { font-weight: bold; font-size: 1 2em; }\n  </style>\n</head>\n<body>\n  <div class=\"header\">\n    <h1>Order Confirmation</h1>\n  </div>\n  <div class=\"content\">\n    <p>Hi {{ customer_name }},</p>\n    <p>Thank you for your order Your order <strong>#{{ order_id }}</strong> has been received and is being processed </p>\n    <h2>Order Details</h2>\n    <table class=\"order-items\">\n      <thead>\n        <tr>\n          <th>Product</th>\n          <th>Quantity</th>\n          <th>Unit Price</th>\n          <th>Total</th>\n        </tr>\n      </thead>\n      <tbody>\n        {{ for item in items }}\n        <tr>\n          <td>{{ item product_id }}</td>\n          <td>{{ item quantity }}</td>\n          <td>${{ item unit_price }}</td>\n          <td>${{ item",
        "startIndex": 8355,
        "preview": "= default ); } ` ECommerce NotificationWorker/Services/ScribanTemplateRenderer cs: `csharp using Scriban; using Scriban Runtime; namespace ECommerce N..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-4",
        "text": "your order Your order <strong>#{{ order_id }}</strong> has been received and is being processed </p> <h2>Order Details</h2> <table class=\"order-items\"> <thead> <tr> <th>Product</th> <th>Quantity</th> <th>Unit Price</th> <th>Total</th> </tr> </thead> <tbody> {{ for item in items }} <tr> <td>{{ item product_id }}</td> <td>{{ item quantity }}</td> <td>${{ item unit_price }}</td> <td>${{ item line_total }}</td>\n        </tr>\n        {{ end }}\n      </tbody>\n    </table>\n    <p class=\"total\">Total: ${{ total_amount }}</p>\n    <h2>Shipping Address</h2>\n    <p>\n      {{ shipping_address street }}<br>\n      {{ shipping_address city }}, {{ shipping_address state }} {{ shipping_address zip_code }}<br>\n      {{ shipping_address country }}\n    </p>\n    <p>We'll send you another email when your order ships </p>\n    <p>Thanks,<br>The ECommerce Team</p>\n  </div>\n</body>\n</html>\n`\n---\nStep 3: Database Schema\nECommerce NotificationWorker/Database/Migrations/001_CreateNotificationsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS notifications (\n  notification_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL,\n  notification_type TEXT NOT NULL,  -- 'OrderConfirmation', 'PaymentReceipt', 'ShipmentNotification'\n  channel TEXT NOT NULL,  -- 'Email', 'SMS'\n  recipient TEXT NOT NULL,\n  subject TEXT,\n  message TEXT NOT NULL,\n  status TEXT NOT NULL,  -- 'Sent', 'Failed', 'Pending'\n  provider_message_id TEXT,\n  error_message TEXT,\n  sent_at TIMESTAMP,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_notifications_order_id ON notifications(order_id);\nCREATE INDEX idx_notifications_status ON notifications(status);\nCREATE INDEX idx_notifications_created_at ON notifications(created_at DESC);\n`\n---\nStep 4: Implement Receptors\nOrder Confirmation Receptor\nECommerce NotificationWorker/Receptors/OrderConfirmationReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce NotificationWorker Services;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce NotificationWorker Receptors;\npublic class OrderConfirmationReceptor : IReceptor<OrderCreated, NotificationSent> {\n  private readonly NpgsqlConnection _db;\n  private readonly IEmailProvider _emailProvider;\n  private readonly ITemplateRenderer _templateRenderer;\n  private readonly ILogger<OrderConfirmationReceptor> _logger;\n  public OrderConfirmationReceptor(\n    NpgsqlConnection db,\n    IEmailProvider emailProvider,\n    ITemplateRenderer templateRenderer,\n    ILogger<OrderConfirmationReceptor> logger\n  ) {\n    _db = db;\n    _emailProvider = emailProvider;\n    _templateRenderer = templateRenderer;\n    _logger = logger;\n  }\n  public async Task<NotificationSent> HandleAsync(\n    OrderCreated @event,\n    CancellationToken ct = default\n  ) {\n    var notificationId = Guid NewGuid() ToString(\"N\");\n    try {\n      // 1",
        "startIndex": 10717,
        "preview": "your order Your order <strong>#{{ order_id }}</strong> has been received and is being processed </p> <h2>Order Details</h2> <table class=\"order-items\"..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-5",
        "text": "readonly ILogger<OrderConfirmationReceptor> _logger; public OrderConfirmationReceptor( NpgsqlConnection db, IEmailProvider emailProvider, ITemplateRenderer templateRenderer, ILogger<OrderConfirmationReceptor> logger ) { _db = db; _emailProvider = emailProvider; _templateRenderer = templateRenderer; _logger = logger; } public async Task<NotificationSent> HandleAsync( OrderCreated @event, CancellationToken ct = default ) { var notificationId = Guid NewGuid() ToString(\"N\"); try { // 1 Get customer email (in production, query customer service)\n      var customerEmail = $\"{@event CustomerId}@example com\";  // Demo\n      // 2 Render email template\n      var htmlBody = await _templateRenderer RenderAsync(\n        \"order-confirmation\",\n        new {\n          customer_name = @event CustomerId,\n          order_id = @event OrderId,\n          items = @event Items Select(i => new {\n            product_id = i ProductId,\n            quantity = i Quantity,\n            unit_price = i UnitPrice,\n            line_total = i LineTotal\n          }),\n          total_amount = @event TotalAmount,\n          shipping_address = new {\n            street = @event ShippingAddress Street,\n            city = @event ShippingAddress City,\n            state = @event ShippingAddress State,\n            zip_code = @event ShippingAddress ZipCode,\n            country = @event ShippingAddress Country\n          }\n        },\n        ct\n      );\n      // 3 Send email\n      var result = await _emailProvider SendEmailAsync(\n        to: customerEmail,\n        subject: $\"Order Confirmation - #{@event OrderId}\",\n        htmlBody: htmlBody,\n        ct: ct\n      );\n      // 4 Track notification\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO notifications (\n          notification_id, order_id, notification_type, channel, recipient, subject, message,\n          status, provider_message_id, error_message, sent_at, created_at\n        )\n        VALUES (\n          @NotificationId, @OrderId, @NotificationType, @Channel, @Recipient, @Subject, @Message,\n          @Status, @ProviderMessageId, @ErrorMessage, @SentAt, NOW()\n        )\n        \"\"\",\n        new {\n          NotificationId = notificationId,\n          OrderId = @event OrderId,\n          NotificationType = \"OrderConfirmation\",\n          Channel = \"Email\",\n          Recipient = customerEmail,\n          Subject = $\"Order Confirmation - #{@event OrderId}\",\n          Message = htmlBody,\n          Status = result Success \"Sent\" : \"Failed\",\n          ProviderMessageId = result MessageId,\n          ErrorMessage = result ErrorMessage,\n          SentAt = result Success DateTime UtcNow : (DateTime )null\n        }\n      );\n      if (result Success) {\n        _logger LogInformation(\n          \"Order confirmation sent for order {OrderId} to {Email}\",\n          @event OrderId,\n          customerEmail\n        );\n        return new NotificationSent(\n          NotificationId: notificationId,\n          OrderId: @event OrderId,\n          NotificationType: \"OrderConfirmation\",\n          Channel: \"Email\",\n          SentAt: DateTime",
        "startIndex": 13133,
        "preview": "readonly ILogger<OrderConfirmationReceptor> _logger; public OrderConfirmationReceptor( NpgsqlConnection db, IEmailProvider emailProvider, ITemplateRen..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-6",
        "text": "= result MessageId, ErrorMessage = result ErrorMessage, SentAt = result Success DateTime UtcNow : (DateTime )null } ); if (result Success) { _logger LogInformation( \"Order confirmation sent for order {OrderId} to {Email}\", @event OrderId, customerEmail ); return new NotificationSent( NotificationId: notificationId, OrderId: @event OrderId, NotificationType: \"OrderConfirmation\", Channel: \"Email\", SentAt: DateTime UtcNow\n        );\n      } else {\n        throw new NotificationFailedException(\n          notificationId,\n          \"OrderConfirmation\",\n          result ErrorMessage \"Email send failed\"\n        );\n      }\n    } catch (Exception ex) when (ex is not NotificationFailedException) {\n      _logger LogError(ex, \"Failed to send order confirmation for order {OrderId}\", @event OrderId);\n      throw new NotificationFailedException(notificationId, \"OrderConfirmation\", ex Message);\n    }\n  }\n}\npublic record NotificationSent(\n  string NotificationId,\n  string OrderId,\n  string NotificationType,\n  string Channel,\n  DateTime SentAt\n) : IEvent;\npublic class NotificationFailedException : Exception {\n  public NotificationFailedException(string notificationId, string type, string message)\n    : base($\"Notification {notificationId} ({type}) failed: {message}\") { }\n}\n`\nPayment Receipt Receptor\nECommerce NotificationWorker/Receptors/PaymentReceiptReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce NotificationWorker Services;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce NotificationWorker Receptors;\npublic class PaymentReceiptReceptor : IReceptor<PaymentProcessed, NotificationSent> {\n  private readonly NpgsqlConnection _db;\n  private readonly IEmailProvider _emailProvider;\n  private readonly ITemplateRenderer _templateRenderer;\n  private readonly ILogger<PaymentReceiptReceptor> _logger;\n  public PaymentReceiptReceptor(\n    NpgsqlConnection db,\n    IEmailProvider emailProvider,\n    ITemplateRenderer templateRenderer,\n    ILogger<PaymentReceiptReceptor> logger\n  ) {\n    _db = db;\n    _emailProvider = emailProvider;\n    _templateRenderer = templateRenderer;\n    _logger = logger;\n  }\n  public async Task<NotificationSent> HandleAsync(\n    PaymentProcessed @event,\n    CancellationToken ct = default\n  ) {\n    var notificationId = Guid NewGuid() ToString(\"N\");\n    // Similar implementation to OrderConfirmationReceptor\n    // Render \"payment-receipt\" template and send email\n    // For brevity, omitted - follows same pattern as OrderConfirmation\n    return new NotificationSent(\n      NotificationId: notificationId,\n      OrderId: @event OrderId,\n      NotificationType: \"PaymentReceipt\",\n      Channel: \"Email\",\n      SentAt: DateTime UtcNow\n    );\n  }\n}\n`\nShipment Notification Receptor (SMS)\nECommerce NotificationWorker/Receptors/ShipmentNotificationReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce NotificationWorker Services;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce NotificationWorker",
        "startIndex": 15732,
        "preview": "= result MessageId, ErrorMessage = result ErrorMessage, SentAt = result Success DateTime UtcNow : (DateTime )null } ); if (result Success) { _logger L..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-7",
        "text": "follows same pattern as OrderConfirmation return new NotificationSent( NotificationId: notificationId, OrderId: @event OrderId, NotificationType: \"PaymentReceipt\", Channel: \"Email\", SentAt: DateTime UtcNow ); } } ` Shipment Notification Receptor (SMS) ECommerce NotificationWorker/Receptors/ShipmentNotificationReceptor cs: `csharp using Whizbang Core; using ECommerce Contracts Events; using ECommerce NotificationWorker Services; using Npgsql; using Dapper; namespace ECommerce NotificationWorker Receptors;\npublic class ShipmentNotificationReceptor : IReceptor<ShipmentCreated, NotificationSent> {\n  private readonly NpgsqlConnection _db;\n  private readonly ISmsProvider _smsProvider;\n  private readonly ILogger<ShipmentNotificationReceptor> _logger;\n  public ShipmentNotificationReceptor(\n    NpgsqlConnection db,\n    ISmsProvider smsProvider,\n    ILogger<ShipmentNotificationReceptor> logger\n  ) {\n    _db = db;\n    _smsProvider = smsProvider;\n    _logger = logger;\n  }\n  public async Task<NotificationSent> HandleAsync(\n    ShipmentCreated @event,\n    CancellationToken ct = default\n  ) {\n    var notificationId = Guid NewGuid() ToString(\"N\");\n    try {\n      // 1 Get customer phone (in production, query customer service)\n      var customerPhone = \"+15551234567\";  // Demo\n      // 2 Build SMS message\n      var message = $\"Your order #{@event OrderId} has shipped \" +\n                    $\"Tracking: {@event TrackingNumber} \" +\n                    $\"Estimated delivery: {@event EstimatedDelivery:MM/dd/yyyy}\";\n      // 3 Send SMS\n      var result = await _smsProvider SendSmsAsync(\n        to: customerPhone,\n        message: message,\n        ct: ct\n      );\n      // 4 Track notification\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO notifications (\n          notification_id, order_id, notification_type, channel, recipient, message,\n          status, provider_message_id, error_message, sent_at, created_at\n        )\n        VALUES (\n          @NotificationId, @OrderId, @NotificationType, @Channel, @Recipient, @Message,\n          @Status, @ProviderMessageId, @ErrorMessage, @SentAt, NOW()\n        )\n        \"\"\",\n        new {\n          NotificationId = notificationId,\n          OrderId = @event OrderId,\n          NotificationType = \"ShipmentNotification\",\n          Channel = \"SMS\",\n          Recipient = customerPhone,\n          Message = message,\n          Status = result Success \"Sent\" : \"Failed\",\n          ProviderMessageId = result MessageSid,\n          ErrorMessage = result ErrorMessage,\n          SentAt = result Success DateTime UtcNow : (DateTime )null\n        }\n      );\n      if (result Success) {\n        _logger LogInformation(\n          \"Shipment notification sent for order {OrderId} to {Phone}\",\n          @event OrderId,\n          customerPhone\n        );\n        return new NotificationSent(\n          NotificationId: notificationId,\n          OrderId: @event OrderId,\n          NotificationType: \"ShipmentNotification\",\n          Channel: \"SMS\",\n          SentAt: DateTime UtcNow\n        );\n      } else {\n        throw new NotificationFailedException(\n          notificationId,\n          \"ShipmentNotification\",\n          result ErrorMessage",
        "startIndex": 18325,
        "preview": "follows same pattern as OrderConfirmation return new NotificationSent( NotificationId: notificationId, OrderId: @event OrderId, NotificationType: \"Pay..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-8",
        "text": "UtcNow : (DateTime )null } ); if (result Success) { _logger LogInformation( \"Shipment notification sent for order {OrderId} to {Phone}\", @event OrderId, customerPhone ); return new NotificationSent( NotificationId: notificationId, OrderId: @event OrderId, NotificationType: \"ShipmentNotification\", Channel: \"SMS\", SentAt: DateTime UtcNow ); } else { throw new NotificationFailedException( notificationId, \"ShipmentNotification\", result ErrorMessage \"SMS send failed\"\n        );\n      }\n    } catch (Exception ex) when (ex is not NotificationFailedException) {\n      _logger LogError(ex, \"Failed to send shipment notification for order {OrderId}\", @event OrderId);\n      throw new NotificationFailedException(notificationId, \"ShipmentNotification\", ex Message);\n    }\n  }\n}\n`\n---\nStep 5: Service Configuration\nECommerce NotificationWorker/Program cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Npgsql;\nusing ECommerce NotificationWorker Services;\nvar builder = Host CreateApplicationBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"NotificationWorker\";\n  options EnableInbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"NotificationDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Add notification providers\nbuilder Services AddSingleton<IEmailProvider, SendGridEmailProvider>();\nbuilder Services AddSingleton<ISmsProvider, TwilioSmsProvider>();\nbuilder Services AddSingleton<ITemplateRenderer, ScribanTemplateRenderer>();\n// 5 Add Worker\nbuilder Services AddHostedService<Worker>();\nvar host = builder Build();\nawait host MigrateDatabaseAsync();\nawait host RunAsync();\n`\nappsettings json:\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Whizbang\": \"Debug\"\n    }\n  },\n  \"ConnectionStrings\": {\n    \"NotificationDb\": \"Host=localhost;Database=notification;Username=postgres;Password=postgres\"\n  },\n  \"SendGrid\": {\n    \"ApiKey\": \"SG xxx\",\n    \"FromEmail\": \"noreply@ecommerce example com\",\n    \"FromName\": \"ECommerce Platform\"\n  },\n  \"Twilio\": {\n    \"AccountSid\": \"ACxxx\",\n    \"AuthToken\": \"xxx\",\n    \"FromNumber\": \"+15551234567\"\n  },\n  \"Templates\": {\n    \"Directory\": \"Templates\"\n  },\n  \"Whizbang\": {\n    \"ServiceName\": \"NotificationWorker\",\n    \"Inbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 100,\n      \"PollingInterval\": \"00:00:05\"\n    }\n  }\n}\n`\n---\nStep 6: Test Notifications\nUpdate Aspire\nECommerce AppHost/Program cs:\n`csharp\nvar notificationDb = postgres AddDatabase(\"notification-db\");\nvar notificationWorker = builder AddProject<Projects ECommerce_NotificationWorker>(\"notification-worker\") WithReference(notificationDb) WithReference(serviceBus);\n`\nCreate Order\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{",
        "startIndex": 21036,
        "preview": "UtcNow : (DateTime )null } ); if (result Success) { _logger LogInformation( \"Shipment notification sent for order {OrderId} to {Phone}\", @event OrderI..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-9",
        "text": "{ \"Enabled\": true, \"BatchSize\": 100, \"PollingInterval\": \"00:00:05\" } } } ` --- Step 6: Test Notifications Update Aspire ECommerce AppHost/Program cs: `csharp var notificationDb = postgres AddDatabase(\"notification-db\"); var notificationWorker = builder AddProject<Projects ECommerce_NotificationWorker>(\"notification-worker\") WithReference(notificationDb) WithReference(serviceBus); ` Create Order `bash curl -X POST http://localhost:5000/api/orders \\ -H \"Content-Type: application/json\" \\ -d '{ }'\n`\nCheck Email (SendGrid Dashboard)\nNavigate to SendGrid dashboard ‚Üí Activity Feed ‚Üí Search for recipient email\nVerify Database\n`sql\nSELECT * FROM notifications WHERE order_id = '<order-id>';\n`\nExpected:\nRow for OrderConfirmation (Email) with status = 'Sent'\nRow for PaymentReceipt (Email) with status = 'Sent'\nRow for ShipmentNotification (SMS) with status = 'Sent'\n---\nKey Concepts\nMulti-Event Subscriptions\n`csharp\n// Single service subscribes to multiple events\npublic class OrderConfirmationReceptor : IReceptor<OrderCreated, NotificationSent> { }\npublic class PaymentReceiptReceptor : IReceptor<PaymentProcessed, NotificationSent> { }\npublic class ShipmentNotificationReceptor : IReceptor<ShipmentCreated, NotificationSent> { }\n`\nAzure Service Bus:\nOrderCreated ‚Üí order-confirmation-subscription\nPaymentProcessed ‚Üí payment-receipt-subscription\nShipmentCreated ‚Üí shipment-notification-subscription\nTemplate Rendering\n`liquid\n{{ for item in items }}\n  <tr>\n    <td>{{ item product_id }}</td>\n    <td>{{ item quantity }}</td>\n    <td>${{ item unit_price }}</td>\n  </tr>\n{{ end }}\n`\nBenefits:\n‚úÖ Separation of Concerns: Business logic separate from presentation\n‚úÖ Non-Technical Editing: Marketing can update templates\n‚úÖ Testability: Unit test template rendering independently\n---\nTesting\nUnit Test - Email Rendering\n`csharp\n[Test]\npublic async Task OrderConfirmation_RendersTemplateCorrectlyAsync() {\n  // Arrange\n  var renderer = new ScribanTemplateRenderer(mockConfig, mockLogger);\n  var model = new {\n    customer_name = \"John Doe\",\n    order_id = \"order-123\",\n    items = new[] {\n      new { product_id = \"prod-456\", quantity = 2, unit_price = 19 99m, line_total = 39 98m }\n    },\n    total_amount = 39 98m,\n    shipping_address = new { street = \"123 Main\", city = \"Springfield\", state = \"IL\", zip_code = \"62701\", country = \"USA\" }\n  };\n  // Act\n  var html = await renderer",
        "startIndex": 23615,
        "preview": "{ \"Enabled\": true, \"BatchSize\": 100, \"PollingInterval\": \"00:00:05\" } } } ` --- Step 6: Test Notifications Update Aspire ECommerce AppHost/Program cs: ..."
      },
      {
        "id": "v0.1.0/tutorial/notification-service-chunk-10",
        "text": "{ product_id = \"prod-456\", quantity = 2, unit_price = 19 99m, line_total = 39 98m } }, total_amount = 39 98m, shipping_address = new { street = \"123 Main\", city = \"Springfield\", state = \"IL\", zip_code = \"62701\", country = \"USA\" } }; // Act var html = await renderer RenderAsync(\"order-confirmation\", model);\n  // Assert\n  await Assert That(html) Contains(\"Order Confirmation\");\n  await Assert That(html) Contains(\"order-123\");\n  await Assert That(html) Contains(\"$39 98\");\n}\n`\n---\nNext Steps\nContinue to Shipping Service to:\nSubscribe to PaymentProcessed events\nCreate shipments via carrier API\nPublish ShipmentCreated events\nTrack shipment status\n---\nKey Takeaways\n‚úÖ Multi-Event Subscriptions - Single service handles multiple event types\n‚úÖ Template Rendering - Scriban for maintainable email templates\n‚úÖ Provider Abstraction - Swap email/SMS providers easily\n‚úÖ Delivery Tracking - Store notification history for auditing\n‚úÖ Graceful Failures - Log errors, don't block order processing\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 25496,
        "preview": "{ product_id = \"prod-456\", quantity = 2, unit_price = 19 99m, line_total = 39 98m } }, total_amount = 39 98m, shipping_address = new { street = \"123 M..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/order-management",
    "title": "Order Management Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/order-management",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/order-management-chunk-0",
        "text": "Order Management Service\nBuild the Order Service - an HTTP API that accepts order creation requests, validates them, persists to PostgreSQL, and publishes events to Azure Service Bus :::note\nThis is Part 1 of the ECommerce Tutorial Start with Tutorial Overview if you haven't already :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Order Service Architecture                             ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ\n‚îÇ  ‚îÇ    HTTP      ‚îÇ                                       ‚îÇ\n‚îÇ  ‚îÇ  Controller  ‚îÇ  POST /orders                         ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ\n‚îÇ         ‚îÇ                                                ‚îÇ\n‚îÇ         ‚ñº                                                ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  CreateOrder command                  ‚îÇ\n‚îÇ  ‚îÇ  Dispatcher  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ             ‚îÇ\n‚îÇ                                            ‚ñº             ‚îÇ\n‚îÇ                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ                                 ‚îÇ CreateOrderReceptor ‚îÇ ‚îÇ\n‚îÇ                                 ‚îÇ  - Validate order   ‚îÇ ‚îÇ\n‚îÇ                                 ‚îÇ  - Save to DB       ‚îÇ ‚îÇ\n‚îÇ                                 ‚îÇ  - Publish event    ‚îÇ ‚îÇ\n‚îÇ                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ                                           ‚îÇ             ‚îÇ\n‚îÇ                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ                              ‚îÇ            ‚îÇ           ‚îÇ ‚îÇ\n‚îÇ                              ‚ñº            ‚ñº           ‚ñº ‚îÇ\n‚îÇ                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                         ‚îÇPostgres‚îÇ  ‚îÇ Outbox  ‚îÇ  ‚îÇ ASB ‚îÇ\n‚îÇ                         ‚îÇ Orders ‚îÇ  ‚îÇ Table   ‚îÇ  ‚îÇ Bus ‚îÇ\n‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ HTTP API endpoint for order creation\n‚úÖ Command handling with validation\n‚úÖ PostgreSQL persistence with outbox pattern\n‚úÖ Event publishing to Azure Service Bus\n‚úÖ Message context (correlation, causation, tracing)\n‚úÖ NET Aspire orchestration\n---\nStep 1: Define Messages\nCommands\nECommerce Contracts/Commands/CreateOrder cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts Commands;\npublic record CreateOrder(\n  string CustomerId,\n  OrderItem[] Items,\n  Address ShippingAddress\n) : ICommand<OrderCreated>;\npublic record OrderItem(\n  string ProductId,\n  int Quantity,\n  decimal UnitPrice\n);\npublic record Address(\n  string Street,\n  string City,\n  string State,\n  string ZipCode,\n  string Country\n);\n`\nEvents\nECommerce Contracts/Events/OrderCreated cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts",
        "startIndex": 0,
        "preview": "Order Management Service\nBuild the Order Service - an HTTP API that accepts order creation requests, validates them, persists to PostgreSQL, and publi..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-1",
        "text": "Contracts Commands; public record CreateOrder( string CustomerId, OrderItem[] Items, Address ShippingAddress ) : ICommand<OrderCreated>; public record OrderItem( string ProductId, int Quantity, decimal UnitPrice ); public record Address( string Street, string City, string State, string ZipCode, string Country ); ` Events ECommerce Contracts/Events/OrderCreated cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events;\npublic record OrderCreated(\n  string OrderId,\n  string CustomerId,\n  OrderItem[] Items,\n  Address ShippingAddress,\n  decimal TotalAmount,\n  DateTime CreatedAt\n) : IEvent;\npublic record OrderItem(\n  string ProductId,\n  int Quantity,\n  decimal UnitPrice,\n  decimal LineTotal\n);\npublic record Address(\n  string Street,\n  string City,\n  string State,\n  string ZipCode,\n  string Country\n);\n`\nWhy separate records Commands and events have different lifecycles\nEvent includes calculated fields (OrderId, TotalAmount, LineTotal)\nEvent is immutable history, command is intent\n---\nStep 2: Database Schema\nOrders Table\nECommerce OrderService API/Database/Migrations/001_CreateOrdersTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS orders (\n  order_id TEXT PRIMARY KEY,\n  customer_id TEXT NOT NULL,\n  total_amount NUMERIC(10, 2) NOT NULL,\n  status TEXT NOT NULL,\n  shipping_address JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_orders_customer_id ON orders(customer_id);\nCREATE INDEX idx_orders_created_at ON orders(created_at DESC);\n`\nOrder Items Table\nECommerce OrderService API/Database/Migrations/002_CreateOrderItemsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS order_items (\n  order_item_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL REFERENCES orders(order_id) ON DELETE CASCADE,\n  product_id TEXT NOT NULL,\n  quantity INTEGER NOT NULL,\n  unit_price NUMERIC(10, 2) NOT NULL,\n  line_total NUMERIC(10, 2) NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_order_items_order_id ON order_items(order_id);\nCREATE INDEX idx_order_items_product_id ON order_items(product_id);\n`\nOutbox Table\nECommerce OrderService API/Database/Migrations/003_CreateOutboxTable",
        "startIndex": 2825,
        "preview": "Contracts Commands; public record CreateOrder( string CustomerId, OrderItem[] Items, Address ShippingAddress ) : ICommand<OrderCreated>; public record..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-2",
        "text": "order_id TEXT NOT NULL REFERENCES orders(order_id) ON DELETE CASCADE, product_id TEXT NOT NULL, quantity INTEGER NOT NULL, unit_price NUMERIC(10, 2) NOT NULL, line_total NUMERIC(10, 2) NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT NOW() ); CREATE INDEX idx_order_items_order_id ON order_items(order_id); CREATE INDEX idx_order_items_product_id ON order_items(product_id); ` Outbox Table ECommerce OrderService API/Database/Migrations/003_CreateOutboxTable sql:\n`sql\n-- Whizbang outbox pattern for reliable event publishing\nCREATE TABLE IF NOT EXISTS outbox (\n  message_id UUID PRIMARY KEY,\n  message_type TEXT NOT NULL,\n  message_body JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP,\n  retry_count INTEGER NOT NULL DEFAULT 0,\n  next_retry_at TIMESTAMP,\n  error_message TEXT\n);\nCREATE INDEX idx_outbox_unprocessed ON outbox(created_at)\n  WHERE processed_at IS NULL;\n`\n---\nStep 3: Implement Receptor\nECommerce OrderService API/Receptors/CreateOrderReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Commands;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce OrderService API Receptors;\npublic class CreateOrderReceptor : IReceptor<CreateOrder, OrderCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly IMessageContext _context;\n  private readonly ILogger<CreateOrderReceptor> _logger;\n  public CreateOrderReceptor(\n    NpgsqlConnection db,\n    IMessageContext context,\n    ILogger<CreateOrderReceptor> logger\n  ) {\n    _db = db;\n    _context = context;\n    _logger = logger;\n  }\n  public async Task<OrderCreated> HandleAsync(\n    CreateOrder command,\n    CancellationToken ct = default\n  ) {\n    // 1 Validate\n    if (command Items Length == 0) {\n      throw new ValidationException(\"Order must have at least one item\");\n    }\n    // 2 Calculate totals\n    var orderId = Guid NewGuid() ToString(\"N\");\n    var totalAmount = command Items Sum(i => i Quantity * i UnitPrice);\n    var createdAt = DateTime UtcNow;\n    // 3 Save order (with outbox pattern)\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // Insert order\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO orders (order_id, customer_id, total_amount, status, shipping_address, created_at, updated_at)\n        VALUES (@OrderId, @CustomerId, @TotalAmount, @Status, @ShippingAddress::jsonb, @CreatedAt, @CreatedAt)\n        \"\"\",\n        new {\n          OrderId = orderId,\n          CustomerId = command CustomerId,\n          TotalAmount = totalAmount,\n          Status = \"Pending\",\n          ShippingAddress = System Text Json JsonSerializer",
        "startIndex": 4581,
        "preview": "order_id TEXT NOT NULL REFERENCES orders(order_id) ON DELETE CASCADE, product_id TEXT NOT NULL, quantity INTEGER NOT NULL, unit_price NUMERIC(10, 2) N..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-3",
        "text": "BeginTransactionAsync(ct); try { // Insert order await _db ExecuteAsync( \"\"\" INSERT INTO orders (order_id, customer_id, total_amount, status, shipping_address, created_at, updated_at) VALUES (@OrderId, @CustomerId, @TotalAmount, @Status, @ShippingAddress::jsonb, @CreatedAt, @CreatedAt) \"\"\", new { OrderId = orderId, CustomerId = command CustomerId, TotalAmount = totalAmount, Status = \"Pending\", ShippingAddress = System Text Json JsonSerializer Serialize(command ShippingAddress),\n          CreatedAt = createdAt\n        },\n        transaction: tx\n      );\n      // Insert order items\n      foreach (var item in command Items) {\n        var lineTotal = item Quantity * item UnitPrice;\n        await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO order_items (order_item_id, order_id, product_id, quantity, unit_price, line_total, created_at)\n          VALUES (@OrderItemId, @OrderId, @ProductId, @Quantity, @UnitPrice, @LineTotal, @CreatedAt)\n          \"\"\",\n          new {\n            OrderItemId = Guid NewGuid() ToString(\"N\"),\n            OrderId = orderId,\n            ProductId = item ProductId,\n            Quantity = item Quantity,\n            UnitPrice = item UnitPrice,\n            LineTotal = lineTotal,\n            CreatedAt = createdAt\n          },\n          transaction: tx\n        );\n      }\n      // 4 Create event\n      var @event = new OrderCreated(\n        OrderId: orderId,\n        CustomerId: command CustomerId,\n        Items: command Items Select(i => new Contracts Events OrderItem(\n          ProductId: i ProductId,\n          Quantity: i Quantity,\n          UnitPrice: i UnitPrice,\n          LineTotal: i Quantity * i UnitPrice\n        )) ToArray(),\n        ShippingAddress: new Contracts Events Address(\n          Street: command ShippingAddress Street,\n          City: command ShippingAddress City,\n          State: command ShippingAddress State,\n          ZipCode: command ShippingAddress ZipCode,\n          Country: command ShippingAddress Country\n        ),\n        TotalAmount: totalAmount,\n        CreatedAt: createdAt\n      );\n      // 5 Insert into outbox (same transaction)\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO outbox (message_id, message_type, message_body, created_at)\n        VALUES (@MessageId, @MessageType, @MessageBody::jsonb, @CreatedAt)\n        \"\"\",\n        new {\n          MessageId = _context MessageId,\n          MessageType = typeof(OrderCreated) FullName,\n          MessageBody = System Text Json JsonSerializer Serialize(@event),\n          CreatedAt = createdAt\n        },\n        transaction: tx\n      );\n      await tx CommitAsync(ct);\n      _logger LogInformation(\n        \"Order {OrderId} created for customer {CustomerId} with {ItemCount} items, total ${TotalAmount}\",\n        orderId,\n        command CustomerId,\n        command Items Length,\n        totalAmount\n      );\n      return @event;\n    } catch {\n      await tx",
        "startIndex": 6774,
        "preview": "BeginTransactionAsync(ct); try { // Insert order await _db ExecuteAsync( \"\"\" INSERT INTO orders (order_id, customer_id, total_amount, status, shipping..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-4",
        "text": "MessageId, MessageType = typeof(OrderCreated) FullName, MessageBody = System Text Json JsonSerializer Serialize(@event), CreatedAt = createdAt }, transaction: tx ); await tx CommitAsync(ct); _logger LogInformation( \"Order {OrderId} created for customer {CustomerId} with {ItemCount} items, total ${TotalAmount}\", orderId, command CustomerId, command Items Length, totalAmount ); return @event; } catch { await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n}\n`\nKey patterns:\n‚úÖ Outbox Pattern: Event inserted in same transaction as order\n‚úÖ Validation: Business rules enforced before persistence\n‚úÖ Message Context: _context MessageId for correlation\n‚úÖ Transactional: All-or-nothing via PostgreSQL transaction\n---\nStep 4: HTTP API\nECommerce OrderService API/Controllers/OrdersController cs:\n`csharp\nusing Microsoft AspNetCore Mvc;\nusing Whizbang Core;\nusing ECommerce Contracts Commands;\nnamespace ECommerce OrderService API Controllers;\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class OrdersController : ControllerBase {\n  private readonly IDispatcher _dispatcher;\n  private readonly ILogger<OrdersController> _logger;\n  public OrdersController(\n    IDispatcher dispatcher,\n    ILogger<OrdersController> logger\n  ) {\n    _dispatcher = dispatcher;\n    _logger = logger;\n  }\n  [HttpPost]\n  [ProducesResponseType(StatusCodes Status201Created)]\n  [ProducesResponseType(StatusCodes Status400BadRequest)]\n  public async Task<IActionResult> CreateOrder(\n    [FromBody] CreateOrder command,\n    CancellationToken ct\n  ) {\n    try {\n      var result = await _dispatcher DispatchAsync(command, ct);\n      return CreatedAtAction(\n        nameof(GetOrder),\n        new { orderId = result OrderId },\n        result\n      );\n    } catch (ValidationException ex) {\n      return BadRequest(new { error = ex Message });\n    }\n  }\n  [HttpGet(\"{orderId}\")]\n  [ProducesResponseType(StatusCodes Status200OK)]\n  [ProducesResponseType(StatusCodes Status404NotFound)]\n  public async Task<IActionResult> GetOrder(string orderId) {\n    // TODO: Implement query (Part 4 - Customer Service)\n    return NotFound();\n  }\n}\n`\n---\nStep 5: Service Configuration\nECommerce OrderService API/Program cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Whizbang Hosting Azure ServiceBus;\nusing Npgsql;\nvar builder = WebApplication CreateBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"OrderService\";\n  options EnableOutbox = true;\n  options EnableInbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"OrdersDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3",
        "startIndex": 9240,
        "preview": "MessageId, MessageType = typeof(OrderCreated) FullName, MessageBody = System Text Json JsonSerializer Serialize(@event), CreatedAt = createdAt }, tran..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-5",
        "text": "using Npgsql; var builder = WebApplication CreateBuilder(args); // 1 Add Whizbang builder Services AddWhizbang(options => { options ServiceName = \"OrderService\"; options EnableOutbox = true; options EnableInbox = true; }); // 2 Add PostgreSQL builder Services AddScoped<NpgsqlConnection>(sp => { var connectionString = builder Configuration GetConnectionString(\"OrdersDb\"); return new NpgsqlConnection(connectionString); }); // 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Add Aspire service defaults\nbuilder AddServiceDefaults();\n// 5 Add controllers\nbuilder Services AddControllers();\nbuilder Services AddEndpointsApiExplorer();\nbuilder Services AddSwaggerGen();\nvar app = builder Build();\n// Configure HTTP pipeline\nif (app Environment IsDevelopment()) {\n  app UseSwagger();\n  app UseSwaggerUI();\n}\napp UseHttpsRedirection();\napp UseAuthorization();\napp MapControllers();\n// Run database migrations\nawait app MigrateDatabaseAsync();\napp Run();\n`\nDatabase migration helper:\nECommerce OrderService API/Extensions/MigrationExtensions cs:\n`csharp\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce OrderService API Extensions;\npublic static class MigrationExtensions {\n  public static async Task MigrateDatabaseAsync(this WebApplication app) {\n    using var scope = app Services CreateScope();\n    var db = scope ServiceProvider GetRequiredService<NpgsqlConnection>();\n    var logger = scope ServiceProvider GetRequiredService<ILogger<Program>>();\n    var migrationFiles = Directory GetFiles(\n      Path Combine(AppContext BaseDirectory, \"Database/Migrations\"),\n      \"* sql\"\n    ) OrderBy(f => f);\n    foreach (var file in migrationFiles) {\n      var sql = await File ReadAllTextAsync(file);\n      await db ExecuteAsync(sql);\n      logger LogInformation(\"Applied migration: {File}\", Path GetFileName(file));\n    }\n  }\n}\n`\n---\nStep 6: Aspire Orchestration\nECommerce AppHost/Program cs:\n`csharp\nvar builder = DistributedApplication CreateBuilder(args);\n// 1 Add PostgreSQL\nvar postgres = builder AddPostgres(\"postgres\") WithPgAdmin();\nvar ordersDb = postgres AddDatabase(\"orders-db\");\n// 2 Add Azure Service Bus (emulator for local dev)\nvar serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator();\n// 3 Add Order Service\nvar orderService = builder AddProject<Projects ECommerce_OrderService_API>(\"order-service\") WithReference(ordersDb) WithReference(serviceBus);\nbuilder Build() Run();\n`\nappsettings json:\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft",
        "startIndex": 11585,
        "preview": "using Npgsql; var builder = WebApplication CreateBuilder(args); // 1 Add Whizbang builder Services AddWhizbang(options => { options ServiceName = \"Ord..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-6",
        "text": "WithPgAdmin(); var ordersDb = postgres AddDatabase(\"orders-db\"); // 2 Add Azure Service Bus (emulator for local dev) var serviceBus = builder AddAzureServiceBus(\"messaging\") RunAsEmulator(); // 3 Add Order Service var orderService = builder AddProject<Projects ECommerce_OrderService_API>(\"order-service\") WithReference(ordersDb) WithReference(serviceBus); builder Build() Run(); ` appsettings json: `json { \"Logging\": { \"LogLevel\": { \"Default\": \"Information\", \"Microsoft AspNetCore\": \"Warning\",\n      \"Whizbang\": \"Debug\"\n    }\n  },\n  \"AllowedHosts\": \"*\",\n  \"ConnectionStrings\": {\n    \"OrdersDb\": \"Host=localhost;Database=orders;Username=postgres;Password=postgres\"\n  },\n  \"Whizbang\": {\n    \"ServiceName\": \"OrderService\",\n    \"Outbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 100,\n      \"PollingInterval\": \"00:00:05\"\n    },\n    \"Inbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 100\n    }\n  }\n}\n`\n---\nStep 7: Test the Flow\nStart Aspire\n`bash\ncd ECommerce AppHost\ndotnet run\n`\nOpen Aspire Dashboard: http://localhost:15000\nCreate Order\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"cust-123\",\n    \"items\": [\n      {\n        \"productId\": \"prod-456\",\n        \"quantity\": 2,\n        \"unitPrice\": 19 99\n      },\n      {\n        \"productId\": \"prod-789\",\n        \"quantity\": 1,\n        \"unitPrice\": 49 99\n      }\n    ],\n    \"shippingAddress\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"Springfield\",\n      \"state\": \"IL\",\n      \"zipCode\": \"62701\",\n      \"country\": \"USA\"\n    }\n  }'\n`\nExpected response:\n`json\n{\n  \"orderId\": \"a1b2c3d4e5f6\",\n  \"customerId\": \"cust-123\",\n  \"items\": [\n    {\n      \"productId\": \"prod-456\",\n      \"quantity\": 2,\n      \"unitPrice\": 19 99,\n      \"lineTotal\": 39 98\n    },\n    {\n      \"productId\": \"prod-789\",\n      \"quantity\": 1,\n      \"unitPrice\": 49 99,\n      \"lineTotal\": 49 99\n    }\n  ],\n  \"shippingAddress\": {\n    \"street\": \"123 Main St\",\n    \"city\": \"Springfield\",\n    \"state\": \"IL\",\n    \"zipCode\": \"62701\",\n    \"country\": \"USA\"\n  },\n  \"totalAmount\": 89",
        "startIndex": 13702,
        "preview": "WithPgAdmin(); var ordersDb = postgres AddDatabase(\"orders-db\"); // 2 Add Azure Service Bus (emulator for local dev) var serviceBus = builder AddAzure..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-7",
        "text": "`json { \"orderId\": \"a1b2c3d4e5f6\", \"customerId\": \"cust-123\", \"items\": [ { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19 99, \"lineTotal\": 39 98 }, { \"productId\": \"prod-789\", \"quantity\": 1, \"unitPrice\": 49 99, \"lineTotal\": 49 99 } ], \"shippingAddress\": { \"street\": \"123 Main St\", \"city\": \"Springfield\", \"state\": \"IL\", \"zipCode\": \"62701\", \"country\": \"USA\" }, \"totalAmount\": 89 97,\n  \"createdAt\": \"2024-12-12T10:30:00Z\"\n}\n`\nVerify Database\n`sql\n-- Connect to PostgreSQL\npsql -h localhost -U postgres -d orders\n-- Check order\nSELECT * FROM orders;\n-- Check items\nSELECT * FROM order_items;\n-- Check outbox (event pending)\nSELECT message_id, message_type, created_at, processed_at\nFROM outbox;\n`\nVerify Event Publishing\nCheck Aspire Dashboard:\nOrder Service: HTTP request logged\nService Bus: OrderCreated event published\nOutbox Worker: Picked up event from outbox table\n---\nKey Concepts\nOutbox Pattern\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Transactional Outbox Pattern                       ‚îÇ\n‚îÇ                                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ  ‚îÇ  PostgreSQL Transaction          ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ                                   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  1 INSERT INTO orders ( )     ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  2 INSERT INTO order_items ( ) ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  3 INSERT INTO outbox ( )     ‚îÇ ‚Üê Same TX",
        "startIndex": 15293,
        "preview": "`json { \"orderId\": \"a1b2c3d4e5f6\", \"customerId\": \"cust-123\", \"items\": [ { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19 99, \"lineTotal\": 39 ..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-8",
        "text": "Outbox Pattern ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ PostgreSQL Transaction ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 INSERT INTO orders ( ) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 INSERT INTO order_items ( ) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 3 INSERT INTO outbox ( ) ‚îÇ ‚Üê Same TX ‚îÇ\n‚îÇ  ‚îÇ                                   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  COMMIT;                          ‚îÇ               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îÇ                 ‚îÇ                                    ‚îÇ\n‚îÇ                 ‚ñº                                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ\n‚îÇ  ‚îÇ  Background Worker (Whizbang)    ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ                                   ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  - SELECT * FROM outbox WHERE    ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ    processed_at IS NULL          ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  - Publish to Azure Service Bus  ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ  - UPDATE outbox SET             ‚îÇ               ‚îÇ\n‚îÇ  ‚îÇ    processed_at = NOW()          ‚îÇ               ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nBenefits:\n‚úÖ Atomic: Order + event in single transaction\n‚úÖ Reliable: Event guaranteed published (eventually)\n‚úÖ Consistent: No partial state (order saved but event lost)\nMessage Context\n`csharp\npublic interface IMessageContext {\n  Guid MessageId { get; }           // Unique ID for this message\n  Guid CorrelationId { get; }      // Business transaction ID\n  Guid CausationId { get; }        // ID of message that caused this one\n  string UserId { get; }           // User who initiated request\n  IDictionary<string, string> Metadata { get; } // Custom metadata\n}\n`\nFlow example:\n`\nHTTP Request\n  CorrelationId: req-123\n  MessageId: msg-001\nCreateOrder Command\n  CorrelationId: req-123 (same)\n  CausationId: msg-001\n  MessageId: msg-002\nOrderCreated Event\n  CorrelationId: req-123 (same)\n  CausationId: msg-002\n  MessageId: msg-003\n`\nThis enables distributed tracing across services ---\nTesting\nUnit Test\nECommerce OrderService Tests/CreateOrderReceptorTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing ECommerce OrderService API Receptors;\nusing ECommerce Contracts Commands;\nnamespace ECommerce OrderService",
        "startIndex": 16321,
        "preview": "Outbox Pattern ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ PostgreSQL Transaction ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 INSERT INTO orders ( ) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 2 INSERT INT..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-9",
        "text": "CorrelationId: req-123 (same) CausationId: msg-001 MessageId: msg-002 OrderCreated Event CorrelationId: req-123 (same) CausationId: msg-002 MessageId: msg-003 ` This enables distributed tracing across services --- Testing Unit Test ECommerce OrderService Tests/CreateOrderReceptorTests cs: `csharp using TUnit Core; using TUnit Assertions; using ECommerce OrderService API Receptors; using ECommerce Contracts Commands; namespace ECommerce OrderService Tests;\npublic class CreateOrderReceptorTests {\n  [Test]\n  public async Task HandleAsync_ValidOrder_ReturnsOrderCreatedEvent() {\n    // Arrange\n    var db = new MockNpgsqlConnection();\n    var context = new MockMessageContext();\n    var logger = new MockLogger<CreateOrderReceptor>();\n    var receptor = new CreateOrderReceptor(db, context, logger);\n    var command = new CreateOrder(\n      CustomerId: \"cust-123\",\n      Items: [\n        new OrderItem(\"prod-456\", 2, 19 99m)\n      ],\n      ShippingAddress: new Address(\"123 Main\", \"Springfield\", \"IL\", \"62701\", \"USA\")\n    );\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    await Assert That(result CustomerId) IsEqualTo(\"cust-123\");\n    await Assert That(result TotalAmount) IsEqualTo(39 98m);\n    await Assert That(result Items) HasCount() EqualTo(1);\n  }\n}\n`\nIntegration Test\n`csharp\n[Test]\npublic async Task CreateOrder_EndToEnd_PublishesEvent() {\n  // Arrange\n  var factory = new WebApplicationFactory<Program>();\n  var client = factory CreateClient();\n  var command = new {\n    customerId = \"cust-123\",\n    items = new[] {\n      new { productId = \"prod-456\", quantity = 2, unitPrice = 19 99 }\n    },\n    shippingAddress = new {\n      street = \"123 Main\",\n      city = \"Springfield\",\n      state = \"IL\",\n      zipCode = \"62701\",\n      country = \"USA\"\n    }\n  };\n  // Act\n  var response = await client PostAsJsonAsync(\"/api/orders\", command);\n  // Assert\n  await Assert That(response StatusCode) IsEqualTo(HttpStatusCode Created);\n  var result = await response Content ReadFromJsonAsync<OrderCreated>();\n  await Assert That(result TotalAmount) IsEqualTo(39 98m);\n}\n`\n---\nCommon Issues\nIssue 1: \"Outbox table not found\"\nCause: Migration not run\nFix:\n`bash\nEnsure migrations executed on startup\ndotnet run --project ECommerce OrderService API\n`\nIssue 2: \"Event not published\"\nCause: Outbox worker not running\nFix: Check Aspire dashboard for worker logs Verify Service Bus connection Issue 3: \"Transaction deadlock\"\nCause: Long-running transaction\nFix: Keep receptor logic fast",
        "startIndex": 18298,
        "preview": "CorrelationId: req-123 (same) CausationId: msg-001 MessageId: msg-002 OrderCreated Event CorrelationId: req-123 (same) CausationId: msg-002 MessageId:..."
      },
      {
        "id": "v0.1.0/tutorial/order-management-chunk-10",
        "text": "Migration not run Fix: `bash Ensure migrations executed on startup dotnet run --project ECommerce OrderService API ` Issue 2: \"Event not published\" Cause: Outbox worker not running Fix: Check Aspire dashboard for worker logs Verify Service Bus connection Issue 3: \"Transaction deadlock\" Cause: Long-running transaction Fix: Keep receptor logic fast Move heavy processing to event handlers ---\nNext Steps\nContinue to Inventory Service to:\nSubscribe to OrderCreated events\nImplement inventory reservation\nPublish InventoryReserved events\nHandle compensation (stock release)\n---\nKey Takeaways\n‚úÖ Outbox Pattern - Atomic event publishing with database transactions\n‚úÖ Command/Event Separation - Clear intent (command) vs fact (event)\n‚úÖ Message Context - Distributed tracing with correlation IDs\n‚úÖ Validation - Business rules enforced in receptors\n‚úÖ NET Aspire - Local orchestration with PostgreSQL + Service Bus emulators\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 20364,
        "preview": "Migration not run Fix: `bash Ensure migrations executed on startup dotnet run --project ECommerce OrderService API ` Issue 2: \"Event not published\" Ca..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/payment-processing",
    "title": "Payment Processing Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/payment-processing",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-0",
        "text": "Payment Processing Service\nBuild the Payment Worker - a background service that subscribes to InventoryReserved events, processes payments via external gateway, and handles failures with compensation :::note\nThis is Part 3 of the ECommerce Tutorial Complete Inventory Service first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Payment Service Architecture                               ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                            ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  InventoryReserved event                   ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ                     ‚îÇ\n‚îÇ                                        ‚ñº                     ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ  Inbox Pattern         ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                                     ‚ñº                        ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ ProcessPaymentReceptor ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Call gateway API    ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Retry logic         ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Store transaction   ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ                      ‚îÇ              ‚îÇ              ‚îÇ        ‚îÇ\n‚îÇ                      ‚ñº              ‚ñº              ‚ñº        ‚îÇ\n‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ                 ‚îÇPostgres ‚îÇ   ‚îÇ Outbox  ‚îÇ   ‚îÇ Payment  ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇPayments ‚îÇ   ‚îÇ Table   ‚îÇ   ‚îÇ Gateway  ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇ  Table  ‚îÇ   ‚îÇ         ‚îÇ   ‚îÇ   API    ‚îÇ   ‚îÇ\n‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ                      ‚îÇ              ‚îÇ              ‚îÇ        ‚îÇ\n‚îÇ                      ‚ñº              ‚ñº              ‚ñº        ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n‚îÇ              ‚îÇPaymentProcessed‚îÇ ‚îÇPaymentFailed ‚îÇ ‚îÇOutbox  ‚îÇ‚îÇ\n‚îÇ              ‚îÇ     Event      ‚îÇ ‚îÇ    Event     ‚îÇ ‚îÇWorker  ‚îÇ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Payment gateway integration (Stripe example)\n‚úÖ Retry logic with exponential backoff\n‚úÖ Idempotency (payment deduplication)\n‚úÖ Distributed transaction coordination\n‚úÖ Compensation (refunds on failure)\n‚úÖ Circuit breaker pattern\n---\nStep 1: Define Events\nPaymentProcessed Event\nECommerce Contracts/Events/PaymentProcessed cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts",
        "startIndex": 0,
        "preview": "Payment Processing Service\nBuild the Payment Worker - a background service that subscribes to InventoryReserved events, processes payments via externa..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-1",
        "text": "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Features: ‚úÖ Payment gateway integration (Stripe example) ‚úÖ Retry logic with exponential backoff ‚úÖ Idempotency (payment deduplication) ‚úÖ Distributed transaction coordination ‚úÖ Compensation (refunds on failure) ‚úÖ Circuit breaker pattern --- Step 1: Define Events PaymentProcessed Event ECommerce Contracts/Events/PaymentProcessed cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events;\npublic record PaymentProcessed(\n  string OrderId,\n  string PaymentId,\n  string TransactionId,\n  decimal Amount,\n  string PaymentMethod,\n  PaymentStatus Status,\n  DateTime ProcessedAt\n) : IEvent;\npublic enum PaymentStatus {\n  Authorized,\n  Captured,\n  Failed,\n  Refunded\n}\n`\nPaymentFailed Event (Compensation)\nECommerce Contracts/Events/PaymentFailed cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts Events;\npublic record PaymentFailed(\n  string OrderId,\n  string PaymentId,\n  string Reason,\n  string ErrorCode,\n  DateTime FailedAt\n) : IEvent;\n`\n---\nStep 2: Database Schema\nPayments Table\nECommerce PaymentWorker/Database/Migrations/001_CreatePaymentsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS payments (\n  payment_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL UNIQUE,  -- One payment per order\n  transaction_id TEXT,  -- External gateway transaction ID\n  amount NUMERIC(10, 2) NOT NULL,\n  payment_method TEXT NOT NULL,\n  status TEXT NOT NULL,\n  gateway_response JSONB,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_payments_order_id ON payments(order_id);\nCREATE INDEX idx_payments_transaction_id ON payments(transaction_id);\nCREATE INDEX idx_payments_status ON payments(status);\n`\n---\nStep 3: Payment Gateway Abstraction\nECommerce PaymentWorker/Services/IPaymentGateway cs:\n`csharp\nnamespace ECommerce PaymentWorker Services;\npublic interface IPaymentGateway {\n  Task<PaymentResult> ChargeAsync(\n    string idempotencyKey,\n    decimal amount,\n    string currency,\n    string paymentMethod,\n    CancellationToken ct = default\n  );\n  Task<RefundResult> RefundAsync(\n    string transactionId,\n    decimal amount,\n    CancellationToken ct = default\n  );\n}\npublic record PaymentResult(\n  bool Success,\n  string TransactionId,\n  string ErrorCode,\n  string ErrorMessage\n);\npublic record RefundResult(\n  bool Success,\n  string RefundId,\n  string ErrorMessage\n);\n`\nStripe Implementation\nECommerce PaymentWorker/Services/StripePaymentGateway cs:\n`csharp\nusing Stripe;\nnamespace ECommerce PaymentWorker",
        "startIndex": 3071,
        "preview": "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ` Features: ‚úÖ Payment gateway integration (Stripe example) ‚úÖ Retry logic w..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-2",
        "text": "ct = default ); Task<RefundResult> RefundAsync( string transactionId, decimal amount, CancellationToken ct = default ); } public record PaymentResult( bool Success, string TransactionId, string ErrorCode, string ErrorMessage ); public record RefundResult( bool Success, string RefundId, string ErrorMessage ); ` Stripe Implementation ECommerce PaymentWorker/Services/StripePaymentGateway cs: `csharp using Stripe; namespace ECommerce PaymentWorker Services;\npublic class StripePaymentGateway : IPaymentGateway {\n  private readonly PaymentIntentService _paymentIntentService;\n  private readonly RefundService _refundService;\n  private readonly ILogger<StripePaymentGateway> _logger;\n  public StripePaymentGateway(\n    PaymentIntentService paymentIntentService,\n    RefundService refundService,\n    ILogger<StripePaymentGateway> logger\n  ) {\n    _paymentIntentService = paymentIntentService;\n    _refundService = refundService;\n    _logger = logger;\n  }\n  public async Task<PaymentResult> ChargeAsync(\n    string idempotencyKey,\n    decimal amount,\n    string currency,\n    string paymentMethod,\n    CancellationToken ct = default\n  ) {\n    try {\n      var options = new PaymentIntentCreateOptions {\n        Amount = (long)(amount * 100), // Stripe uses cents\n        Currency = currency ToLowerInvariant(),\n        PaymentMethod = paymentMethod,\n        Confirm = true,\n        AutomaticPaymentMethods = new PaymentIntentAutomaticPaymentMethodsOptions {\n          Enabled = true,\n          AllowRedirects = \"never\"\n        }\n      };\n      var requestOptions = new RequestOptions {\n        IdempotencyKey = idempotencyKey  // Prevents duplicate charges\n      };\n      var intent = await _paymentIntentService CreateAsync(\n        options,\n        requestOptions,\n        ct\n      );\n      if (intent Status == \"succeeded\") {\n        return new PaymentResult(\n          Success: true,\n          TransactionId: intent Id,\n          ErrorCode: null,\n          ErrorMessage: null\n        );\n      } else {\n        return new PaymentResult(\n          Success: false,\n          TransactionId: intent Id,\n          ErrorCode: intent Status,\n          ErrorMessage: $\"Payment intent status: {intent Status}\"\n        );\n      }\n    } catch (StripeException ex) {\n      _logger LogError(ex, \"Stripe payment failed: {ErrorCode}\", ex StripeError Code);\n      return new PaymentResult(\n        Success: false,\n        TransactionId: null,\n        ErrorCode: ex StripeError Code \"unknown\",\n        ErrorMessage: ex Message\n      );\n    }\n  }\n  public async Task<RefundResult> RefundAsync(\n    string transactionId,\n    decimal amount,\n    CancellationToken ct = default\n  ) {\n    try {\n      var options = new RefundCreateOptions {\n        PaymentIntent = transactionId,\n        Amount = (long)(amount * 100)\n      };\n      var refund = await _refundService CreateAsync(options, cancellationToken: ct);\n      return new RefundResult(\n        Success: refund Status == \"succeeded\",\n        RefundId: refund Id,\n        ErrorMessage: refund Status == \"failed\" refund",
        "startIndex": 5158,
        "preview": "ct = default ); Task<RefundResult> RefundAsync( string transactionId, decimal amount, CancellationToken ct = default ); } public record PaymentResult(..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-3",
        "text": "decimal amount, CancellationToken ct = default ) { try { var options = new RefundCreateOptions { PaymentIntent = transactionId, Amount = (long)(amount * 100) }; var refund = await _refundService CreateAsync(options, cancellationToken: ct); return new RefundResult( Success: refund Status == \"succeeded\", RefundId: refund Id, ErrorMessage: refund Status == \"failed\" refund FailureReason : null\n      );\n    } catch (StripeException ex) {\n      _logger LogError(ex, \"Stripe refund failed: {ErrorCode}\", ex StripeError Code);\n      return new RefundResult(\n        Success: false,\n        RefundId: null,\n        ErrorMessage: ex Message\n      );\n    }\n  }\n}\n`\n---\nStep 4: Implement Receptor\nECommerce PaymentWorker/Receptors/ProcessPaymentReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce PaymentWorker Services;\nusing Npgsql;\nusing Dapper;\nusing Polly;\nusing Polly CircuitBreaker;\nnamespace ECommerce PaymentWorker Receptors;\npublic class ProcessPaymentReceptor : IReceptor<InventoryReserved, PaymentProcessed> {\n  private readonly NpgsqlConnection _db;\n  private readonly IPaymentGateway _gateway;\n  private readonly IMessageContext _context;\n  private readonly ILogger<ProcessPaymentReceptor> _logger;\n  // Retry policy: 3 attempts with exponential backoff\n  private static readonly AsyncPolicy<PaymentResult> RetryPolicy = Policy Handle<HttpRequestException>() Or<TaskCanceledException>() OrResult<PaymentResult>(r => r Success && r ErrorCode == \"network_error\") WaitAndRetryAsync(\n      retryCount: 3,\n      sleepDurationProvider: attempt => TimeSpan FromSeconds(Math Pow(2, attempt)),\n      onRetry: (outcome, timespan, retryCount, context) => {\n        Console WriteLine($\"Payment retry {retryCount} after {timespan}\");\n      }\n    );\n  // Circuit breaker: Open after 5 consecutive failures, half-open after 30s\n  private static readonly AsyncCircuitBreakerPolicy CircuitBreakerPolicy = Policy Handle<HttpRequestException>() CircuitBreakerAsync(\n      exceptionsAllowedBeforeBreaking: 5,\n      durationOfBreak: TimeSpan FromSeconds(30),\n      onBreak: (ex, duration) => {\n        Console WriteLine($\"Circuit breaker opened for {duration}\");\n      },\n      onReset: () => {\n        Console WriteLine(\"Circuit breaker reset\");\n      }\n    );\n  public ProcessPaymentReceptor(\n    NpgsqlConnection db,\n    IPaymentGateway gateway,\n    IMessageContext context,\n    ILogger<ProcessPaymentReceptor> logger\n  ) {\n    _db = db;\n    _gateway = gateway;\n    _context = context;\n    _logger = logger;\n  }\n  public async Task<PaymentProcessed> HandleAsync(\n    InventoryReserved @event,\n    CancellationToken ct = default\n  ) {\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // 1 Check if payment already exists (idempotency)\n      var existingPayment = await _db",
        "startIndex": 7767,
        "preview": "decimal amount, CancellationToken ct = default ) { try { var options = new RefundCreateOptions { PaymentIntent = transactionId, Amount = (long)(amount..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-4",
        "text": ") { _db = db; _gateway = gateway; _context = context; _logger = logger; } public async Task<PaymentProcessed> HandleAsync( InventoryReserved @event, CancellationToken ct = default ) { await using var tx = await _db BeginTransactionAsync(ct); try { // 1 Check if payment already exists (idempotency) var existingPayment = await _db QuerySingleOrDefaultAsync<PaymentRow>(\n        \"\"\"\n        SELECT payment_id, order_id, transaction_id, amount, status\n        FROM payments\n        WHERE order_id = @OrderId\n        \"\"\",\n        new { OrderId = @event OrderId },\n        transaction: tx\n      );\n      if (existingPayment = null) {\n        _logger LogInformation(\n          \"Payment already exists for order {OrderId}, skipping\",\n          @event OrderId\n        );\n        return new PaymentProcessed(\n          OrderId: existingPayment OrderId,\n          PaymentId: existingPayment PaymentId,\n          TransactionId: existingPayment TransactionId ,\n          Amount: existingPayment Amount,\n          PaymentMethod: \"card\",\n          Status: PaymentStatus Captured,\n          ProcessedAt: DateTime UtcNow\n        );\n      }\n      // 2 Get order details (to determine amount)\n      var order = await GetOrderAsync(@event OrderId, ct);\n      if (order == null) {\n        throw new InvalidOperationException($\"Order {event OrderId} not found\");\n      }\n      // 3 Call payment gateway with retry + circuit breaker\n      var paymentId = Guid NewGuid() ToString(\"N\");\n      var idempotencyKey = $\"order-{@event OrderId}-payment-{paymentId}\";\n      var result = await CircuitBreakerPolicy ExecuteAsync(() =>\n        RetryPolicy ExecuteAsync(() =>\n          _gateway ChargeAsync(\n            idempotencyKey: idempotencyKey,\n            amount: order TotalAmount,\n            currency: \"usd\",\n            paymentMethod: \"pm_card_visa\",  // Demo: Use test payment method\n            ct: ct\n          )\n        )\n      );\n      // 4 Store payment record\n      if (result Success) {\n        await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO payments (\n            payment_id, order_id, transaction_id, amount, payment_method, status, gateway_response, created_at, updated_at\n          )\n          VALUES (@PaymentId, @OrderId, @TransactionId, @Amount, @PaymentMethod, @Status, @GatewayResponse::jsonb, NOW(), NOW())\n          \"\"\",\n          new {\n            PaymentId = paymentId,\n            OrderId = @event OrderId,\n            TransactionId = result TransactionId,\n            Amount = order TotalAmount,\n            PaymentMethod = \"card\",\n            Status = \"Captured\",\n            GatewayResponse = System Text Json JsonSerializer Serialize(result)\n          },\n          transaction: tx\n        );\n        // 5 Publish PaymentProcessed event\n        var processedEvent = new PaymentProcessed(\n          OrderId: @event OrderId,\n          PaymentId: paymentId,\n          TransactionId: result TransactionId ,\n          Amount: order TotalAmount,\n          PaymentMethod: \"card\",\n          Status: PaymentStatus Captured,\n          ProcessedAt: DateTime",
        "startIndex": 10257,
        "preview": ") { _db = db; _gateway = gateway; _context = context; _logger = logger; } public async Task<PaymentProcessed> HandleAsync( InventoryReserved @event, C..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-5",
        "text": "Amount = order TotalAmount, PaymentMethod = \"card\", Status = \"Captured\", GatewayResponse = System Text Json JsonSerializer Serialize(result) }, transaction: tx ); // 5 Publish PaymentProcessed event var processedEvent = new PaymentProcessed( OrderId: @event OrderId, PaymentId: paymentId, TransactionId: result TransactionId , Amount: order TotalAmount, PaymentMethod: \"card\", Status: PaymentStatus Captured, ProcessedAt: DateTime UtcNow\n        );\n        await PublishEventAsync(processedEvent, tx, ct);\n        await tx CommitAsync(ct);\n        _logger LogInformation(\n          \"Payment processed for order {OrderId}, transaction {TransactionId}, amount ${Amount}\",\n          @event OrderId,\n          result TransactionId,\n          order TotalAmount\n        );\n        return processedEvent;\n      } else {\n        // 6 Payment failed - store failure and publish PaymentFailed event\n        await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO payments (\n            payment_id, order_id, amount, payment_method, status, gateway_response, created_at, updated_at\n          )\n          VALUES (@PaymentId, @OrderId, @Amount, @PaymentMethod, @Status, @GatewayResponse::jsonb, NOW(), NOW())\n          \"\"\",\n          new {\n            PaymentId = paymentId,\n            OrderId = @event OrderId,\n            Amount = order TotalAmount,\n            PaymentMethod = \"card\",\n            Status = \"Failed\",\n            GatewayResponse = System Text Json JsonSerializer Serialize(result)\n          },\n          transaction: tx\n        );\n        var failedEvent = new PaymentFailed(\n          OrderId: @event OrderId,\n          PaymentId: paymentId,\n          Reason: result ErrorMessage \"Unknown error\",\n          ErrorCode: result ErrorCode \"unknown\",\n          FailedAt: DateTime UtcNow\n        );\n        await PublishEventAsync(failedEvent, tx, ct);\n        await tx CommitAsync(ct);\n        _logger LogError(\n          \"Payment failed for order {OrderId}: {ErrorCode} - {ErrorMessage}\",\n          @event OrderId,\n          result ErrorCode,\n          result ErrorMessage\n        );\n        throw new PaymentFailedException(\n          @event OrderId,\n          result ErrorCode \"unknown\",\n          result ErrorMessage \"Unknown error\"\n        );\n      }\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n  private async Task<OrderRow > GetOrderAsync(string orderId, CancellationToken ct) {\n    // Query Order Service database (cross-service query for demo)\n    // In production, use event-carried state transfer or query API\n    return await _db QuerySingleOrDefaultAsync<OrderRow>(\n      \"\"\"\n      SELECT order_id, total_amount\n      FROM orders\n      WHERE order_id = @OrderId\n      \"\"\",\n      new { OrderId = orderId }\n    );\n  }\n  private async Task PublishEventAsync<TEvent>(\n    TEvent @event,\n    NpgsqlTransaction tx,\n    CancellationToken ct\n  ) where TEvent : IEvent {\n    await _db",
        "startIndex": 12994,
        "preview": "Amount = order TotalAmount, PaymentMethod = \"card\", Status = \"Captured\", GatewayResponse = System Text Json JsonSerializer Serialize(result) }, transa..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-6",
        "text": "In production, use event-carried state transfer or query API return await _db QuerySingleOrDefaultAsync<OrderRow>( \"\"\" SELECT order_id, total_amount FROM orders WHERE order_id = @OrderId \"\"\", new { OrderId = orderId } ); } private async Task PublishEventAsync<TEvent>( TEvent @event, NpgsqlTransaction tx, CancellationToken ct ) where TEvent : IEvent { await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO outbox (message_id, message_type, message_body, created_at)\n      VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW())\n      \"\"\",\n      new {\n        MessageId = Guid NewGuid(),\n        MessageType = typeof(TEvent) FullName,\n        MessageBody = System Text Json JsonSerializer Serialize(@event)\n      },\n      transaction: tx\n    );\n  }\n}\npublic record PaymentRow(\n  string PaymentId,\n  string OrderId,\n  string TransactionId,\n  decimal Amount,\n  string Status\n);\npublic record OrderRow(\n  string OrderId,\n  decimal TotalAmount\n);\npublic class PaymentFailedException : Exception {\n  public PaymentFailedException(string orderId, string errorCode, string message)\n    : base($\"Payment failed for order {orderId}: {errorCode} - {message}\") { }\n}\n`\nKey patterns:\n‚úÖ Idempotency: Check existing payment before charging\n‚úÖ Retry Logic: Polly retry policy with exponential backoff\n‚úÖ Circuit Breaker: Polly circuit breaker to prevent cascading failures\n‚úÖ Compensation: Publish PaymentFailed event to trigger inventory release\n---\nStep 5: Compensation Receptor\nECommerce PaymentWorker/Receptors/RefundPaymentReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce PaymentWorker Services;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce PaymentWorker Receptors;\npublic class RefundPaymentReceptor : IReceptor<OrderCancelled, PaymentRefunded> {\n  private readonly NpgsqlConnection _db;\n  private readonly IPaymentGateway _gateway;\n  private readonly ILogger<RefundPaymentReceptor> _logger;\n  public RefundPaymentReceptor(\n    NpgsqlConnection db,\n    IPaymentGateway gateway,\n    ILogger<RefundPaymentReceptor> logger\n  ) {\n    _db = db;\n    _gateway = gateway;\n    _logger = logger;\n  }\n  public async Task<PaymentRefunded> HandleAsync(\n    OrderCancelled @event,\n    CancellationToken ct = default\n  ) {\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // 1 Find payment for this order\n      var payment = await _db QuerySingleOrDefaultAsync<PaymentRow>(\n        \"\"\"\n        SELECT payment_id, order_id, transaction_id, amount, status\n        FROM payments\n        WHERE order_id = @OrderId AND status = 'Captured'\n        \"\"\",\n        new { OrderId = @event",
        "startIndex": 15498,
        "preview": "In production, use event-carried state transfer or query API return await _db QuerySingleOrDefaultAsync<OrderRow>( \"\"\" SELECT order_id, total_amount F..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-7",
        "text": "= default ) { await using var tx = await _db BeginTransactionAsync(ct); try { // 1 Find payment for this order var payment = await _db QuerySingleOrDefaultAsync<PaymentRow>( \"\"\" SELECT payment_id, order_id, transaction_id, amount, status FROM payments WHERE order_id = @OrderId AND status = 'Captured' \"\"\", new { OrderId = @event OrderId },\n        transaction: tx\n      );\n      if (payment == null) {\n        _logger LogWarning(\n          \"No captured payment found for order {OrderId}, skipping refund\",\n          @event OrderId\n        );\n        throw new InvalidOperationException($\"No payment to refund for order {event OrderId}\");\n      }\n      // 2 Call payment gateway for refund\n      var result = await _gateway RefundAsync(\n        transactionId: payment TransactionId ,\n        amount: payment Amount,\n        ct: ct\n      );\n      if (result Success) {\n        // 3 Update payment status\n        await _db ExecuteAsync(\n          \"\"\"\n          UPDATE payments\n          SET status = 'Refunded', updated_at = NOW()\n          WHERE payment_id = @PaymentId\n          \"\"\",\n          new { PaymentId = payment PaymentId },\n          transaction: tx\n        );\n        // 4 Publish PaymentRefunded event\n        var refundedEvent = new PaymentRefunded(\n          OrderId: @event OrderId,\n          PaymentId: payment PaymentId,\n          RefundId: result RefundId ,\n          Amount: payment Amount,\n          RefundedAt: DateTime UtcNow\n        );\n        await PublishEventAsync(refundedEvent, tx, ct);\n        await tx CommitAsync(ct);\n        _logger LogInformation(\n          \"Payment refunded for order {OrderId}, refund {RefundId}, amount ${Amount}\",\n          @event OrderId,\n          result RefundId,\n          payment Amount\n        );\n        return refundedEvent;\n      } else {\n        throw new RefundFailedException(\n          @event OrderId,\n          result ErrorMessage \"Refund failed\"\n        );\n      }\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n  private async Task PublishEventAsync<TEvent>(\n    TEvent @event,\n    NpgsqlTransaction tx,\n    CancellationToken ct\n  ) where TEvent : IEvent {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO outbox (message_id, message_type, message_body, created_at)\n      VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW())\n      \"\"\",\n      new {\n        MessageId = Guid NewGuid(),\n        MessageType = typeof(TEvent) FullName,\n        MessageBody = System Text Json JsonSerializer",
        "startIndex": 17767,
        "preview": "= default ) { await using var tx = await _db BeginTransactionAsync(ct); try { // 1 Find payment for this order var payment = await _db QuerySingleOrDe..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-8",
        "text": "} private async Task PublishEventAsync<TEvent>( TEvent @event, NpgsqlTransaction tx, CancellationToken ct ) where TEvent : IEvent { await _db ExecuteAsync( \"\"\" INSERT INTO outbox (message_id, message_type, message_body, created_at) VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW()) \"\"\", new { MessageId = Guid NewGuid(), MessageType = typeof(TEvent) FullName, MessageBody = System Text Json JsonSerializer Serialize(@event)\n      },\n      transaction: tx\n    );\n  }\n}\npublic record PaymentRefunded(\n  string OrderId,\n  string PaymentId,\n  string RefundId,\n  decimal Amount,\n  DateTime RefundedAt\n) : IEvent;\npublic class RefundFailedException : Exception {\n  public RefundFailedException(string orderId, string message)\n    : base($\"Refund failed for order {orderId}: {message}\") { }\n}\n`\n---\nStep 6: Service Configuration\nECommerce PaymentWorker/Program cs:\n`csharp\nusing Whizbang Core;\nusing Whizbang Data Postgres;\nusing Whizbang Transports AzureServiceBus;\nusing Npgsql;\nusing Stripe;\nusing ECommerce PaymentWorker Services;\nvar builder = Host CreateApplicationBuilder(args);\n// 1 Add Whizbang\nbuilder Services AddWhizbang(options => {\n  options ServiceName = \"PaymentWorker\";\n  options EnableInbox = true;\n  options EnableOutbox = true;\n});\n// 2 Add PostgreSQL\nbuilder Services AddScoped<NpgsqlConnection>(sp => {\n  var connectionString = builder Configuration GetConnectionString(\"PaymentDb\");\n  return new NpgsqlConnection(connectionString);\n});\n// 3 Add Azure Service Bus\nbuilder AddAzureServiceBus(\"messaging\");\n// 4 Configure Stripe\nStripeConfiguration ApiKey = builder Configuration[\"Stripe:SecretKey\"];\nbuilder Services AddSingleton<PaymentIntentService>();\nbuilder Services AddSingleton<RefundService>();\nbuilder Services AddScoped<IPaymentGateway, StripePaymentGateway>();\n// 5 Add Worker\nbuilder Services AddHostedService<Worker>();\nvar host = builder Build();\nawait host MigrateDatabaseAsync();\nawait host RunAsync();\n`\nappsettings json:\n`json\n{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Whizbang\": \"Debug\"\n    }\n  },\n  \"ConnectionStrings\": {\n    \"PaymentDb\": \"Host=localhost;Database=payment;Username=postgres;Password=postgres\"\n  },\n  \"Stripe\": {\n    \"SecretKey\": \"sk_test_ \",\n    \"PublishableKey\": \"pk_test_ \"\n  },\n  \"Whizbang\": {\n    \"ServiceName\": \"PaymentWorker\",\n    \"Inbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 50,\n      \"PollingInterval\": \"00:00:05\"\n    },\n    \"Outbox\": {\n      \"Enabled\": true,\n      \"BatchSize\": 50,\n      \"PollingInterval\": \"00:00:05\"\n    }\n  }\n}\n`\n---\nStep 7: Test the Flow\nUpdate Aspire Configuration\nECommerce AppHost/Program cs:\n`csharp\nvar paymentDb = postgres AddDatabase(\"payment-db\");\nvar paymentWorker = builder AddProject<Projects ECommerce_PaymentWorker>(\"payment-worker\") WithReference(paymentDb)",
        "startIndex": 19937,
        "preview": "} private async Task PublishEventAsync<TEvent>( TEvent @event, NpgsqlTransaction tx, CancellationToken ct ) where TEvent : IEvent { await _db ExecuteA..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-9",
        "text": "\"Whizbang\": { \"ServiceName\": \"PaymentWorker\", \"Inbox\": { \"Enabled\": true, \"BatchSize\": 50, \"PollingInterval\": \"00:00:05\" }, \"Outbox\": { \"Enabled\": true, \"BatchSize\": 50, \"PollingInterval\": \"00:00:05\" } } } ` --- Step 7: Test the Flow Update Aspire Configuration ECommerce AppHost/Program cs: `csharp var paymentDb = postgres AddDatabase(\"payment-db\"); var paymentWorker = builder AddProject<Projects ECommerce_PaymentWorker>(\"payment-worker\") WithReference(paymentDb) WithReference(serviceBus);\n`\nCreate Order (Full Flow)\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"cust-123\",\n    \"items\": [\n      { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19 99 }\n    ],\n    \"shippingAddress\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"Springfield\",\n      \"state\": \"IL\",\n      \"zipCode\": \"62701\",\n      \"country\": \"USA\"\n    }\n  }'\n`\nObserve Distributed Transaction\nAspire Dashboard shows:\nOrder Service: OrderCreated event published\nInventory Worker: InventoryReserved event published\nPayment Worker: Payment processed via Stripe\nPayment Worker: PaymentProcessed event published\nVerify Payment\n`sql\nSELECT * FROM payments WHERE order_id = '<order-id>';\n`\nExpected:\nstatus = 'Captured'\ntransaction_id = 'pi_ ' (Stripe payment intent ID)\ngateway_response contains full Stripe response\n---\nKey Concepts\nSaga Pattern - Distributed Transactions\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Saga: Order Processing (Happy Path)                    ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  1 CreateOrder ‚Üí OrderCreated                          ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  2 OrderCreated ‚Üí ReserveInventory ‚Üí InventoryReserved ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  3 InventoryReserved ‚Üí ProcessPayment ‚Üí PaymentProcessed‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  4 PaymentProcessed ‚Üí CreateShipment ‚Üí ShipmentCreated ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  5 ShipmentCreated ‚Üí SendNotification ‚Üí NotificationSent‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Saga: Payment Failure (Compensation)                   ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ  1 CreateOrder ‚Üí OrderCreated                          ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  2 OrderCreated ‚Üí ReserveInventory ‚Üí InventoryReserved ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  3 InventoryReserved ‚Üí ProcessPayment ‚Üí PaymentFailed  ‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  4 PaymentFailed ‚Üí ReleaseInventory ‚Üí InventoryReleased‚îÇ\n‚îÇ       ‚Üì                                                  ‚îÇ\n‚îÇ  5",
        "startIndex": 22337,
        "preview": "\"Whizbang\": { \"ServiceName\": \"PaymentWorker\", \"Inbox\": { \"Enabled\": true, \"BatchSize\": 50, \"PollingInterval\": \"00:00:05\" }, \"Outbox\": { \"Enabled\": tru..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-10",
        "text": "Saga: Payment Failure (Compensation) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 CreateOrder ‚Üí OrderCreated ‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 2 OrderCreated ‚Üí ReserveInventory ‚Üí InventoryReserved ‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 3 InventoryReserved ‚Üí ProcessPayment ‚Üí PaymentFailed ‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 4 PaymentFailed ‚Üí ReleaseInventory ‚Üí InventoryReleased‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 5 InventoryReleased ‚Üí CancelOrder ‚Üí OrderCancelled    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nCompensating transactions:\nPaymentFailed ‚Üí ReleaseInventory (return stock to available)\nOrderCancelled ‚Üí RefundPayment (refund customer)\nRetry Logic with Polly\n`csharp\n// Exponential backoff: 2s, 4s, 8s\nPolicy Handle<HttpRequestException>() WaitAndRetryAsync(\n    retryCount: 3,\n    sleepDurationProvider: attempt => TimeSpan FromSeconds(Math Pow(2, attempt))\n  );\n`\nWhen to retry:\n‚úÖ Network errors (transient)\n‚úÖ Gateway timeouts (transient)\n‚ùå Invalid card (permanent)\n‚ùå Insufficient funds (permanent)\nCircuit Breaker\n`csharp\n// Open circuit after 5 failures, half-open after 30s\nPolicy Handle<HttpRequestException>() CircuitBreakerAsync(\n    exceptionsAllowedBeforeBreaking: 5,\n    durationOfBreak: TimeSpan FromSeconds(30)\n  );\n`\nStates:\nClosed: Normal operation\nOpen: Gateway unavailable, fail fast\nHalf-Open: Test if gateway recovered\n---\nTesting\nUnit Test - Successful Payment\n`csharp\n[Test]\npublic async Task ProcessPayment_ValidCard_ChargesAndPublishesEventAsync() {\n  // Arrange\n  var mockGateway = new MockPaymentGateway();\n  mockGateway SetupSuccessfulCharge(\"pi_123456\");\n  var receptor = new ProcessPaymentReceptor(mockDb, mockGateway, mockContext, mockLogger);\n  var @event = new InventoryReserved(\n    OrderId: \"order-123\",\n    ProductId: \"prod-456\",\n    QuantityReserved: 2,\n    RemainingStock: 98,\n    ReservedAt: DateTime UtcNow\n  );\n  // Act\n  var result = await receptor HandleAsync(@event);\n  // Assert\n  await Assert That(result Status) IsEqualTo(PaymentStatus Captured);\n  await Assert That(result TransactionId) IsEqualTo(\"pi_123456\");\n}\n`\nUnit Test - Payment Failure\n`csharp\n[Test]\npublic async Task ProcessPayment_InvalidCard_PublishesPaymentFailedEventAsync() {\n  // Arrange\n  var mockGateway = new MockPaymentGateway();\n  mockGateway SetupFailedCharge(\"card_declined\", \"Your card was declined\");\n  var receptor = new ProcessPaymentReceptor(mockDb, mockGateway, mockContext, mockLogger);\n  var @event = new InventoryReserved( );\n  // Act & Assert\n  await Assert That(async () => await receptor HandleAsync(@event)) Throws<PaymentFailedException>();\n  // Verify PaymentFailed event was published\n  var outboxEvent = mockDb GetOutboxEvents() Single();\n  await Assert That(outboxEvent MessageType)",
        "startIndex": 24751,
        "preview": "Saga: Payment Failure (Compensation) ‚îÇ ‚îÇ ‚îÇ ‚îÇ 1 CreateOrder ‚Üí OrderCreated ‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 2 OrderCreated ‚Üí ReserveInventory ‚Üí InventoryReserved ‚îÇ ‚îÇ ‚Üì ‚îÇ ‚îÇ 3 ..."
      },
      {
        "id": "v0.1.0/tutorial/payment-processing-chunk-11",
        "text": "MockPaymentGateway(); mockGateway SetupFailedCharge(\"card_declined\", \"Your card was declined\"); var receptor = new ProcessPaymentReceptor(mockDb, mockGateway, mockContext, mockLogger); var @event = new InventoryReserved( ); // Act & Assert await Assert That(async () => await receptor HandleAsync(@event)) Throws<PaymentFailedException>(); // Verify PaymentFailed event was published var outboxEvent = mockDb GetOutboxEvents() Single(); await Assert That(outboxEvent MessageType) Contains(\"PaymentFailed\");\n}\n`\n---\nNext Steps\nContinue to Notification Service to:\nSubscribe to PaymentProcessed events\nSend order confirmation emails\nIntegrate with email/SMS providers\nHandle notification failures gracefully\n---\nKey Takeaways\n‚úÖ Idempotency - Prevent duplicate charges with idempotency keys\n‚úÖ Retry Logic - Exponential backoff for transient failures\n‚úÖ Circuit Breaker - Fail fast when gateway is down\n‚úÖ Saga Pattern - Distributed transactions with compensation\n‚úÖ Gateway Abstraction - Swap payment providers easily\n‚úÖ Compensation - Refunds and inventory release on failure\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 27107,
        "preview": "MockPaymentGateway(); mockGateway SetupFailedCharge(\"card_declined\", \"Your card was declined\"); var receptor = new ProcessPaymentReceptor(mockDb, mock..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/shipping-service",
    "title": "Shipping Service",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/shipping-service",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-0",
        "text": "Shipping Service\nBuild the Shipping Worker - a background service that subscribes to PaymentProcessed events, creates shipments via carrier APIs (FedEx/UPS/USPS), and publishes tracking information :::note\nThis is Part 5 of the ECommerce Tutorial Complete Notification Service first :::\n---\nWhat You'll Build\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Shipping Service Architecture                              ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                            ‚îÇ\n‚îÇ  ‚îÇAzure Service‚îÇ  PaymentProcessed event                    ‚îÇ\n‚îÇ  ‚îÇ     Bus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ                     ‚îÇ\n‚îÇ                                        ‚ñº                     ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇCreateShipmentReceptor  ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Get order details   ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Call carrier API    ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ  - Store tracking info ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ\n‚îÇ                      ‚îÇ              ‚îÇ              ‚îÇ        ‚îÇ\n‚îÇ                      ‚ñº              ‚ñº              ‚ñº        ‚îÇ\n‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ                 ‚îÇPostgres ‚îÇ   ‚îÇ Outbox  ‚îÇ   ‚îÇ Carrier  ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇShipments‚îÇ   ‚îÇ Table   ‚îÇ   ‚îÇ   API    ‚îÇ   ‚îÇ\n‚îÇ                 ‚îÇ  Table  ‚îÇ   ‚îÇ         ‚îÇ   ‚îÇ(FedEx)   ‚îÇ   ‚îÇ\n‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îÇ                                     ‚îÇ                        ‚îÇ\n‚îÇ                                     ‚ñº                        ‚îÇ\n‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n‚îÇ                          ‚îÇ Azure Service Bus      ‚îÇ         ‚îÇ\n‚îÇ                          ‚îÇ ShipmentCreated        ‚îÇ         ‚îÇ\n‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nFeatures:\n‚úÖ Carrier API integration (FedEx example)\n‚úÖ Shipment creation with tracking\n‚úÖ Address validation\n‚úÖ Rate shopping (cheapest/fastest)\n‚úÖ Webhook integration for status updates\n‚úÖ Label generation (PDF)\n---\nStep 1: Define Events\nShipmentCreated Event\nECommerce Contracts/Events/ShipmentCreated cs:\n`csharp\nusing Whizbang Core;\nnamespace ECommerce Contracts Events;\npublic record ShipmentCreated(\n  string ShipmentId,\n  string OrderId,\n  string Carrier,\n  string TrackingNumber,\n  string LabelUrl,\n  decimal ShippingCost,\n  DateTime EstimatedDelivery,\n  DateTime CreatedAt\n) : IEvent;\n`\n---\nStep 2: Carrier API Abstraction\nECommerce ShippingWorker/Services/ICarrierService cs:\n`csharp\nnamespace ECommerce ShippingWorker",
        "startIndex": 0,
        "preview": "Shipping Service\nBuild the Shipping Worker - a background service that subscribes to PaymentProcessed events, creates shipments via carrier APIs (FedE..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-1",
        "text": "Events ShipmentCreated Event ECommerce Contracts/Events/ShipmentCreated cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events; public record ShipmentCreated( string ShipmentId, string OrderId, string Carrier, string TrackingNumber, string LabelUrl, decimal ShippingCost, DateTime EstimatedDelivery, DateTime CreatedAt ) : IEvent; ` --- Step 2: Carrier API Abstraction ECommerce ShippingWorker/Services/ICarrierService cs: `csharp namespace ECommerce ShippingWorker Services;\npublic interface ICarrierService {\n  Task<ShipmentResult> CreateShipmentAsync(\n    ShipmentRequest request,\n    CancellationToken ct = default\n  );\n  Task<TrackingResult> GetTrackingAsync(\n    string trackingNumber,\n    CancellationToken ct = default\n  );\n}\npublic record ShipmentRequest(\n  string OrderId,\n  Address From,\n  Address To,\n  Package Package,\n  ShipmentOptions Options\n);\npublic record Address(\n  string Name,\n  string Street,\n  string City,\n  string State,\n  string ZipCode,\n  string Country,\n  string Phone = null\n);\npublic record Package(\n  decimal WeightPounds,\n  int LengthInches,\n  int WidthInches,\n  int HeightInches\n);\npublic record ShipmentOptions(\n  string ServiceLevel,  // \"Standard\", \"Express\", \"Overnight\"\n  bool SignatureRequired = false,\n  bool SaturdayDelivery = false\n);\npublic record ShipmentResult(\n  bool Success,\n  string ShipmentId,\n  string TrackingNumber,\n  string LabelUrl,\n  decimal ShippingCost,\n  DateTime EstimatedDelivery,\n  string ErrorMessage\n);\npublic record TrackingResult(\n  string TrackingNumber,\n  string Status,\n  DateTime EstimatedDelivery,\n  TrackingEvent[] Events\n);\npublic record TrackingEvent(\n  string Status,\n  string Location,\n  DateTime Timestamp\n);\n`\n---\nStep 3: FedEx Implementation\nECommerce ShippingWorker/Services/FedExCarrierService cs:\n`csharp\nusing System Net Http Json;\nnamespace ECommerce ShippingWorker Services;\npublic class FedExCarrierService : ICarrierService {\n  private readonly HttpClient _httpClient;\n  private readonly string _accountNumber;\n  private readonly string _meterNumber;\n  private readonly ILogger<FedExCarrierService> _logger;\n  public FedExCarrierService(\n    HttpClient httpClient,\n    IConfiguration configuration,\n    ILogger<FedExCarrierService> logger\n  ) {\n    _httpClient = httpClient;\n    _accountNumber = configuration[\"FedEx:AccountNumber\"] throw new InvalidOperationException(\"FedEx:AccountNumber not configured\");\n    _meterNumber = configuration[\"FedEx:MeterNumber\"] throw new InvalidOperationException(\"FedEx:MeterNumber not configured\");\n    _logger = logger;\n    _httpClient BaseAddress = new Uri(configuration[\"FedEx:ApiUrl\"] \"https://apis-sandbox fedex com\");\n  }\n  public async Task<ShipmentResult> CreateShipmentAsync(\n    ShipmentRequest request,\n    CancellationToken ct = default\n  ) {\n    try {\n      // 1 Get OAuth token\n      var token = await GetOAuthTokenAsync(ct);\n      // 2",
        "startIndex": 2960,
        "preview": "Events ShipmentCreated Event ECommerce Contracts/Events/ShipmentCreated cs: `csharp using Whizbang Core; namespace ECommerce Contracts Events; public ..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-2",
        "text": "new InvalidOperationException(\"FedEx:AccountNumber not configured\"); _meterNumber = configuration[\"FedEx:MeterNumber\"] throw new InvalidOperationException(\"FedEx:MeterNumber not configured\"); _logger = logger; _httpClient BaseAddress = new Uri(configuration[\"FedEx:ApiUrl\"] \"https://apis-sandbox fedex com\"); } public async Task<ShipmentResult> CreateShipmentAsync( ShipmentRequest request, CancellationToken ct = default ) { try { // 1 Get OAuth token var token = await GetOAuthTokenAsync(ct); // 2 Build shipment request\n      var fedexRequest = new {\n        accountNumber = new {\n          value = _accountNumber\n        },\n        requestedShipment = new {\n          shipper = new {\n            contact = new {\n              personName = request From Name,\n              phoneNumber = request From Phone \"5551234567\"\n            },\n            address = new {\n              streetLines = new[] { request From Street },\n              city = request From City,\n              stateOrProvinceCode = request From State,\n              postalCode = request From ZipCode,\n              countryCode = request From Country\n            }\n          },\n          recipients = new[] {\n            new {\n              contact = new {\n                personName = request To Name,\n                phoneNumber = request To Phone \"5551234567\"\n              },\n              address = new {\n                streetLines = new[] { request To Street },\n                city = request To City,\n                stateOrProvinceCode = request To State,\n                postalCode = request To ZipCode,\n                countryCode = request To Country\n              }\n            }\n          },\n          pickupType = \"USE_SCHEDULED_PICKUP\",\n          serviceType = MapServiceLevel(request Options ServiceLevel),\n          packagingType = \"YOUR_PACKAGING\",\n          shippingChargesPayment = new {\n            paymentType = \"SENDER\"\n          },\n          labelSpecification = new {\n            labelFormatType = \"COMMON2D\",\n            imageType = \"PDF\",\n            labelStockType = \"PAPER_4X6\"\n          },\n          requestedPackageLineItems = new[] {\n            new {\n              weight = new {\n                units = \"LB\",\n                value = request Package WeightPounds\n              },\n              dimensions = new {\n                length = request Package LengthInches,\n                width = request Package WidthInches,\n                height = request Package HeightInches,\n                units = \"IN\"\n              }\n            }\n          }\n        }\n      };\n      // 3 Call FedEx API\n      var httpRequest = new HttpRequestMessage(HttpMethod Post, \"/ship/v1/shipments\");\n      httpRequest Headers Add(\"Authorization\", $\"Bearer {token}\");\n      httpRequest Headers Add(\"X-locale\", \"en_US\");\n      httpRequest Content = JsonContent Create(fedexRequest);\n      var response = await _httpClient SendAsync(httpRequest, ct);\n      var responseContent = await response Content",
        "startIndex": 5400,
        "preview": "new InvalidOperationException(\"FedEx:AccountNumber not configured\"); _meterNumber = configuration[\"FedEx:MeterNumber\"] throw new InvalidOperationExcep..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-3",
        "text": "request Package HeightInches, units = \"IN\" } } } } }; // 3 Call FedEx API var httpRequest = new HttpRequestMessage(HttpMethod Post, \"/ship/v1/shipments\"); httpRequest Headers Add(\"Authorization\", $\"Bearer {token}\"); httpRequest Headers Add(\"X-locale\", \"en_US\"); httpRequest Content = JsonContent Create(fedexRequest); var response = await _httpClient SendAsync(httpRequest, ct); var responseContent = await response Content ReadAsStringAsync(ct);\n      if (response IsSuccessStatusCode) {\n        var fedexResponse = System Text Json JsonSerializer Deserialize<FedExShipmentResponse>(responseContent);\n        var trackingNumber = fedexResponse output transactionShipments [0] masterTrackingNumber;\n        var labelUrl = fedexResponse output transactionShipments [0] pieceResponses [0] packageDocuments [0] url;\n        var shippingCost = fedexResponse output transactionShipments [0] shipmentDocuments [0] netCharge;\n        _logger LogInformation(\n          \"FedEx shipment created for order {OrderId}, tracking: {TrackingNumber}\",\n          request OrderId,\n          trackingNumber\n        );\n        return new ShipmentResult(\n          Success: true,\n          ShipmentId: trackingNumber,\n          TrackingNumber: trackingNumber,\n          LabelUrl: labelUrl,\n          ShippingCost: shippingCost 0,\n          EstimatedDelivery: DateTime UtcNow AddDays(3),  // Simplified\n          ErrorMessage: null\n        );\n      } else {\n        _logger LogError(\n          \"FedEx shipment failed for order {OrderId}: {StatusCode} - {Response}\",\n          request OrderId,\n          response StatusCode,\n          responseContent\n        );\n        return new ShipmentResult(\n          Success: false,\n          ShipmentId: null,\n          TrackingNumber: null,\n          LabelUrl: null,\n          ShippingCost: null,\n          EstimatedDelivery: null,\n          ErrorMessage: $\"FedEx API error: {response StatusCode}\"\n        );\n      }\n    } catch (Exception ex) {\n      _logger LogError(ex, \"FedEx shipment exception for order {OrderId}\", request OrderId);\n      return new ShipmentResult(\n        Success: false,\n        ShipmentId: null,\n        TrackingNumber: null,\n        LabelUrl: null,\n        ShippingCost: null,\n        EstimatedDelivery: null,\n        ErrorMessage: ex Message\n      );\n    }\n  }\n  public async Task<TrackingResult> GetTrackingAsync(\n    string trackingNumber,\n    CancellationToken ct = default\n  ) {\n    // Similar implementation for tracking API\n    // For brevity, omitted\n    return new TrackingResult(\n      TrackingNumber: trackingNumber,\n      Status: \"In Transit\",\n      EstimatedDelivery: DateTime UtcNow AddDays(2),\n      Events: [\n        new TrackingEvent(\"Picked Up\", \"Memphis, TN\", DateTime UtcNow AddDays(-1)),\n        new TrackingEvent(\"In Transit\", \"Indianapolis, IN\", DateTime UtcNow",
        "startIndex": 7886,
        "preview": "request Package HeightInches, units = \"IN\" } } } } }; // 3 Call FedEx API var httpRequest = new HttpRequestMessage(HttpMethod Post, \"/ship/v1/shipment..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-4",
        "text": "async Task<TrackingResult> GetTrackingAsync( string trackingNumber, CancellationToken ct = default ) { // Similar implementation for tracking API // For brevity, omitted return new TrackingResult( TrackingNumber: trackingNumber, Status: \"In Transit\", EstimatedDelivery: DateTime UtcNow AddDays(2), Events: [ new TrackingEvent(\"Picked Up\", \"Memphis, TN\", DateTime UtcNow AddDays(-1)), new TrackingEvent(\"In Transit\", \"Indianapolis, IN\", DateTime UtcNow AddHours(-6))\n      ]\n    );\n  }\n  private async Task<string> GetOAuthTokenAsync(CancellationToken ct) {\n    // FedEx OAuth token exchange\n    // Simplified for demo\n    return \"fake-oauth-token\";\n  }\n  private string MapServiceLevel(string serviceLevel) {\n    return serviceLevel switch {\n      \"Standard\" => \"FEDEX_GROUND\",\n      \"Express\" => \"FEDEX_2_DAY\",\n      \"Overnight\" => \"FEDEX_PRIORITY_OVERNIGHT\",\n      _ => \"FEDEX_GROUND\"\n    };\n  }\n}\n// FedEx API response models (simplified)\npublic record FedExShipmentResponse(\n  FedExOutput output\n);\npublic record FedExOutput(\n  FedExTransactionShipment[] transactionShipments\n);\npublic record FedExTransactionShipment(\n  string masterTrackingNumber,\n  FedExPieceResponse[] pieceResponses,\n  FedExShipmentDocument[] shipmentDocuments\n);\npublic record FedExPieceResponse(\n  FedExPackageDocument[] packageDocuments\n);\npublic record FedExPackageDocument(\n  string url\n);\npublic record FedExShipmentDocument(\n  decimal netCharge\n);\n`\n---\nStep 4: Database Schema\nECommerce ShippingWorker/Database/Migrations/001_CreateShipmentsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS shipments (\n  shipment_id TEXT PRIMARY KEY,\n  order_id TEXT NOT NULL UNIQUE,\n  carrier TEXT NOT NULL,\n  tracking_number TEXT NOT NULL UNIQUE,\n  label_url TEXT NOT NULL,\n  shipping_cost NUMERIC(10, 2) NOT NULL,\n  estimated_delivery TIMESTAMP NOT NULL,\n  actual_delivery TIMESTAMP,\n  status TEXT NOT NULL,  -- 'Created', 'InTransit', 'Delivered', 'Exception'\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_shipments_order_id ON shipments(order_id);\nCREATE INDEX idx_shipments_tracking_number ON shipments(tracking_number);\nCREATE INDEX idx_shipments_status ON shipments(status);\n`\nECommerce ShippingWorker/Database/Migrations/002_CreateTrackingEventsTable sql:\n`sql\nCREATE TABLE IF NOT EXISTS tracking_events (\n  event_id TEXT PRIMARY KEY,\n  shipment_id TEXT NOT NULL REFERENCES shipments(shipment_id),\n  status TEXT NOT NULL,\n  location TEXT NOT NULL,\n  timestamp TIMESTAMP NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_tracking_events_shipment_id ON tracking_events(shipment_id);\nCREATE INDEX idx_tracking_events_timestamp ON tracking_events(timestamp DESC);\n`\n---\nStep 5: Implement Receptor\nECommerce ShippingWorker/Receptors/CreateShipmentReceptor cs:\n`csharp\nusing Whizbang Core;\nusing ECommerce Contracts Events;\nusing ECommerce",
        "startIndex": 10307,
        "preview": "async Task<TrackingResult> GetTrackingAsync( string trackingNumber, CancellationToken ct = default ) { // Similar implementation for tracking API // F..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-5",
        "text": "shipments(shipment_id), status TEXT NOT NULL, location TEXT NOT NULL, timestamp TIMESTAMP NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT NOW() ); CREATE INDEX idx_tracking_events_shipment_id ON tracking_events(shipment_id); CREATE INDEX idx_tracking_events_timestamp ON tracking_events(timestamp DESC); ` --- Step 5: Implement Receptor ECommerce ShippingWorker/Receptors/CreateShipmentReceptor cs: `csharp using Whizbang Core; using ECommerce Contracts Events; using ECommerce ShippingWorker Services;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce ShippingWorker Receptors;\npublic class CreateShipmentReceptor : IReceptor<PaymentProcessed, ShipmentCreated> {\n  private readonly NpgsqlConnection _db;\n  private readonly ICarrierService _carrierService;\n  private readonly IMessageContext _context;\n  private readonly ILogger<CreateShipmentReceptor> _logger;\n  public CreateShipmentReceptor(\n    NpgsqlConnection db,\n    ICarrierService carrierService,\n    IMessageContext context,\n    ILogger<CreateShipmentReceptor> logger\n  ) {\n    _db = db;\n    _carrierService = carrierService;\n    _context = context;\n    _logger = logger;\n  }\n  public async Task<ShipmentCreated> HandleAsync(\n    PaymentProcessed @event,\n    CancellationToken ct = default\n  ) {\n    await using var tx = await _db BeginTransactionAsync(ct);\n    try {\n      // 1 Check if shipment already exists (idempotency)\n      var existingShipment = await _db QuerySingleOrDefaultAsync<ShipmentRow>(\n        \"\"\"\n        SELECT shipment_id, order_id, carrier, tracking_number, label_url, shipping_cost, estimated_delivery\n        FROM shipments\n        WHERE order_id = @OrderId\n        \"\"\",\n        new { OrderId = @event OrderId },\n        transaction: tx\n      );\n      if (existingShipment = null) {\n        _logger LogInformation(\n          \"Shipment already exists for order {OrderId}, skipping\",\n          @event OrderId\n        );\n        return new ShipmentCreated(\n          ShipmentId: existingShipment ShipmentId,\n          OrderId: existingShipment OrderId,\n          Carrier: existingShipment Carrier,\n          TrackingNumber: existingShipment TrackingNumber,\n          LabelUrl: existingShipment LabelUrl,\n          ShippingCost: existingShipment ShippingCost,\n          EstimatedDelivery: existingShipment EstimatedDelivery,\n          CreatedAt: DateTime UtcNow\n        );\n      }\n      // 2 Get order details (from Order Service DB - cross-service query for demo)\n      var order = await GetOrderAsync(@event OrderId, ct);\n      if (order == null) {\n        throw new InvalidOperationException($\"Order {event OrderId} not found\");\n      }\n      // 3 Build shipment request\n      var shipmentRequest = new ShipmentRequest(\n        OrderId: @event OrderId,\n        From: new Address(\n          Name: \"ECommerce Warehouse\",\n          Street: \"1000 Warehouse Blvd\",\n          City: \"Memphis\",\n          State: \"TN\",\n          ZipCode: \"38101\",\n          Country: \"US\",\n          Phone: \"9015551234\"\n        ),\n        To: new Address(\n          Name: order CustomerName,\n          Street: order ShippingAddress Street,\n          City: order ShippingAddress City,\n          State: order",
        "startIndex": 2873,
        "preview": "shipments(shipment_id), status TEXT NOT NULL, location TEXT NOT NULL, timestamp TIMESTAMP NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT NOW() ); CRE..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-6",
        "text": "// 3 Build shipment request var shipmentRequest = new ShipmentRequest( OrderId: @event OrderId, From: new Address( Name: \"ECommerce Warehouse\", Street: \"1000 Warehouse Blvd\", City: \"Memphis\", State: \"TN\", ZipCode: \"38101\", Country: \"US\", Phone: \"9015551234\" ), To: new Address( Name: order CustomerName, Street: order ShippingAddress Street, City: order ShippingAddress City, State: order ShippingAddress State,\n          ZipCode: order ShippingAddress ZipCode,\n          Country: order ShippingAddress Country\n        ),\n        Package: new Package(\n          WeightPounds: 5 0m,  // Demo: Hard-coded weight\n          LengthInches: 12,\n          WidthInches: 10,\n          HeightInches: 8\n        ),\n        Options: new ShipmentOptions(\n          ServiceLevel: \"Standard\"\n        )\n      );\n      // 4 Call carrier API\n      var result = await _carrierService CreateShipmentAsync(shipmentRequest, ct);\n      if (result Success) {\n        var shipmentId = Guid NewGuid() ToString(\"N\");\n        // 5 Store shipment\n        await _db ExecuteAsync(\n          \"\"\"\n          INSERT INTO shipments (\n            shipment_id, order_id, carrier, tracking_number, label_url, shipping_cost, estimated_delivery, status, created_at, updated_at\n          )\n          VALUES (@ShipmentId, @OrderId, @Carrier, @TrackingNumber, @LabelUrl, @ShippingCost, @EstimatedDelivery, @Status, NOW(), NOW())\n          \"\"\",\n          new {\n            ShipmentId = shipmentId,\n            OrderId = @event OrderId,\n            Carrier = \"FedEx\",\n            TrackingNumber = result TrackingNumber,\n            LabelUrl = result LabelUrl,\n            ShippingCost = result ShippingCost,\n            EstimatedDelivery = result EstimatedDelivery,\n            Status = \"Created\"\n          },\n          transaction: tx\n        );\n        // 6 Publish ShipmentCreated event\n        var shipmentCreatedEvent = new ShipmentCreated(\n          ShipmentId: shipmentId,\n          OrderId: @event OrderId,\n          Carrier: \"FedEx\",\n          TrackingNumber: result TrackingNumber ,\n          LabelUrl: result LabelUrl ,\n          ShippingCost: result ShippingCost Value,\n          EstimatedDelivery: result EstimatedDelivery Value,\n          CreatedAt: DateTime UtcNow\n        );\n        await PublishEventAsync(shipmentCreatedEvent, tx, ct);\n        await tx CommitAsync(ct);\n        _logger LogInformation(\n          \"Shipment created for order {OrderId}, tracking: {TrackingNumber}, cost: ${ShippingCost}\",\n          @event OrderId,\n          result TrackingNumber,\n          result ShippingCost\n        );\n        return shipmentCreatedEvent;\n      } else {\n        throw new ShipmentCreationFailedException(\n          @event OrderId,\n          result ErrorMessage \"Shipment creation failed\"\n        );\n      }\n    } catch {\n      await tx RollbackAsync(ct);\n      throw;\n    }\n  }\n  private async Task<OrderRow > GetOrderAsync(string orderId, CancellationToken ct) {\n    // Cross-service query (demo only - use event-carried state transfer in production)\n    return await _db QuerySingleOrDefaultAsync<OrderRow>(\n      \"\"\"\n      SELECT\n        o order_id,\n        o customer_id AS customer_name,\n        o",
        "startIndex": 15357,
        "preview": "// 3 Build shipment request var shipmentRequest = new ShipmentRequest( OrderId: @event OrderId, From: new Address( Name: \"ECommerce Warehouse\", Street..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-7",
        "text": "result ErrorMessage \"Shipment creation failed\" ); } } catch { await tx RollbackAsync(ct); throw; } } private async Task<OrderRow > GetOrderAsync(string orderId, CancellationToken ct) { // Cross-service query (demo only - use event-carried state transfer in production) return await _db QuerySingleOrDefaultAsync<OrderRow>( \"\"\" SELECT o order_id, o customer_id AS customer_name, o shipping_address\n      FROM orders o\n      WHERE o order_id = @OrderId\n      \"\"\",\n      new { OrderId = orderId }\n    );\n  }\n  private async Task PublishEventAsync<TEvent>(\n    TEvent @event,\n    NpgsqlTransaction tx,\n    CancellationToken ct\n  ) where TEvent : IEvent {\n    await _db ExecuteAsync(\n      \"\"\"\n      INSERT INTO outbox (message_id, message_type, message_body, created_at)\n      VALUES (@MessageId, @MessageType, @MessageBody::jsonb, NOW())\n      \"\"\",\n      new {\n        MessageId = Guid NewGuid(),\n        MessageType = typeof(TEvent) FullName,\n        MessageBody = System Text Json JsonSerializer Serialize(@event)\n      },\n      transaction: tx\n    );\n  }\n}\npublic record ShipmentRow(\n  string ShipmentId,\n  string OrderId,\n  string Carrier,\n  string TrackingNumber,\n  string LabelUrl,\n  decimal ShippingCost,\n  DateTime EstimatedDelivery\n);\npublic record OrderRow(\n  string OrderId,\n  string CustomerName,\n  ShippingAddress ShippingAddress\n);\npublic record ShippingAddress(\n  string Street,\n  string City,\n  string State,\n  string ZipCode,\n  string Country\n);\npublic class ShipmentCreationFailedException : Exception {\n  public ShipmentCreationFailedException(string orderId, string message)\n    : base($\"Shipment creation failed for order {orderId}: {message}\") { }\n}\n`\n---\nStep 6: Tracking Updates (Webhook)\nECommerce ShippingWorker/Controllers/WebhooksController cs:\n`csharp\nusing Microsoft AspNetCore Mvc;\nusing Npgsql;\nusing Dapper;\nnamespace ECommerce ShippingWorker Controllers;\n[ApiController]\n[Route(\"api/webhooks\")]\npublic class WebhooksController : ControllerBase {\n  private readonly NpgsqlConnection _db;\n  private readonly ILogger<WebhooksController> _logger;\n  public WebhooksController(\n    NpgsqlConnection db,\n    ILogger<WebhooksController> logger\n  ) {\n    _db = db;\n    _logger = logger;\n  }\n  [HttpPost(\"fedex/tracking\")]\n  public async Task<IActionResult> FedExTrackingUpdate([FromBody] FedExTrackingWebhook webhook) {\n    try {\n      var trackingNumber = webhook TrackingNumber;\n      var status = webhook Status;\n      var location = webhook Location;\n      var timestamp = webhook Timestamp;\n      // 1 Find shipment\n      var shipment = await _db",
        "startIndex": 18241,
        "preview": "result ErrorMessage \"Shipment creation failed\" ); } } catch { await tx RollbackAsync(ct); throw; } } private async Task<OrderRow > GetOrderAsync(strin..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-8",
        "text": "ILogger<WebhooksController> logger ) { _db = db; _logger = logger; } [HttpPost(\"fedex/tracking\")] public async Task<IActionResult> FedExTrackingUpdate([FromBody] FedExTrackingWebhook webhook) { try { var trackingNumber = webhook TrackingNumber; var status = webhook Status; var location = webhook Location; var timestamp = webhook Timestamp; // 1 Find shipment var shipment = await _db QuerySingleOrDefaultAsync<ShipmentRow>(\n        \"\"\"\n        SELECT shipment_id, order_id, tracking_number\n        FROM shipments\n        WHERE tracking_number = @TrackingNumber\n        \"\"\",\n        new { TrackingNumber = trackingNumber }\n      );\n      if (shipment == null) {\n        _logger LogWarning(\"Shipment not found for tracking {TrackingNumber}\", trackingNumber);\n        return NotFound();\n      }\n      // 2 Insert tracking event\n      await _db ExecuteAsync(\n        \"\"\"\n        INSERT INTO tracking_events (event_id, shipment_id, status, location, timestamp, created_at)\n        VALUES (@EventId, @ShipmentId, @Status, @Location, @Timestamp, NOW())\n        \"\"\",\n        new {\n          EventId = Guid NewGuid() ToString(\"N\"),\n          ShipmentId = shipment ShipmentId,\n          Status = status,\n          Location = location,\n          Timestamp = timestamp\n        }\n      );\n      // 3 Update shipment status\n      if (status == \"Delivered\") {\n        await _db ExecuteAsync(\n          \"\"\"\n          UPDATE shipments\n          SET status = 'Delivered', actual_delivery = @Timestamp, updated_at = NOW()\n          WHERE shipment_id = @ShipmentId\n          \"\"\",\n          new { ShipmentId = shipment ShipmentId, Timestamp = timestamp }\n        );\n      }\n      _logger LogInformation(\n        \"Tracking update for {TrackingNumber}: {Status} at {Location}\",\n        trackingNumber,\n        status,\n        location\n      );\n      return Ok();\n    } catch (Exception ex) {\n      _logger LogError(ex, \"Failed to process FedEx tracking webhook\");\n      return StatusCode(500);\n    }\n  }\n}\npublic record FedExTrackingWebhook(\n  string TrackingNumber,\n  string Status,\n  string Location,\n  DateTime Timestamp\n);\n`\n---\nStep 7: Test Shipping Flow\nCreate Order (Full End-to-End)\n`bash\ncurl -X POST http://localhost:5000/api/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{",
        "startIndex": 20436,
        "preview": "ILogger<WebhooksController> logger ) { _db = db; _logger = logger; } [HttpPost(\"fedex/tracking\")] public async Task<IActionResult> FedExTrackingUpdate..."
      },
      {
        "id": "v0.1.0/tutorial/shipping-service-chunk-9",
        "text": "ex) { _logger LogError(ex, \"Failed to process FedEx tracking webhook\"); return StatusCode(500); } } } public record FedExTrackingWebhook( string TrackingNumber, string Status, string Location, DateTime Timestamp ); ` --- Step 7: Test Shipping Flow Create Order (Full End-to-End) `bash curl -X POST http://localhost:5000/api/orders \\ -H \"Content-Type: application/json\" \\ -d '{ }'\n`\nObserve Event Flow\nAspire Dashboard:\nOrder Service: OrderCreated\nInventory Worker: InventoryReserved\nPayment Worker: PaymentProcessed\nShipping Worker: ShipmentCreated (THIS STEP)\nNotification Worker: ShipmentNotification (SMS)\nVerify Shipment\n`sql\nSELECT * FROM shipments WHERE order_id = '<order-id>';\n`\nExpected:\ntracking_number = '123456789012'\ncarrier = 'FedEx'\nstatus = 'Created'\nlabel_url contains PDF URL\n---\nKey Takeaways\n‚úÖ Carrier API Abstraction - Swap carriers easily (FedEx, UPS, USPS)\n‚úÖ Idempotency - Prevent duplicate shipments\n‚úÖ Webhook Integration - Real-time tracking updates\n‚úÖ Label Generation - PDF shipping labels\n‚úÖ Event-Driven - ShipmentCreated triggers notifications\n---\nNext Steps\nContinue to Customer Service to:\nBuild BFF (Backend for Frontend) API\nImplement perspectives for read models\nQuery order summaries\nAggregate data from multiple services\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 22328,
        "preview": "ex) { _logger LogError(ex, \"Failed to process FedEx tracking webhook\"); return StatusCode(500); } } } public record FedExTrackingWebhook( string Track..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/testing-strategy",
    "title": "Testing Strategy",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/testing-strategy",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-0",
        "text": "Testing Strategy\nBuild a comprehensive testing strategy for the ECommerce system covering unit tests, integration tests, end-to-end tests, test fixtures, and mocking patterns :::note\nThis is Part 8 of the ECommerce Tutorial Complete Analytics Service first :::\n---\nTesting Pyramid\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Testing Pyramid                                         ‚îÇ\n‚îÇ                                                          ‚îÇ\n‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ\n‚îÇ              ‚îÇ  E2E Tests     ‚îÇ ‚Üê 10% (Slow, Expensive)  ‚îÇ\n‚îÇ              ‚îÇ  Full system   ‚îÇ                          ‚îÇ\n‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ\n‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ\n‚îÇ         ‚îÇ  Integration Tests    ‚îÇ ‚Üê 30% (Medium)        ‚îÇ\n‚îÇ         ‚îÇ  Service + DB + Bus   ‚îÇ                        ‚îÇ\n‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ\n‚îÇ    ‚îÇ      Unit Tests               ‚îÇ ‚Üê 60% (Fast, Cheap) ‚îÇ\n‚îÇ    ‚îÇ  Receptors, Perspectives,     ‚îÇ                     ‚îÇ\n‚îÇ    ‚îÇ  Business Logic               ‚îÇ                     ‚îÇ\n‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\n---\nUnit Tests\nTesting Receptors\nECommerce OrderService Tests/CreateOrderReceptorTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing ECommerce OrderService API Receptors;\nusing ECommerce Contracts Commands;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Moq;\nnamespace ECommerce OrderService Tests;\n[TestFixture]\npublic class CreateOrderReceptorTests {\n  [Test]\n  public async Task HandleAsync_ValidOrder_CreatesOrderAndPublishesEventAsync() {\n    // Arrange\n    var mockDb = new Mock<NpgsqlConnection>();\n    var mockContext = new Mock<IMessageContext>();\n    var mockLogger = new Mock<ILogger<CreateOrderReceptor>>();\n    // Setup message context\n    mockContext Setup(c => c MessageId) Returns(Guid NewGuid());\n    mockContext Setup(c => c CorrelationId) Returns(Guid NewGuid());\n    var receptor = new CreateOrderReceptor(\n      mockDb Object,\n      mockContext Object,\n      mockLogger Object\n    );\n    var command = new CreateOrder(\n      CustomerId: \"cust-123\",\n      Items: [\n        new OrderItem(\"prod-456\", 2, 19 99m)\n      ],\n      ShippingAddress: new Address(\n        Street: \"123 Main St\",\n        City: \"Springfield\",\n        State: \"IL\",\n        ZipCode: \"62701\",\n        Country: \"USA\"\n      )\n    );\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    await Assert That(result) IsNotNull();\n    await Assert That(result CustomerId) IsEqualTo(\"cust-123\");\n    await Assert That(result TotalAmount) IsEqualTo(39 98m);\n    await Assert That(result Items) HasCount() EqualTo(1);\n    await Assert That(result Items[0] LineTotal) IsEqualTo(39",
        "startIndex": 0,
        "preview": "Testing Strategy\nBuild a comprehensive testing strategy for the ECommerce system covering unit tests, integration tests, end-to-end tests, test fixtur..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-1",
        "text": "\"123 Main St\", City: \"Springfield\", State: \"IL\", ZipCode: \"62701\", Country: \"USA\" ) ); // Act var result = await receptor HandleAsync(command); // Assert await Assert That(result) IsNotNull(); await Assert That(result CustomerId) IsEqualTo(\"cust-123\"); await Assert That(result TotalAmount) IsEqualTo(39 98m); await Assert That(result Items) HasCount() EqualTo(1); await Assert That(result Items[0] LineTotal) IsEqualTo(39 98m);\n  }\n  [Test]\n  public async Task HandleAsync_EmptyItems_ThrowsValidationExceptionAsync() {\n    // Arrange\n    var mockDb = new Mock<NpgsqlConnection>();\n    var mockContext = new Mock<IMessageContext>();\n    var mockLogger = new Mock<ILogger<CreateOrderReceptor>>();\n    var receptor = new CreateOrderReceptor(\n      mockDb Object,\n      mockContext Object,\n      mockLogger Object\n    );\n    var command = new CreateOrder(\n      CustomerId: \"cust-123\",\n      Items: [],  // Empty items\n      ShippingAddress: new Address(\"123 Main\", \"Springfield\", \"IL\", \"62701\", \"USA\")\n    );\n    // Act & Assert\n    await Assert That(async () => await receptor HandleAsync(command)) Throws<ValidationException>() WithMessage() Contains(\"at least one item\");\n  }\n  [Test]\n  public async Task HandleAsync_DuplicateOrder_ReturnsExistingOrderAsync() {\n    // Arrange\n    var mockDb = new Mock<NpgsqlConnection>();\n    // Setup to return existing order\n    mockDb Setup(db => db QuerySingleOrDefaultAsync<OrderRow>(\n      It IsAny<string>(),\n      It IsAny<object>(),\n      It IsAny<NpgsqlTransaction>()\n    )) ReturnsAsync(new OrderRow(\n      OrderId: \"order-existing\",\n      CustomerId: \"cust-123\",\n      TotalAmount: 39 98m\n    ));\n    var receptor = new CreateOrderReceptor(mockDb Object, mockContext Object, mockLogger Object);\n    var command = new CreateOrder( );\n    // Act\n    var result = await receptor HandleAsync(command);\n    // Assert\n    await Assert That(result OrderId) IsEqualTo(\"order-existing\");\n  }\n}\n`\nTesting Perspectives\nECommerce CustomerService Tests/OrderSummaryPerspectiveTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing ECommerce CustomerService API Perspectives;\nusing ECommerce Contracts Events;\nusing Npgsql;\nusing Dapper;\nusing Moq;\nnamespace ECommerce CustomerService Tests;\n[TestFixture]\npublic class OrderSummaryPerspectiveTests {\n  [Test]\n  public async Task HandleAsync_OrderCreated_InsertsOrderSummaryAsync() {\n    // Arrange\n    var mockDb = new Mock<NpgsqlConnection>();\n    var mockLogger = new Mock<ILogger<OrderSummaryPerspective>>();\n    var perspective = new OrderSummaryPerspective(\n      mockDb Object,\n      mockLogger Object\n    );\n    var @event = new OrderCreated(\n      OrderId: \"order-123\",\n      CustomerId: \"cust-456\",\n      Items: [\n        new OrderItem(\"prod-789\", 2, 19 99m, 39 98m)\n      ],\n      ShippingAddress: new Address(\"123 Main\", \"Springfield\", \"IL\", \"62701\", \"USA\"),\n      TotalAmount: 39 98m,\n      CreatedAt: DateTime",
        "startIndex": 2931,
        "preview": "\"123 Main St\", City: \"Springfield\", State: \"IL\", ZipCode: \"62701\", Country: \"USA\" ) ); // Act var result = await receptor HandleAsync(command); // Ass..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-2",
        "text": "= new Mock<NpgsqlConnection>(); var mockLogger = new Mock<ILogger<OrderSummaryPerspective>>(); var perspective = new OrderSummaryPerspective( mockDb Object, mockLogger Object ); var @event = new OrderCreated( OrderId: \"order-123\", CustomerId: \"cust-456\", Items: [ new OrderItem(\"prod-789\", 2, 19 99m, 39 98m) ], ShippingAddress: new Address(\"123 Main\", \"Springfield\", \"IL\", \"62701\", \"USA\"), TotalAmount: 39 98m, CreatedAt: DateTime UtcNow\n    );\n    // Act\n    await perspective HandleAsync(@event);\n    // Assert\n    mockDb Verify(db => db ExecuteAsync(\n      It Is<string>(sql => sql Contains(\"INSERT INTO order_summary\")),\n      It Is<object>(param =>\n        ((dynamic)param) OrderId == \"order-123\" &&\n        ((dynamic)param) TotalAmount == 39 98m\n      ),\n      It IsAny<NpgsqlTransaction>(),\n      It IsAny<int>(),\n      It IsAny<CommandType>()\n    ), Times Once);\n  }\n  [Test]\n  public async Task HandleAsync_PaymentProcessed_UpdatesOrderSummaryAsync() {\n    // Arrange\n    var mockDb = new Mock<NpgsqlConnection>();\n    var mockLogger = new Mock<ILogger<OrderSummaryPerspective>>();\n    var perspective = new OrderSummaryPerspective(\n      mockDb Object,\n      mockLogger Object\n    );\n    var @event = new PaymentProcessed(\n      OrderId: \"order-123\",\n      PaymentId: \"pay-456\",\n      TransactionId: \"txn-789\",\n      Amount: 39 98m,\n      PaymentMethod: \"card\",\n      Status: PaymentStatus Captured,\n      ProcessedAt: DateTime UtcNow\n    );\n    // Act\n    await perspective HandleAsync(@event);\n    // Assert\n    mockDb Verify(db => db ExecuteAsync(\n      It Is<string>(sql => sql Contains(\"UPDATE order_summary\")),\n      It Is<object>(param =>\n        ((dynamic)param) OrderId == \"order-123\" &&\n        ((dynamic)param) PaymentId == \"pay-456\"\n      ),\n      It IsAny<NpgsqlTransaction>(),\n      It IsAny<int>(),\n      It IsAny<CommandType>()\n    ), Times Once);\n  }\n}\n`\n---\nIntegration Tests\nTesting with Test Database\nECommerce OrderService IntegrationTests/CreateOrderIntegrationTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing Microsoft AspNetCore Mvc Testing;\nusing ECommerce OrderService API;\nusing ECommerce Contracts Commands;\nusing System Net Http Json;\nnamespace ECommerce OrderService IntegrationTests;\n[TestFixture]\npublic class CreateOrderIntegrationTests : IAsyncDisposable {\n  private WebApplicationFactory<Program> _factory;\n  private HttpClient _client;\n  [Before(Test)]\n  public async Task SetupAsync() {\n    _factory = new WebApplicationFactory<Program>() WithWebHostBuilder(builder => {\n        builder ConfigureServices(services => {\n          // Override connection string to use test database\n          services Configure<ConnectionStrings>(options => {\n            options OrdersDb = \"Host=localhost;Database=orders_test;Username=postgres;Password=postgres\";\n          });\n        });\n      });\n    _client = _factory",
        "startIndex": 5442,
        "preview": "= new Mock<NpgsqlConnection>(); var mockLogger = new Mock<ILogger<OrderSummaryPerspective>>(); var perspective = new OrderSummaryPerspective( mockDb O..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-3",
        "text": "class CreateOrderIntegrationTests : IAsyncDisposable { private WebApplicationFactory<Program> _factory; private HttpClient _client; [Before(Test)] public async Task SetupAsync() { _factory = new WebApplicationFactory<Program>() WithWebHostBuilder(builder => { builder ConfigureServices(services => { // Override connection string to use test database services Configure<ConnectionStrings>(options => { options OrdersDb = \"Host=localhost;Database=orders_test;Username=postgres;Password=postgres\"; }); }); }); _client = _factory CreateClient();\n    // Clean database before each test\n    await CleanDatabaseAsync();\n  }\n  [After(Test)]\n  public async Task TeardownAsync() {\n    await CleanDatabaseAsync();\n  }\n  [Test]\n  public async Task POST_CreateOrder_ReturnsCreatedStatusAsync() {\n    // Arrange\n    var command = new {\n      customerId = \"cust-123\",\n      items = new[] {\n        new { productId = \"prod-456\", quantity = 2, unitPrice = 19 99 }\n      },\n      shippingAddress = new {\n        street = \"123 Main St\",\n        city = \"Springfield\",\n        state = \"IL\",\n        zipCode = \"62701\",\n        country = \"USA\"\n      }\n    };\n    // Act\n    var response = await _client PostAsJsonAsync(\"/api/orders\", command);\n    // Assert\n    await Assert That(response StatusCode) IsEqualTo(HttpStatusCode Created);\n    var result = await response Content ReadFromJsonAsync<OrderCreated>();\n    await Assert That(result) IsNotNull();\n    await Assert That(result CustomerId) IsEqualTo(\"cust-123\");\n    await Assert That(result TotalAmount) IsEqualTo(39 98m);\n  }\n  [Test]\n  public async Task POST_CreateOrder_SavesOrderToDatabase_AndPublishesToOutboxAsync() {\n    // Arrange\n    var command = new { };\n    // Act\n    var response = await _client PostAsJsonAsync(\"/api/orders\", command);\n    var result = await response Content ReadFromJsonAsync<OrderCreated>();\n    // Assert - Query database directly\n    using var connection = new NpgsqlConnection(\"Host=localhost;Database=orders_test; \");\n    await connection OpenAsync();\n    // Check order exists\n    var order = await connection QuerySingleOrDefaultAsync<OrderRow>(\n      \"SELECT * FROM orders WHERE order_id = @OrderId\",\n      new { OrderId = result OrderId }\n    );\n    await Assert That(order) IsNotNull();\n    // Check outbox entry exists\n    var outboxMessage = await connection QuerySingleOrDefaultAsync<OutboxRow>(\n      \"SELECT * FROM outbox WHERE message_type = @MessageType\",\n      new { MessageType = typeof(OrderCreated) FullName }\n    );\n    await Assert That(outboxMessage) IsNotNull();\n  }\n  private async Task CleanDatabaseAsync() {\n    using var connection = new NpgsqlConnection(\"Host=localhost;Database=orders_test; \");\n    await connection OpenAsync();\n    await connection",
        "startIndex": 7888,
        "preview": "class CreateOrderIntegrationTests : IAsyncDisposable { private WebApplicationFactory<Program> _factory; private HttpClient _client; [Before(Test)] pub..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-4",
        "text": "IsNotNull(); // Check outbox entry exists var outboxMessage = await connection QuerySingleOrDefaultAsync<OutboxRow>( \"SELECT * FROM outbox WHERE message_type = @MessageType\", new { MessageType = typeof(OrderCreated) FullName } ); await Assert That(outboxMessage) IsNotNull(); } private async Task CleanDatabaseAsync() { using var connection = new NpgsqlConnection(\"Host=localhost;Database=orders_test; \"); await connection OpenAsync(); await connection ExecuteAsync(\"TRUNCATE TABLE orders, order_items, outbox CASCADE\");\n  }\n  public async ValueTask DisposeAsync() {\n    await _client DisposeAsync();\n    await _factory DisposeAsync();\n  }\n}\n`\nTesting Event Flow\nECommerce IntegrationTests/OrderToPaymentFlowTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing Whizbang Testing;\nnamespace ECommerce IntegrationTests;\n[TestFixture]\npublic class OrderToPaymentFlowTests {\n  private TestHarness _harness;\n  [Before(Test)]\n  public async Task SetupAsync() {\n    _harness = new TestHarness() AddService<OrderService>() AddService<InventoryWorker>() AddService<PaymentWorker>() UseInMemoryServiceBus();\n    await _harness StartAsync();\n  }\n  [After(Test)]\n  public async Task TeardownAsync() {\n    await _harness StopAsync();\n  }\n  [Test]\n  public async Task CreateOrder_WithSufficientInventory_ProcessesPaymentAsync() {\n    // Arrange\n    var command = new CreateOrder( );\n    // Act\n    var orderCreatedEvent = await _harness SendCommandAsync<CreateOrder, OrderCreated>(command);\n    // Wait for event propagation\n    await _harness WaitForEventAsync<InventoryReserved>(\n      e => e OrderId == orderCreatedEvent OrderId,\n      timeout: TimeSpan FromSeconds(10)\n    );\n    await _harness WaitForEventAsync<PaymentProcessed>(\n      e => e OrderId == orderCreatedEvent OrderId,\n      timeout: TimeSpan FromSeconds(10)\n    );\n    // Assert\n    var events = _harness GetPublishedEvents();\n    await Assert That(events) HasCount() EqualTo(3);  // OrderCreated, InventoryReserved, PaymentProcessed\n    var paymentEvent = events OfType<PaymentProcessed>() Single();\n    await Assert That(paymentEvent Status) IsEqualTo(PaymentStatus Captured);\n  }\n}\n`\n---\nEnd-to-End Tests\nECommerce E2ETests/FullOrderLifecycleTests cs:\n`csharp\nusing TUnit Core;\nusing TUnit Assertions;\nusing Testcontainers PostgreSql;\nusing Testcontainers AzuriteServiceBus;\nnamespace ECommerce E2ETests;\n[TestFixture]\npublic class FullOrderLifecycleTests : IAsyncDisposable {\n  private PostgreSqlContainer _postgresContainer;\n  private AzuriteServiceBusContainer _serviceBusContainer;\n  private HttpClient _orderServiceClient;\n  private HttpClient _customerServiceClient;\n  [Before(Test)]\n  public async Task SetupAsync() {\n    // Start containers\n    _postgresContainer = new PostgreSqlBuilder() WithImage(\"postgres:16\") Build();\n    _serviceBusContainer = new AzuriteServiceBusBuilder() WithImage(\"mcr microsoft com/azure-messaging/servicebus-emulator\") Build();\n    await _postgresContainer StartAsync();\n    await _serviceBusContainer StartAsync();\n    // Start services with container connection strings\n    _orderServiceClient = await StartServiceAsync<OrderService>(\n      connectionString: _postgresContainer GetConnectionString(),\n      serviceBusConnectionString: _serviceBusContainer",
        "startIndex": 10119,
        "preview": "IsNotNull(); // Check outbox entry exists var outboxMessage = await connection QuerySingleOrDefaultAsync<OutboxRow>( \"SELECT * FROM outbox WHERE messa..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-5",
        "text": "HttpClient _orderServiceClient; private HttpClient _customerServiceClient; [Before(Test)] public async Task SetupAsync() { // Start containers _postgresContainer = new PostgreSqlBuilder() WithImage(\"postgres:16\") Build(); _serviceBusContainer = new AzuriteServiceBusBuilder() WithImage(\"mcr microsoft com/azure-messaging/servicebus-emulator\") Build(); await _postgresContainer StartAsync(); await _serviceBusContainer StartAsync(); // Start services with container connection strings _orderServiceClient = await StartServiceAsync<OrderService>( connectionString: _postgresContainer GetConnectionString(), serviceBusConnectionString: _serviceBusContainer GetConnectionString()\n    );\n    _customerServiceClient = await StartServiceAsync<CustomerService>(\n      connectionString: _postgresContainer GetConnectionString(),\n      serviceBusConnectionString: _serviceBusContainer GetConnectionString()\n    );\n    // Other services }\n  [Test]\n  public async Task CreateOrder_FullLifecycle_CompletesSuccessfullyAsync() {\n    // Arrange\n    var command = new {\n      customerId = \"cust-123\",\n      items = new[] {\n        new { productId = \"prod-456\", quantity = 2, unitPrice = 19 99 }\n      },\n      shippingAddress = new {\n        street = \"123 Main St\",\n        city = \"Springfield\",\n        state = \"IL\",\n        zipCode = \"62701\",\n        country = \"USA\"\n      }\n    };\n    // Act\n    var createResponse = await _orderServiceClient PostAsJsonAsync(\"/api/orders\", command);\n    var orderCreated = await createResponse Content ReadFromJsonAsync<OrderCreated>();\n    // Wait for processing (eventually consistent)\n    await Task Delay(TimeSpan FromSeconds(15));\n    // Query order summary from Customer Service (read model)\n    var orderSummary = await _customerServiceClient GetFromJsonAsync<OrderSummaryDto>(\n      $\"/api/orders/{orderCreated OrderId}\"\n    );\n    // Assert\n    await Assert That(orderSummary) IsNotNull();\n    await Assert That(orderSummary Status) IsEqualTo(\"Shipped\");\n    await Assert That(orderSummary PaymentInfo) IsNotNull();\n    await Assert That(orderSummary PaymentInfo Status) IsEqualTo(\"Captured\");\n    await Assert That(orderSummary ShipmentInfo) IsNotNull();\n    await Assert That(orderSummary ShipmentInfo TrackingNumber) IsNotNull();\n  }\n  public async ValueTask DisposeAsync() {\n    await _postgresContainer StopAsync();\n    await _serviceBusContainer StopAsync();\n    await _postgresContainer DisposeAsync();\n    await _serviceBusContainer DisposeAsync();\n  }\n}\n`\n---\nTest Fixtures\nECommerce Testing/Fixtures/OrderFixture cs:\n`csharp\nusing Bogus;\nusing ECommerce Contracts Commands;\nusing ECommerce Contracts Events;\nnamespace ECommerce Testing Fixtures;\npublic static class OrderFixture {\n  private static readonly Faker<CreateOrder> CreateOrderFaker = new Faker<CreateOrder>() CustomInstantiator(f => new CreateOrder(\n      CustomerId: f Random AlphaNumeric(10),\n      Items: Enumerable Range(0, f Random Int(1, 5)) Select(_ => new OrderItem(\n          ProductId: f Commerce Product(),\n          Quantity: f Random Int(1, 10),\n          UnitPrice: f Finance Amount(5, 100)\n        )) ToArray(),\n      ShippingAddress: new Address(\n        Street: f Address StreetAddress(),\n        City: f",
        "startIndex": 12990,
        "preview": "HttpClient _orderServiceClient; private HttpClient _customerServiceClient; [Before(Test)] public async Task SetupAsync() { // Start containers _postgr..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-6",
        "text": "readonly Faker<CreateOrder> CreateOrderFaker = new Faker<CreateOrder>() CustomInstantiator(f => new CreateOrder( CustomerId: f Random AlphaNumeric(10), Items: Enumerable Range(0, f Random Int(1, 5)) Select(_ => new OrderItem( ProductId: f Commerce Product(), Quantity: f Random Int(1, 10), UnitPrice: f Finance Amount(5, 100) )) ToArray(), ShippingAddress: new Address( Street: f Address StreetAddress(), City: f Address City(),\n        State: f Address StateAbbr(),\n        ZipCode: f Address ZipCode(),\n        Country: \"USA\"\n      )\n    ));\n  public static CreateOrder GenerateCreateOrderCommand() {\n    return CreateOrderFaker Generate();\n  }\n  public static CreateOrder[] GenerateCreateOrderCommands(int count) {\n    return CreateOrderFaker Generate(count) ToArray();\n  }\n}\n`\nUsage:\n`csharp\n[Test]\npublic async Task SomeTest_WithRandomData_WorksCorrectlyAsync() {\n  // Arrange\n  var command = OrderFixture GenerateCreateOrderCommand();\n  // Act\n  var result = await receptor HandleAsync(command);\n  // Assert\n  await Assert That(result) IsNotNull();\n}\n`\n---\nMocking External Services\nECommerce Testing/Mocks/MockPaymentGateway cs:\n`csharp\nusing ECommerce PaymentWorker Services;\nnamespace ECommerce Testing Mocks;\npublic class MockPaymentGateway : IPaymentGateway {\n  private readonly List<PaymentResult> _results = [];\n  public void SetupSuccessfulCharge(string transactionId) {\n    _results Add(new PaymentResult(\n      Success: true,\n      TransactionId: transactionId,\n      ErrorCode: null,\n      ErrorMessage: null\n    ));\n  }\n  public void SetupFailedCharge(string errorCode, string errorMessage) {\n    _results Add(new PaymentResult(\n      Success: false,\n      TransactionId: null,\n      ErrorCode: errorCode,\n      ErrorMessage: errorMessage\n    ));\n  }\n  public Task<PaymentResult> ChargeAsync(\n    string idempotencyKey,\n    decimal amount,\n    string currency,\n    string paymentMethod,\n    CancellationToken ct = default\n  ) {\n    if (_results Count == 0) {\n      throw new InvalidOperationException(\"No payment results configured\");\n    }\n    var result = _results[0];\n    _results RemoveAt(0);\n    return Task FromResult(result);\n  }\n  public Task<RefundResult> RefundAsync(\n    string transactionId,\n    decimal amount,\n    CancellationToken ct = default\n  ) {\n    return Task FromResult(new RefundResult(\n      Success: true,\n      RefundId: Guid NewGuid() ToString(\"N\"),\n      ErrorMessage: null\n    ));\n  }\n}\n`\n---\nTest Coverage\nRunning Tests with Coverage\n`bash\ncd ECommerce OrderService Tests\ndotnet run -- --coverage --coverage-output-format cobertura --coverage-output coverage",
        "startIndex": 2396,
        "preview": "readonly Faker<CreateOrder> CreateOrderFaker = new Faker<CreateOrder>() CustomInstantiator(f => new CreateOrder( CustomerId: f Random AlphaNumeric(10)..."
      },
      {
        "id": "v0.1.0/tutorial/testing-strategy-chunk-7",
        "text": "} public Task<RefundResult> RefundAsync( string transactionId, decimal amount, CancellationToken ct = default ) { return Task FromResult(new RefundResult( Success: true, RefundId: Guid NewGuid() ToString(\"N\"), ErrorMessage: null )); } } ` --- Test Coverage Running Tests with Coverage `bash cd ECommerce OrderService Tests dotnet run -- --coverage --coverage-output-format cobertura --coverage-output coverage xml\n`\nCoverage Targets\n| Component | Target | Rationale |\n|-----------|--------|-----------|\n| Receptors | 90%+ | Core business logic |\n| Perspectives | 80%+ | Event handling logic |\n| Controllers | 70%+ | HTTP API endpoints |\n| Services | 80%+ | Infrastructure code |\n---\nKey Takeaways\n‚úÖ Testing Pyramid - 60% unit, 30% integration, 10% e2e\n‚úÖ Test Fixtures - Bogus for test data generation\n‚úÖ Mock External Services - Isolate unit tests from dependencies\n‚úÖ Integration Tests - Test with real database and message bus\n‚úÖ E2E Tests - Testcontainers for full environment simulation\n‚úÖ Test Coverage - 80%+ for core business logic\n---\nNext Steps\nContinue to Deployment to:\nDeploy to Azure Kubernetes Service (AKS)\nConfigure CI/CD pipelines\nSet up monitoring and alerting\nImplement blue-green deployments\n---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 17784,
        "preview": "} public Task<RefundResult> RefundAsync( string transactionId, decimal amount, CancellationToken ct = default ) { return Task FromResult(new RefundRes..."
      }
    ]
  },
  {
    "type": "document",
    "slug": "v0.1.0/tutorial/tutorial-overview",
    "title": "ECommerce Tutorial Overview",
    "category": "Tutorial",
    "url": "/docs/v0.1.0/tutorial/tutorial-overview",
    "chunks": [
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-0",
        "text": "ECommerce Tutorial Overview\nBuild a complete e-commerce system using Whizbang to learn all framework features through a realistic, production-ready example",
        "startIndex": 0,
        "preview": "ECommerce Tutorial Overview\nBuild a complete e-commerce system using Whizbang to learn all framework features through a realistic, production-ready ex..."
      },
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-1",
        "text": "ECommerce Tutorial Overview Build a complete e-commerce system using Whizbang to learn all framework features through a realistic, production-ready example What You'll Build\nA distributed e-commerce platform with 7 microservices:\n`\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  ECommerce Platform Architecture                            ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n‚îÇ  ‚îÇ   Order      ‚îÇ  ‚îÇ  Inventory   ‚îÇ  ‚îÇ   Payment    ‚îÇ     ‚îÇ\n‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ     ‚îÇ\n‚îÇ  ‚îÇ  (Commands)  ‚îÇ  ‚îÇ  (Commands)  ‚îÇ  ‚îÇ  (Commands)  ‚îÇ     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ             ‚îÇ\n‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ\n‚îÇ                            ‚îÇ                                ‚îÇ\n‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ\n‚îÇ                  ‚îÇ  Azure Service    ‚îÇ                      ‚îÇ\n‚îÇ                  ‚îÇ      Bus          ‚îÇ                      ‚îÇ\n‚îÇ                  ‚îÇ   (Event Hub)     ‚îÇ                      ‚îÇ\n‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ\n‚îÇ                            ‚îÇ                                ‚îÇ\n‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ\n‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ             ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n‚îÇ  ‚îÇNotification  ‚îÇ  ‚îÇ   Shipping   ‚îÇ  ‚îÇ  Analytics   ‚îÇ     ‚îÇ\n‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ     ‚îÇ\n‚îÇ  ‚îÇ  (Events)    ‚îÇ  ‚îÇ  (Events)    ‚îÇ  ‚îÇ(Perspectives)‚îÇ     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n`\nServices\n| Service | Type | Purpose |\n|---------|------|---------|\n| Order Service | Command API | Order management, CRUD operations |\n| Inventory Service | Command Worker | Stock tracking, reservations |\n| Payment Service | Command Worker | Payment processing, transactions |\n| Notification Service | Event Worker | Email/SMS notifications |\n| Shipping Service | Event Worker | Shipment creation, tracking |\n| Customer Service | Query API | Customer read models (BFF) |\n| Analytics Service | Event Worker | Real-time analytics, reporting |\nWhat You'll Learn\nCore Features\n‚úÖ Commands & Events - Request/response + pub/sub patterns\n‚úÖ Receptors - Message handlers with business logic\n‚úÖ Perspectives - Event-driven read models (CQRS)\n‚úÖ Dispatcher - Zero-reflection message routing\n‚úÖ Message Context - Correlation, causation, tracing\nMessaging Patterns\n‚úÖ Outbox Pattern - Reliable cross-service events\n‚úÖ Inbox Pattern - Exactly-once message processing\n‚úÖ Work Coordination - Lease-based distributed processing\n‚úÖ Event Envelopes - Hop-based observability\nData Access\n‚úÖ Dapper + PostgreSQL - High-performance queries\n‚úÖ EF Core 10 - Full-featured ORM\n‚úÖ Event Store - Event sourcing with time-travel\n‚úÖ Perspectives Storage - Read model schemas\nInfrastructure\n‚úÖ",
        "startIndex": 157,
        "preview": "ECommerce Tutorial Overview Build a complete e-commerce system using Whizbang to learn all framework features through a realistic, production-ready ex..."
      },
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-2",
        "text": "- Exactly-once message processing ‚úÖ Work Coordination - Lease-based distributed processing ‚úÖ Event Envelopes - Hop-based observability Data Access ‚úÖ Dapper + PostgreSQL - High-performance queries ‚úÖ EF Core 10 - Full-featured ORM ‚úÖ Event Store - Event sourcing with time-travel ‚úÖ Perspectives Storage - Read model schemas Infrastructure ‚úÖ NET Aspire - Local orchestration with emulators\n‚úÖ Azure Service Bus - Production messaging\n‚úÖ Health Checks - Kubernetes readiness/liveness\n‚úÖ Policy-Based Routing - Multi-tenant, environment-aware\nAdvanced Topics\n‚úÖ Source Generators - Zero-reflection discovery\n‚úÖ AOT Compatibility - Native AOT deployment\n‚úÖ Testing - Unit, integration, e2e tests\n‚úÖ Deployment - Docker, Kubernetes, Azure\nPrerequisites NET 10 0 RC2+ SDK\nDocker Desktop (for PostgreSQL, Azurite, Service Bus emulator)\nVisual Studio 2024 or VS Code with CDevKit\nAzure CLI (for production deployment)\nBasic Cknowledge (records, async/await, dependency injection)\nTutorial Structure\nPart 1: Foundation (Order & Inventory)\nTutorial Overview ‚Üê You are here\nOrder Management - Create orders, command handling\nInventory Service - Stock reservations, event publishing\nPart 2: Distributed Processing (Payment & Notifications)\nPayment Processing - Payment gateway integration\nNotification Service - Email/SMS via events\nPart 3: Logistics & Analytics (Shipping & Reporting)\nShipping Service - Shipment creation, tracking\nAnalytics Service - Real-time dashboards\nPart 4: Customer Experience (Read Models)\nCustomer Service - BFF pattern, perspectives\nPart 5: Production Readiness\nTesting Strategy - Unit, integration, e2e tests\nDeployment - Docker, Kubernetes, Azure\nProject Setup\nCreate Solution\n`bash\nmkdir ECommerce\ncd ECommerce\ndotnet new sln -n ECommerce\n`\nAdd Projects\n`bash\nOrder Service (HTTP API)\ndotnet new webapi -n ECommerce OrderService API\ndotnet sln add ECommerce OrderService API\nInventory Service (Background Worker)\ndotnet new worker -n ECommerce InventoryWorker\ndotnet sln add ECommerce InventoryWorker\nPayment Service (Background Worker)\ndotnet new worker -n ECommerce PaymentWorker\ndotnet sln add ECommerce",
        "startIndex": 3069,
        "preview": "- Exactly-once message processing ‚úÖ Work Coordination - Lease-based distributed processing ‚úÖ Event Envelopes - Hop-based observability Data Access ‚úÖ D..."
      },
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-3",
        "text": "` Add Projects `bash Order Service (HTTP API) dotnet new webapi -n ECommerce OrderService API dotnet sln add ECommerce OrderService API Inventory Service (Background Worker) dotnet new worker -n ECommerce InventoryWorker dotnet sln add ECommerce InventoryWorker Payment Service (Background Worker) dotnet new worker -n ECommerce PaymentWorker dotnet sln add ECommerce PaymentWorker\nNotification Service (Background Worker)\ndotnet new worker -n ECommerce NotificationWorker\ndotnet sln add ECommerce NotificationWorker\nShipping Service (Background Worker)\ndotnet new worker -n ECommerce ShippingWorker\ndotnet sln add ECommerce ShippingWorker\nCustomer Service (HTTP API - BFF)\ndotnet new webapi -n ECommerce CustomerService API\ndotnet sln add ECommerce CustomerService API\nAnalytics Service (Background Worker)\ndotnet new worker -n ECommerce AnalyticsWorker\ndotnet sln add ECommerce AnalyticsWorker\nShared Contracts\ndotnet new classlib -n ECommerce Contracts\ndotnet sln add ECommerce Contracts\nAspire App Host (Orchestration)\ndotnet new aspire-apphost -n ECommerce AppHost\ndotnet sln add ECommerce AppHost\n`\nAdd Whizbang Packages\n`bash\nAll projects\ndotnet add ECommerce OrderService API package Whizbang Core\ndotnet add ECommerce InventoryWorker package Whizbang Core\ndotnet add ECommerce PaymentWorker package Whizbang Core\ndotnet add ECommerce NotificationWorker package Whizbang Core\ndotnet add ECommerce ShippingWorker package Whizbang Core\ndotnet add ECommerce CustomerService API package Whizbang Core\ndotnet add ECommerce AnalyticsWorker package Whizbang Core\nProjects with Azure Service Bus\ndotnet add ECommerce OrderService API package Whizbang Transports AzureServiceBus\ndotnet add ECommerce InventoryWorker package Whizbang Transports AzureServiceBus\ndotnet add ECommerce PaymentWorker package Whizbang Transports AzureServiceBus\ndotnet add ECommerce NotificationWorker package Whizbang Transports AzureServiceBus\ndotnet add ECommerce ShippingWorker package Whizbang Transports AzureServiceBus\ndotnet add ECommerce AnalyticsWorker package Whizbang Transports AzureServiceBus\nProjects with PostgreSQL\ndotnet add ECommerce OrderService API package Whizbang Data Postgres\ndotnet add ECommerce InventoryWorker package Whizbang Data Postgres\ndotnet add ECommerce CustomerService API package Whizbang Data Postgres\ndotnet add ECommerce AnalyticsWorker package Whizbang Data Postgres\nAspire integration\ndotnet add ECommerce OrderService",
        "startIndex": 4848,
        "preview": "` Add Projects `bash Order Service (HTTP API) dotnet new webapi -n ECommerce OrderService API dotnet sln add ECommerce OrderService API Inventory Serv..."
      },
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-4",
        "text": "add ECommerce AnalyticsWorker package Whizbang Transports AzureServiceBus Projects with PostgreSQL dotnet add ECommerce OrderService API package Whizbang Data Postgres dotnet add ECommerce InventoryWorker package Whizbang Data Postgres dotnet add ECommerce CustomerService API package Whizbang Data Postgres dotnet add ECommerce AnalyticsWorker package Whizbang Data Postgres Aspire integration dotnet add ECommerce OrderService API package Whizbang Hosting Azure ServiceBus\ndotnet add ECommerce AppHost package Aspire Hosting Azure ServiceBus\n`\nProject Structure\n`\nECommerce/\n‚îú‚îÄ‚îÄ ECommerce sln\n‚îú‚îÄ‚îÄ ECommerce AppHost/ NET Aspire orchestration\n‚îú‚îÄ‚îÄ ECommerce Contracts/           Shared messages\n‚îÇ   ‚îú‚îÄ‚îÄ Commands/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrder cs\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReserveInventory cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProcessPayment cs\n‚îÇ   ‚îî‚îÄ‚îÄ Events/\n‚îÇ       ‚îú‚îÄ‚îÄ OrderCreated cs\n‚îÇ       ‚îú‚îÄ‚îÄ InventoryReserved cs\n‚îÇ       ‚îî‚îÄ‚îÄ PaymentProcessed cs\n‚îú‚îÄ‚îÄ ECommerce OrderService API/    Order management\n‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CreateOrderReceptor cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CancelOrderReceptor cs\n‚îÇ   ‚îî‚îÄ‚îÄ Controllers/\n‚îÇ       ‚îî‚îÄ‚îÄ OrdersController cs\n‚îú‚îÄ‚îÄ ECommerce InventoryWorker/     Inventory management\n‚îÇ   ‚îú‚îÄ‚îÄ Receptors/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ReserveInventoryReceptor cs\n‚îÇ   ‚îî‚îÄ‚îÄ Perspectives/\n‚îÇ       ‚îî‚îÄ‚îÄ InventorySummaryPerspective cs\n‚îú‚îÄ‚îÄ ECommerce PaymentWorker/       Payment processing\n‚îÇ   ‚îî‚îÄ‚îÄ Receptors/\n‚îÇ       ‚îî‚îÄ‚îÄ ProcessPaymentReceptor cs\n‚îú‚îÄ‚îÄ ECommerce NotificationWorker/  Notifications\n‚îÇ   ‚îî‚îÄ‚îÄ Receptors/\n‚îÇ       ‚îî‚îÄ‚îÄ SendNotificationReceptor cs\n‚îú‚îÄ‚îÄ ECommerce ShippingWorker/      Shipping\n‚îÇ   ‚îî‚îÄ‚îÄ Receptors/\n‚îÇ       ‚îî‚îÄ‚îÄ CreateShipmentReceptor cs\n‚îú‚îÄ‚îÄ ECommerce CustomerService API/ Customer BFF\n‚îÇ   ‚îú‚îÄ‚îÄ Perspectives/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OrderSummaryPerspective cs\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CustomerActivityPerspective cs\n‚îÇ   ‚îî‚îÄ‚îÄ Controllers/\n‚îÇ       ‚îî‚îÄ‚îÄ CustomersController cs\n‚îî‚îÄ‚îÄ ECommerce AnalyticsWorker/     Analytics\n    ‚îî‚îÄ‚îÄ Perspectives/\n        ‚îî‚îÄ‚îÄ DailySalesAnalyticsPerspective",
        "startIndex": 5660,
        "preview": "add ECommerce AnalyticsWorker package Whizbang Transports AzureServiceBus Projects with PostgreSQL dotnet add ECommerce OrderService API package Whizb..."
      },
      {
        "id": "v0.1.0/tutorial/tutorial-overview-chunk-5",
        "text": "Receptors/ ‚îÇ ‚îî‚îÄ‚îÄ SendNotificationReceptor cs ‚îú‚îÄ‚îÄ ECommerce ShippingWorker/ Shipping ‚îÇ ‚îî‚îÄ‚îÄ Receptors/ ‚îÇ ‚îî‚îÄ‚îÄ CreateShipmentReceptor cs ‚îú‚îÄ‚îÄ ECommerce CustomerService API/ Customer BFF ‚îÇ ‚îú‚îÄ‚îÄ Perspectives/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ OrderSummaryPerspective cs ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ CustomerActivityPerspective cs ‚îÇ ‚îî‚îÄ‚îÄ Controllers/ ‚îÇ ‚îî‚îÄ‚îÄ CustomersController cs ‚îî‚îÄ‚îÄ ECommerce AnalyticsWorker/ Analytics ‚îî‚îÄ‚îÄ Perspectives/ ‚îî‚îÄ‚îÄ DailySalesAnalyticsPerspective cs\n`\nKey Concepts Demonstrated\nEvent-Driven Architecture\n`csharp\n// Command: Create Order (synchronous)\nCreateOrder command ‚Üí CreateOrderReceptor ‚Üí OrderCreated event\n// Event: Order Created (asynchronous pub/sub)\nOrderCreated event ‚Üí Published to Azure Service Bus\n  ‚îú‚îÄ InventoryWorker ‚Üí ReserveInventory\n  ‚îú‚îÄ NotificationWorker ‚Üí SendOrderConfirmation\n  ‚îî‚îÄ AnalyticsWorker ‚Üí UpdateDailySales (perspective)\n`\nCQRS (Command Query Responsibility Segregation)\nWrite Side:\nOrder Service receives CreateOrder command\nCreateOrderReceptor handles command\nPublishes OrderCreated event to event bus\nRead Side:\nCustomer Service subscribes to OrderCreated events\nOrderSummaryPerspective updates read model\nCustomersController queries read model (fast )\nSaga Pattern (Distributed Transactions)\n`\nCreateOrder ‚Üí OrderCreated\nOrderCreated ‚Üí ReserveInventory ‚Üí InventoryReserved\nInventoryReserved ‚Üí ProcessPayment ‚Üí PaymentProcessed\nPaymentProcessed ‚Üí CreateShipment ‚Üí ShipmentCreated\nShipmentCreated ‚Üí SendShippingNotification ‚Üí NotificationSent\nCompensation (if payment fails):\nPaymentFailed ‚Üí ReleaseInventory ‚Üí InventoryReleased\n`\nDevelopment Workflow\nRun Locally (Aspire)\n`bash\ncd ECommerce AppHost\ndotnet run\n`\nOpen Aspire Dashboard: http://localhost:15000\nCreate Order via API\n`bash\ncurl -X POST http://localhost:5000/orders \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"customerId\": \"cust-123\",\n    \"items\": [\n      { \"productId\": \"prod-456\", \"quantity\": 2, \"unitPrice\": 19 99 }\n    ]\n  }'\n`\nObserve Event Flow\nCheck Aspire Dashboard:\nOrder Service: HTTP request logged\nService Bus: OrderCreated event published\nInventory Worker: InventoryReserved event published\nPayment Worker: PaymentProcessed event published\nNotification Worker: Email sent\nQuery Read Model\n`bash\ncurl http://localhost:5001/customers/cust-123/orders\n`\nReturns denormalized order summary from read model (fast ) Next Steps\nContinue to Order Management to start building the Order Service ---\nVersion 0 1 0 - Foundation Release | Last Updated: 2024-12-12",
        "startIndex": 8424,
        "preview": "Receptors/ ‚îÇ ‚îî‚îÄ‚îÄ SendNotificationReceptor cs ‚îú‚îÄ‚îÄ ECommerce ShippingWorker/ Shipping ‚îÇ ‚îî‚îÄ‚îÄ Receptors/ ‚îÇ ‚îî‚îÄ‚îÄ CreateShipmentReceptor cs ‚îú‚îÄ‚îÄ ECommerce Cus..."
      }
    ]
  }
]