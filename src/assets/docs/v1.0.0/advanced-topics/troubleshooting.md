---
title: Troubleshooting Guide
version: 1.0.0
category: Advanced Topics
order: 9
description: 'Common issues, debugging techniques, diagnostic tools, and solutions'
tags: 'troubleshooting, debugging, diagnostics, common-issues, solutions'
---

# Troubleshooting Guide

Comprehensive **troubleshooting guide** for Whizbang applications - common issues, debugging techniques, diagnostic tools, and step-by-step solutions.

---

## Common Issues

| Issue | Symptom | Root Cause | Solution |
|-------|---------|------------|----------|
| **No Handler Found** | `InvalidOperationException` | Missing receptor registration | Check DI registration |
| **Message Not Published** | Events not reaching subscribers | Outbox stuck | Check outbox worker |
| **Duplicate Processing** | Message handled twice | Inbox not working | Check inbox deduplication |
| **High Latency** | Slow responses | Database query | Add indexes |
| **Memory Leak** | Memory grows indefinitely | Unclosed connections | Use `await using` |

---

## Issue 1: No Handler Found

### Symptom

```
System.InvalidOperationException: No handler registered for CreateOrder
```

### Diagnosis

```csharp
// Check DI container
var dispatcher = serviceProvider.GetService<IDispatcher>();
var receptor = serviceProvider.GetService<IReceptor<CreateOrder, OrderCreated>>();

if (receptor is null) {
  Console.WriteLine("ERROR: Receptor not registered!");
}
```

### Solution 1: Missing DI Registration

**Problem**:

```csharp
// ❌ Receptor not registered
builder.Services.AddSingleton<IDispatcher, GeneratedDispatcher>();
```

**Fix**:

```csharp
// ✅ Register receptor
builder.Services.AddSingleton<IDispatcher, GeneratedDispatcher>();
builder.Services.AddSingleton<IReceptor<CreateOrder, OrderCreated>, CreateOrderReceptor>();
```

### Solution 2: Use Source-Generated Registration

**Whizbang ReceptorDiscoveryGenerator** automatically generates DI registrations:

```csharp
// Generated by Whizbang.Generators.ReceptorDiscoveryGenerator
builder.Services.AddGeneratedReceptors();  // Registers all receptors
```

---

## Issue 2: Message Not Published

### Symptom

Events not reaching subscribers (no errors in logs).

### Diagnosis

```sql
-- Check outbox backlog
SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL;

-- If count > 0, outbox worker is stuck
```

### Solution 1: Outbox Worker Not Running

**Problem**: Outbox worker background service not registered.

**Fix**:

```csharp
builder.Services.AddHostedService<OutboxWorker>();
```

### Solution 2: Database Transaction Not Committed

**Problem**:

```csharp
// ❌ Transaction never committed
await using var tx = await _db.BeginTransactionAsync(ct);

await _db.ExecuteAsync("INSERT INTO orders (...)", transaction: tx);
await _db.ExecuteAsync("INSERT INTO outbox (...)", transaction: tx);

// Missing: await tx.CommitAsync(ct);
```

**Fix**:

```csharp
// ✅ Always commit transaction
await using var tx = await _db.BeginTransactionAsync(ct);

try {
  await _db.ExecuteAsync("INSERT INTO orders (...)", transaction: tx);
  await _db.ExecuteAsync("INSERT INTO outbox (...)", transaction: tx);

  await tx.CommitAsync(ct);  // ✅ Commit
} catch {
  await tx.RollbackAsync(ct);
  throw;
}
```

### Solution 3: Service Bus Connection String Wrong

**Problem**: Wrong connection string or permissions.

**Diagnosis**:

```bash
# Test Service Bus connection
curl -X POST https://myservicebus.servicebus.windows.net/orders/messages \
  -H "Authorization: SharedAccessSignature ..." \
  -d '{"test": true}'
```

**Fix**:

```json
{
  "AzureServiceBus": {
    "ConnectionString": "Endpoint=sb://myservicebus.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=***"
  }
}
```

---

## Issue 3: Duplicate Processing

### Symptom

Message handled twice (duplicate database inserts).

### Diagnosis

```sql
-- Check inbox for duplicate messages
SELECT message_id, COUNT(*) AS count
FROM inbox
GROUP BY message_id
HAVING COUNT(*) > 1;
```

### Solution 1: Inbox Not Implemented

**Problem**: No inbox deduplication.

**Fix**: Implement inbox pattern:

```csharp
public async Task HandleAsync(OrderCreated @event, CancellationToken ct) {
  await using var tx = await _db.BeginTransactionAsync(ct);

  try {
    // 1. Check inbox (deduplication)
    var exists = await _db.ExecuteScalarAsync<bool>(
      "SELECT EXISTS(SELECT 1 FROM inbox WHERE message_id = @MessageId)",
      new { MessageId = @event.MessageId },
      transaction: tx
    );

    if (exists) {
      _logger.LogWarning("Message {MessageId} already processed (duplicate)", @event.MessageId);
      await tx.CommitAsync(ct);
      return;  // ✅ Skip duplicate
    }

    // 2. Process message
    await _db.ExecuteAsync("UPDATE order_summary SET ...", transaction: tx);

    // 3. Record in inbox
    await _db.ExecuteAsync(
      "INSERT INTO inbox (message_id, processed_at) VALUES (@MessageId, NOW())",
      new { MessageId = @event.MessageId },
      transaction: tx
    );

    await tx.CommitAsync(ct);
  } catch {
    await tx.RollbackAsync(ct);
    throw;
  }
}
```

### Solution 2: Service Bus PeekLock Not Used

**Problem**: Using `ReceiveAndDelete` mode (at-most-once delivery).

**Fix**: Use `PeekLock` mode (at-least-once delivery):

```csharp
var processor = client.CreateProcessor("orders", new ServiceBusProcessorOptions {
  ReceiveMode = ServiceBusReceiveMode.PeekLock,  // ✅ Use PeekLock
  MaxConcurrentCalls = 10
});
```

---

## Issue 4: High Latency

### Symptom

API responses taking > 1 second.

### Diagnosis

**Application Insights query**:

```kusto
requests
| where timestamp > ago(1h)
| summarize p95 = percentile(duration, 95) by name
| where p95 > 1000  // > 1 second
| order by p95 desc
```

**PostgreSQL slow query log**:

```sql
-- Enable slow query log
ALTER DATABASE orders SET log_min_duration_statement = 1000;  -- Log queries > 1s

-- View slow queries
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
WHERE mean_exec_time > 1000
ORDER BY mean_exec_time DESC
LIMIT 10;
```

### Solution 1: Missing Index

**Problem**: Full table scan on large table.

**Diagnosis**:

```sql
EXPLAIN ANALYZE
SELECT * FROM orders WHERE customer_id = 'cust-123';

-- Output:
-- Seq Scan on orders (cost=0.00..100000.00 rows=1 width=100)
-- Planning Time: 0.5 ms
-- Execution Time: 1234.5 ms
```

**Fix**: Add index:

```sql
CREATE INDEX idx_orders_customer_id ON orders(customer_id);

-- After index:
-- Index Scan using idx_orders_customer_id (cost=0.29..8.31 rows=1 width=100)
-- Planning Time: 0.5 ms
-- Execution Time: 1.2 ms
```

### Solution 2: N+1 Query Problem

**Problem**:

```csharp
// ❌ N+1 queries (1 for orders, N for items)
var orders = await _db.QueryAsync<OrderRow>("SELECT * FROM orders WHERE customer_id = @CustomerId");

foreach (var order in orders) {
  order.Items = await _db.QueryAsync<OrderItemRow>(
    "SELECT * FROM order_items WHERE order_id = @OrderId",
    new { OrderId = order.OrderId }
  );
}
```

**Fix**: Use JOIN or batch query:

```csharp
// ✅ Single query with JOIN
var orders = await _db.QueryAsync<OrderRow, OrderItemRow, OrderRow>(
  """
  SELECT o.*, i.*
  FROM orders o
  LEFT JOIN order_items i ON o.order_id = i.order_id
  WHERE o.customer_id = @CustomerId
  """,
  (order, item) => {
    order.Items.Add(item);
    return order;
  },
  new { CustomerId = customerId }
);
```

---

## Issue 5: Memory Leak

### Symptom

Memory usage grows indefinitely, eventually causing OOM.

### Diagnosis

**dotnet-counters**:

```bash
dotnet-counters monitor --process-id 1234 System.Runtime

# Output:
# [System.Runtime]
#   GC Heap Size (MB)                      500 -> 1000 -> 1500 -> 2000 (growing)
#   Gen 0 GC Count                         1000
#   Gen 1 GC Count                         100
#   Gen 2 GC Count                         10
```

**dotnet-gcdump**:

```bash
dotnet-gcdump collect --process-id 1234
dotnet-gcdump report gcdump_20250101_123456
```

### Solution 1: Unclosed Connections

**Problem**:

```csharp
// ❌ Connection not disposed
var connection = new NpgsqlConnection(connectionString);
await connection.OpenAsync();

// Process data...

// Missing: await connection.DisposeAsync();
```

**Fix**:

```csharp
// ✅ Use await using
await using var connection = new NpgsqlConnection(connectionString);
await connection.OpenAsync();

// Process data...

// Automatically disposed
```

### Solution 2: Event Handler Not Unsubscribed

**Problem**:

```csharp
// ❌ Event handler keeps object alive
public class OrderProcessor {
  public OrderProcessor(IEventBus eventBus) {
    eventBus.OrderCreated += HandleOrderCreated;  // Never unsubscribed
  }

  private void HandleOrderCreated(OrderCreated @event) {
    // Process order...
  }
}
```

**Fix**:

```csharp
// ✅ Unsubscribe when disposed
public class OrderProcessor : IDisposable {
  private readonly IEventBus _eventBus;

  public OrderProcessor(IEventBus eventBus) {
    _eventBus = eventBus;
    _eventBus.OrderCreated += HandleOrderCreated;
  }

  public void Dispose() {
    _eventBus.OrderCreated -= HandleOrderCreated;  // ✅ Unsubscribe
  }
}
```

---

## Debugging Techniques

### 1. Enable Detailed Logging

**appsettings.Development.json**:

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Debug",
      "Microsoft": "Information",
      "Whizbang": "Trace"
    }
  }
}
```

### 2. Use Correlation IDs

```csharp
public class CorrelationIdMiddleware {
  private readonly RequestDelegate _next;

  public async Task InvokeAsync(HttpContext context) {
    var correlationId = context.Request.Headers["X-Correlation-ID"].FirstOrDefault()
      ?? Guid.NewGuid().ToString();

    context.Response.Headers.Add("X-Correlation-ID", correlationId);

    using (_logger.BeginScope(new Dictionary<string, object> {
      ["CorrelationId"] = correlationId
    })) {
      await _next(context);
    }
  }
}
```

**Application Insights query**:

```kusto
traces
| where customDimensions.CorrelationId == "abc-123"
| order by timestamp asc
```

### 3. SQL Query Logging

**Program.cs**:

```csharp
builder.Logging.AddFilter("Microsoft.EntityFrameworkCore.Database.Command", LogLevel.Information);
```

**Output**:

```
Executed DbCommand (123ms) [Parameters=[@CustomerId='cust-123'], CommandType='Text', CommandTimeout='30']
SELECT * FROM orders WHERE customer_id = @CustomerId
```

### 4. Distributed Tracing

**View trace in Application Insights**:

```kusto
dependencies
| where operation_Id == "abc-123"
| project timestamp, target, name, duration
| order by timestamp asc

// Output:
// timestamp                 target                    name                  duration
// 2025-01-01 12:00:00.000   postgres.myapp.com        SELECT * FROM orders  123ms
// 2025-01-01 12:00:00.150   servicebus.windows.net    Send message          45ms
```

---

## Diagnostic Tools

### 1. dotnet-counters (Live Metrics)

```bash
# Monitor live counters
dotnet-counters monitor --process-id 1234

# Output:
# [System.Runtime]
#   CPU Usage (%)                          45
#   GC Heap Size (MB)                      256
#   Gen 0 GC Count                         100
#   Gen 1 GC Count                         10
#   Gen 2 GC Count                         1
#   Exception Count                        5
#   ThreadPool Thread Count                25
```

### 2. dotnet-trace (Performance Profiling)

```bash
# Collect trace
dotnet-trace collect --process-id 1234 --profile cpu-sampling

# Convert to speedscope format
dotnet-trace convert trace.nettrace --format speedscope

# Open in speedscope.app
```

### 3. dotnet-dump (Memory Analysis)

```bash
# Capture memory dump
dotnet-dump collect --process-id 1234

# Analyze dump
dotnet-dump analyze dump_20250101_123456

# Commands:
# > dumpheap -stat        # Object statistics
# > gcroot <address>      # GC root analysis
# > dumpheap -mt <type>   # Objects of specific type
```

### 4. kubectl logs (Kubernetes)

```bash
# View logs
kubectl logs order-service-abc123

# Follow logs
kubectl logs -f order-service-abc123

# View logs from all pods
kubectl logs -l app=order-service --tail=100

# View logs from previous pod (after crash)
kubectl logs order-service-abc123 --previous
```

### 5. kubectl exec (Shell Access)

```bash
# Execute command in pod
kubectl exec order-service-abc123 -- ps aux

# Interactive shell
kubectl exec -it order-service-abc123 -- /bin/bash

# Test database connectivity
kubectl exec order-service-abc123 -- psql $DATABASE_URL -c "SELECT 1"
```

---

## Performance Profiling

### BenchmarkDotNet

**CreateOrderBenchmark.cs**:

```csharp
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

[MemoryDiagnoser]
[SimpleJob(warmupCount: 3, iterationCount: 10)]
public class CreateOrderBenchmark {
  [Benchmark]
  public async Task<OrderCreated> CreateOrder() {
    return await _receptor.HandleAsync(_command);
  }
}
```

**Run**:

```bash
dotnet run -c Release --project Benchmarks

# Output:
# | Method      | Mean     | Error   | StdDev | Allocated |
# |------------ |---------:|--------:|-------:|----------:|
# | CreateOrder | 125.3 μs | 2.34 μs | 2.19 μs |     512 B |
```

### PerfView (Windows)

```bash
# Collect CPU samples
PerfView.exe collect /MaxCollectSec:30 /Zip:true

# Analyze trace
PerfView.exe trace.etl
```

---

## Health Check Diagnostics

### Check Health Endpoint

```bash
curl https://order-service.myapp.com/health

# Output:
# {
#   "status": "Unhealthy",
#   "results": {
#     "database": { "status": "Healthy" },
#     "servicebus": { "status": "Unhealthy", "description": "Connection failed" }
#   }
# }
```

### Custom Health Check

```csharp
public class OutboxHealthCheck : IHealthCheck {
  public async Task<HealthCheckResult> CheckHealthAsync(
    HealthCheckContext context,
    CancellationToken ct = default
  ) {
    var backlog = await _db.ExecuteScalarAsync<int>(
      "SELECT COUNT(*) FROM outbox WHERE processed_at IS NULL"
    );

    if (backlog > 10000) {
      return HealthCheckResult.Degraded(
        $"Outbox backlog is {backlog} messages",
        data: new Dictionary<string, object> { ["backlog"] = backlog }
      );
    }

    return HealthCheckResult.Healthy();
  }
}
```

---

## Key Takeaways

✅ **No Handler Found** - Check DI registration or use source-generated `AddGeneratedReceptors()`
✅ **Message Not Published** - Check outbox worker, transaction commit, Service Bus connection
✅ **Duplicate Processing** - Implement inbox pattern for idempotency
✅ **High Latency** - Add database indexes, avoid N+1 queries
✅ **Memory Leak** - Use `await using` for connections, unsubscribe event handlers
✅ **Diagnostic Tools** - dotnet-counters, dotnet-trace, dotnet-dump, kubectl logs

---

## Troubleshooting Checklist

- [ ] Check logs in Application Insights or Kubernetes
- [ ] Verify DI registrations (receptors, perspectives, policies)
- [ ] Check database connectivity and connection string
- [ ] Verify Service Bus connection and permissions
- [ ] Check outbox/inbox tables for backlog
- [ ] Review slow query log in PostgreSQL
- [ ] Monitor metrics (CPU, memory, request rate, error rate)
- [ ] Use correlation IDs to trace requests across services
- [ ] Profile with dotnet-trace or BenchmarkDotNet
- [ ] Check health endpoints for service status

---

*Version 1.0.0 - Foundation Release | Last Updated: 2024-12-12*
